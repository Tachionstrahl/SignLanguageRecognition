{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Datasets by word total:\n",
      "Computer :  57;  Deutschland :  65;  Haben :  68;  Hallo :  57;  Mainz :  65;  Software :  67;  Welt :  66;  du :  66;  ich :  66;  unser :  64;  zeigen :  69;   \n",
      "\n",
      "Amount Datasets by word training:\n",
      "Computer :  30;  Deutschland :  41;  Haben :  43;  Hallo :  42;  Mainz :  43;  Software :  38;  Welt :  41;  du :  35;  ich :  44;  unser :  32;  zeigen :  37;   \n",
      "\n",
      "Amount Datasets by word validiation:\n",
      "Computer :  9;  Deutschland :  13;  Haben :  13;  Hallo :  9;  Mainz :  13;  Software :  18;  Welt :  13;  du :  13;  ich :  11;  unser :  17;  zeigen :  13;   \n",
      "\n",
      "Amount Datasets by word test:\n",
      "Computer :  18;  Deutschland :  11;  Haben :  12;  Hallo :  6;  Mainz :  9;  Software :  11;  Welt :  12;  du :  18;  ich :  11;  unser :  15;  zeigen :  19;   \n",
      "\n",
      "Distribution of data:\n",
      "Amount total: 710\n",
      "Amount training: 426\n",
      "Amount validiation: 142\n",
      "Amount test: 142\n",
      "\n",
      "Tokens:\n",
      "{'zeigen': 1, 'unser': 2, 'deutschland': 3, 'computer': 4, 'welt': 5, 'software': 6, 'du': 7, 'hallo': 8, 'ich': 9, 'mainz': 10, 'haben': 11}\n",
      "\n",
      "Categories in OneHot anotation:\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      "Dataset coordinate Values:\n",
      "[[[0.474263 0.264446 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.478196 0.264415 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.477982 0.257375 0.       ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]\n",
      "\n",
      " [[0.485154 0.226551 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.486115 0.230469 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.489345 0.230469 0.       ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]\n",
      "\n",
      " [[0.447755 0.432864 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.448488 0.430835 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.444384 0.428364 0.       ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.494767 0.2571   0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.500348 0.257359 0.348264 ... 0.5      0.5      0.5     ]\n",
      "  [0.503016 0.260641 0.337969 ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]\n",
      "\n",
      " [[0.477542 0.284109 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.475506 0.28457  0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.477343 0.283514 0.       ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]\n",
      "\n",
      " [[0.446496 0.301835 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.446419 0.302225 0.       ... 0.5      0.5      0.5     ]\n",
      "  [0.446526 0.300783 0.       ... 0.5      0.5      0.5     ]\n",
      "  ...\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]\n",
      "  [0.5      0.5      0.5      ... 0.5      0.5      0.5     ]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"./data/\"  \n",
    "\n",
    "# Constant frame count.\n",
    "frames = 100\n",
    "\n",
    "\n",
    "#Preparation Stage - Load data and normalize\n",
    "listfile = os.listdir(dirname)\n",
    "data = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, frames)), fill_value=0.5)\n",
    "        content.fillna(0.5, inplace = True) \n",
    "        data.append((wordname, content))\n",
    "        \n",
    "#Split data 60-20-20\n",
    "\n",
    "features = [n[1] for n in data]\n",
    "features = [f.to_numpy() for f in features]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.40, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.50, random_state=42)\n",
    "\n",
    "#Enumerate\n",
    "def printCountDataSets(dataset):\n",
    "    wortCounter = []\n",
    "    #Liste mit einmaligen Labels erstellen\n",
    "    labels = sorted(set(dataset), key=dataset.index)\n",
    "    #Liste nochmal Alphabetisch sortieren\n",
    "    labels = sorted(labels)\n",
    "    for label in labels:\n",
    "        wortCounter.append(0)\n",
    "    for row in dataset:\n",
    "        for i in range(len(labels)):\n",
    "            if str(labels[i]).startswith(row):\n",
    "                wortCounter[i] += 1\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i], ': ', wortCounter[i], end =\";  \")\n",
    "    print(' ')        \n",
    "    \n",
    "print('Amount Datasets by word total:')\n",
    "printCountDataSets(labels)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word training:')\n",
    "printCountDataSets(y_train)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word validiation:')\n",
    "printCountDataSets(y_val)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word test:')\n",
    "printCountDataSets(y_test)\n",
    "print('')\n",
    "\n",
    "\n",
    "# Display data distribution\n",
    "print('Distribution of data:')\n",
    "print(\"Amount total:\", len(labels))\n",
    "print(\"Amount training:\", len(y_train))\n",
    "print(\"Amount validiation:\", len(y_val))\n",
    "print(\"Amount test:\", len(y_test))\n",
    "print('')\n",
    "\n",
    "#Tokenize (One Hot)\n",
    "tokenizer = tools.tokenize(dirname)\n",
    "print('Tokens:')\n",
    "print(tokenizer.word_index)\n",
    "print('')\n",
    "with open('tokens_json.txt', 'w') as outfile:\n",
    "    outfile.write(tokenizer.to_json())\n",
    "\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_val=tokenizer.texts_to_sequences([y_val])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "\n",
    "y_train = to_categorical(encoded_train)\n",
    "y_val = to_categorical(encoded_val)\n",
    "y_test = to_categorical(encoded_test)\n",
    "\n",
    "print('Categories in OneHot anotation:')\n",
    "print(y_train)\n",
    "print('')\n",
    "# Making numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_val=np.array(x_val)\n",
    "y_val=np.array(y_val)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print('Dataset coordinate Values:')\n",
    "print(x_train)\n",
    "print('')\n",
    "\n",
    "#import winsound\n",
    "#def finished(num):\n",
    "#    frequency = 2000  # Set Frequency To 2500 Hertz\n",
    "#    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "#    for i in range(0, num):\n",
    "#        winsound.Beep(frequency, duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage\n",
    "Configure the model and train it.\n",
    "\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
    "<img src=\"assets/precision_recall.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\"> Hyperparametertuned LSTM </span>\n",
    "##### Here it is necessary to install the Keras-Tuner Module by executing:\n",
    "#####  <span style=\"color:green\"> via Conda:</span>\n",
    "conda install -c conda-forge keras-tuner\n",
    "#####  <span style=\"color:green\"> for pip:</span>\n",
    "pip install keras-tuner\n",
    "\n",
    "Right now there are three different builds we are testing:\n",
    "- classic LSTM\n",
    "- CuDNNLSTM\n",
    "- bidriectional LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from time import time, strftime\n",
    "\n",
    "\n",
    "starttime= strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "LOG_DIR = \"C:\\ML\\Optimization_\"f\"{starttime}\" #<-In Windows below Log_dir Path will maybe be too long for Windows to handle, so use a shorter path like this here\n",
    "#LOG_DIR = \"./Optimization_\"f\"{starttime}\" # LOG_DIR holds json files with information and a model of each single trial\n",
    "\n",
    "def build_model_lstm(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_CuDNNLSTM(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_bdlstm(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64),\n",
    "                                        return_sequences=True),\n",
    "                                        input_shape=(100, 86)))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True)))\n",
    "    \n",
    "    model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32))))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adamax']),\n",
    "                  metrics=['accuracy']) \n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <span style=\"color:red\">Necesarry only in case of using Nvidia GPU  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Keras-Tuner Approaches\n",
    "### 1 - RandomSearch\n",
    "Parameter of variables are ranomly used (number of layers, number of nodes) and \"best\" model is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 128)          77312     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 218,124\n",
      "Trainable params: 218,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 512)          702464    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 384)          1082880   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               229888    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,016,780\n",
      "Trainable params: 2,016,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4662 - accuracy: 0.1103 - val_loss: 2.4628 - val_accuracy: 0.0775\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 2.3874 - accuracy: 0.1080 - val_loss: 2.3815 - val_accuracy: 0.1268\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 2.2694 - accuracy: 0.2019 - val_loss: 2.2686 - val_accuracy: 0.2254\n",
      "Epoch 4/200\n",
      "14/14 - 1s - loss: 2.0801 - accuracy: 0.2653 - val_loss: 2.1520 - val_accuracy: 0.2535\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 1.8836 - accuracy: 0.3756 - val_loss: 2.1283 - val_accuracy: 0.2324\n",
      "Epoch 6/200\n",
      "14/14 - 0s - loss: 1.8364 - accuracy: 0.3826 - val_loss: 2.0376 - val_accuracy: 0.2817\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 1.6507 - accuracy: 0.4507 - val_loss: 1.8981 - val_accuracy: 0.3662\n",
      "Epoch 8/200\n",
      "14/14 - 0s - loss: 1.5251 - accuracy: 0.5282 - val_loss: 1.8751 - val_accuracy: 0.3169\n",
      "Epoch 9/200\n",
      "14/14 - 0s - loss: 1.5879 - accuracy: 0.4601 - val_loss: 1.8704 - val_accuracy: 0.3521\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.4911 - accuracy: 0.5023 - val_loss: 1.8807 - val_accuracy: 0.3239\n",
      "Epoch 11/200\n",
      "14/14 - 1s - loss: 1.3720 - accuracy: 0.5775 - val_loss: 1.6800 - val_accuracy: 0.4014\n",
      "Epoch 12/200\n",
      "14/14 - 1s - loss: 1.2010 - accuracy: 0.6385 - val_loss: 1.6623 - val_accuracy: 0.4296\n",
      "Epoch 13/200\n",
      "14/14 - 0s - loss: 1.1581 - accuracy: 0.6291 - val_loss: 1.6237 - val_accuracy: 0.4437\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 1.0546 - accuracy: 0.6526 - val_loss: 1.5161 - val_accuracy: 0.4366\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 0.9696 - accuracy: 0.7019 - val_loss: 1.6644 - val_accuracy: 0.4155\n",
      "Epoch 16/200\n",
      "14/14 - 1s - loss: 1.0220 - accuracy: 0.6643 - val_loss: 1.4593 - val_accuracy: 0.5211\n",
      "Epoch 17/200\n",
      "14/14 - 0s - loss: 0.9746 - accuracy: 0.7066 - val_loss: 1.5525 - val_accuracy: 0.4507\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 1.0556 - accuracy: 0.6479 - val_loss: 1.5539 - val_accuracy: 0.3873\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.8720 - accuracy: 0.7254 - val_loss: 1.4411 - val_accuracy: 0.5211\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 0.8143 - accuracy: 0.7488 - val_loss: 1.4280 - val_accuracy: 0.5423\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.8958 - accuracy: 0.7089 - val_loss: 1.3575 - val_accuracy: 0.4789\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 0.7218 - accuracy: 0.7488 - val_loss: 1.5257 - val_accuracy: 0.4577\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.7135 - accuracy: 0.7606 - val_loss: 1.3275 - val_accuracy: 0.5070\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.6843 - accuracy: 0.7700 - val_loss: 1.3171 - val_accuracy: 0.5141\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.6337 - accuracy: 0.8075 - val_loss: 1.3290 - val_accuracy: 0.5563\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 0.5415 - accuracy: 0.8380 - val_loss: 1.2319 - val_accuracy: 0.5493\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 0.4921 - accuracy: 0.8521 - val_loss: 1.2664 - val_accuracy: 0.5282\n",
      "Epoch 28/200\n",
      "14/14 - 1s - loss: 0.4690 - accuracy: 0.8662 - val_loss: 1.3483 - val_accuracy: 0.5915\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 0.5174 - accuracy: 0.8380 - val_loss: 1.3337 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.5273 - accuracy: 0.8333 - val_loss: 1.2754 - val_accuracy: 0.5634\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.4510 - accuracy: 0.8638 - val_loss: 1.1662 - val_accuracy: 0.5845\n",
      "Epoch 32/200\n",
      "14/14 - 1s - loss: 0.4173 - accuracy: 0.8685 - val_loss: 1.1034 - val_accuracy: 0.6408\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 0.3919 - accuracy: 0.8850 - val_loss: 1.0885 - val_accuracy: 0.6479\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.3616 - accuracy: 0.8967 - val_loss: 1.3825 - val_accuracy: 0.5211\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 0.3954 - accuracy: 0.8709 - val_loss: 1.0802 - val_accuracy: 0.6056\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.3294 - accuracy: 0.9038 - val_loss: 1.0888 - val_accuracy: 0.6197\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 0.3538 - accuracy: 0.9061 - val_loss: 1.1355 - val_accuracy: 0.5986\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 0.3134 - accuracy: 0.9014 - val_loss: 1.1980 - val_accuracy: 0.6268\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 0.3159 - accuracy: 0.9108 - val_loss: 1.1501 - val_accuracy: 0.6127\n",
      "Epoch 40/200\n",
      "14/14 - 0s - loss: 0.3939 - accuracy: 0.8850 - val_loss: 1.1689 - val_accuracy: 0.6056\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.3594 - accuracy: 0.8826 - val_loss: 1.3340 - val_accuracy: 0.6056\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.3423 - accuracy: 0.8967 - val_loss: 1.0729 - val_accuracy: 0.6197\n",
      "Epoch 43/200\n",
      "14/14 - 1s - loss: 0.2659 - accuracy: 0.9272 - val_loss: 0.9782 - val_accuracy: 0.6549\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.2149 - accuracy: 0.9624 - val_loss: 0.9906 - val_accuracy: 0.6690\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.1993 - accuracy: 0.9554 - val_loss: 0.9936 - val_accuracy: 0.6761\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.1645 - accuracy: 0.9742 - val_loss: 0.9195 - val_accuracy: 0.6901\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.1481 - accuracy: 0.9812 - val_loss: 0.9320 - val_accuracy: 0.6901\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.1501 - accuracy: 0.9765 - val_loss: 0.9673 - val_accuracy: 0.6901\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.1776 - accuracy: 0.9577 - val_loss: 0.8991 - val_accuracy: 0.7113\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.2156 - accuracy: 0.9413 - val_loss: 0.9214 - val_accuracy: 0.7254\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.2856 - accuracy: 0.8967 - val_loss: 1.3818 - val_accuracy: 0.5704\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.3065 - accuracy: 0.8944 - val_loss: 1.1242 - val_accuracy: 0.6479\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.3036 - accuracy: 0.9061 - val_loss: 0.9627 - val_accuracy: 0.6761\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.2076 - accuracy: 0.9460 - val_loss: 0.9578 - val_accuracy: 0.7042\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.1649 - accuracy: 0.9624 - val_loss: 0.9172 - val_accuracy: 0.6972\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.1280 - accuracy: 0.9789 - val_loss: 0.8638 - val_accuracy: 0.7465\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.1030 - accuracy: 0.9812 - val_loss: 0.9310 - val_accuracy: 0.7183\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.0923 - accuracy: 0.9836 - val_loss: 0.8359 - val_accuracy: 0.7465\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.1069 - accuracy: 0.9765 - val_loss: 0.9712 - val_accuracy: 0.6972\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.1365 - accuracy: 0.9601 - val_loss: 0.9180 - val_accuracy: 0.7394\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.1195 - accuracy: 0.9742 - val_loss: 0.9260 - val_accuracy: 0.7254\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.1268 - accuracy: 0.9695 - val_loss: 0.7800 - val_accuracy: 0.7676\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.1212 - accuracy: 0.9765 - val_loss: 0.8187 - val_accuracy: 0.7465\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.0978 - accuracy: 0.9836 - val_loss: 0.8702 - val_accuracy: 0.7254\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.0824 - accuracy: 0.9906 - val_loss: 0.8221 - val_accuracy: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.0788 - accuracy: 0.9859 - val_loss: 0.8007 - val_accuracy: 0.7606\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0733 - accuracy: 0.9930 - val_loss: 0.7195 - val_accuracy: 0.7676\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.0731 - accuracy: 0.9812 - val_loss: 0.7587 - val_accuracy: 0.7324\n",
      "Epoch 69/200\n",
      "14/14 - 1s - loss: 0.0517 - accuracy: 0.9977 - val_loss: 0.6766 - val_accuracy: 0.7887\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.0600 - accuracy: 0.9906 - val_loss: 0.7648 - val_accuracy: 0.7394\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.0653 - accuracy: 0.9906 - val_loss: 0.6992 - val_accuracy: 0.7887\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.0476 - accuracy: 0.9977 - val_loss: 0.7600 - val_accuracy: 0.7606\n",
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0540 - accuracy: 0.9953 - val_loss: 0.6878 - val_accuracy: 0.7817\n",
      "Epoch 74/200\n",
      "14/14 - 0s - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.7535\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.7535\n",
      "Epoch 76/200\n",
      "14/14 - 1s - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.7958\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.7887\n",
      "Epoch 78/200\n",
      "14/14 - 1s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8028\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8028\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.7958\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 0.8028\n",
      "Epoch 82/200\n",
      "14/14 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8099\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8028\n",
      "Epoch 84/200\n",
      "14/14 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.8169\n",
      "Epoch 85/200\n",
      "14/14 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8169\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.8169\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8099\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.8028\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.8169\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8028\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.7958\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.7958\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.8028\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.8099\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.8099\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.8099\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8169\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.8169\n",
      "Epoch 99/200\n",
      "14/14 - 1s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8239\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.8169\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6074 - val_accuracy: 0.8239\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8310\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8310\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8239\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.8239\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.8310\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.8239\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8239\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8239\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.8310\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.8169\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8310\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8169\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8169\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.8239\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8169\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.8169\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8169\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.8310\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.8169\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8239\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.8239\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8310\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8239\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8169\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8169\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.8239\n",
      "Epoch 128/200\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.8239\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.8239\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.8169\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8169\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.8239\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.8169\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8169\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8169\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8239\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8239\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8169\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5975 - val_accuracy: 0.8239\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8169\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8239\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8169\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 0.8169\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.8239\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8169\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8169\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8310\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.8310\n",
      "Epoch 150/200\n",
      "14/14 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8380\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8380\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8310\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8380\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.8380\n",
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8380\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8310\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.8380\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.8380\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8380\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.8380\n",
      "Epoch 161/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.8380\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5932 - val_accuracy: 0.8380\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8380\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8380\n",
      "Epoch 165/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8380\n",
      "Epoch 166/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.8380\n",
      "Epoch 167/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.8380\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8310\n",
      "Epoch 169/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8380\n",
      "Epoch 170/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8380\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.8380\n",
      "Epoch 172/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8380\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8310\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.8380\n",
      "Epoch 175/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8380\n",
      "Epoch 176/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.8380\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8380\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.8380\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8380\n",
      "Epoch 180/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8380\n",
      "Epoch 181/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5810 - val_accuracy: 0.8380\n",
      "Epoch 182/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8380\n",
      "Epoch 183/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.8380\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.8380\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8380\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8380\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8380\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8380\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.8380\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8380\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.8380\n",
      "Epoch 192/200\n",
      "14/14 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.8451\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8380\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.8310\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.8239\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.8451\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.8310\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.8380\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8239\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5689 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 7104b3687a36fa9b53640aa7eb05490d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8450704216957092</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 256)          220160    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 192)               172800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                2316      \n",
      "=================================================================\n",
      "Total params: 953,868\n",
      "Trainable params: 953,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4584 - accuracy: 0.0939 - val_loss: 2.4133 - val_accuracy: 0.0915\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 2.3899 - accuracy: 0.1174 - val_loss: 2.4005 - val_accuracy: 0.0845\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 2.2860 - accuracy: 0.1995 - val_loss: 2.2985 - val_accuracy: 0.2042\n",
      "Epoch 4/200\n",
      "14/14 - 0s - loss: 2.1164 - accuracy: 0.2770 - val_loss: 2.1818 - val_accuracy: 0.2183\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 1.9576 - accuracy: 0.3286 - val_loss: 2.0914 - val_accuracy: 0.2746\n",
      "Epoch 6/200\n",
      "14/14 - 1s - loss: 1.8171 - accuracy: 0.4038 - val_loss: 1.9530 - val_accuracy: 0.3380\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 1.6601 - accuracy: 0.4577 - val_loss: 1.9614 - val_accuracy: 0.2958\n",
      "Epoch 8/200\n",
      "14/14 - 1s - loss: 1.5821 - accuracy: 0.4953 - val_loss: 1.7817 - val_accuracy: 0.3873\n",
      "Epoch 9/200\n",
      "14/14 - 0s - loss: 1.4811 - accuracy: 0.5141 - val_loss: 1.6497 - val_accuracy: 0.4366\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.3068 - accuracy: 0.5634 - val_loss: 1.7070 - val_accuracy: 0.4085\n",
      "Epoch 11/200\n",
      "14/14 - 1s - loss: 1.2246 - accuracy: 0.6150 - val_loss: 1.4696 - val_accuracy: 0.4718\n",
      "Epoch 12/200\n",
      "14/14 - 1s - loss: 1.0945 - accuracy: 0.6408 - val_loss: 1.4816 - val_accuracy: 0.4859\n",
      "Epoch 13/200\n",
      "14/14 - 1s - loss: 0.9863 - accuracy: 0.6737 - val_loss: 1.3770 - val_accuracy: 0.5282\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 0.9441 - accuracy: 0.6784 - val_loss: 1.5637 - val_accuracy: 0.4225\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 0.9244 - accuracy: 0.7183 - val_loss: 1.3915 - val_accuracy: 0.4718\n",
      "Epoch 16/200\n",
      "14/14 - 0s - loss: 1.0018 - accuracy: 0.6479 - val_loss: 1.6563 - val_accuracy: 0.3944\n",
      "Epoch 17/200\n",
      "14/14 - 1s - loss: 0.8676 - accuracy: 0.7160 - val_loss: 1.2456 - val_accuracy: 0.5352\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 0.8374 - accuracy: 0.7207 - val_loss: 1.1422 - val_accuracy: 0.5986\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.6599 - accuracy: 0.7746 - val_loss: 1.0896 - val_accuracy: 0.6056\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 0.6417 - accuracy: 0.7981 - val_loss: 1.0482 - val_accuracy: 0.6197\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.5723 - accuracy: 0.8216 - val_loss: 1.0104 - val_accuracy: 0.6479\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 0.5440 - accuracy: 0.8005 - val_loss: 1.2500 - val_accuracy: 0.5141\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.6575 - accuracy: 0.7840 - val_loss: 1.1735 - val_accuracy: 0.5634\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.5187 - accuracy: 0.8333 - val_loss: 1.1615 - val_accuracy: 0.5493\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.4803 - accuracy: 0.8545 - val_loss: 1.1800 - val_accuracy: 0.5775\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 0.4517 - accuracy: 0.8662 - val_loss: 0.9763 - val_accuracy: 0.6549\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 0.3909 - accuracy: 0.8615 - val_loss: 0.9983 - val_accuracy: 0.6408\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 0.3742 - accuracy: 0.8732 - val_loss: 0.8726 - val_accuracy: 0.6972\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 0.3339 - accuracy: 0.8991 - val_loss: 1.1277 - val_accuracy: 0.5845\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.3650 - accuracy: 0.8709 - val_loss: 0.9210 - val_accuracy: 0.6479\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.2966 - accuracy: 0.8944 - val_loss: 0.8616 - val_accuracy: 0.7113\n",
      "Epoch 32/200\n",
      "14/14 - 1s - loss: 0.2668 - accuracy: 0.9131 - val_loss: 0.8887 - val_accuracy: 0.6831\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 0.2624 - accuracy: 0.9225 - val_loss: 0.8736 - val_accuracy: 0.7676\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.2563 - accuracy: 0.9249 - val_loss: 1.0475 - val_accuracy: 0.6197\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 0.2277 - accuracy: 0.9484 - val_loss: 0.8931 - val_accuracy: 0.6761\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.2392 - accuracy: 0.9178 - val_loss: 0.9805 - val_accuracy: 0.6761\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 0.2710 - accuracy: 0.9061 - val_loss: 1.0027 - val_accuracy: 0.6549\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 0.2748 - accuracy: 0.9061 - val_loss: 0.8650 - val_accuracy: 0.6761\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 0.1795 - accuracy: 0.9624 - val_loss: 0.7889 - val_accuracy: 0.7113\n",
      "Epoch 40/200\n",
      "14/14 - 0s - loss: 0.1759 - accuracy: 0.9531 - val_loss: 0.8337 - val_accuracy: 0.7254\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.1619 - accuracy: 0.9695 - val_loss: 0.7460 - val_accuracy: 0.7394\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.1913 - accuracy: 0.9484 - val_loss: 0.8638 - val_accuracy: 0.7254\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.1573 - accuracy: 0.9624 - val_loss: 0.8353 - val_accuracy: 0.7324\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.3220 - accuracy: 0.8826 - val_loss: 1.0218 - val_accuracy: 0.6338\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.2618 - accuracy: 0.9178 - val_loss: 0.7907 - val_accuracy: 0.7465\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.2207 - accuracy: 0.9366 - val_loss: 0.9593 - val_accuracy: 0.6620\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.2163 - accuracy: 0.9366 - val_loss: 0.7921 - val_accuracy: 0.7676\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.1740 - accuracy: 0.9484 - val_loss: 0.8136 - val_accuracy: 0.7606\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.1546 - accuracy: 0.9554 - val_loss: 0.7332 - val_accuracy: 0.8028\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.1363 - accuracy: 0.9577 - val_loss: 0.7722 - val_accuracy: 0.7324\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.1324 - accuracy: 0.9601 - val_loss: 0.7248 - val_accuracy: 0.7606\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.1059 - accuracy: 0.9624 - val_loss: 0.7239 - val_accuracy: 0.7817\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.0797 - accuracy: 0.9859 - val_loss: 0.7285 - val_accuracy: 0.7676\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.0623 - accuracy: 0.9906 - val_loss: 0.7397 - val_accuracy: 0.7676\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.0661 - accuracy: 0.9930 - val_loss: 0.7636 - val_accuracy: 0.7535\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.0758 - accuracy: 0.9883 - val_loss: 0.8419 - val_accuracy: 0.7113\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.1045 - accuracy: 0.9671 - val_loss: 0.8834 - val_accuracy: 0.7324\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.0955 - accuracy: 0.9695 - val_loss: 0.7419 - val_accuracy: 0.7958\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.1305 - accuracy: 0.9624 - val_loss: 0.8443 - val_accuracy: 0.7324\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.1200 - accuracy: 0.9695 - val_loss: 0.7757 - val_accuracy: 0.7324\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.8764 - val_accuracy: 0.7606\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.0982 - accuracy: 0.9742 - val_loss: 0.7145 - val_accuracy: 0.7958\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.0799 - accuracy: 0.9742 - val_loss: 0.7342 - val_accuracy: 0.8099\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.0942 - accuracy: 0.9718 - val_loss: 0.7089 - val_accuracy: 0.7817\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.0682 - accuracy: 0.9859 - val_loss: 0.7601 - val_accuracy: 0.7887\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.0461 - accuracy: 0.9953 - val_loss: 0.6691 - val_accuracy: 0.7887\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0633 - accuracy: 0.9859 - val_loss: 0.7114 - val_accuracy: 0.7887\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.0904 - accuracy: 0.9765 - val_loss: 0.8486 - val_accuracy: 0.7676\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.1064 - accuracy: 0.9742 - val_loss: 0.8230 - val_accuracy: 0.7746\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.1325 - accuracy: 0.9507 - val_loss: 1.1808 - val_accuracy: 0.6761\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.2218 - accuracy: 0.9319 - val_loss: 0.9305 - val_accuracy: 0.7324\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.1585 - accuracy: 0.9507 - val_loss: 0.8783 - val_accuracy: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0838 - accuracy: 0.9859 - val_loss: 0.7460 - val_accuracy: 0.7887\n",
      "Epoch 74/200\n",
      "14/14 - 0s - loss: 0.0554 - accuracy: 0.9906 - val_loss: 0.8384 - val_accuracy: 0.7676\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0438 - accuracy: 0.9953 - val_loss: 0.7029 - val_accuracy: 0.7817\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.0332 - accuracy: 0.9977 - val_loss: 0.6906 - val_accuracy: 0.8169\n",
      "Epoch 77/200\n",
      "14/14 - 1s - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.7887\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.8028\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8169\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8169\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8239\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8310\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8310\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8310\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.8310\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8310\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8310\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.8310\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.8380\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8380\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.8380\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.8310\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8380\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.8310\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.8310\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.8310\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8310\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8310\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.8310\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8310\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.8310\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8310\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6164 - val_accuracy: 0.8310\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.8310\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.8310\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8310\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.8380\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8310\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8380\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8380\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8380\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8380\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.8380\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8380\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.8380\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8380\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8380\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8451\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.8451\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.8451\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.8451\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.8451\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8451\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8380\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.8380\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.8451\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.8380\n",
      "Epoch 128/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.8380\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8380\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8380\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.8380\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.8380\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8380\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6277 - val_accuracy: 0.8380\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.8380\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8380\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6319 - val_accuracy: 0.8380\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8380\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8380\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8380\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.8380\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.8380\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.8380\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8380\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8380\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8380\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8380\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8380\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8380\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8380\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.8380\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8380\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8380\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.8380\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6444 - val_accuracy: 0.8380\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.8310\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8310\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.8310\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8310\n",
      "Epoch 161/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.8310\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.8310\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.8310\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.8310\n",
      "Epoch 165/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8310\n",
      "Epoch 166/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8310\n",
      "Epoch 167/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8310\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.8310\n",
      "Epoch 169/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.8310\n",
      "Epoch 170/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.8310\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6510 - val_accuracy: 0.8310\n",
      "Epoch 172/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.8310\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8310\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 0.8310\n",
      "Epoch 175/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.8310\n",
      "Epoch 176/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.8310\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8310\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 0.8310\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.8310\n",
      "Epoch 180/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8310\n",
      "Epoch 181/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8310\n",
      "Epoch 182/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.8310\n",
      "Epoch 183/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8310\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8310\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8310\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8310\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8310\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8310\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8310\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8310\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8310\n",
      "Epoch 192/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8310\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8380\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8380\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8310\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 9.8724e-04 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8310\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 9.7135e-04 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.8380\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 9.5241e-04 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8380\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 9.4005e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8380\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 9.2290e-04 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 686beab900498d5e3740facfd43e5b30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8450704216957092</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_input: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 384)          428544    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          525312    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               164352    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 1,513,996\n",
      "Trainable params: 1,513,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4541 - accuracy: 0.1103 - val_loss: 2.4024 - val_accuracy: 0.1268\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 2.2985 - accuracy: 0.1995 - val_loss: 2.2545 - val_accuracy: 0.1127\n",
      "Epoch 3/200\n",
      "14/14 - 1s - loss: 2.1297 - accuracy: 0.2512 - val_loss: 2.1650 - val_accuracy: 0.1972\n",
      "Epoch 4/200\n",
      "14/14 - 1s - loss: 1.9497 - accuracy: 0.3357 - val_loss: 2.1331 - val_accuracy: 0.1901\n",
      "Epoch 5/200\n",
      "14/14 - 1s - loss: 1.7933 - accuracy: 0.3638 - val_loss: 1.9038 - val_accuracy: 0.3310\n",
      "Epoch 6/200\n",
      "14/14 - 1s - loss: 1.5842 - accuracy: 0.5023 - val_loss: 1.8429 - val_accuracy: 0.3380\n",
      "Epoch 7/200\n",
      "14/14 - 1s - loss: 1.5309 - accuracy: 0.5023 - val_loss: 1.8720 - val_accuracy: 0.3662\n",
      "Epoch 8/200\n",
      "14/14 - 1s - loss: 1.3933 - accuracy: 0.5798 - val_loss: 1.6744 - val_accuracy: 0.4014\n",
      "Epoch 9/200\n",
      "14/14 - 1s - loss: 1.3312 - accuracy: 0.5751 - val_loss: 1.6282 - val_accuracy: 0.4225\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.2982 - accuracy: 0.5939 - val_loss: 1.6933 - val_accuracy: 0.4155\n",
      "Epoch 11/200\n",
      "14/14 - 1s - loss: 1.2073 - accuracy: 0.6103 - val_loss: 1.6058 - val_accuracy: 0.4930\n",
      "Epoch 12/200\n",
      "14/14 - 0s - loss: 1.1857 - accuracy: 0.5939 - val_loss: 1.6019 - val_accuracy: 0.4296\n",
      "Epoch 13/200\n",
      "14/14 - 1s - loss: 1.1817 - accuracy: 0.6455 - val_loss: 1.5583 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 1.0833 - accuracy: 0.6479 - val_loss: 1.3919 - val_accuracy: 0.4789\n",
      "Epoch 15/200\n",
      "14/14 - 1s - loss: 0.9628 - accuracy: 0.7042 - val_loss: 1.3478 - val_accuracy: 0.5352\n",
      "Epoch 16/200\n",
      "14/14 - 1s - loss: 0.8514 - accuracy: 0.7535 - val_loss: 1.3166 - val_accuracy: 0.5493\n",
      "Epoch 17/200\n",
      "14/14 - 1s - loss: 0.7795 - accuracy: 0.7582 - val_loss: 1.2619 - val_accuracy: 0.5634\n",
      "Epoch 18/200\n",
      "14/14 - 1s - loss: 0.7421 - accuracy: 0.7840 - val_loss: 1.1995 - val_accuracy: 0.5986\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.7089 - accuracy: 0.7911 - val_loss: 1.1013 - val_accuracy: 0.5775\n",
      "Epoch 20/200\n",
      "14/14 - 1s - loss: 0.6254 - accuracy: 0.8146 - val_loss: 1.1478 - val_accuracy: 0.6127\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.6161 - accuracy: 0.8005 - val_loss: 1.1768 - val_accuracy: 0.5634\n",
      "Epoch 22/200\n",
      "14/14 - 1s - loss: 0.5659 - accuracy: 0.8404 - val_loss: 1.1875 - val_accuracy: 0.6479\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.4933 - accuracy: 0.8474 - val_loss: 1.0813 - val_accuracy: 0.6268\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.4801 - accuracy: 0.8615 - val_loss: 1.2067 - val_accuracy: 0.6127\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.4660 - accuracy: 0.8521 - val_loss: 1.0084 - val_accuracy: 0.6408\n",
      "Epoch 26/200\n",
      "14/14 - 1s - loss: 0.4573 - accuracy: 0.8662 - val_loss: 1.0169 - val_accuracy: 0.6901\n",
      "Epoch 27/200\n",
      "14/14 - 1s - loss: 0.4294 - accuracy: 0.8803 - val_loss: 1.0884 - val_accuracy: 0.6690\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 0.4095 - accuracy: 0.8779 - val_loss: 1.0337 - val_accuracy: 0.6761\n",
      "Epoch 29/200\n",
      "14/14 - 1s - loss: 0.3798 - accuracy: 0.8779 - val_loss: 1.0165 - val_accuracy: 0.6690\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.3372 - accuracy: 0.9014 - val_loss: 0.9826 - val_accuracy: 0.6761\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.3755 - accuracy: 0.8873 - val_loss: 0.9919 - val_accuracy: 0.6690\n",
      "Epoch 32/200\n",
      "14/14 - 0s - loss: 0.3529 - accuracy: 0.9038 - val_loss: 0.9204 - val_accuracy: 0.6831\n",
      "Epoch 33/200\n",
      "14/14 - 1s - loss: 0.3330 - accuracy: 0.9061 - val_loss: 1.0167 - val_accuracy: 0.7113\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.3978 - accuracy: 0.8709 - val_loss: 1.1232 - val_accuracy: 0.6338\n",
      "Epoch 35/200\n",
      "14/14 - 1s - loss: 0.3797 - accuracy: 0.8732 - val_loss: 0.9459 - val_accuracy: 0.7183\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.3680 - accuracy: 0.8826 - val_loss: 1.0828 - val_accuracy: 0.6831\n",
      "Epoch 37/200\n",
      "14/14 - 1s - loss: 0.3256 - accuracy: 0.9061 - val_loss: 1.0687 - val_accuracy: 0.6408\n",
      "Epoch 38/200\n",
      "14/14 - 1s - loss: 0.3078 - accuracy: 0.9202 - val_loss: 0.9370 - val_accuracy: 0.6761\n",
      "Epoch 39/200\n",
      "14/14 - 1s - loss: 0.2948 - accuracy: 0.9108 - val_loss: 0.8495 - val_accuracy: 0.6972\n",
      "Epoch 40/200\n",
      "14/14 - 1s - loss: 0.2291 - accuracy: 0.9413 - val_loss: 0.9020 - val_accuracy: 0.7324\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.2031 - accuracy: 0.9554 - val_loss: 0.8880 - val_accuracy: 0.7324\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.2080 - accuracy: 0.9460 - val_loss: 0.9223 - val_accuracy: 0.7113\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.1860 - accuracy: 0.9531 - val_loss: 0.9034 - val_accuracy: 0.7113\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.1720 - accuracy: 0.9601 - val_loss: 0.8962 - val_accuracy: 0.6831\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.1324 - accuracy: 0.9789 - val_loss: 0.8987 - val_accuracy: 0.7183\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.1675 - accuracy: 0.9624 - val_loss: 0.9147 - val_accuracy: 0.7042\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.2186 - accuracy: 0.9484 - val_loss: 0.8911 - val_accuracy: 0.6831\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.3048 - accuracy: 0.9178 - val_loss: 1.0046 - val_accuracy: 0.6761\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.2656 - accuracy: 0.9225 - val_loss: 0.9816 - val_accuracy: 0.6690\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.2497 - accuracy: 0.9296 - val_loss: 0.9836 - val_accuracy: 0.7254\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.1673 - accuracy: 0.9577 - val_loss: 1.0086 - val_accuracy: 0.7183\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.2178 - accuracy: 0.9319 - val_loss: 0.9646 - val_accuracy: 0.6972\n",
      "Epoch 53/200\n",
      "14/14 - 1s - loss: 0.2037 - accuracy: 0.9390 - val_loss: 0.9104 - val_accuracy: 0.6831\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.1801 - accuracy: 0.9484 - val_loss: 0.9126 - val_accuracy: 0.7042\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.1771 - accuracy: 0.9531 - val_loss: 1.1847 - val_accuracy: 0.6338\n",
      "Epoch 56/200\n",
      "14/14 - 1s - loss: 0.1416 - accuracy: 0.9648 - val_loss: 0.8872 - val_accuracy: 0.7817\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.1158 - accuracy: 0.9765 - val_loss: 0.9467 - val_accuracy: 0.6690\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.1555 - accuracy: 0.9577 - val_loss: 0.8856 - val_accuracy: 0.7676\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.0993 - accuracy: 0.9836 - val_loss: 0.7759 - val_accuracy: 0.7394\n",
      "Epoch 60/200\n",
      "14/14 - 1s - loss: 0.0809 - accuracy: 0.9883 - val_loss: 0.7667 - val_accuracy: 0.7606\n",
      "Epoch 61/200\n",
      "14/14 - 1s - loss: 0.0753 - accuracy: 0.9883 - val_loss: 0.7413 - val_accuracy: 0.7676\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.0625 - accuracy: 0.9859 - val_loss: 0.7997 - val_accuracy: 0.7746\n",
      "Epoch 63/200\n",
      "14/14 - 1s - loss: 0.0523 - accuracy: 0.9977 - val_loss: 0.7570 - val_accuracy: 0.7887\n",
      "Epoch 64/200\n",
      "14/14 - 1s - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.7817\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.7676\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7887\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.7817\n",
      "Epoch 68/200\n",
      "14/14 - 1s - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.7701 - val_accuracy: 0.8169\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.7958\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.7887\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8028\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.7887\n",
      "Epoch 74/200\n",
      "14/14 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.7817\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.7746\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.7887\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7746\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7958\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.7958\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.7958\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.8028\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.7817\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8028\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7887\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.8028\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.7958\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7958\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.8028\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.7885 - val_accuracy: 0.8028\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.7958\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.8028\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7958\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.8037 - val_accuracy: 0.7958\n",
      "Epoch 94/200\n",
      "14/14 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.8028\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.8028\n",
      "Epoch 96/200\n",
      "14/14 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.8028\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.8028\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.7958\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8028\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8124 - val_accuracy: 0.7958\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8028\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.7958\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.7958\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.8028\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.7958\n",
      "Epoch 106/200\n",
      "14/14 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7958\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7887\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8228 - val_accuracy: 0.7887\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7887\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.7958\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.7958\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.7887\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.7887\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.7958\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.7958\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7958\n",
      "Epoch 117/200\n",
      "14/14 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.7958\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7958\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.7958\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.7887\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8173 - val_accuracy: 0.7958\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.7958\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.7958\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.7958\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.7958\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7958\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.7958\n",
      "Epoch 128/200\n",
      "14/14 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.7958\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.7958\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.7958\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8281 - val_accuracy: 0.7958\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.8099\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8125 - val_accuracy: 0.7958\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.7958\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.8099\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.8028\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.7958\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8438 - val_accuracy: 0.7887\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.8028\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.8028\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8104 - val_accuracy: 0.8028\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.7958\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.7958\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.7958\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.7958\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.8028\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7958\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.7958\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8028\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.7958\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7958\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.7958\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.8028\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.8028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.8028\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.8099\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.8169\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.8099\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8259 - val_accuracy: 0.7958\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8099\n",
      "Epoch 161/200\n",
      "14/14 - 1s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.8099\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.8099\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8185 - val_accuracy: 0.8169\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.8169\n",
      "Epoch 165/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.8169\n",
      "Epoch 166/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.8169\n",
      "Epoch 167/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.8239\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.8099\n",
      "Epoch 169/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.8239\n",
      "Epoch 170/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.8239\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.8169\n",
      "Epoch 172/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.8239\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.8239\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.8239\n",
      "Epoch 175/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.8099\n",
      "Epoch 176/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7958\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.3739 - accuracy: 0.9038 - val_loss: 1.4338 - val_accuracy: 0.6408\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.5969 - accuracy: 0.8099 - val_loss: 0.8613 - val_accuracy: 0.7113\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.3307 - accuracy: 0.8967 - val_loss: 1.2215 - val_accuracy: 0.6197\n",
      "Epoch 180/200\n",
      "14/14 - 0s - loss: 0.2515 - accuracy: 0.9085 - val_loss: 0.8995 - val_accuracy: 0.7465\n",
      "Epoch 181/200\n",
      "14/14 - 1s - loss: 0.1136 - accuracy: 0.9695 - val_loss: 0.7883 - val_accuracy: 0.7535\n",
      "Epoch 182/200\n",
      "14/14 - 0s - loss: 0.0610 - accuracy: 0.9859 - val_loss: 0.7827 - val_accuracy: 0.7746\n",
      "Epoch 183/200\n",
      "14/14 - 0s - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.8582 - val_accuracy: 0.7606\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.1782 - accuracy: 0.9460 - val_loss: 1.3061 - val_accuracy: 0.6197\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.2161 - accuracy: 0.9343 - val_loss: 0.9750 - val_accuracy: 0.7394\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0916 - accuracy: 0.9742 - val_loss: 0.9548 - val_accuracy: 0.7254\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0845 - accuracy: 0.9695 - val_loss: 0.8573 - val_accuracy: 0.7817\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0472 - accuracy: 0.9906 - val_loss: 0.9717 - val_accuracy: 0.7394\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0570 - accuracy: 0.9789 - val_loss: 0.9071 - val_accuracy: 0.7465\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0461 - accuracy: 0.9883 - val_loss: 0.8350 - val_accuracy: 0.7887\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.7428 - val_accuracy: 0.7746\n",
      "Epoch 192/200\n",
      "14/14 - 0s - loss: 0.0400 - accuracy: 0.9930 - val_loss: 0.8404 - val_accuracy: 0.7606\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.7958\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8028\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8028\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8028\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.8028\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.8028\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.8099\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.8099\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: a680680153603bcfe38ed6206fc89956</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8239436745643616</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 384)          428544    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          525312    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 384)          689664    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 192)               369408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                2316      \n",
      "=================================================================\n",
      "Total params: 2,015,244\n",
      "Trainable params: 2,015,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4796 - accuracy: 0.0610 - val_loss: 2.4357 - val_accuracy: 0.0704\n",
      "Epoch 2/200\n",
      "14/14 - 1s - loss: 2.3444 - accuracy: 0.1455 - val_loss: 2.3389 - val_accuracy: 0.1268\n",
      "Epoch 3/200\n",
      "14/14 - 1s - loss: 2.2195 - accuracy: 0.2183 - val_loss: 2.3058 - val_accuracy: 0.1620\n",
      "Epoch 4/200\n",
      "14/14 - 1s - loss: 2.0469 - accuracy: 0.2793 - val_loss: 2.1144 - val_accuracy: 0.2606\n",
      "Epoch 5/200\n",
      "14/14 - 1s - loss: 1.7968 - accuracy: 0.3521 - val_loss: 1.9618 - val_accuracy: 0.3592\n",
      "Epoch 6/200\n",
      "14/14 - 1s - loss: 1.5815 - accuracy: 0.4953 - val_loss: 1.8224 - val_accuracy: 0.3944\n",
      "Epoch 7/200\n",
      "14/14 - 1s - loss: 1.4361 - accuracy: 0.5000 - val_loss: 1.6480 - val_accuracy: 0.4437\n",
      "Epoch 8/200\n",
      "14/14 - 1s - loss: 1.2246 - accuracy: 0.6221 - val_loss: 1.5464 - val_accuracy: 0.4930\n",
      "Epoch 9/200\n",
      "14/14 - 1s - loss: 1.0803 - accuracy: 0.6244 - val_loss: 1.5089 - val_accuracy: 0.4930\n",
      "Epoch 10/200\n",
      "14/14 - 1s - loss: 1.0299 - accuracy: 0.6620 - val_loss: 1.3846 - val_accuracy: 0.4577\n",
      "Epoch 11/200\n",
      "14/14 - 1s - loss: 0.9220 - accuracy: 0.7089 - val_loss: 1.3213 - val_accuracy: 0.5282\n",
      "Epoch 12/200\n",
      "14/14 - 1s - loss: 0.9089 - accuracy: 0.6854 - val_loss: 1.6184 - val_accuracy: 0.4577\n",
      "Epoch 13/200\n",
      "14/14 - 1s - loss: 0.9879 - accuracy: 0.6808 - val_loss: 1.4781 - val_accuracy: 0.4718\n",
      "Epoch 14/200\n",
      "14/14 - 1s - loss: 0.8122 - accuracy: 0.7488 - val_loss: 1.2628 - val_accuracy: 0.5563\n",
      "Epoch 15/200\n",
      "14/14 - 1s - loss: 0.7020 - accuracy: 0.7770 - val_loss: 1.2023 - val_accuracy: 0.5493\n",
      "Epoch 16/200\n",
      "14/14 - 1s - loss: 0.6374 - accuracy: 0.7911 - val_loss: 1.2849 - val_accuracy: 0.5493\n",
      "Epoch 17/200\n",
      "14/14 - 1s - loss: 0.6227 - accuracy: 0.8005 - val_loss: 1.1876 - val_accuracy: 0.6197\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 0.5879 - accuracy: 0.8052 - val_loss: 1.2089 - val_accuracy: 0.5915\n",
      "Epoch 19/200\n",
      "14/14 - 1s - loss: 0.6310 - accuracy: 0.7958 - val_loss: 1.1572 - val_accuracy: 0.6268\n",
      "Epoch 20/200\n",
      "14/14 - 1s - loss: 0.5225 - accuracy: 0.8427 - val_loss: 1.1671 - val_accuracy: 0.6408\n",
      "Epoch 21/200\n",
      "14/14 - 1s - loss: 0.5569 - accuracy: 0.8075 - val_loss: 1.1491 - val_accuracy: 0.5493\n",
      "Epoch 22/200\n",
      "14/14 - 1s - loss: 0.5311 - accuracy: 0.8239 - val_loss: 1.1469 - val_accuracy: 0.5282\n",
      "Epoch 23/200\n",
      "14/14 - 1s - loss: 0.4591 - accuracy: 0.8333 - val_loss: 1.1628 - val_accuracy: 0.6056\n",
      "Epoch 24/200\n",
      "14/14 - 1s - loss: 0.4337 - accuracy: 0.8732 - val_loss: 1.0495 - val_accuracy: 0.6197\n",
      "Epoch 25/200\n",
      "14/14 - 1s - loss: 0.3351 - accuracy: 0.9155 - val_loss: 1.0325 - val_accuracy: 0.6338\n",
      "Epoch 26/200\n",
      "14/14 - 1s - loss: 0.3166 - accuracy: 0.9108 - val_loss: 1.0503 - val_accuracy: 0.6549\n",
      "Epoch 27/200\n",
      "14/14 - 1s - loss: 0.2987 - accuracy: 0.9108 - val_loss: 1.0648 - val_accuracy: 0.6408\n",
      "Epoch 28/200\n",
      "14/14 - 1s - loss: 0.3246 - accuracy: 0.8826 - val_loss: 1.0575 - val_accuracy: 0.6338\n",
      "Epoch 29/200\n",
      "14/14 - 1s - loss: 0.3254 - accuracy: 0.8967 - val_loss: 1.0715 - val_accuracy: 0.6479\n",
      "Epoch 30/200\n",
      "14/14 - 1s - loss: 0.2915 - accuracy: 0.9038 - val_loss: 1.0052 - val_accuracy: 0.6338\n",
      "Epoch 31/200\n",
      "14/14 - 1s - loss: 0.2615 - accuracy: 0.9249 - val_loss: 1.0329 - val_accuracy: 0.6690\n",
      "Epoch 32/200\n",
      "14/14 - 1s - loss: 0.2347 - accuracy: 0.9413 - val_loss: 0.9488 - val_accuracy: 0.6620\n",
      "Epoch 33/200\n",
      "14/14 - 1s - loss: 0.2139 - accuracy: 0.9296 - val_loss: 0.9436 - val_accuracy: 0.6972\n",
      "Epoch 34/200\n",
      "14/14 - 1s - loss: 0.2069 - accuracy: 0.9413 - val_loss: 0.9783 - val_accuracy: 0.6831\n",
      "Epoch 35/200\n",
      "14/14 - 1s - loss: 0.2275 - accuracy: 0.9296 - val_loss: 0.9263 - val_accuracy: 0.6831\n",
      "Epoch 36/200\n",
      "14/14 - 1s - loss: 0.1873 - accuracy: 0.9554 - val_loss: 0.9285 - val_accuracy: 0.6831\n",
      "Epoch 37/200\n",
      "14/14 - 1s - loss: 0.1470 - accuracy: 0.9671 - val_loss: 0.9384 - val_accuracy: 0.6901\n",
      "Epoch 38/200\n",
      "14/14 - 1s - loss: 0.2592 - accuracy: 0.9131 - val_loss: 1.0558 - val_accuracy: 0.6620\n",
      "Epoch 39/200\n",
      "14/14 - 1s - loss: 0.2817 - accuracy: 0.8991 - val_loss: 1.2070 - val_accuracy: 0.5986\n",
      "Epoch 40/200\n",
      "14/14 - 1s - loss: 0.2468 - accuracy: 0.9249 - val_loss: 1.0281 - val_accuracy: 0.6620\n",
      "Epoch 41/200\n",
      "14/14 - 1s - loss: 0.2261 - accuracy: 0.9343 - val_loss: 1.0182 - val_accuracy: 0.6620\n",
      "Epoch 42/200\n",
      "14/14 - 1s - loss: 0.2016 - accuracy: 0.9343 - val_loss: 0.9769 - val_accuracy: 0.6197\n",
      "Epoch 43/200\n",
      "14/14 - 1s - loss: 0.2076 - accuracy: 0.9296 - val_loss: 1.0801 - val_accuracy: 0.6549\n",
      "Epoch 44/200\n",
      "14/14 - 1s - loss: 0.2168 - accuracy: 0.9390 - val_loss: 0.9431 - val_accuracy: 0.7183\n",
      "Epoch 45/200\n",
      "14/14 - 1s - loss: 0.2027 - accuracy: 0.9366 - val_loss: 0.8312 - val_accuracy: 0.7254\n",
      "Epoch 46/200\n",
      "14/14 - 1s - loss: 0.2036 - accuracy: 0.9319 - val_loss: 0.9077 - val_accuracy: 0.6831\n",
      "Epoch 47/200\n",
      "14/14 - 1s - loss: 0.1429 - accuracy: 0.9601 - val_loss: 1.0257 - val_accuracy: 0.6972\n",
      "Epoch 48/200\n",
      "14/14 - 1s - loss: 0.1137 - accuracy: 0.9695 - val_loss: 0.9045 - val_accuracy: 0.7324\n",
      "Epoch 49/200\n",
      "14/14 - 1s - loss: 0.0908 - accuracy: 0.9836 - val_loss: 0.8707 - val_accuracy: 0.7324\n",
      "Epoch 50/200\n",
      "14/14 - 1s - loss: 0.1055 - accuracy: 0.9765 - val_loss: 0.9094 - val_accuracy: 0.7183\n",
      "Epoch 51/200\n",
      "14/14 - 1s - loss: 0.1093 - accuracy: 0.9742 - val_loss: 0.9598 - val_accuracy: 0.7324\n",
      "Epoch 52/200\n",
      "14/14 - 1s - loss: 0.0791 - accuracy: 0.9859 - val_loss: 0.8982 - val_accuracy: 0.7042\n",
      "Epoch 53/200\n",
      "14/14 - 1s - loss: 0.0716 - accuracy: 0.9906 - val_loss: 0.9152 - val_accuracy: 0.7254\n",
      "Epoch 54/200\n",
      "14/14 - 1s - loss: 0.0944 - accuracy: 0.9789 - val_loss: 0.8932 - val_accuracy: 0.7042\n",
      "Epoch 55/200\n",
      "14/14 - 1s - loss: 0.1413 - accuracy: 0.9648 - val_loss: 0.9619 - val_accuracy: 0.6901\n",
      "Epoch 56/200\n",
      "14/14 - 1s - loss: 0.1132 - accuracy: 0.9695 - val_loss: 0.9321 - val_accuracy: 0.7113\n",
      "Epoch 57/200\n",
      "14/14 - 1s - loss: 0.0932 - accuracy: 0.9765 - val_loss: 0.9020 - val_accuracy: 0.7324\n",
      "Epoch 58/200\n",
      "14/14 - 1s - loss: 0.0976 - accuracy: 0.9671 - val_loss: 0.8901 - val_accuracy: 0.7183\n",
      "Epoch 59/200\n",
      "14/14 - 1s - loss: 0.2083 - accuracy: 0.9484 - val_loss: 0.8242 - val_accuracy: 0.7465\n",
      "Epoch 60/200\n",
      "14/14 - 1s - loss: 0.1189 - accuracy: 0.9671 - val_loss: 0.8095 - val_accuracy: 0.7324\n",
      "Epoch 61/200\n",
      "14/14 - 1s - loss: 0.0758 - accuracy: 0.9836 - val_loss: 0.8112 - val_accuracy: 0.7394\n",
      "Epoch 62/200\n",
      "14/14 - 1s - loss: 0.1211 - accuracy: 0.9695 - val_loss: 0.7523 - val_accuracy: 0.7535\n",
      "Epoch 63/200\n",
      "14/14 - 1s - loss: 0.1029 - accuracy: 0.9695 - val_loss: 0.9069 - val_accuracy: 0.7324\n",
      "Epoch 64/200\n",
      "14/14 - 1s - loss: 0.0656 - accuracy: 0.9953 - val_loss: 0.7467 - val_accuracy: 0.7465\n",
      "Epoch 65/200\n",
      "14/14 - 1s - loss: 0.0575 - accuracy: 0.9930 - val_loss: 0.8594 - val_accuracy: 0.7606\n",
      "Epoch 66/200\n",
      "14/14 - 1s - loss: 0.0445 - accuracy: 0.9953 - val_loss: 0.7611 - val_accuracy: 0.7465\n",
      "Epoch 67/200\n",
      "14/14 - 1s - loss: 0.0499 - accuracy: 0.9930 - val_loss: 0.6894 - val_accuracy: 0.7606\n",
      "Epoch 68/200\n",
      "14/14 - 1s - loss: 0.0597 - accuracy: 0.9836 - val_loss: 0.7641 - val_accuracy: 0.7817\n",
      "Epoch 69/200\n",
      "14/14 - 1s - loss: 0.0457 - accuracy: 0.9953 - val_loss: 0.7349 - val_accuracy: 0.7958\n",
      "Epoch 70/200\n",
      "14/14 - 1s - loss: 0.0365 - accuracy: 0.9930 - val_loss: 0.7593 - val_accuracy: 0.7746\n",
      "Epoch 71/200\n",
      "14/14 - 1s - loss: 0.0327 - accuracy: 0.9953 - val_loss: 0.6763 - val_accuracy: 0.8169\n",
      "Epoch 72/200\n",
      "14/14 - 1s - loss: 0.0372 - accuracy: 0.9977 - val_loss: 0.6900 - val_accuracy: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "14/14 - 1s - loss: 0.0269 - accuracy: 0.9953 - val_loss: 0.6740 - val_accuracy: 0.8099\n",
      "Epoch 74/200\n",
      "14/14 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8028\n",
      "Epoch 75/200\n",
      "14/14 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.7958\n",
      "Epoch 76/200\n",
      "14/14 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.7958\n",
      "Epoch 77/200\n",
      "14/14 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.7958\n",
      "Epoch 78/200\n",
      "14/14 - 1s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.7958\n",
      "Epoch 79/200\n",
      "14/14 - 1s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.8099\n",
      "Epoch 80/200\n",
      "14/14 - 1s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.7958\n",
      "Epoch 81/200\n",
      "14/14 - 1s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.7958\n",
      "Epoch 82/200\n",
      "14/14 - 1s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.7958\n",
      "Epoch 83/200\n",
      "14/14 - 1s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.8169\n",
      "Epoch 84/200\n",
      "14/14 - 1s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.8169\n",
      "Epoch 85/200\n",
      "14/14 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.8099\n",
      "Epoch 86/200\n",
      "14/14 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8169\n",
      "Epoch 87/200\n",
      "14/14 - 1s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.8239\n",
      "Epoch 88/200\n",
      "14/14 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8239\n",
      "Epoch 89/200\n",
      "14/14 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.8239\n",
      "Epoch 90/200\n",
      "14/14 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.8169\n",
      "Epoch 91/200\n",
      "14/14 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.8169\n",
      "Epoch 92/200\n",
      "14/14 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.8239\n",
      "Epoch 93/200\n",
      "14/14 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.8239\n",
      "Epoch 94/200\n",
      "14/14 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8239\n",
      "Epoch 95/200\n",
      "14/14 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.8239\n",
      "Epoch 96/200\n",
      "14/14 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8310\n",
      "Epoch 97/200\n",
      "14/14 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.8239\n",
      "Epoch 98/200\n",
      "14/14 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8239\n",
      "Epoch 99/200\n",
      "14/14 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.8169\n",
      "Epoch 100/200\n",
      "14/14 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.8239\n",
      "Epoch 101/200\n",
      "14/14 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8169\n",
      "Epoch 102/200\n",
      "14/14 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 0.8239\n",
      "Epoch 103/200\n",
      "14/14 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8239\n",
      "Epoch 104/200\n",
      "14/14 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8169\n",
      "Epoch 105/200\n",
      "14/14 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.8169\n",
      "Epoch 106/200\n",
      "14/14 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.8099\n",
      "Epoch 107/200\n",
      "14/14 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8169\n",
      "Epoch 108/200\n",
      "14/14 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8239\n",
      "Epoch 109/200\n",
      "14/14 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.8239\n",
      "Epoch 110/200\n",
      "14/14 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.8239\n",
      "Epoch 111/200\n",
      "14/14 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8239\n",
      "Epoch 112/200\n",
      "14/14 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8239\n",
      "Epoch 113/200\n",
      "14/14 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8239\n",
      "Epoch 114/200\n",
      "14/14 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.8239\n",
      "Epoch 115/200\n",
      "14/14 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8239\n",
      "Epoch 116/200\n",
      "14/14 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.8239\n",
      "Epoch 117/200\n",
      "14/14 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8239\n",
      "Epoch 118/200\n",
      "14/14 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 0.8310\n",
      "Epoch 119/200\n",
      "14/14 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8239\n",
      "Epoch 120/200\n",
      "14/14 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8239\n",
      "Epoch 121/200\n",
      "14/14 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.8310\n",
      "Epoch 122/200\n",
      "14/14 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.8239\n",
      "Epoch 123/200\n",
      "14/14 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.8310\n",
      "Epoch 124/200\n",
      "14/14 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.8239\n",
      "Epoch 125/200\n",
      "14/14 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8239\n",
      "Epoch 126/200\n",
      "14/14 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.8239\n",
      "Epoch 127/200\n",
      "14/14 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8239\n",
      "Epoch 128/200\n",
      "14/14 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.8239\n",
      "Epoch 129/200\n",
      "14/14 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.8239\n",
      "Epoch 130/200\n",
      "14/14 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8310\n",
      "Epoch 131/200\n",
      "14/14 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8239\n",
      "Epoch 132/200\n",
      "14/14 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8310\n",
      "Epoch 133/200\n",
      "14/14 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6556 - val_accuracy: 0.8239\n",
      "Epoch 134/200\n",
      "14/14 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8310\n",
      "Epoch 135/200\n",
      "14/14 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8239\n",
      "Epoch 136/200\n",
      "14/14 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8169\n",
      "Epoch 137/200\n",
      "14/14 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 0.8169\n",
      "Epoch 138/200\n",
      "14/14 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.8239\n",
      "Epoch 139/200\n",
      "14/14 - 1s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8169\n",
      "Epoch 140/200\n",
      "14/14 - 1s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8169\n",
      "Epoch 141/200\n",
      "14/14 - 1s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8169\n",
      "Epoch 142/200\n",
      "14/14 - 1s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8239\n",
      "Epoch 143/200\n",
      "14/14 - 1s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8169\n",
      "Epoch 144/200\n",
      "14/14 - 1s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.8239\n",
      "Epoch 145/200\n",
      "14/14 - 1s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8169\n",
      "Epoch 146/200\n",
      "14/14 - 1s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8169\n",
      "Epoch 147/200\n",
      "14/14 - 1s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8239\n",
      "Epoch 148/200\n",
      "14/14 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8239\n",
      "Epoch 149/200\n",
      "14/14 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8169\n",
      "Epoch 150/200\n",
      "14/14 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8239\n",
      "Epoch 151/200\n",
      "14/14 - 1s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8239\n",
      "Epoch 152/200\n",
      "14/14 - 1s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8239\n",
      "Epoch 153/200\n",
      "14/14 - 1s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8239\n",
      "Epoch 154/200\n",
      "14/14 - 1s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "14/14 - 1s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.8310\n",
      "Epoch 156/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8310\n",
      "Epoch 157/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.8310\n",
      "Epoch 158/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.8310\n",
      "Epoch 159/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.8310\n",
      "Epoch 160/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8310\n",
      "Epoch 161/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.8380\n",
      "Epoch 162/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8380\n",
      "Epoch 163/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8310\n",
      "Epoch 164/200\n",
      "14/14 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.8380\n",
      "Epoch 165/200\n",
      "14/14 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8380\n",
      "Epoch 166/200\n",
      "14/14 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8380\n",
      "Epoch 167/200\n",
      "14/14 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8451\n",
      "Epoch 168/200\n",
      "14/14 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.8380\n",
      "Epoch 169/200\n",
      "14/14 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8380\n",
      "Epoch 170/200\n",
      "14/14 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8380\n",
      "Epoch 171/200\n",
      "14/14 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8380\n",
      "Epoch 172/200\n",
      "14/14 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.8380\n",
      "Epoch 173/200\n",
      "14/14 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8380\n",
      "Epoch 174/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8380\n",
      "Epoch 175/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8380\n",
      "Epoch 176/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8380\n",
      "Epoch 177/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8380\n",
      "Epoch 178/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8380\n",
      "Epoch 179/200\n",
      "14/14 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8380\n",
      "Epoch 180/200\n",
      "14/14 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8451\n",
      "Epoch 181/200\n",
      "14/14 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.8380\n",
      "Epoch 182/200\n",
      "14/14 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8451\n",
      "Epoch 183/200\n",
      "14/14 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8521\n",
      "Epoch 184/200\n",
      "14/14 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8521\n",
      "Epoch 185/200\n",
      "14/14 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.8521\n",
      "Epoch 186/200\n",
      "14/14 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8521\n",
      "Epoch 187/200\n",
      "14/14 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8521\n",
      "Epoch 188/200\n",
      "14/14 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8592\n",
      "Epoch 189/200\n",
      "14/14 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8521\n",
      "Epoch 190/200\n",
      "14/14 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8592\n",
      "Epoch 191/200\n",
      "14/14 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8662\n",
      "Epoch 192/200\n",
      "14/14 - 1s - loss: 9.8511e-04 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.8592\n",
      "Epoch 193/200\n",
      "14/14 - 1s - loss: 9.6650e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8592\n",
      "Epoch 194/200\n",
      "14/14 - 1s - loss: 9.4731e-04 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8592\n",
      "Epoch 195/200\n",
      "14/14 - 1s - loss: 9.3116e-04 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8592\n",
      "Epoch 196/200\n",
      "14/14 - 1s - loss: 9.1380e-04 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8592\n",
      "Epoch 197/200\n",
      "14/14 - 1s - loss: 8.9669e-04 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8521\n",
      "Epoch 198/200\n",
      "14/14 - 1s - loss: 8.8036e-04 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8592\n",
      "Epoch 199/200\n",
      "14/14 - 1s - loss: 8.6726e-04 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8592\n",
      "Epoch 200/200\n",
      "14/14 - 1s - loss: 8.4877e-04 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5ed25b435af15434556249257680899d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8661971688270569</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 100, 256)          220160    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 879,116\n",
      "Trainable params: 879,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4690 - accuracy: 0.0869 - val_loss: 2.4013 - val_accuracy: 0.0915\n",
      "Epoch 2/200\n",
      "14/14 - 1s - loss: 2.3805 - accuracy: 0.1268 - val_loss: 2.3929 - val_accuracy: 0.1268\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 2.2855 - accuracy: 0.2136 - val_loss: 2.3077 - val_accuracy: 0.1549\n",
      "Epoch 4/200\n",
      "14/14 - 0s - loss: 2.1435 - accuracy: 0.2606 - val_loss: 2.1805 - val_accuracy: 0.2183\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 1.9766 - accuracy: 0.3380 - val_loss: 2.0557 - val_accuracy: 0.3239\n",
      "Epoch 6/200\n",
      "14/14 - 0s - loss: 1.7802 - accuracy: 0.4460 - val_loss: 2.0093 - val_accuracy: 0.3592\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 1.6690 - accuracy: 0.4671 - val_loss: 1.8910 - val_accuracy: 0.3803\n",
      "Epoch 8/200\n",
      "14/14 - 0s - loss: 1.4534 - accuracy: 0.5704 - val_loss: 1.6287 - val_accuracy: 0.4718\n",
      "Epoch 9/200\n",
      "14/14 - 0s - loss: 1.3135 - accuracy: 0.6127 - val_loss: 1.5783 - val_accuracy: 0.4789\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.2052 - accuracy: 0.6596 - val_loss: 1.5049 - val_accuracy: 0.4718\n",
      "Epoch 11/200\n",
      "14/14 - 0s - loss: 1.1785 - accuracy: 0.6197 - val_loss: 1.5763 - val_accuracy: 0.4718\n",
      "Epoch 12/200\n",
      "14/14 - 0s - loss: 1.1009 - accuracy: 0.6526 - val_loss: 1.4499 - val_accuracy: 0.5070\n",
      "Epoch 13/200\n",
      "14/14 - 0s - loss: 0.9541 - accuracy: 0.6690 - val_loss: 1.4181 - val_accuracy: 0.5282\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 0.9081 - accuracy: 0.7019 - val_loss: 1.3860 - val_accuracy: 0.5704\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 1.0467 - accuracy: 0.6526 - val_loss: 1.4793 - val_accuracy: 0.5141\n",
      "Epoch 16/200\n",
      "14/14 - 0s - loss: 0.8830 - accuracy: 0.7230 - val_loss: 1.3509 - val_accuracy: 0.5211\n",
      "Epoch 17/200\n",
      "14/14 - 0s - loss: 0.8300 - accuracy: 0.7300 - val_loss: 1.3248 - val_accuracy: 0.5634\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 0.7236 - accuracy: 0.7746 - val_loss: 1.2095 - val_accuracy: 0.5915\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.6876 - accuracy: 0.7887 - val_loss: 1.1208 - val_accuracy: 0.6268\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 0.5966 - accuracy: 0.8239 - val_loss: 1.2401 - val_accuracy: 0.6268\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.5574 - accuracy: 0.8310 - val_loss: 1.1807 - val_accuracy: 0.5845\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 0.5915 - accuracy: 0.8216 - val_loss: 1.2513 - val_accuracy: 0.5563\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.5346 - accuracy: 0.8357 - val_loss: 1.3250 - val_accuracy: 0.5634\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.5460 - accuracy: 0.8286 - val_loss: 1.1027 - val_accuracy: 0.5845\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.4899 - accuracy: 0.8380 - val_loss: 1.1858 - val_accuracy: 0.6197\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 0.4572 - accuracy: 0.8592 - val_loss: 1.0856 - val_accuracy: 0.6268\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 0.4409 - accuracy: 0.8709 - val_loss: 1.0426 - val_accuracy: 0.6197\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 0.4245 - accuracy: 0.8756 - val_loss: 1.0863 - val_accuracy: 0.6197\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 0.4170 - accuracy: 0.8638 - val_loss: 1.0884 - val_accuracy: 0.6127\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.4587 - accuracy: 0.8474 - val_loss: 1.1145 - val_accuracy: 0.6127\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.3994 - accuracy: 0.8615 - val_loss: 0.9968 - val_accuracy: 0.6268\n",
      "Epoch 32/200\n",
      "14/14 - 0s - loss: 0.3466 - accuracy: 0.8873 - val_loss: 0.9686 - val_accuracy: 0.6620\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 0.3326 - accuracy: 0.9038 - val_loss: 1.0223 - val_accuracy: 0.6479\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.3196 - accuracy: 0.9014 - val_loss: 1.1070 - val_accuracy: 0.6549\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 0.3089 - accuracy: 0.9038 - val_loss: 0.9694 - val_accuracy: 0.6408\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.3301 - accuracy: 0.8944 - val_loss: 1.0606 - val_accuracy: 0.6408\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 0.4002 - accuracy: 0.8592 - val_loss: 1.0072 - val_accuracy: 0.6197\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 0.4304 - accuracy: 0.8521 - val_loss: 1.0045 - val_accuracy: 0.6268\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 0.2952 - accuracy: 0.9131 - val_loss: 0.9721 - val_accuracy: 0.6831\n",
      "Epoch 40/200\n",
      "14/14 - 1s - loss: 0.2819 - accuracy: 0.9225 - val_loss: 1.0225 - val_accuracy: 0.6197\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.2556 - accuracy: 0.9061 - val_loss: 0.9266 - val_accuracy: 0.6761\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.2161 - accuracy: 0.9437 - val_loss: 0.9047 - val_accuracy: 0.6690\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.1820 - accuracy: 0.9484 - val_loss: 0.8620 - val_accuracy: 0.7183\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.1581 - accuracy: 0.9648 - val_loss: 0.9515 - val_accuracy: 0.7042\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.1612 - accuracy: 0.9695 - val_loss: 0.8873 - val_accuracy: 0.7254\n",
      "Epoch 46/200\n",
      "14/14 - 1s - loss: 0.1432 - accuracy: 0.9577 - val_loss: 0.9184 - val_accuracy: 0.6831\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.2232 - accuracy: 0.9366 - val_loss: 0.8998 - val_accuracy: 0.6690\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.3494 - accuracy: 0.8732 - val_loss: 1.2432 - val_accuracy: 0.6056\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.3969 - accuracy: 0.8662 - val_loss: 0.9023 - val_accuracy: 0.6690\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.2449 - accuracy: 0.9366 - val_loss: 0.9238 - val_accuracy: 0.6761\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.2532 - accuracy: 0.9155 - val_loss: 0.8405 - val_accuracy: 0.7324\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.1810 - accuracy: 0.9577 - val_loss: 0.8955 - val_accuracy: 0.6831\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.1436 - accuracy: 0.9742 - val_loss: 0.9249 - val_accuracy: 0.7042\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.1280 - accuracy: 0.9765 - val_loss: 0.8820 - val_accuracy: 0.6901\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.1010 - accuracy: 0.9906 - val_loss: 0.8798 - val_accuracy: 0.7113\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.0944 - accuracy: 0.9883 - val_loss: 0.8367 - val_accuracy: 0.7465\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.0831 - accuracy: 0.9930 - val_loss: 0.7753 - val_accuracy: 0.7535\n",
      "Epoch 58/200\n",
      "14/14 - 1s - loss: 0.0767 - accuracy: 0.9906 - val_loss: 0.8059 - val_accuracy: 0.7394\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.1199 - accuracy: 0.9812 - val_loss: 0.9925 - val_accuracy: 0.7183\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.1745 - accuracy: 0.9484 - val_loss: 0.9565 - val_accuracy: 0.7042\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.2246 - accuracy: 0.9343 - val_loss: 1.0151 - val_accuracy: 0.7042\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.2464 - accuracy: 0.9225 - val_loss: 0.8946 - val_accuracy: 0.6901\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.2723 - accuracy: 0.9131 - val_loss: 0.9384 - val_accuracy: 0.6972\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.2841 - accuracy: 0.9085 - val_loss: 1.0167 - val_accuracy: 0.6972\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.1644 - accuracy: 0.9507 - val_loss: 0.9457 - val_accuracy: 0.7324\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.1123 - accuracy: 0.9859 - val_loss: 0.8189 - val_accuracy: 0.7535\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0810 - accuracy: 0.9930 - val_loss: 0.8537 - val_accuracy: 0.7606\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.0670 - accuracy: 0.9930 - val_loss: 0.8279 - val_accuracy: 0.7465\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.0593 - accuracy: 0.9953 - val_loss: 0.8354 - val_accuracy: 0.7676\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.0545 - accuracy: 0.9977 - val_loss: 0.8849 - val_accuracy: 0.7183\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.0557 - accuracy: 0.9930 - val_loss: 0.8223 - val_accuracy: 0.7676\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.0518 - accuracy: 0.9953 - val_loss: 0.7670 - val_accuracy: 0.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.7817\n",
      "Epoch 74/200\n",
      "14/14 - 1s - loss: 0.0419 - accuracy: 0.9953 - val_loss: 0.7746 - val_accuracy: 0.7746\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0435 - accuracy: 0.9977 - val_loss: 0.7995 - val_accuracy: 0.7817\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.0396 - accuracy: 0.9977 - val_loss: 0.8064 - val_accuracy: 0.7535\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.0525 - accuracy: 0.9930 - val_loss: 0.9941 - val_accuracy: 0.7324\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.0818 - accuracy: 0.9789 - val_loss: 0.9324 - val_accuracy: 0.7183\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.1100 - accuracy: 0.9718 - val_loss: 0.7765 - val_accuracy: 0.7465\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0801 - accuracy: 0.9812 - val_loss: 0.7364 - val_accuracy: 0.7887\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.1420 - accuracy: 0.9648 - val_loss: 0.8514 - val_accuracy: 0.7394\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.1590 - accuracy: 0.9460 - val_loss: 0.8280 - val_accuracy: 0.7394\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.1817 - accuracy: 0.9484 - val_loss: 0.8700 - val_accuracy: 0.7676\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.1068 - accuracy: 0.9859 - val_loss: 0.8014 - val_accuracy: 0.7535\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.0838 - accuracy: 0.9789 - val_loss: 0.8236 - val_accuracy: 0.7606\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0733 - accuracy: 0.9883 - val_loss: 0.8466 - val_accuracy: 0.7887\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0850 - accuracy: 0.9859 - val_loss: 0.8858 - val_accuracy: 0.7606\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0606 - accuracy: 0.9953 - val_loss: 0.8225 - val_accuracy: 0.7465\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0487 - accuracy: 0.9930 - val_loss: 0.9269 - val_accuracy: 0.7606\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.1366 - accuracy: 0.9671 - val_loss: 0.9773 - val_accuracy: 0.7042\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.2143 - accuracy: 0.9272 - val_loss: 0.8841 - val_accuracy: 0.7324\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.1427 - accuracy: 0.9554 - val_loss: 0.8938 - val_accuracy: 0.7746\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.1820 - accuracy: 0.9484 - val_loss: 0.9127 - val_accuracy: 0.7394\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.1226 - accuracy: 0.9671 - val_loss: 0.8068 - val_accuracy: 0.7676\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0700 - accuracy: 0.9836 - val_loss: 0.7172 - val_accuracy: 0.7606\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.0821 - accuracy: 0.9789 - val_loss: 0.6885 - val_accuracy: 0.8099\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.0741 - accuracy: 0.9930 - val_loss: 0.6783 - val_accuracy: 0.8099\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0563 - accuracy: 0.9930 - val_loss: 0.6335 - val_accuracy: 0.8239\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.0478 - accuracy: 0.9883 - val_loss: 0.7843 - val_accuracy: 0.7817\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0618 - accuracy: 0.9883 - val_loss: 0.7831 - val_accuracy: 0.7676\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0434 - accuracy: 0.9953 - val_loss: 0.7423 - val_accuracy: 0.7887\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.7887\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.7817\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.8099\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8099\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.0210 - accuracy: 0.9977 - val_loss: 0.7306 - val_accuracy: 0.7958\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.7887\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8099\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8099\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8169\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8099\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.8099\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.8239\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8099\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.8099\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.8099\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8099\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8169\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8099\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8169\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.8169\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7214 - val_accuracy: 0.8099\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8099\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.8099\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8099\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8099\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.7247 - val_accuracy: 0.8099\n",
      "Epoch 128/200\n",
      "14/14 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8169\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.8099\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8028\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8028\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8028\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8169\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.8099\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8099\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8169\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8169\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.8169\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.8239\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.8099\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.7289 - val_accuracy: 0.8239\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8239\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8169\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8169\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8169\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.8169\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8169\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.8169\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.8169\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.8169\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8169\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.8169\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8169\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8169\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-27a56ed6078d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#tuner.search_space_summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m tuner.search(x=x_train,      #syntax just like in fit\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner  = RandomSearch(\n",
    "    build_model_bdlstm,     #Function to use search in... See different builds above\n",
    "    objective = \"val_accuracy\",  #Chooses \"best model\" looking for highest value of val_accuracy\n",
    "    max_trials = 30,       # Number of different combinations tried Nodes and layers\n",
    "    executions_per_trial = 1, \n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train,      #syntax just like in fit\n",
    "                y= y_train,\n",
    "            epochs=200,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val),\n",
    "            verbose=2\n",
    "            )\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Hyperband\n",
    "Variation of RandomSearch http://jmlr.org/papers/volume18/16-558/16-558.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner  = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=150,\n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train, \n",
    "            y= y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laut Randomsearch bestes Model am 23.06.2020\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True)) \n",
    "model.add(layers.LSTM(96))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=170,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_19 (Bidirectio (None, 100, 512)          702464    \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 100, 384)          1082880   \n",
      "_________________________________________________________________\n",
      "bidirectional_21 (Bidirectio (None, 128)               229888    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,016,780\n",
      "Trainable params: 2,016,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(layers.LSTM(256, return_sequences=True),\n",
    "                                        input_shape=(100, 86)))\n",
    "    \n",
    "model.add(layers.Bidirectional(layers.LSTM(192,return_sequences=True)))\n",
    "    \n",
    "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  optimizer='Adamax',\n",
    "                  metrics='accuracy') \n",
    "model.summary()\n",
    "#history=model.fit(x_train,y_train,epochs=170,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tuner object into pickle file\n",
    "so it can be used in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_\"f\"{starttime}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best Trial from Tuner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "bestmodel= tuner.hypermodel.build(best_hp)\n",
    "\n",
    "bestmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 - 2s - loss: 2.4932 - accuracy: 0.0986 - val_loss: 2.4271 - val_accuracy: 0.0845\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 2.4145 - accuracy: 0.1408 - val_loss: 2.4145 - val_accuracy: 0.0915\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 2.3220 - accuracy: 0.1761 - val_loss: 2.3426 - val_accuracy: 0.1479\n",
      "Epoch 4/200\n",
      "14/14 - 0s - loss: 2.1796 - accuracy: 0.2488 - val_loss: 2.2356 - val_accuracy: 0.2042\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 2.0189 - accuracy: 0.3474 - val_loss: 2.1792 - val_accuracy: 0.2465\n",
      "Epoch 6/200\n",
      "14/14 - 0s - loss: 1.8795 - accuracy: 0.3944 - val_loss: 1.9614 - val_accuracy: 0.3732\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 1.6340 - accuracy: 0.5094 - val_loss: 1.9169 - val_accuracy: 0.3592\n",
      "Epoch 8/200\n",
      "14/14 - 1s - loss: 1.5186 - accuracy: 0.5000 - val_loss: 1.7466 - val_accuracy: 0.4507\n",
      "Epoch 9/200\n",
      "14/14 - 1s - loss: 1.3658 - accuracy: 0.5892 - val_loss: 1.7231 - val_accuracy: 0.3873\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.3070 - accuracy: 0.5869 - val_loss: 1.7869 - val_accuracy: 0.4225\n",
      "Epoch 11/200\n",
      "14/14 - 1s - loss: 1.3419 - accuracy: 0.5587 - val_loss: 1.5946 - val_accuracy: 0.4577\n",
      "Epoch 12/200\n",
      "14/14 - 0s - loss: 1.1358 - accuracy: 0.6362 - val_loss: 1.6075 - val_accuracy: 0.4437\n",
      "Epoch 13/200\n",
      "14/14 - 0s - loss: 1.0391 - accuracy: 0.6620 - val_loss: 1.5337 - val_accuracy: 0.4648\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 0.9448 - accuracy: 0.6948 - val_loss: 1.5720 - val_accuracy: 0.4366\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 0.9103 - accuracy: 0.7019 - val_loss: 1.5064 - val_accuracy: 0.5070\n",
      "Epoch 16/200\n",
      "14/14 - 0s - loss: 0.9407 - accuracy: 0.7113 - val_loss: 1.5114 - val_accuracy: 0.5070\n",
      "Epoch 17/200\n",
      "14/14 - 0s - loss: 1.0436 - accuracy: 0.6268 - val_loss: 1.6589 - val_accuracy: 0.4718\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 1.0224 - accuracy: 0.6502 - val_loss: 1.4208 - val_accuracy: 0.5211\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.8533 - accuracy: 0.6784 - val_loss: 1.3540 - val_accuracy: 0.5141\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 0.7905 - accuracy: 0.7347 - val_loss: 1.4012 - val_accuracy: 0.5141\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.8205 - accuracy: 0.7113 - val_loss: 1.2969 - val_accuracy: 0.5282\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 0.7419 - accuracy: 0.7441 - val_loss: 1.2764 - val_accuracy: 0.4930\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.6745 - accuracy: 0.7746 - val_loss: 1.2090 - val_accuracy: 0.5775\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.6695 - accuracy: 0.7817 - val_loss: 1.3841 - val_accuracy: 0.5282\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.6507 - accuracy: 0.7840 - val_loss: 1.2135 - val_accuracy: 0.5775\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 0.6858 - accuracy: 0.7676 - val_loss: 1.3119 - val_accuracy: 0.5563\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 0.6337 - accuracy: 0.7981 - val_loss: 1.2405 - val_accuracy: 0.6056\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 0.5591 - accuracy: 0.8169 - val_loss: 1.1478 - val_accuracy: 0.6056\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 0.4844 - accuracy: 0.8756 - val_loss: 1.0973 - val_accuracy: 0.6056\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.4650 - accuracy: 0.8732 - val_loss: 1.1377 - val_accuracy: 0.6127\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.4590 - accuracy: 0.8474 - val_loss: 1.1918 - val_accuracy: 0.6056\n",
      "Epoch 32/200\n",
      "14/14 - 0s - loss: 0.4844 - accuracy: 0.8333 - val_loss: 1.0724 - val_accuracy: 0.6268\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 0.4045 - accuracy: 0.8732 - val_loss: 1.1236 - val_accuracy: 0.6197\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.4759 - accuracy: 0.8638 - val_loss: 1.1847 - val_accuracy: 0.6197\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 0.4208 - accuracy: 0.8920 - val_loss: 1.2358 - val_accuracy: 0.6127\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.4131 - accuracy: 0.8779 - val_loss: 1.3054 - val_accuracy: 0.6056\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 0.3921 - accuracy: 0.8850 - val_loss: 1.3711 - val_accuracy: 0.5775\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 0.4145 - accuracy: 0.8756 - val_loss: 1.1067 - val_accuracy: 0.6197\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 0.2879 - accuracy: 0.9249 - val_loss: 1.1606 - val_accuracy: 0.5986\n",
      "Epoch 40/200\n",
      "14/14 - 0s - loss: 0.3073 - accuracy: 0.9202 - val_loss: 1.1492 - val_accuracy: 0.6127\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.3875 - accuracy: 0.8779 - val_loss: 1.2303 - val_accuracy: 0.6056\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.3768 - accuracy: 0.8779 - val_loss: 1.1405 - val_accuracy: 0.6127\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.3048 - accuracy: 0.9178 - val_loss: 1.0488 - val_accuracy: 0.6549\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.2430 - accuracy: 0.9366 - val_loss: 1.0268 - val_accuracy: 0.6620\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.2163 - accuracy: 0.9366 - val_loss: 1.0137 - val_accuracy: 0.6831\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.1894 - accuracy: 0.9554 - val_loss: 0.9487 - val_accuracy: 0.6761\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.1831 - accuracy: 0.9554 - val_loss: 1.0272 - val_accuracy: 0.6901\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.1800 - accuracy: 0.9507 - val_loss: 1.0346 - val_accuracy: 0.6972\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.1730 - accuracy: 0.9671 - val_loss: 1.0907 - val_accuracy: 0.6338\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.1895 - accuracy: 0.9577 - val_loss: 1.0405 - val_accuracy: 0.6338\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.1894 - accuracy: 0.9390 - val_loss: 1.0000 - val_accuracy: 0.6549\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.1599 - accuracy: 0.9554 - val_loss: 1.0123 - val_accuracy: 0.6479\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.1422 - accuracy: 0.9671 - val_loss: 1.1077 - val_accuracy: 0.6549\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.1608 - accuracy: 0.9601 - val_loss: 1.0058 - val_accuracy: 0.7042\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.1531 - accuracy: 0.9624 - val_loss: 1.2453 - val_accuracy: 0.6690\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.2301 - accuracy: 0.9343 - val_loss: 1.1259 - val_accuracy: 0.6690\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.1964 - accuracy: 0.9554 - val_loss: 1.0577 - val_accuracy: 0.6620\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.1614 - accuracy: 0.9624 - val_loss: 1.0329 - val_accuracy: 0.6620\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.1918 - accuracy: 0.9343 - val_loss: 1.0888 - val_accuracy: 0.6549\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.1922 - accuracy: 0.9507 - val_loss: 0.9962 - val_accuracy: 0.6972\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.1225 - accuracy: 0.9812 - val_loss: 0.9123 - val_accuracy: 0.6972\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.0913 - accuracy: 0.9836 - val_loss: 0.9051 - val_accuracy: 0.7042\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.0864 - accuracy: 0.9883 - val_loss: 0.9888 - val_accuracy: 0.6831\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.0659 - accuracy: 0.9906 - val_loss: 0.9144 - val_accuracy: 0.7113\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.0503 - accuracy: 0.9977 - val_loss: 0.8822 - val_accuracy: 0.7465\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.7254\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0392 - accuracy: 0.9977 - val_loss: 0.8832 - val_accuracy: 0.7465\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.8863 - val_accuracy: 0.7676\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.7465\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.8847 - val_accuracy: 0.7535\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.7535\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.7535\n",
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.7606\n",
      "Epoch 74/200\n",
      "14/14 - 0s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.7606\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7676\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.7676\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.7676\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.7676\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.7676\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.8836 - val_accuracy: 0.7676\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8864 - val_accuracy: 0.7676\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.7676\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.7676\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.7746\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.7676\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.7676\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.7676\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7676\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.7676\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.7676\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.7676\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8911 - val_accuracy: 0.7676\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.7676\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.7606\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.7676\n",
      "Epoch 97/200\n",
      "14/14 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.7746\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.7676\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.7606\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.7606\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8920 - val_accuracy: 0.7746\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8977 - val_accuracy: 0.7606\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.7606\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.7606\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8881 - val_accuracy: 0.7746\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8903 - val_accuracy: 0.7606\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.7606\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7676\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8850 - val_accuracy: 0.7746\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.7606\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.7746\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.7746\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.7746\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.7746\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.7746\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.7746\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.7746\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8726 - val_accuracy: 0.7746\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8723 - val_accuracy: 0.7817\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.7817\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.7817\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.7817\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.7887\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.7887\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.7887\n",
      "Epoch 126/200\n",
      "14/14 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.7887\n",
      "Epoch 127/200\n",
      "14/14 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8785 - val_accuracy: 0.7887\n",
      "Epoch 128/200\n",
      "14/14 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.7958\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.7887\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.8028\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.7887\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.7958\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.7887\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.7887\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.7958\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.7887\n",
      "Epoch 137/200\n",
      "14/14 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.7887\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.8028\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.7887\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.7887\n",
      "Epoch 141/200\n",
      "14/14 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8028\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.7887\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.7887\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8700 - val_accuracy: 0.8028\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7958\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8770 - val_accuracy: 0.7958\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.8028\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.7958\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8790 - val_accuracy: 0.7958\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8784 - val_accuracy: 0.7958\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.8028\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.7887\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.8028\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.8028\n",
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.7958\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.7887\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8770 - val_accuracy: 0.7958\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.7958\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8766 - val_accuracy: 0.7958\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.7887\n",
      "Epoch 161/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.7887\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.8028\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.7958\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.7887\n",
      "Epoch 166/200\n",
      "14/14 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.7958\n",
      "Epoch 167/200\n",
      "14/14 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.7958\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.7746\n",
      "Epoch 169/200\n",
      "14/14 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.7746\n",
      "Epoch 170/200\n",
      "14/14 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.7958\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.7958\n",
      "Epoch 172/200\n",
      "14/14 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.7746\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.7746\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.7817\n",
      "Epoch 175/200\n",
      "14/14 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.7887\n",
      "Epoch 176/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.7746\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.7746\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.7817\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.7817\n",
      "Epoch 180/200\n",
      "14/14 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.7746\n",
      "Epoch 181/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.7746\n",
      "Epoch 182/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8740 - val_accuracy: 0.7817\n",
      "Epoch 183/200\n",
      "14/14 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.7958\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.7817\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.7887\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.7887\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8710 - val_accuracy: 0.7887\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.7887\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7817\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7958\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8689 - val_accuracy: 0.7958\n",
      "Epoch 192/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8703 - val_accuracy: 0.7958\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.8028\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.7958\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.8028\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.7958\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.8028\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 9.9144e-04 - accuracy: 1.0000 - val_loss: 0.8669 - val_accuracy: 0.7958\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 9.7570e-04 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.7958\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 9.5796e-04 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.7958\n"
     ]
    }
   ],
   "source": [
    "#tmp_chekpoints= \"tmp\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "#csv_log = tf.keras.callbacks.CSVLogger(\"log.csv\", separator=',', append=False)\n",
    "csv_log = tf.keras.callbacks.CSVLogger(\"C:\\ML\\logs\\log.csv\", separator=',', append=False)\n",
    "\n",
    "#tb = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir='C:\\ML\\logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "chk= tf.keras.callbacks.ModelCheckpoint(tmp_chekpoints, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=200,batch_size=32, validation_data=(x_val,y_val),shuffle=False, verbose=2, callbacks=[csv_log, chk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/ML/loss2020_07_09_213429.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-32bb7328fcc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/ML/loss\"\u001b[0m\u001b[0;34mf\"{starttime}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m                 result = print_method(\n\u001b[0m\u001b[1;32m   2120\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[1;32m    537\u001b[0m                                metadata={**default_metadata, **metadata})\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor-gpu/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/ML/loss2020_07_09_213429.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.savefig(\"C:/ML/loss\"f\"{starttime}.png\")\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower right')\n",
    "pyplot.savefig(\"C:/ML/accuracy_\"f\"{starttime}.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit Example\n",
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png\" width=\"400\">\n",
    "\n",
    "#### Good Fit Example\n",
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-a-Good-Fit-for-a-Model.png\" width=\"400\">\n",
    "\n",
    "#### Overfit Example\n",
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "This may be a sign of too many training epochs.\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./tmp/epoch49-0.90-0.39.hdf5')\n",
    "\n",
    "\n",
    "#bestmodel.evaluate(x=x_test, y=y_test, verbose=2)\n",
    "model.evaluate(x=x_test, y=y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel.save(\"sign_lang_recognition_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
