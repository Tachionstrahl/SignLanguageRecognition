{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"./data/\"  \n",
    "\n",
    "# Constant frame count.\n",
    "frames = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation Stage\n",
    "### Load data and normalize\n",
    "For training it's required to extend/reduce every dataset to n frames, where n is `frames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listfile = os.listdir(dirname)\n",
    "data = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, frames)), fill_value=0.0)\n",
    "        content.fillna(0.0, inplace = True) \n",
    "        data.append((wordname, content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zeigen'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the content of the first dataframe\n",
    "data[700][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "Split the dataset up into the following segments:\n",
    "1. Training Data: 60%\n",
    "2. Validation Data: 20%\n",
    "3. Test Data: 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [n[1] for n in data]\n",
    "features = [f.to_numpy() for f in features]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.40, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Klassensätze\n",
      "Computer :  57;  Deutschland :  65;  Haben :  68;  Hallo :  57;  Mainz :  65;  Software :  67;  Welt :  66;  du :  66;  ich :  66;  unser :  64;  zeigen :  69;   \n",
      "Trainings Klassensätze\n",
      "Computer :  31;  Deutschland :  30;  Haben :  38;  Hallo :  34;  Mainz :  38;  Software :  46;  Welt :  43;  du :  42;  ich :  37;  unser :  43;  zeigen :  44;   \n",
      "Validation Klassensätze\n",
      "Computer :  13;  Deutschland :  15;  Haben :  11;  Hallo :  11;  Mainz :  10;  Software :  13;  Welt :  14;  du :  13;  ich :  19;  unser :  10;  zeigen :  13;   \n",
      "Test Klassensätze\n",
      "Computer :  13;  Deutschland :  20;  Haben :  19;  Hallo :  12;  Mainz :  17;  Software :  8;  Welt :  9;  du :  11;  ich :  10;  unser :  11;  zeigen :  12;   \n"
     ]
    }
   ],
   "source": [
    "def printCountDataSets(dataset):\n",
    "    wortCounter = []\n",
    "    #Liste mit einmaligen Labels erstellen\n",
    "    labels = sorted(set(dataset), key=dataset.index)\n",
    "    #Liste nochmal Alphabetisch sortieren\n",
    "    labels = sorted(labels)\n",
    "    for label in labels:\n",
    "        wortCounter.append(0)\n",
    "    for row in dataset:\n",
    "        for i in range(len(labels)):\n",
    "            if str(labels[i]).startswith(row):\n",
    "                wortCounter[i] += 1\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i], ': ', wortCounter[i], end =\";  \")\n",
    "    print(' ')        \n",
    "        \n",
    "print('Alle Klassensätze')\n",
    "printCountDataSets(labels)\n",
    "print('Trainings Klassensätze')\n",
    "printCountDataSets(y_train)\n",
    "print('Validation Klassensätze')\n",
    "printCountDataSets(y_val)  \n",
    "print('Test Klassensätze')\n",
    "printCountDataSets(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 710\n",
      "Training: 426 60.0\n",
      "Val: 142 20.0\n",
      "Test: 142 20.0\n"
     ]
    }
   ],
   "source": [
    "# Display data distribution\n",
    "print(\"Total:\", len(labels))\n",
    "print(\"Training:\", len(y_train), len(y_train) / len(labels) * 100)\n",
    "print(\"Val:\", len(y_val), len(y_val) / len(labels) * 100)\n",
    "print(\"Test:\", len(y_test), len(y_test) / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize (One Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'deutschland': 2, 'du': 3, 'haben': 4, 'hallo': 5, 'ich': 6, 'mainz': 7, 'software': 8, 'unser': 9, 'welt': 10, 'zeigen': 11}\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tools.tokenize(dirname)\n",
    "print(tokenizer.word_index)\n",
    "\n",
    "with open('tokens_json.txt', 'w') as outfile:\n",
    "    outfile.write(tokenizer.to_json())\n",
    "\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_val=tokenizer.texts_to_sequences([y_val])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "\n",
    "y_train = to_categorical(encoded_train)\n",
    "y_val = to_categorical(encoded_val)\n",
    "y_test = to_categorical(encoded_test)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_val=np.array(x_val)\n",
    "y_val=np.array(y_val)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.39615  0.398918 0.267371 ... 0.981109 0.505336 0.997934]\n",
      "  [0.395785 0.39586  0.249782 ... 1.0012   0.500846 1.02185 ]\n",
      "  [0.397311 0.395266 0.247748 ... 0.954924 0.514182 0.971554]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]\n",
      "\n",
      " [[0.374127 0.427507 0.466542 ... 0.       0.       0.      ]\n",
      "  [0.371845 0.434132 0.453027 ... 0.       0.       0.      ]\n",
      "  [0.369134 0.440652 0.450106 ... 0.       0.       0.      ]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]\n",
      "\n",
      " [[0.441569 0.323025 0.       ... 0.       0.       0.      ]\n",
      "  [0.442028 0.322752 0.       ... 0.       0.       0.      ]\n",
      "  [0.440985 0.323315 0.       ... 0.       0.       0.      ]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.445863 0.426787 0.       ... 0.       0.       0.      ]\n",
      "  [0.447222 0.427649 0.       ... 0.       0.       0.      ]\n",
      "  [0.447077 0.426849 0.       ... 0.       0.       0.      ]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]\n",
      "\n",
      " [[0.493763 0.242344 0.       ... 0.       0.       0.      ]\n",
      "  [0.494503 0.237877 0.       ... 0.       0.       0.      ]\n",
      "  [0.495819 0.230682 0.       ... 0.       0.       0.      ]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]\n",
      "\n",
      " [[0.47383  0.146982 0.       ... 0.       0.       0.      ]\n",
      "  [0.474502 0.146467 0.       ... 0.       0.       0.      ]\n",
      "  [0.474695 0.146444 0.       ... 0.       0.       0.      ]\n",
      "  ...\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]\n",
      "  [0.       0.       0.       ... 0.       0.       0.      ]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage\n",
    "Configure the model and train it.\n",
    "\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
    "<img src=\"assets/precision_recall.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model\n",
    "Configures the model with the specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(256, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(layers.LSTM(32))  # return a single vector of dimension 32\n",
    "#model.add(layers.LSTM(16))  # return a single vector of dimension 32\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or\n",
    "#### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(100, 86)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or\n",
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, input_shape=(200, 42)))\n",
    "model.add(Dense(64, activation=\"softmax\")) #softmax, linear 어떤걸 기준으로 하지\n",
    "model.add(Dense(128, activation=\"linear\")) #softmax, linear 어떤걸 기준으로 하지\n",
    "model.add(Dense(21))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or\n",
    "#### <span style=\"color:blue\"> Hyperparametertuned LSTM </span>\n",
    "##### Here it is necessary to install the Keras-Tuner Module by executing:\n",
    "#####  <span style=\"color:green\"> via Conda:</span>\n",
    "conda install -c conda-forge keras-tuner\n",
    "#####  <span style=\"color:green\"> for pip:</span>\n",
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from time import time, strftime\n",
    "\n",
    "\n",
    "starttime= strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "LOG_DIR = \"C:\\ML\\Optimization_\"f\"{starttime}\" #<-In Windows below Log_dir Path will maybe be too long for Windows to handle, so use a shorter path like this here\n",
    "#LOG_DIR = \"./Optimization_\"f\"{starttime}\" # LOG_DIR holds json files with information and a model of each single trial\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <span style=\"color:red\">Necesarry only in case of using Nvidia GPU  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1752: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Keras-Tuner Approaches\n",
    "### 1 - RandomSearch\n",
    "Parameter of variables are ranomly used (number of layers, number of nodes) and \"best\" model is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 172,300\n",
      "Trainable params: 172,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 64)           65792     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 456,204\n",
      "Trainable params: 456,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:21 - loss: 2.4870 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 23s - loss: 2.4811 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 11s - loss: 2.4613 - accuracy: 0.1688 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 6s - loss: 2.4359 - accuracy: 0.1741 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 3s - loss: 2.4162 - accuracy: 0.1632 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.3688 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3249 - accuracy: 0.1755 - precision: 0.0000e+00 - recall: 0.0000e+0 - 9s 21ms/sample - loss: 2.3217 - accuracy: 0.1808 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.5658 - val_accuracy: 0.0704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4672 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4791 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4947 - accuracy: 0.1406 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4958 - accuracy: 0.1302 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4836 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4645 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4521 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4355 - accuracy: 0.1298 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.4324 - accuracy: 0.1291 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4426 - val_accuracy: 0.0986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3556 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3124 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3042 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2985 - accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2901 - accuracy: 0.1597 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2807 - accuracy: 0.1648 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2838 - accuracy: 0.1641 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.2818 - accuracy: 0.1549 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2324 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1336 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1122 - accuracy: 0.1406 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1450 - accuracy: 0.1719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1178 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1168 - accuracy: 0.1786 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1181 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1287 - accuracy: 0.1818 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1191 - accuracy: 0.1849 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.1021 - accuracy: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0032 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6871 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9993 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0398 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9937 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0050 - accuracy: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0058 - accuracy: 0.1818 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0054 - accuracy: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9984 - accuracy: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8864 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7958 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8829 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8742 - accuracy: 0.2344 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9153 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9105 - accuracy: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9201 - accuracy: 0.1781 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9192 - accuracy: 0.1849 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9092 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8497 - val_accuracy: 0.1479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8103 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8475 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8518 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8607 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8861 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8774 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8950 - accuracy: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9027 - accuracy: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9236 - accuracy: 0.1827 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9255 - accuracy: 0.1808 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8588 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8119 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8188 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8530 - accuracy: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9234 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9234 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9287 - accuracy: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9386 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9443 - accuracy: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9413 - accuracy: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9390 - accuracy: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8125 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8932 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9302 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9035 - accuracy: 0.2750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9672 - accuracy: 0.2552 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9132 - accuracy: 0.2695 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9253 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9178 - accuracy: 0.2469 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9136 - accuracy: 0.2266 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9086 - accuracy: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8167 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7868 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8380 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8745 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8649 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8633 - accuracy: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8647 - accuracy: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8636 - accuracy: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8729 - accuracy: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8628 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0262 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9597 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9520 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9356 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9170 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8852 - accuracy: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8756 - accuracy: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8798 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0946 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0641 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2220 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1415 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0553 - accuracy: 0.1652 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0294 - accuracy: 0.1840 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0303 - accuracy: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0299 - accuracy: 0.1923 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0270 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8517 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8406 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7915 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8158 - accuracy: 0.2679 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8205 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8607 - accuracy: 0.2472 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8442 - accuracy: 0.2476 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8522 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8249 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8902 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9722 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8969 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8610 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8581 - accuracy: 0.2361 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8295 - accuracy: 0.2472 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8221 - accuracy: 0.2380 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8197 - accuracy: 0.2371 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7827 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8202 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7823 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8077 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8341 - accuracy: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8319 - accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8429 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8403 - accuracy: 0.2284 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8367 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7808 - val_accuracy: 0.2887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7193 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7726 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7501 - accuracy: 0.2937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7574 - accuracy: 0.2991 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7839 - accuracy: 0.2778 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7865 - accuracy: 0.2983 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8130 - accuracy: 0.2837 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8172 - accuracy: 0.2793 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8516 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7720 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8797 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8455 - accuracy: 0.1750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8985 - accuracy: 0.1607 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9324 - accuracy: 0.1632 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9359 - accuracy: 0.1591 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9084 - accuracy: 0.1659 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8999 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8622 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9367 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9080 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8406 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8525 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8353 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8323 - accuracy: 0.2472 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8186 - accuracy: 0.2404 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8142 - accuracy: 0.2418 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8355 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8194 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7899 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7785 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7780 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7592 - accuracy: 0.2222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7754 - accuracy: 0.2358 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8442 - accuracy: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8526 - accuracy: 0.2254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8422 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8146 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7465 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7865 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7505 - accuracy: 0.2946 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7490 - accuracy: 0.2639 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7651 - accuracy: 0.2557 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7435 - accuracy: 0.2668 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7453 - accuracy: 0.2653 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7752 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6119 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7135 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7635 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7807 - accuracy: 0.3036 - precision: 0.5000 - recall: 0.0045        - ETA: 0s - loss: 1.7756 - accuracy: 0.2882 - precision: 0.4000 - recall: 0.006 - ETA: 0s - loss: 1.7499 - accuracy: 0.3011 - precision: 0.4286 - recall: 0.008 - ETA: 0s - loss: 1.7236 - accuracy: 0.3077 - precision: 0.5000 - recall: 0.009 - 1s 1ms/sample - loss: 1.7172 - accuracy: 0.3075 - precision: 0.5000 - recall: 0.0094 - val_loss: 1.7104 - val_accuracy: 0.3239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6961 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7278 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7320 - accuracy: 0.2750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7018 - accuracy: 0.3170 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6863 - accuracy: 0.3299 - precision: 1.0000 - recall: 0.0035        - ETA: 0s - loss: 1.6915 - accuracy: 0.3182 - precision: 0.6667 - recall: 0.005 - ETA: 0s - loss: 1.6685 - accuracy: 0.3269 - precision: 0.7500 - recall: 0.007 - 1s 1ms/sample - loss: 1.6654 - accuracy: 0.3310 - precision: 0.7500 - recall: 0.0070 - val_loss: 1.6778 - val_accuracy: 0.3451 - val_precision: 0.6000 - val_recall: 0.0211\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8142 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6771 - accuracy: 0.3542 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.6698 - accuracy: 0.3875 - precision: 0.7500 - recall: 0.018 - ETA: 0s - loss: 1.6733 - accuracy: 0.3884 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.6856 - accuracy: 0.3542 - precision: 0.5833 - recall: 0.024 - ETA: 0s - loss: 1.6918 - accuracy: 0.3494 - precision: 0.6000 - recall: 0.034 - ETA: 0s - loss: 1.6846 - accuracy: 0.3413 - precision: 0.5833 - recall: 0.033 - 1s 1ms/sample - loss: 1.6873 - accuracy: 0.3451 - precision: 0.5833 - recall: 0.0329 - val_loss: 1.7248 - val_accuracy: 0.2958 - val_precision: 0.5000 - val_recall: 0.0070\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6199 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6940 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7295 - accuracy: 0.2937 - precision: 0.7500 - recall: 0.0188        - ETA: 0s - loss: 1.7101 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.026 - ETA: 0s - loss: 1.7141 - accuracy: 0.2986 - precision: 0.4000 - recall: 0.027 - ETA: 0s - loss: 1.7037 - accuracy: 0.3068 - precision: 0.4074 - recall: 0.031 - ETA: 0s - loss: 1.7073 - accuracy: 0.3125 - precision: 0.4074 - recall: 0.026 - 1s 1ms/sample - loss: 1.7075 - accuracy: 0.3075 - precision: 0.4074 - recall: 0.0258 - val_loss: 1.6648 - val_accuracy: 0.2958 - val_precision: 0.6000 - val_recall: 0.0211\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5071 - accuracy: 0.4375 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4984 - accuracy: 0.4271 - precision: 0.5455 - recall: 0.062 - ETA: 0s - loss: 1.5374 - accuracy: 0.3875 - precision: 0.5385 - recall: 0.043 - ETA: 0s - loss: 1.5919 - accuracy: 0.3571 - precision: 0.4667 - recall: 0.031 - ETA: 0s - loss: 1.6132 - accuracy: 0.3507 - precision: 0.4667 - recall: 0.024 - ETA: 0s - loss: 1.6438 - accuracy: 0.3523 - precision: 0.4667 - recall: 0.019 - ETA: 0s - loss: 1.6627 - accuracy: 0.3413 - precision: 0.4667 - recall: 0.016 - 1s 1ms/sample - loss: 1.6608 - accuracy: 0.3404 - precision: 0.4667 - recall: 0.0164 - val_loss: 1.5861 - val_accuracy: 0.3239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5630 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6185 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6397 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6612 - accuracy: 0.3214 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6204 - accuracy: 0.3576 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6076 - accuracy: 0.3693 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6041 - accuracy: 0.3582 - precision: 0.7500 - recall: 0.0072        - 1s 1ms/sample - loss: 1.5978 - accuracy: 0.3615 - precision: 0.8000 - recall: 0.0094 - val_loss: 1.5466 - val_accuracy: 0.3873 - val_precision: 0.8125 - val_recall: 0.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5189 - accuracy: 0.5312 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5927 - accuracy: 0.4167 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.5619 - accuracy: 0.4000 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.5741 - accuracy: 0.3884 - precision: 0.6071 - recall: 0.075 - ETA: 0s - loss: 1.5660 - accuracy: 0.4062 - precision: 0.6250 - recall: 0.069 - ETA: 0s - loss: 1.5672 - accuracy: 0.3977 - precision: 0.6579 - recall: 0.071 - ETA: 0s - loss: 1.5556 - accuracy: 0.3942 - precision: 0.7045 - recall: 0.074 - 1s 1ms/sample - loss: 1.5507 - accuracy: 0.3991 - precision: 0.7111 - recall: 0.0751 - val_loss: 1.6012 - val_accuracy: 0.3451 - val_precision: 0.8571 - val_recall: 0.0845\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4603 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5006 - accuracy: 0.3646 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.5785 - accuracy: 0.3938 - precision: 0.7500 - recall: 0.075 - ETA: 0s - loss: 1.5659 - accuracy: 0.3795 - precision: 0.7500 - recall: 0.067 - ETA: 0s - loss: 1.5738 - accuracy: 0.3785 - precision: 0.7692 - recall: 0.069 - ETA: 0s - loss: 1.5535 - accuracy: 0.3892 - precision: 0.7250 - recall: 0.082 - ETA: 0s - loss: 1.5530 - accuracy: 0.3798 - precision: 0.7234 - recall: 0.081 - 1s 1ms/sample - loss: 1.5547 - accuracy: 0.3756 - precision: 0.7234 - recall: 0.0798 - val_loss: 1.4831 - val_accuracy: 0.3873 - val_precision: 0.8947 - val_recall: 0.1197\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7009 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6641 - accuracy: 0.3333 - precision: 0.3333 - recall: 0.052 - ETA: 0s - loss: 1.6434 - accuracy: 0.3375 - precision: 0.4800 - recall: 0.075 - ETA: 0s - loss: 1.6054 - accuracy: 0.3527 - precision: 0.5172 - recall: 0.067 - ETA: 0s - loss: 1.5946 - accuracy: 0.3646 - precision: 0.6216 - recall: 0.079 - ETA: 0s - loss: 1.5927 - accuracy: 0.3551 - precision: 0.6364 - recall: 0.079 - ETA: 0s - loss: 1.5639 - accuracy: 0.3654 - precision: 0.6538 - recall: 0.081 - 1s 1ms/sample - loss: 1.5583 - accuracy: 0.3685 - precision: 0.6604 - recall: 0.0822 - val_loss: 1.4416 - val_accuracy: 0.4225 - val_precision: 0.9412 - val_recall: 0.1127\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4576 - accuracy: 0.4688 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5195 - accuracy: 0.3750 - precision: 0.7333 - recall: 0.114 - ETA: 0s - loss: 1.5808 - accuracy: 0.3187 - precision: 0.7778 - recall: 0.087 - ETA: 0s - loss: 1.5411 - accuracy: 0.3393 - precision: 0.8000 - recall: 0.089 - ETA: 0s - loss: 1.5339 - accuracy: 0.3507 - precision: 0.7812 - recall: 0.086 - ETA: 0s - loss: 1.5474 - accuracy: 0.3636 - precision: 0.7381 - recall: 0.088 - ETA: 0s - loss: 1.5703 - accuracy: 0.3510 - precision: 0.7000 - recall: 0.084 - 1s 1ms/sample - loss: 1.5717 - accuracy: 0.3498 - precision: 0.6981 - recall: 0.0869 - val_loss: 1.5140 - val_accuracy: 0.3380 - val_precision: 0.7778 - val_recall: 0.1479\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5105 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.6374 - accuracy: 0.3229 - precision: 0.5000 - recall: 0.052 - ETA: 0s - loss: 1.6371 - accuracy: 0.3438 - precision: 0.5417 - recall: 0.081 - ETA: 0s - loss: 1.5974 - accuracy: 0.3348 - precision: 0.5897 - recall: 0.102 - ETA: 0s - loss: 1.5558 - accuracy: 0.3542 - precision: 0.6122 - recall: 0.104 - ETA: 0s - loss: 1.5694 - accuracy: 0.3580 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.5716 - accuracy: 0.3630 - precision: 0.5429 - recall: 0.091 - 1s 1ms/sample - loss: 1.5690 - accuracy: 0.3662 - precision: 0.5556 - recall: 0.0939 - val_loss: 1.6974 - val_accuracy: 0.3169 - val_precision: 0.5556 - val_recall: 0.1408\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.4375 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6208 - accuracy: 0.3646 - precision: 0.5200 - recall: 0.135 - ETA: 0s - loss: 1.5555 - accuracy: 0.3438 - precision: 0.4545 - recall: 0.125 - ETA: 0s - loss: 1.5448 - accuracy: 0.3616 - precision: 0.5082 - recall: 0.138 - ETA: 0s - loss: 1.5609 - accuracy: 0.3576 - precision: 0.5263 - recall: 0.138 - ETA: 0s - loss: 1.5297 - accuracy: 0.3778 - precision: 0.5532 - recall: 0.147 - ETA: 0s - loss: 1.5331 - accuracy: 0.3750 - precision: 0.5660 - recall: 0.144 - 1s 1ms/sample - loss: 1.5319 - accuracy: 0.3732 - precision: 0.5701 - recall: 0.1432 - val_loss: 1.6205 - val_accuracy: 0.3169 - val_precision: 0.8462 - val_recall: 0.0775\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5755 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5353 - accuracy: 0.3542 - precision: 0.7000 - recall: 0.0729        - ETA: 0s - loss: 1.5575 - accuracy: 0.3812 - precision: 0.6875 - recall: 0.068 - ETA: 0s - loss: 1.5340 - accuracy: 0.3973 - precision: 0.7368 - recall: 0.062 - ETA: 0s - loss: 1.4959 - accuracy: 0.4132 - precision: 0.7778 - recall: 0.072 - ETA: 0s - loss: 1.5142 - accuracy: 0.4091 - precision: 0.8000 - recall: 0.068 - ETA: 0s - loss: 1.5181 - accuracy: 0.3990 - precision: 0.7692 - recall: 0.072 - 1s 1ms/sample - loss: 1.5266 - accuracy: 0.3967 - precision: 0.7561 - recall: 0.0728 - val_loss: 1.4936 - val_accuracy: 0.3521 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4066 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.4263 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.041 - ETA: 0s - loss: 1.4359 - accuracy: 0.4313 - precision: 0.9167 - recall: 0.068 - ETA: 0s - loss: 1.4553 - accuracy: 0.4330 - precision: 0.9500 - recall: 0.084 - ETA: 0s - loss: 1.4687 - accuracy: 0.4028 - precision: 0.9565 - recall: 0.076 - ETA: 0s - loss: 1.4639 - accuracy: 0.4062 - precision: 0.9677 - recall: 0.085 - ETA: 0s - loss: 1.4615 - accuracy: 0.4159 - precision: 0.8947 - recall: 0.081 - 1s 1ms/sample - loss: 1.4660 - accuracy: 0.4178 - precision: 0.8947 - recall: 0.0798 - val_loss: 1.4378 - val_accuracy: 0.4014 - val_precision: 0.9000 - val_recall: 0.1268\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4385 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.3744 - accuracy: 0.3854 - precision: 0.8571 - recall: 0.125 - ETA: 0s - loss: 1.3737 - accuracy: 0.4437 - precision: 0.8750 - recall: 0.131 - ETA: 0s - loss: 1.4158 - accuracy: 0.4375 - precision: 0.8519 - recall: 0.102 - ETA: 0s - loss: 1.4158 - accuracy: 0.4271 - precision: 0.8056 - recall: 0.100 - ETA: 0s - loss: 1.4263 - accuracy: 0.4347 - precision: 0.7619 - recall: 0.090 - ETA: 0s - loss: 1.4303 - accuracy: 0.4255 - precision: 0.7451 - recall: 0.091 - 1s 1ms/sample - loss: 1.4333 - accuracy: 0.4225 - precision: 0.7222 - recall: 0.0915 - val_loss: 1.4532 - val_accuracy: 0.4014 - val_precision: 0.7250 - val_recall: 0.2042\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3153 - accuracy: 0.4375 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.4159 - accuracy: 0.4167 - precision: 0.7188 - recall: 0.239 - ETA: 0s - loss: 1.4076 - accuracy: 0.4437 - precision: 0.6458 - recall: 0.193 - ETA: 0s - loss: 1.3533 - accuracy: 0.4598 - precision: 0.6857 - recall: 0.214 - ETA: 0s - loss: 1.4192 - accuracy: 0.4167 - precision: 0.6625 - recall: 0.184 - ETA: 0s - loss: 1.4137 - accuracy: 0.4205 - precision: 0.6489 - recall: 0.173 - ETA: 0s - loss: 1.4280 - accuracy: 0.4207 - precision: 0.6455 - recall: 0.170 - 1s 1ms/sample - loss: 1.4317 - accuracy: 0.4178 - precision: 0.6455 - recall: 0.1667 - val_loss: 1.5014 - val_accuracy: 0.3944 - val_precision: 0.6957 - val_recall: 0.2254\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4281 - accuracy: 0.4062 - precision: 0.5385 - recall: 0.218 - ETA: 0s - loss: 1.5463 - accuracy: 0.3333 - precision: 0.5000 - recall: 0.135 - ETA: 0s - loss: 1.4730 - accuracy: 0.3625 - precision: 0.5833 - recall: 0.131 - ETA: 0s - loss: 1.4882 - accuracy: 0.3661 - precision: 0.5625 - recall: 0.120 - ETA: 0s - loss: 1.4699 - accuracy: 0.3854 - precision: 0.6034 - recall: 0.121 - ETA: 0s - loss: 1.4847 - accuracy: 0.3693 - precision: 0.6308 - recall: 0.116 - ETA: 0s - loss: 1.4767 - accuracy: 0.3726 - precision: 0.6438 - recall: 0.113 - 1s 1ms/sample - loss: 1.4631 - accuracy: 0.3826 - precision: 0.6623 - recall: 0.1197 - val_loss: 1.4196 - val_accuracy: 0.3732 - val_precision: 0.8824 - val_recall: 0.1056\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.4325 - accuracy: 0.3333 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.4373 - accuracy: 0.3938 - precision: 0.7500 - recall: 0.056 - ETA: 0s - loss: 1.4141 - accuracy: 0.4196 - precision: 0.8000 - recall: 0.071 - ETA: 0s - loss: 1.4240 - accuracy: 0.4028 - precision: 0.7241 - recall: 0.072 - ETA: 0s - loss: 1.4055 - accuracy: 0.4261 - precision: 0.7500 - recall: 0.085 - ETA: 0s - loss: 1.4141 - accuracy: 0.4183 - precision: 0.6441 - recall: 0.091 - 1s 1ms/sample - loss: 1.4030 - accuracy: 0.4225 - precision: 0.6667 - recall: 0.0986 - val_loss: 1.7549 - val_accuracy: 0.3451 - val_precision: 0.5682 - val_recall: 0.1761\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5093 - accuracy: 0.5938 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.5971 - accuracy: 0.3854 - precision: 0.5200 - recall: 0.135 - ETA: 0s - loss: 1.6088 - accuracy: 0.3688 - precision: 0.5750 - recall: 0.143 - ETA: 0s - loss: 1.6335 - accuracy: 0.3482 - precision: 0.5263 - recall: 0.133 - ETA: 0s - loss: 1.6323 - accuracy: 0.3403 - precision: 0.5571 - recall: 0.135 - ETA: 0s - loss: 1.6376 - accuracy: 0.3494 - precision: 0.5844 - recall: 0.127 - ETA: 0s - loss: 1.6561 - accuracy: 0.3269 - precision: 0.5543 - recall: 0.122 - 1s 1ms/sample - loss: 1.6430 - accuracy: 0.3357 - precision: 0.5638 - recall: 0.1244 - val_loss: 1.5525 - val_accuracy: 0.3803 - val_precision: 0.6053 - val_recall: 0.1620\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7942 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.6620 - accuracy: 0.2812 - precision: 0.6875 - recall: 0.114 - ETA: 0s - loss: 1.5443 - accuracy: 0.3562 - precision: 0.7353 - recall: 0.156 - ETA: 0s - loss: 1.5209 - accuracy: 0.3661 - precision: 0.6792 - recall: 0.160 - ETA: 0s - loss: 1.5514 - accuracy: 0.3646 - precision: 0.6216 - recall: 0.159 - ETA: 0s - loss: 1.5319 - accuracy: 0.3750 - precision: 0.6122 - recall: 0.170 - ETA: 0s - loss: 1.5235 - accuracy: 0.3726 - precision: 0.6106 - recall: 0.165 - 1s 1ms/sample - loss: 1.5188 - accuracy: 0.3756 - precision: 0.6140 - recall: 0.1643 - val_loss: 1.4139 - val_accuracy: 0.3732 - val_precision: 0.7576 - val_recall: 0.1761\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3683 - accuracy: 0.5625 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.3676 - accuracy: 0.5000 - precision: 0.5600 - recall: 0.145 - ETA: 0s - loss: 1.3713 - accuracy: 0.4938 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.4206 - accuracy: 0.4554 - precision: 0.6522 - recall: 0.133 - ETA: 0s - loss: 1.4425 - accuracy: 0.4444 - precision: 0.6207 - recall: 0.125 - ETA: 0s - loss: 1.4276 - accuracy: 0.4489 - precision: 0.6049 - recall: 0.139 - ETA: 0s - loss: 1.4555 - accuracy: 0.4327 - precision: 0.5859 - recall: 0.139 - 1s 1ms/sample - loss: 1.4619 - accuracy: 0.4296 - precision: 0.5842 - recall: 0.1385 - val_loss: 1.5510 - val_accuracy: 0.3099 - val_precision: 0.5319 - val_recall: 0.1761\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5318 - accuracy: 0.3438 - precision: 0.2727 - recall: 0.093 - ETA: 0s - loss: 1.4166 - accuracy: 0.4271 - precision: 0.5385 - recall: 0.145 - ETA: 0s - loss: 1.3547 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.3682 - accuracy: 0.4286 - precision: 0.6724 - recall: 0.174 - ETA: 0s - loss: 1.3789 - accuracy: 0.4271 - precision: 0.6667 - recall: 0.180 - ETA: 0s - loss: 1.4115 - accuracy: 0.4119 - precision: 0.6593 - recall: 0.170 - ETA: 0s - loss: 1.4009 - accuracy: 0.4255 - precision: 0.6727 - recall: 0.177 - 1s 1ms/sample - loss: 1.4018 - accuracy: 0.4296 - precision: 0.6549 - recall: 0.1737 - val_loss: 1.5596 - val_accuracy: 0.3732 - val_precision: 0.6829 - val_recall: 0.1972\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4390 - accuracy: 0.3750 - precision: 0.7391 - recall: 0.177 - ETA: 0s - loss: 1.3945 - accuracy: 0.4250 - precision: 0.7250 - recall: 0.181 - ETA: 0s - loss: 1.4287 - accuracy: 0.3973 - precision: 0.7234 - recall: 0.151 - ETA: 0s - loss: 1.4160 - accuracy: 0.4102 - precision: 0.7458 - recall: 0.171 - ETA: 0s - loss: 1.4082 - accuracy: 0.4281 - precision: 0.7183 - recall: 0.159 - ETA: 0s - loss: 1.4403 - accuracy: 0.4141 - precision: 0.6824 - recall: 0.151 - 1s 2ms/sample - loss: 1.4572 - accuracy: 0.4014 - precision: 0.6667 - recall: 0.1455 - val_loss: 1.4715 - val_accuracy: 0.3521 - val_precision: 0.6579 - val_recall: 0.1761\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6269 - accuracy: 0.3438 - precision: 0.4444 - recall: 0.125 - ETA: 0s - loss: 1.5415 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.145 - ETA: 0s - loss: 1.5030 - accuracy: 0.3500 - precision: 0.6216 - recall: 0.143 - ETA: 0s - loss: 1.4854 - accuracy: 0.3661 - precision: 0.6531 - recall: 0.142 - ETA: 0s - loss: 1.5273 - accuracy: 0.3438 - precision: 0.6379 - recall: 0.128 - ETA: 0s - loss: 1.5202 - accuracy: 0.3375 - precision: 0.6269 - recall: 0.131 - ETA: 0s - loss: 1.5083 - accuracy: 0.3490 - precision: 0.6341 - recall: 0.135 - 1s 1ms/sample - loss: 1.4931 - accuracy: 0.3685 - precision: 0.6593 - recall: 0.1408 - val_loss: 1.4842 - val_accuracy: 0.3592 - val_precision: 0.6765 - val_recall: 0.1620\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3763 - accuracy: 0.4688 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.4721 - accuracy: 0.3646 - precision: 0.5455 - recall: 0.125 - ETA: 0s - loss: 1.4105 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.168 - ETA: 0s - loss: 1.3835 - accuracy: 0.4420 - precision: 0.6032 - recall: 0.169 - ETA: 0s - loss: 1.3922 - accuracy: 0.4375 - precision: 0.6118 - recall: 0.180 - ETA: 0s - loss: 1.4065 - accuracy: 0.4290 - precision: 0.6019 - recall: 0.176 - ETA: 0s - loss: 1.4207 - accuracy: 0.4303 - precision: 0.5969 - recall: 0.185 - 1s 1ms/sample - loss: 1.4214 - accuracy: 0.4319 - precision: 0.5985 - recall: 0.1854 - val_loss: 1.5394 - val_accuracy: 0.3662 - val_precision: 0.6250 - val_recall: 0.2113\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.3750 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3318 - accuracy: 0.4531 - precision: 0.7059 - recall: 0.187 - ETA: 0s - loss: 1.3389 - accuracy: 0.4766 - precision: 0.6970 - recall: 0.179 - ETA: 0s - loss: 1.3136 - accuracy: 0.4688 - precision: 0.7609 - recall: 0.182 - ETA: 0s - loss: 1.3566 - accuracy: 0.4609 - precision: 0.7581 - recall: 0.183 - ETA: 0s - loss: 1.3739 - accuracy: 0.4437 - precision: 0.7273 - recall: 0.175 - ETA: 0s - loss: 1.3895 - accuracy: 0.4375 - precision: 0.7273 - recall: 0.166 - 1s 1ms/sample - loss: 1.3863 - accuracy: 0.4437 - precision: 0.7000 - recall: 0.1643 - val_loss: 1.4360 - val_accuracy: 0.3732 - val_precision: 0.7838 - val_recall: 0.2042\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.3110 - accuracy: 0.4688 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3140 - accuracy: 0.4896 - precision: 0.6522 - recall: 0.156 - ETA: 0s - loss: 1.3086 - accuracy: 0.5125 - precision: 0.7188 - recall: 0.143 - ETA: 0s - loss: 1.3350 - accuracy: 0.4911 - precision: 0.7391 - recall: 0.151 - ETA: 0s - loss: 1.3371 - accuracy: 0.4688 - precision: 0.7419 - recall: 0.159 - ETA: 0s - loss: 1.3657 - accuracy: 0.4517 - precision: 0.7432 - recall: 0.156 - ETA: 0s - loss: 1.3546 - accuracy: 0.4591 - precision: 0.7500 - recall: 0.151 - 1s 1ms/sample - loss: 1.3613 - accuracy: 0.4531 - precision: 0.7500 - recall: 0.1479 - val_loss: 1.4551 - val_accuracy: 0.4014 - val_precision: 0.8667 - val_recall: 0.1831\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3130 - accuracy: 0.5312 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.3621 - accuracy: 0.5104 - precision: 0.6500 - recall: 0.135 - ETA: 0s - loss: 1.4040 - accuracy: 0.4437 - precision: 0.6389 - recall: 0.143 - ETA: 0s - loss: 1.3812 - accuracy: 0.4598 - precision: 0.6600 - recall: 0.147 - ETA: 0s - loss: 1.3798 - accuracy: 0.4583 - precision: 0.6406 - recall: 0.142 - ETA: 0s - loss: 1.3394 - accuracy: 0.4858 - precision: 0.7262 - recall: 0.173 - ETA: 0s - loss: 1.3440 - accuracy: 0.4784 - precision: 0.7000 - recall: 0.185 - 1s 1ms/sample - loss: 1.3489 - accuracy: 0.4695 - precision: 0.6754 - recall: 0.1808 - val_loss: 1.4243 - val_accuracy: 0.4014 - val_precision: 0.6957 - val_recall: 0.2254\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6164 - accuracy: 0.3125 - precision: 0.5455 - recall: 0.187 - ETA: 0s - loss: 1.4360 - accuracy: 0.3438 - precision: 0.5357 - recall: 0.156 - ETA: 0s - loss: 1.4580 - accuracy: 0.3938 - precision: 0.5366 - recall: 0.137 - ETA: 0s - loss: 1.5070 - accuracy: 0.3705 - precision: 0.5652 - recall: 0.116 - ETA: 0s - loss: 1.4644 - accuracy: 0.3785 - precision: 0.6364 - recall: 0.121 - ETA: 0s - loss: 1.4672 - accuracy: 0.3864 - precision: 0.6667 - recall: 0.119 - ETA: 0s - loss: 1.4568 - accuracy: 0.3990 - precision: 0.6761 - recall: 0.115 - 1s 1ms/sample - loss: 1.4606 - accuracy: 0.3920 - precision: 0.6761 - recall: 0.1127 - val_loss: 1.5022 - val_accuracy: 0.3451 - val_precision: 0.8095 - val_recall: 0.1197\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4474 - accuracy: 0.4688 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.4372 - accuracy: 0.4375 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.4470 - accuracy: 0.3938 - precision: 0.6176 - recall: 0.131 - ETA: 0s - loss: 1.4189 - accuracy: 0.4196 - precision: 0.6444 - recall: 0.129 - ETA: 0s - loss: 1.4016 - accuracy: 0.4236 - precision: 0.6275 - recall: 0.111 - ETA: 0s - loss: 1.3802 - accuracy: 0.4432 - precision: 0.6761 - recall: 0.136 - ETA: 0s - loss: 1.4010 - accuracy: 0.4399 - precision: 0.6628 - recall: 0.137 - 1s 1ms/sample - loss: 1.4013 - accuracy: 0.4366 - precision: 0.6444 - recall: 0.1362 - val_loss: 1.4650 - val_accuracy: 0.4225 - val_precision: 0.7949 - val_recall: 0.2183\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2426 - accuracy: 0.5000 - precision: 0.8182 - recall: 0.281 - ETA: 0s - loss: 1.2515 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.208 - ETA: 0s - loss: 1.3359 - accuracy: 0.4625 - precision: 0.6585 - recall: 0.168 - ETA: 0s - loss: 1.3406 - accuracy: 0.4821 - precision: 0.7049 - recall: 0.192 - ETA: 0s - loss: 1.3613 - accuracy: 0.4688 - precision: 0.6538 - recall: 0.177 - ETA: 0s - loss: 1.3517 - accuracy: 0.4716 - precision: 0.6774 - recall: 0.179 - ETA: 0s - loss: 1.3544 - accuracy: 0.4712 - precision: 0.6822 - recall: 0.175 - 1s 1ms/sample - loss: 1.3513 - accuracy: 0.4718 - precision: 0.6881 - recall: 0.1761 - val_loss: 1.4778 - val_accuracy: 0.3592 - val_precision: 0.8519 - val_recall: 0.1620\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3843 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4372 - accuracy: 0.4271 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.3389 - accuracy: 0.4688 - precision: 0.8214 - recall: 0.143 - ETA: 0s - loss: 1.3577 - accuracy: 0.4643 - precision: 0.8293 - recall: 0.151 - ETA: 0s - loss: 1.3837 - accuracy: 0.4583 - precision: 0.7679 - recall: 0.149 - ETA: 0s - loss: 1.3728 - accuracy: 0.4659 - precision: 0.7262 - recall: 0.173 - ETA: 0s - loss: 1.3925 - accuracy: 0.4543 - precision: 0.6827 - recall: 0.170 - 1s 1ms/sample - loss: 1.3965 - accuracy: 0.4484 - precision: 0.6762 - recall: 0.1667 - val_loss: 1.4685 - val_accuracy: 0.3732 - val_precision: 0.7179 - val_recall: 0.1972\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4365 - accuracy: 0.3438 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.4031 - accuracy: 0.3750 - precision: 0.6800 - recall: 0.177 - ETA: 0s - loss: 1.3998 - accuracy: 0.3938 - precision: 0.6923 - recall: 0.168 - ETA: 0s - loss: 1.4488 - accuracy: 0.3839 - precision: 0.6346 - recall: 0.147 - ETA: 0s - loss: 1.4331 - accuracy: 0.3819 - precision: 0.6429 - recall: 0.156 - ETA: 0s - loss: 1.4054 - accuracy: 0.3977 - precision: 0.6667 - recall: 0.153 - ETA: 0s - loss: 1.4050 - accuracy: 0.4062 - precision: 0.6602 - recall: 0.163 - 1s 1ms/sample - loss: 1.4058 - accuracy: 0.4085 - precision: 0.6667 - recall: 0.1643 - val_loss: 1.5824 - val_accuracy: 0.3380 - val_precision: 0.7429 - val_recall: 0.1831\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5490 - accuracy: 0.4375 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4157 - accuracy: 0.3958 - precision: 0.7083 - recall: 0.177 - ETA: 0s - loss: 1.4424 - accuracy: 0.4125 - precision: 0.6444 - recall: 0.181 - ETA: 0s - loss: 1.4057 - accuracy: 0.4286 - precision: 0.6557 - recall: 0.178 - ETA: 0s - loss: 1.4229 - accuracy: 0.4236 - precision: 0.6667 - recall: 0.173 - ETA: 0s - loss: 1.4298 - accuracy: 0.4176 - precision: 0.6667 - recall: 0.164 - ETA: 0s - loss: 1.4179 - accuracy: 0.4279 - precision: 0.7000 - recall: 0.168 - 1s 1ms/sample - loss: 1.4198 - accuracy: 0.4272 - precision: 0.6931 - recall: 0.1643 - val_loss: 1.3648 - val_accuracy: 0.4085 - val_precision: 0.8649 - val_recall: 0.2254\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3134 - accuracy: 0.4375 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.2858 - accuracy: 0.4167 - precision: 0.7419 - recall: 0.239 - ETA: 0s - loss: 1.3401 - accuracy: 0.4062 - precision: 0.7018 - recall: 0.250 - ETA: 0s - loss: 1.3664 - accuracy: 0.4018 - precision: 0.7179 - recall: 0.250 - ETA: 0s - loss: 1.3784 - accuracy: 0.4028 - precision: 0.6907 - recall: 0.232 - ETA: 0s - loss: 1.3548 - accuracy: 0.4233 - precision: 0.6937 - recall: 0.218 - ETA: 0s - loss: 1.3570 - accuracy: 0.4303 - precision: 0.6692 - recall: 0.213 - 1s 1ms/sample - loss: 1.3605 - accuracy: 0.4272 - precision: 0.6716 - recall: 0.2113 - val_loss: 1.4826 - val_accuracy: 0.3380 - val_precision: 0.6667 - val_recall: 0.2254\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3324 - accuracy: 0.5000 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.2983 - accuracy: 0.5000 - precision: 0.6129 - recall: 0.197 - ETA: 0s - loss: 1.3094 - accuracy: 0.4875 - precision: 0.6545 - recall: 0.225 - ETA: 0s - loss: 1.3721 - accuracy: 0.4554 - precision: 0.6235 - recall: 0.236 - ETA: 0s - loss: 1.3388 - accuracy: 0.4618 - precision: 0.6389 - recall: 0.239 - ETA: 0s - loss: 1.3318 - accuracy: 0.4545 - precision: 0.6241 - recall: 0.235 - ETA: 0s - loss: 1.3441 - accuracy: 0.4567 - precision: 0.6218 - recall: 0.233 - 1s 1ms/sample - loss: 1.3492 - accuracy: 0.4554 - precision: 0.6289 - recall: 0.2347 - val_loss: 1.5122 - val_accuracy: 0.3592 - val_precision: 0.6750 - val_recall: 0.1901\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2447 - accuracy: 0.4688 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.3312 - accuracy: 0.3958 - precision: 0.6957 - recall: 0.166 - ETA: 0s - loss: 1.3534 - accuracy: 0.3938 - precision: 0.6750 - recall: 0.168 - ETA: 0s - loss: 1.3241 - accuracy: 0.4330 - precision: 0.7458 - recall: 0.196 - ETA: 0s - loss: 1.3210 - accuracy: 0.4340 - precision: 0.7467 - recall: 0.194 - ETA: 0s - loss: 1.3218 - accuracy: 0.4403 - precision: 0.7553 - recall: 0.201 - ETA: 0s - loss: 1.3084 - accuracy: 0.4447 - precision: 0.7615 - recall: 0.199 - 1s 1ms/sample - loss: 1.3096 - accuracy: 0.4437 - precision: 0.7636 - recall: 0.1972 - val_loss: 1.4309 - val_accuracy: 0.3592 - val_precision: 0.7556 - val_recall: 0.2394\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2337 - accuracy: 0.5000 - precision: 0.6111 - recall: 0.343 - ETA: 0s - loss: 1.2641 - accuracy: 0.5000 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.3063 - accuracy: 0.4812 - precision: 0.6250 - recall: 0.218 - ETA: 0s - loss: 1.2927 - accuracy: 0.4955 - precision: 0.6375 - recall: 0.227 - ETA: 0s - loss: 1.2710 - accuracy: 0.5104 - precision: 0.6832 - recall: 0.239 - ETA: 0s - loss: 1.2906 - accuracy: 0.5114 - precision: 0.6864 - recall: 0.230 - ETA: 0s - loss: 1.2783 - accuracy: 0.5024 - precision: 0.6690 - recall: 0.228 - 1s 1ms/sample - loss: 1.2722 - accuracy: 0.5000 - precision: 0.6644 - recall: 0.2277 - val_loss: 1.3846 - val_accuracy: 0.4366 - val_precision: 0.6111 - val_recall: 0.2324\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3891 - accuracy: 0.3750 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.2932 - accuracy: 0.4792 - precision: 0.6571 - recall: 0.239 - ETA: 0s - loss: 1.3310 - accuracy: 0.4812 - precision: 0.6667 - recall: 0.237 - ETA: 0s - loss: 1.3160 - accuracy: 0.4732 - precision: 0.6790 - recall: 0.245 - ETA: 0s - loss: 1.2995 - accuracy: 0.5069 - precision: 0.7037 - recall: 0.263 - ETA: 0s - loss: 1.3352 - accuracy: 0.4801 - precision: 0.6718 - recall: 0.250 - ETA: 0s - loss: 1.3316 - accuracy: 0.4784 - precision: 0.6689 - recall: 0.238 - 1s 1ms/sample - loss: 1.3313 - accuracy: 0.4789 - precision: 0.6689 - recall: 0.2371 - val_loss: 1.6181 - val_accuracy: 0.3310 - val_precision: 0.6829 - val_recall: 0.1972\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3864 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.281 - ETA: 0s - loss: 1.4480 - accuracy: 0.4479 - precision: 0.6757 - recall: 0.260 - ETA: 0s - loss: 1.4118 - accuracy: 0.4500 - precision: 0.6667 - recall: 0.225 - ETA: 0s - loss: 1.4546 - accuracy: 0.4375 - precision: 0.5844 - recall: 0.200 - ETA: 0s - loss: 1.4107 - accuracy: 0.4549 - precision: 0.6132 - recall: 0.225 - ETA: 0s - loss: 1.4366 - accuracy: 0.4318 - precision: 0.5746 - recall: 0.218 - ETA: 0s - loss: 1.4417 - accuracy: 0.4303 - precision: 0.5772 - recall: 0.206 - 1s 1ms/sample - loss: 1.4335 - accuracy: 0.4343 - precision: 0.5882 - recall: 0.2113 - val_loss: 1.4531 - val_accuracy: 0.3732 - val_precision: 0.6545 - val_recall: 0.2535\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2714 - accuracy: 0.5000 - precision: 0.6429 - recall: 0.281 - ETA: 0s - loss: 1.2719 - accuracy: 0.5208 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.2211 - accuracy: 0.5437 - precision: 0.7000 - recall: 0.262 - ETA: 0s - loss: 1.2519 - accuracy: 0.5134 - precision: 0.6883 - recall: 0.236 - ETA: 0s - loss: 1.2675 - accuracy: 0.4931 - precision: 0.6602 - recall: 0.236 - ETA: 0s - loss: 1.2905 - accuracy: 0.4801 - precision: 0.6423 - recall: 0.224 - ETA: 0s - loss: 1.3009 - accuracy: 0.4760 - precision: 0.6400 - recall: 0.230 - 1s 1ms/sample - loss: 1.2963 - accuracy: 0.4789 - precision: 0.6471 - recall: 0.2324 - val_loss: 1.4805 - val_accuracy: 0.3592 - val_precision: 0.8000 - val_recall: 0.2254\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1023 - accuracy: 0.6250 - precision: 0.9231 - recall: 0.375 - ETA: 0s - loss: 1.2950 - accuracy: 0.5417 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.2869 - accuracy: 0.5188 - precision: 0.6735 - recall: 0.206 - ETA: 0s - loss: 1.3118 - accuracy: 0.4911 - precision: 0.6324 - recall: 0.192 - ETA: 0s - loss: 1.2900 - accuracy: 0.4757 - precision: 0.6593 - recall: 0.208 - ETA: 0s - loss: 1.3104 - accuracy: 0.4631 - precision: 0.6762 - recall: 0.201 - ETA: 0s - loss: 1.3058 - accuracy: 0.4639 - precision: 0.6825 - recall: 0.206 - 1s 1ms/sample - loss: 1.3030 - accuracy: 0.4671 - precision: 0.6822 - recall: 0.2066 - val_loss: 1.4850 - val_accuracy: 0.3521 - val_precision: 0.6222 - val_recall: 0.1972\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2160 - accuracy: 0.5000 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.2876 - accuracy: 0.4792 - precision: 0.6562 - recall: 0.218 - ETA: 0s - loss: 1.2550 - accuracy: 0.5000 - precision: 0.6415 - recall: 0.212 - ETA: 0s - loss: 1.2827 - accuracy: 0.4866 - precision: 0.6438 - recall: 0.209 - ETA: 0s - loss: 1.2772 - accuracy: 0.5000 - precision: 0.6436 - recall: 0.225 - ETA: 0s - loss: 1.2252 - accuracy: 0.5256 - precision: 0.6905 - recall: 0.247 - ETA: 0s - loss: 1.2361 - accuracy: 0.5168 - precision: 0.6711 - recall: 0.245 - 1s 1ms/sample - loss: 1.2404 - accuracy: 0.5164 - precision: 0.6795 - recall: 0.2488 - val_loss: 1.4074 - val_accuracy: 0.3873 - val_precision: 0.6939 - val_recall: 0.2394\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.6250 - precision: 0.8000 - recall: 0.375 - ETA: 0s - loss: 1.1263 - accuracy: 0.5521 - precision: 0.6842 - recall: 0.270 - ETA: 0s - loss: 1.1747 - accuracy: 0.5250 - precision: 0.6418 - recall: 0.268 - ETA: 0s - loss: 1.1430 - accuracy: 0.5625 - precision: 0.6429 - recall: 0.281 - ETA: 0s - loss: 1.2084 - accuracy: 0.5382 - precision: 0.6270 - recall: 0.274 - ETA: 0s - loss: 1.1996 - accuracy: 0.5312 - precision: 0.6471 - recall: 0.281 - ETA: 0s - loss: 1.2161 - accuracy: 0.5264 - precision: 0.6413 - recall: 0.283 - 1s 1ms/sample - loss: 1.2129 - accuracy: 0.5282 - precision: 0.6364 - recall: 0.2793 - val_loss: 1.3580 - val_accuracy: 0.4225 - val_precision: 0.6600 - val_recall: 0.2324\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3475 - accuracy: 0.4062 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.1997 - accuracy: 0.5833 - precision: 0.7021 - recall: 0.343 - ETA: 0s - loss: 1.2036 - accuracy: 0.5625 - precision: 0.6875 - recall: 0.343 - ETA: 0s - loss: 1.2026 - accuracy: 0.5536 - precision: 0.6636 - recall: 0.325 - ETA: 0s - loss: 1.1818 - accuracy: 0.5556 - precision: 0.6815 - recall: 0.319 - ETA: 0s - loss: 1.1866 - accuracy: 0.5597 - precision: 0.6946 - recall: 0.329 - ETA: 0s - loss: 1.1796 - accuracy: 0.5481 - precision: 0.6837 - recall: 0.322 - 1s 1ms/sample - loss: 1.1766 - accuracy: 0.5516 - precision: 0.6897 - recall: 0.3286 - val_loss: 1.3125 - val_accuracy: 0.4930 - val_precision: 0.6667 - val_recall: 0.2817\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9444 - accuracy: 0.6875 - precision: 0.8824 - recall: 0.468 - ETA: 0s - loss: 0.9877 - accuracy: 0.6771 - precision: 0.7333 - recall: 0.458 - ETA: 0s - loss: 1.0497 - accuracy: 0.6187 - precision: 0.6957 - recall: 0.400 - ETA: 0s - loss: 1.0390 - accuracy: 0.6250 - precision: 0.7120 - recall: 0.397 - ETA: 0s - loss: 1.0796 - accuracy: 0.6042 - precision: 0.6993 - recall: 0.371 - ETA: 0s - loss: 1.1021 - accuracy: 0.5938 - precision: 0.6978 - recall: 0.360 - ETA: 0s - loss: 1.1198 - accuracy: 0.5769 - precision: 0.6774 - recall: 0.353 - 1s 1ms/sample - loss: 1.1512 - accuracy: 0.5704 - precision: 0.6682 - recall: 0.3451 - val_loss: 1.4982 - val_accuracy: 0.4507 - val_precision: 0.5676 - val_recall: 0.2958\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6946 - accuracy: 0.4375 - precision: 0.4000 - recall: 0.187 - ETA: 0s - loss: 1.5109 - accuracy: 0.4271 - precision: 0.4375 - recall: 0.218 - ETA: 0s - loss: 1.4601 - accuracy: 0.3938 - precision: 0.4524 - recall: 0.237 - ETA: 0s - loss: 1.4130 - accuracy: 0.4241 - precision: 0.4746 - recall: 0.250 - ETA: 0s - loss: 1.3680 - accuracy: 0.4444 - precision: 0.4968 - recall: 0.270 - ETA: 0s - loss: 1.3646 - accuracy: 0.4631 - precision: 0.5160 - recall: 0.275 - ETA: 0s - loss: 1.3337 - accuracy: 0.4808 - precision: 0.5388 - recall: 0.283 - 1s 1ms/sample - loss: 1.3315 - accuracy: 0.4859 - precision: 0.5442 - recall: 0.2887 - val_loss: 1.4229 - val_accuracy: 0.3873 - val_precision: 0.6061 - val_recall: 0.2817\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9696 - accuracy: 0.7188 - precision: 0.7778 - recall: 0.437 - ETA: 0s - loss: 1.2196 - accuracy: 0.5625 - precision: 0.6667 - recall: 0.354 - ETA: 0s - loss: 1.1882 - accuracy: 0.5688 - precision: 0.6452 - recall: 0.375 - ETA: 0s - loss: 1.1966 - accuracy: 0.5670 - precision: 0.6532 - recall: 0.361 - ETA: 0s - loss: 1.2312 - accuracy: 0.5312 - precision: 0.6376 - recall: 0.329 - ETA: 0s - loss: 1.2421 - accuracy: 0.5256 - precision: 0.6339 - recall: 0.329 - ETA: 0s - loss: 1.2263 - accuracy: 0.5312 - precision: 0.6476 - recall: 0.326 - 1s 1ms/sample - loss: 1.2370 - accuracy: 0.5258 - precision: 0.6432 - recall: 0.3216 - val_loss: 1.4805 - val_accuracy: 0.3944 - val_precision: 0.5507 - val_recall: 0.2676\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0506 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.312 - ETA: 0s - loss: 1.1368 - accuracy: 0.5625 - precision: 0.6977 - recall: 0.312 - ETA: 0s - loss: 1.1991 - accuracy: 0.5250 - precision: 0.6912 - recall: 0.293 - ETA: 0s - loss: 1.2054 - accuracy: 0.5357 - precision: 0.7033 - recall: 0.285 - ETA: 0s - loss: 1.2283 - accuracy: 0.5347 - precision: 0.6833 - recall: 0.284 - ETA: 0s - loss: 1.2472 - accuracy: 0.5199 - precision: 0.6622 - recall: 0.278 - ETA: 0s - loss: 1.2241 - accuracy: 0.5288 - precision: 0.6805 - recall: 0.276 - 1s 1ms/sample - loss: 1.2203 - accuracy: 0.5329 - precision: 0.6842 - recall: 0.2746 - val_loss: 1.3123 - val_accuracy: 0.4577 - val_precision: 0.6935 - val_recall: 0.3028\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2423 - accuracy: 0.5000 - precision: 0.5625 - recall: 0.281 - ETA: 0s - loss: 1.2034 - accuracy: 0.4896 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 1.2168 - accuracy: 0.5125 - precision: 0.7105 - recall: 0.337 - ETA: 0s - loss: 1.2416 - accuracy: 0.5179 - precision: 0.6549 - recall: 0.330 - ETA: 0s - loss: 1.2204 - accuracy: 0.5312 - precision: 0.6443 - recall: 0.333 - ETA: 0s - loss: 1.2190 - accuracy: 0.5312 - precision: 0.6393 - recall: 0.332 - ETA: 0s - loss: 1.1912 - accuracy: 0.5457 - precision: 0.6558 - recall: 0.338 - 1s 1ms/sample - loss: 1.2011 - accuracy: 0.5399 - precision: 0.6500 - recall: 0.3357 - val_loss: 1.2970 - val_accuracy: 0.4577 - val_precision: 0.6271 - val_recall: 0.2606\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1001 - accuracy: 0.5625 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 1.2383 - accuracy: 0.5417 - precision: 0.7200 - recall: 0.375 - ETA: 0s - loss: 1.1472 - accuracy: 0.5938 - precision: 0.7561 - recall: 0.387 - ETA: 0s - loss: 1.1075 - accuracy: 0.6027 - precision: 0.7699 - recall: 0.388 - ETA: 0s - loss: 1.0938 - accuracy: 0.6042 - precision: 0.7600 - recall: 0.395 - ETA: 0s - loss: 1.0878 - accuracy: 0.6051 - precision: 0.7432 - recall: 0.386 - ETA: 0s - loss: 1.0808 - accuracy: 0.5986 - precision: 0.7293 - recall: 0.401 - 1s 1ms/sample - loss: 1.0824 - accuracy: 0.5962 - precision: 0.7246 - recall: 0.4014 - val_loss: 1.1809 - val_accuracy: 0.5423 - val_precision: 0.6098 - val_recall: 0.3521\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0949 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.312 - ETA: 0s - loss: 1.0682 - accuracy: 0.5833 - precision: 0.6731 - recall: 0.364 - ETA: 0s - loss: 1.1019 - accuracy: 0.5750 - precision: 0.6506 - recall: 0.337 - ETA: 0s - loss: 1.0703 - accuracy: 0.5804 - precision: 0.6555 - recall: 0.348 - ETA: 0s - loss: 1.0879 - accuracy: 0.5729 - precision: 0.6471 - recall: 0.343 - ETA: 0s - loss: 1.1036 - accuracy: 0.5767 - precision: 0.6579 - recall: 0.355 - ETA: 0s - loss: 1.1015 - accuracy: 0.5769 - precision: 0.6549 - recall: 0.355 - 1s 1ms/sample - loss: 1.0948 - accuracy: 0.5822 - precision: 0.6609 - recall: 0.3615 - val_loss: 1.1570 - val_accuracy: 0.5493 - val_precision: 0.6892 - val_recall: 0.3592\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.6875 - precision: 0.7727 - recall: 0.531 - ETA: 0s - loss: 0.9999 - accuracy: 0.6146 - precision: 0.7458 - recall: 0.458 - ETA: 0s - loss: 0.9791 - accuracy: 0.6328 - precision: 0.7531 - recall: 0.476 - ETA: 0s - loss: 1.0350 - accuracy: 0.6094 - precision: 0.7436 - recall: 0.453 - ETA: 0s - loss: 1.0689 - accuracy: 0.5938 - precision: 0.7226 - recall: 0.437 - ETA: 0s - loss: 1.0573 - accuracy: 0.5969 - precision: 0.7202 - recall: 0.434 - ETA: 0s - loss: 1.0407 - accuracy: 0.6094 - precision: 0.7357 - recall: 0.434 - 1s 1ms/sample - loss: 1.0261 - accuracy: 0.6150 - precision: 0.7336 - recall: 0.4460 - val_loss: 1.2126 - val_accuracy: 0.5211 - val_precision: 0.6220 - val_recall: 0.3592\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9407 - accuracy: 0.6250 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.8771 - accuracy: 0.6979 - precision: 0.8644 - recall: 0.531 - ETA: 0s - loss: 0.8703 - accuracy: 0.7000 - precision: 0.8447 - recall: 0.543 - ETA: 0s - loss: 0.8681 - accuracy: 0.6875 - precision: 0.8079 - recall: 0.544 - ETA: 0s - loss: 0.8755 - accuracy: 0.6771 - precision: 0.8040 - recall: 0.555 - ETA: 0s - loss: 0.8905 - accuracy: 0.6591 - precision: 0.7893 - recall: 0.542 - ETA: 0s - loss: 0.9247 - accuracy: 0.6466 - precision: 0.7593 - recall: 0.538 - 1s 1ms/sample - loss: 0.9340 - accuracy: 0.6432 - precision: 0.7525 - recall: 0.5352 - val_loss: 1.0667 - val_accuracy: 0.5704 - val_precision: 0.6702 - val_recall: 0.4437\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.6250 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 0.9511 - accuracy: 0.6354 - precision: 0.7536 - recall: 0.541 - ETA: 0s - loss: 0.9869 - accuracy: 0.6375 - precision: 0.7018 - recall: 0.500 - ETA: 0s - loss: 0.9647 - accuracy: 0.6562 - precision: 0.7117 - recall: 0.517 - ETA: 0s - loss: 0.9598 - accuracy: 0.6424 - precision: 0.7327 - recall: 0.513 - ETA: 0s - loss: 0.9722 - accuracy: 0.6420 - precision: 0.7218 - recall: 0.508 - ETA: 0s - loss: 1.0030 - accuracy: 0.6298 - precision: 0.7083 - recall: 0.490 - 1s 1ms/sample - loss: 1.0043 - accuracy: 0.6244 - precision: 0.7099 - recall: 0.4883 - val_loss: 1.1421 - val_accuracy: 0.5141 - val_precision: 0.6452 - val_recall: 0.4225\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.5938 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 1.0029 - accuracy: 0.6146 - precision: 0.7460 - recall: 0.489 - ETA: 0s - loss: 0.9926 - accuracy: 0.6250 - precision: 0.7476 - recall: 0.481 - ETA: 0s - loss: 0.9887 - accuracy: 0.6295 - precision: 0.7534 - recall: 0.491 - ETA: 0s - loss: 0.9714 - accuracy: 0.6424 - precision: 0.7565 - recall: 0.506 - ETA: 0s - loss: 0.9576 - accuracy: 0.6506 - precision: 0.7615 - recall: 0.517 - ETA: 0s - loss: 0.9419 - accuracy: 0.6490 - precision: 0.7552 - recall: 0.519 - 1s 1ms/sample - loss: 0.9494 - accuracy: 0.6432 - precision: 0.7466 - recall: 0.5117 - val_loss: 1.1108 - val_accuracy: 0.5634 - val_precision: 0.6703 - val_recall: 0.4296\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1338 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.375 - ETA: 0s - loss: 1.1177 - accuracy: 0.5208 - precision: 0.6333 - recall: 0.395 - ETA: 0s - loss: 1.1647 - accuracy: 0.5625 - precision: 0.6415 - recall: 0.425 - ETA: 0s - loss: 1.2010 - accuracy: 0.5536 - precision: 0.6579 - recall: 0.446 - ETA: 0s - loss: 1.2877 - accuracy: 0.5382 - precision: 0.6294 - recall: 0.430 - ETA: 0s - loss: 1.2712 - accuracy: 0.5312 - precision: 0.6255 - recall: 0.417 - ETA: 0s - loss: 1.2342 - accuracy: 0.5457 - precision: 0.6449 - recall: 0.427 - 1s 1ms/sample - loss: 1.2287 - accuracy: 0.5493 - precision: 0.6454 - recall: 0.4272 - val_loss: 1.2995 - val_accuracy: 0.4507 - val_precision: 0.5316 - val_recall: 0.2958\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.6250 - precision: 0.8421 - recall: 0.500 - ETA: 0s - loss: 1.3132 - accuracy: 0.5938 - precision: 0.6721 - recall: 0.427 - ETA: 0s - loss: 1.2735 - accuracy: 0.5813 - precision: 0.6630 - recall: 0.381 - ETA: 0s - loss: 1.2920 - accuracy: 0.5491 - precision: 0.6489 - recall: 0.379 - ETA: 0s - loss: 1.2597 - accuracy: 0.5521 - precision: 0.6548 - recall: 0.381 - ETA: 0s - loss: 1.2538 - accuracy: 0.5398 - precision: 0.6580 - recall: 0.360 - ETA: 0s - loss: 1.2054 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.355 - 1s 1ms/sample - loss: 1.2072 - accuracy: 0.5282 - precision: 0.6652 - recall: 0.3545 - val_loss: 1.1214 - val_accuracy: 0.5000 - val_precision: 0.6883 - val_recall: 0.3732\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9893 - accuracy: 0.5000 - precision: 0.7059 - recall: 0.375 - ETA: 0s - loss: 1.0661 - accuracy: 0.5208 - precision: 0.6939 - recall: 0.354 - ETA: 0s - loss: 1.0343 - accuracy: 0.5688 - precision: 0.7143 - recall: 0.375 - ETA: 0s - loss: 1.0307 - accuracy: 0.5893 - precision: 0.7107 - recall: 0.383 - ETA: 0s - loss: 1.0326 - accuracy: 0.6007 - precision: 0.7301 - recall: 0.413 - ETA: 0s - loss: 1.0102 - accuracy: 0.6193 - precision: 0.7353 - recall: 0.426 - ETA: 0s - loss: 1.0107 - accuracy: 0.6130 - precision: 0.7333 - recall: 0.423 - 1s 1ms/sample - loss: 1.0079 - accuracy: 0.6127 - precision: 0.7377 - recall: 0.4225 - val_loss: 1.1964 - val_accuracy: 0.5634 - val_precision: 0.7162 - val_recall: 0.3732\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7856 - accuracy: 0.6875 - precision: 0.9412 - recall: 0.500 - ETA: 0s - loss: 0.9380 - accuracy: 0.6250 - precision: 0.8148 - recall: 0.458 - ETA: 0s - loss: 1.0177 - accuracy: 0.6000 - precision: 0.7447 - recall: 0.437 - ETA: 0s - loss: 0.9957 - accuracy: 0.6295 - precision: 0.7556 - recall: 0.455 - ETA: 0s - loss: 0.9874 - accuracy: 0.6215 - precision: 0.7486 - recall: 0.465 - ETA: 0s - loss: 0.9659 - accuracy: 0.6307 - precision: 0.7577 - recall: 0.488 - ETA: 0s - loss: 0.9979 - accuracy: 0.6226 - precision: 0.7365 - recall: 0.490 - 1s 1ms/sample - loss: 0.9933 - accuracy: 0.6244 - precision: 0.7359 - recall: 0.4906 - val_loss: 1.1598 - val_accuracy: 0.4859 - val_precision: 0.6292 - val_recall: 0.3944\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2859 - accuracy: 0.5312 - precision: 0.6364 - recall: 0.437 - ETA: 0s - loss: 1.1119 - accuracy: 0.5521 - precision: 0.6562 - recall: 0.437 - ETA: 0s - loss: 0.9886 - accuracy: 0.5938 - precision: 0.7117 - recall: 0.493 - ETA: 0s - loss: 0.9968 - accuracy: 0.6071 - precision: 0.7143 - recall: 0.491 - ETA: 0s - loss: 0.9495 - accuracy: 0.6389 - precision: 0.7423 - recall: 0.500 - ETA: 0s - loss: 0.9274 - accuracy: 0.6477 - precision: 0.7427 - recall: 0.508 - ETA: 0s - loss: 0.9160 - accuracy: 0.6562 - precision: 0.7552 - recall: 0.519 - 1s 1ms/sample - loss: 0.9290 - accuracy: 0.6526 - precision: 0.7500 - recall: 0.5141 - val_loss: 1.1517 - val_accuracy: 0.5493 - val_precision: 0.6705 - val_recall: 0.4155\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0581 - accuracy: 0.5625 - precision: 0.6190 - recall: 0.406 - ETA: 0s - loss: 1.0096 - accuracy: 0.5625 - precision: 0.6508 - recall: 0.427 - ETA: 0s - loss: 0.9230 - accuracy: 0.6500 - precision: 0.7207 - recall: 0.500 - ETA: 0s - loss: 0.9373 - accuracy: 0.6429 - precision: 0.7244 - recall: 0.504 - ETA: 0s - loss: 0.9626 - accuracy: 0.6319 - precision: 0.7136 - recall: 0.493 - ETA: 0s - loss: 0.9649 - accuracy: 0.6278 - precision: 0.7131 - recall: 0.494 - ETA: 0s - loss: 0.9615 - accuracy: 0.6346 - precision: 0.7207 - recall: 0.502 - 1s 1ms/sample - loss: 0.9609 - accuracy: 0.6338 - precision: 0.7181 - recall: 0.5023 - val_loss: 1.4657 - val_accuracy: 0.4507 - val_precision: 0.5368 - val_recall: 0.3592\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.6875 - precision: 0.7407 - recall: 0.625 - ETA: 0s - loss: 1.2366 - accuracy: 0.5417 - precision: 0.6197 - recall: 0.458 - ETA: 0s - loss: 1.2595 - accuracy: 0.5375 - precision: 0.6071 - recall: 0.425 - ETA: 0s - loss: 1.1961 - accuracy: 0.5312 - precision: 0.6218 - recall: 0.433 - ETA: 0s - loss: 1.2147 - accuracy: 0.5069 - precision: 0.6010 - recall: 0.423 - ETA: 0s - loss: 1.2544 - accuracy: 0.5199 - precision: 0.6129 - recall: 0.431 - ETA: 0s - loss: 1.2799 - accuracy: 0.5264 - precision: 0.6162 - recall: 0.439 - 1s 1ms/sample - loss: 1.2657 - accuracy: 0.5282 - precision: 0.6238 - recall: 0.4437 - val_loss: 1.5220 - val_accuracy: 0.4648 - val_precision: 0.5670 - val_recall: 0.3873\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6990 - accuracy: 0.4688 - precision: 0.6000 - recall: 0.468 - ETA: 0s - loss: 1.6862 - accuracy: 0.4271 - precision: 0.5217 - recall: 0.375 - ETA: 0s - loss: 1.4910 - accuracy: 0.4437 - precision: 0.5833 - recall: 0.393 - ETA: 0s - loss: 1.4812 - accuracy: 0.4598 - precision: 0.5833 - recall: 0.375 - ETA: 0s - loss: 1.5044 - accuracy: 0.4757 - precision: 0.6012 - recall: 0.361 - ETA: 0s - loss: 1.5153 - accuracy: 0.4631 - precision: 0.5969 - recall: 0.332 - ETA: 0s - loss: 1.5220 - accuracy: 0.4663 - precision: 0.6205 - recall: 0.334 - 1s 1ms/sample - loss: 1.5107 - accuracy: 0.4695 - precision: 0.6288 - recall: 0.3380 - val_loss: 1.4785 - val_accuracy: 0.4155 - val_precision: 0.5692 - val_recall: 0.2606\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1958 - accuracy: 0.5312 - precision: 0.7692 - recall: 0.312 - ETA: 0s - loss: 1.1868 - accuracy: 0.5417 - precision: 0.6596 - recall: 0.322 - ETA: 0s - loss: 1.1690 - accuracy: 0.5250 - precision: 0.6506 - recall: 0.337 - ETA: 0s - loss: 1.2023 - accuracy: 0.5045 - precision: 0.6400 - recall: 0.357 - ETA: 0s - loss: 1.2375 - accuracy: 0.5000 - precision: 0.6478 - recall: 0.357 - ETA: 0s - loss: 1.2475 - accuracy: 0.4858 - precision: 0.6281 - recall: 0.355 - ETA: 0s - loss: 1.2169 - accuracy: 0.5048 - precision: 0.6444 - recall: 0.370 - 1s 1ms/sample - loss: 1.2061 - accuracy: 0.5117 - precision: 0.6516 - recall: 0.3732 - val_loss: 1.2970 - val_accuracy: 0.4648 - val_precision: 0.6271 - val_recall: 0.2606\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2243 - accuracy: 0.5312 - precision: 0.6471 - recall: 0.343 - ETA: 0s - loss: 1.1336 - accuracy: 0.5208 - precision: 0.6531 - recall: 0.333 - ETA: 0s - loss: 1.1223 - accuracy: 0.5375 - precision: 0.6966 - recall: 0.387 - ETA: 0s - loss: 1.1370 - accuracy: 0.5357 - precision: 0.7155 - recall: 0.370 - ETA: 0s - loss: 1.1704 - accuracy: 0.5312 - precision: 0.6757 - recall: 0.347 - ETA: 0s - loss: 1.1329 - accuracy: 0.5597 - precision: 0.6806 - recall: 0.369 - ETA: 0s - loss: 1.1213 - accuracy: 0.5601 - precision: 0.6766 - recall: 0.382 - 1s 1ms/sample - loss: 1.1237 - accuracy: 0.5587 - precision: 0.6763 - recall: 0.3826 - val_loss: 1.3339 - val_accuracy: 0.4507 - val_precision: 0.5591 - val_recall: 0.3662\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4684 - accuracy: 0.4688 - precision: 0.5000 - recall: 0.406 - ETA: 0s - loss: 1.2819 - accuracy: 0.5417 - precision: 0.6133 - recall: 0.479 - ETA: 0s - loss: 1.3517 - accuracy: 0.5375 - precision: 0.5929 - recall: 0.418 - ETA: 0s - loss: 1.3405 - accuracy: 0.5491 - precision: 0.6104 - recall: 0.419 - ETA: 0s - loss: 1.3340 - accuracy: 0.5451 - precision: 0.6257 - recall: 0.406 - ETA: 0s - loss: 1.2976 - accuracy: 0.5483 - precision: 0.6460 - recall: 0.414 - ETA: 0s - loss: 1.3258 - accuracy: 0.5288 - precision: 0.6324 - recall: 0.384 - 1s 1ms/sample - loss: 1.3228 - accuracy: 0.5282 - precision: 0.6332 - recall: 0.3850 - val_loss: 1.4728 - val_accuracy: 0.4225 - val_precision: 0.4737 - val_recall: 0.3169\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2332 - accuracy: 0.5312 - precision: 0.6500 - recall: 0.406 - ETA: 0s - loss: 1.2277 - accuracy: 0.4896 - precision: 0.6271 - recall: 0.385 - ETA: 0s - loss: 1.2321 - accuracy: 0.5312 - precision: 0.6275 - recall: 0.400 - ETA: 0s - loss: 1.1978 - accuracy: 0.5223 - precision: 0.6127 - recall: 0.388 - ETA: 0s - loss: 1.1596 - accuracy: 0.5417 - precision: 0.6374 - recall: 0.402 - ETA: 0s - loss: 1.1289 - accuracy: 0.5511 - precision: 0.6502 - recall: 0.411 - ETA: 0s - loss: 1.1276 - accuracy: 0.5529 - precision: 0.6732 - recall: 0.415 - 1s 1ms/sample - loss: 1.1268 - accuracy: 0.5516 - precision: 0.6756 - recall: 0.4155 - val_loss: 1.0736 - val_accuracy: 0.5352 - val_precision: 0.6944 - val_recall: 0.3521\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9649 - accuracy: 0.5625 - precision: 0.9412 - recall: 0.500 - ETA: 0s - loss: 0.8654 - accuracy: 0.6458 - precision: 0.8833 - recall: 0.552 - ETA: 0s - loss: 0.9584 - accuracy: 0.5938 - precision: 0.7938 - recall: 0.481 - ETA: 0s - loss: 1.0273 - accuracy: 0.5670 - precision: 0.7422 - recall: 0.424 - ETA: 0s - loss: 1.0197 - accuracy: 0.5764 - precision: 0.7564 - recall: 0.409 - ETA: 0s - loss: 0.9974 - accuracy: 0.5852 - precision: 0.7676 - recall: 0.403 - ETA: 0s - loss: 0.9997 - accuracy: 0.5865 - precision: 0.7816 - recall: 0.387 - 1s 1ms/sample - loss: 1.0085 - accuracy: 0.5845 - precision: 0.7847 - recall: 0.3850 - val_loss: 1.0783 - val_accuracy: 0.5070 - val_precision: 0.7458 - val_recall: 0.3099\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0624 - accuracy: 0.6250 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 0.9502 - accuracy: 0.6354 - precision: 0.8333 - recall: 0.364 - ETA: 0s - loss: 0.9450 - accuracy: 0.6375 - precision: 0.8841 - recall: 0.381 - ETA: 0s - loss: 0.9560 - accuracy: 0.6339 - precision: 0.8654 - recall: 0.401 - ETA: 0s - loss: 0.9294 - accuracy: 0.6493 - precision: 0.8500 - recall: 0.413 - ETA: 0s - loss: 0.9261 - accuracy: 0.6477 - precision: 0.8555 - recall: 0.420 - ETA: 0s - loss: 0.9310 - accuracy: 0.6418 - precision: 0.8302 - recall: 0.423 - 1s 1ms/sample - loss: 0.9229 - accuracy: 0.6455 - precision: 0.8311 - recall: 0.4272 - val_loss: 1.0363 - val_accuracy: 0.5352 - val_precision: 0.6591 - val_recall: 0.4085\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0938 - accuracy: 0.5625 - precision: 0.6500 - recall: 0.406 - ETA: 0s - loss: 0.9549 - accuracy: 0.6354 - precision: 0.7705 - recall: 0.489 - ETA: 0s - loss: 0.9118 - accuracy: 0.6562 - precision: 0.7755 - recall: 0.475 - ETA: 0s - loss: 0.8736 - accuracy: 0.6518 - precision: 0.7955 - recall: 0.468 - ETA: 0s - loss: 0.8843 - accuracy: 0.6562 - precision: 0.7829 - recall: 0.475 - ETA: 0s - loss: 0.8889 - accuracy: 0.6506 - precision: 0.7818 - recall: 0.488 - ETA: 0s - loss: 0.8826 - accuracy: 0.6484 - precision: 0.7778 - recall: 0.492 - 1s 3ms/sample - loss: 0.8742 - accuracy: 0.6526 - precision: 0.7836 - recall: 0.4930 - val_loss: 1.0600 - val_accuracy: 0.5282 - val_precision: 0.6506 - val_recall: 0.3803\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.7188 - precision: 0.9048 - recall: 0.593 - ETA: 0s - loss: 1.0429 - accuracy: 0.5938 - precision: 0.7627 - recall: 0.468 - ETA: 0s - loss: 0.9268 - accuracy: 0.6438 - precision: 0.7938 - recall: 0.481 - ETA: 0s - loss: 0.9341 - accuracy: 0.6295 - precision: 0.7820 - recall: 0.464 - ETA: 0s - loss: 0.8890 - accuracy: 0.6389 - precision: 0.7853 - recall: 0.482 - ETA: 0s - loss: 0.8742 - accuracy: 0.6420 - precision: 0.7945 - recall: 0.494 - ETA: 0s - loss: 0.8789 - accuracy: 0.6418 - precision: 0.7969 - recall: 0.490 - 1s 1ms/sample - loss: 0.8762 - accuracy: 0.6408 - precision: 0.8000 - recall: 0.4883 - val_loss: 0.9917 - val_accuracy: 0.5563 - val_precision: 0.7237 - val_recall: 0.3873\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.6562 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.8231 - accuracy: 0.6667 - precision: 0.8103 - recall: 0.489 - ETA: 0s - loss: 0.8523 - accuracy: 0.6187 - precision: 0.7917 - recall: 0.475 - ETA: 0s - loss: 0.8720 - accuracy: 0.6250 - precision: 0.7926 - recall: 0.477 - ETA: 0s - loss: 0.8703 - accuracy: 0.6354 - precision: 0.7978 - recall: 0.506 - ETA: 0s - loss: 0.8692 - accuracy: 0.6335 - precision: 0.7826 - recall: 0.511 - ETA: 0s - loss: 0.8555 - accuracy: 0.6442 - precision: 0.7889 - recall: 0.512 - 1s 1ms/sample - loss: 0.8495 - accuracy: 0.6479 - precision: 0.7935 - recall: 0.5141 - val_loss: 1.0318 - val_accuracy: 0.5423 - val_precision: 0.6629 - val_recall: 0.4155\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.6875 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.9022 - accuracy: 0.6146 - precision: 0.7313 - recall: 0.510 - ETA: 0s - loss: 0.9185 - accuracy: 0.6438 - precision: 0.7477 - recall: 0.518 - ETA: 0s - loss: 0.9049 - accuracy: 0.6473 - precision: 0.7718 - recall: 0.513 - ETA: 0s - loss: 0.8792 - accuracy: 0.6597 - precision: 0.7720 - recall: 0.517 - ETA: 0s - loss: 0.8639 - accuracy: 0.6648 - precision: 0.7821 - recall: 0.519 - ETA: 0s - loss: 0.8501 - accuracy: 0.6707 - precision: 0.7929 - recall: 0.533 - 1s 1ms/sample - loss: 0.8431 - accuracy: 0.6690 - precision: 0.7944 - recall: 0.5352 - val_loss: 1.0357 - val_accuracy: 0.5000 - val_precision: 0.6824 - val_recall: 0.4085\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.8125 - precision: 0.8750 - recall: 0.656 - ETA: 0s - loss: 0.7247 - accuracy: 0.7604 - precision: 0.8551 - recall: 0.614 - ETA: 0s - loss: 0.7728 - accuracy: 0.7250 - precision: 0.8158 - recall: 0.581 - ETA: 0s - loss: 0.7788 - accuracy: 0.7054 - precision: 0.8141 - recall: 0.567 - ETA: 0s - loss: 0.7755 - accuracy: 0.7014 - precision: 0.8168 - recall: 0.572 - ETA: 0s - loss: 0.8114 - accuracy: 0.6818 - precision: 0.7928 - recall: 0.565 - ETA: 0s - loss: 0.8249 - accuracy: 0.6683 - precision: 0.7752 - recall: 0.555 - 1s 1ms/sample - loss: 0.8382 - accuracy: 0.6596 - precision: 0.7697 - recall: 0.5493 - val_loss: 1.0891 - val_accuracy: 0.5211 - val_precision: 0.6667 - val_recall: 0.4085\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8540 - accuracy: 0.6250 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 0.8885 - accuracy: 0.6458 - precision: 0.7206 - recall: 0.510 - ETA: 0s - loss: 0.9556 - accuracy: 0.6250 - precision: 0.7168 - recall: 0.506 - ETA: 0s - loss: 0.9621 - accuracy: 0.6116 - precision: 0.7051 - recall: 0.491 - ETA: 0s - loss: 0.9557 - accuracy: 0.6007 - precision: 0.7035 - recall: 0.486 - ETA: 0s - loss: 0.9499 - accuracy: 0.6136 - precision: 0.7137 - recall: 0.502 - ETA: 0s - loss: 0.9693 - accuracy: 0.6010 - precision: 0.7073 - recall: 0.488 - 1s 1ms/sample - loss: 0.9602 - accuracy: 0.6056 - precision: 0.7143 - recall: 0.4930 - val_loss: 0.9970 - val_accuracy: 0.5563 - val_precision: 0.7273 - val_recall: 0.3944\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8485 - accuracy: 0.7188 - precision: 0.9000 - recall: 0.562 - ETA: 0s - loss: 0.8553 - accuracy: 0.6354 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.8747 - accuracy: 0.6562 - precision: 0.7807 - recall: 0.556 - ETA: 0s - loss: 0.9199 - accuracy: 0.6295 - precision: 0.7532 - recall: 0.517 - ETA: 0s - loss: 0.9360 - accuracy: 0.6215 - precision: 0.7461 - recall: 0.500 - ETA: 0s - loss: 0.9256 - accuracy: 0.6165 - precision: 0.7574 - recall: 0.505 - ETA: 0s - loss: 0.9246 - accuracy: 0.6130 - precision: 0.7446 - recall: 0.497 - 1s 1ms/sample - loss: 0.9263 - accuracy: 0.6127 - precision: 0.7430 - recall: 0.4953 - val_loss: 1.1014 - val_accuracy: 0.5000 - val_precision: 0.6353 - val_recall: 0.3803\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7638 - accuracy: 0.7188 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 0.8963 - accuracy: 0.6667 - precision: 0.7600 - recall: 0.395 - ETA: 0s - loss: 0.8898 - accuracy: 0.6750 - precision: 0.7955 - recall: 0.437 - ETA: 0s - loss: 0.9023 - accuracy: 0.6652 - precision: 0.7591 - recall: 0.464 - ETA: 0s - loss: 0.9116 - accuracy: 0.6701 - precision: 0.7528 - recall: 0.465 - ETA: 0s - loss: 0.8959 - accuracy: 0.6705 - precision: 0.7661 - recall: 0.474 - ETA: 0s - loss: 0.8771 - accuracy: 0.6755 - precision: 0.7769 - recall: 0.485 - 1s 1ms/sample - loss: 0.8746 - accuracy: 0.6737 - precision: 0.7744 - recall: 0.4836 - val_loss: 0.9617 - val_accuracy: 0.5704 - val_precision: 0.6932 - val_recall: 0.4296\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9813 - accuracy: 0.6562 - precision: 0.8421 - recall: 0.500 - ETA: 0s - loss: 0.8390 - accuracy: 0.6979 - precision: 0.8387 - recall: 0.541 - ETA: 0s - loss: 0.8523 - accuracy: 0.6687 - precision: 0.7885 - recall: 0.512 - ETA: 0s - loss: 0.8019 - accuracy: 0.6652 - precision: 0.8067 - recall: 0.540 - ETA: 0s - loss: 0.8437 - accuracy: 0.6667 - precision: 0.7887 - recall: 0.531 - ETA: 0s - loss: 0.8488 - accuracy: 0.6562 - precision: 0.7664 - recall: 0.531 - ETA: 0s - loss: 0.8397 - accuracy: 0.6562 - precision: 0.7762 - recall: 0.533 - 1s 1ms/sample - loss: 0.8376 - accuracy: 0.6596 - precision: 0.7801 - recall: 0.5329 - val_loss: 0.9817 - val_accuracy: 0.5563 - val_precision: 0.6932 - val_recall: 0.4296\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8208 - accuracy: 0.7188 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.7760 - accuracy: 0.7083 - precision: 0.8333 - recall: 0.572 - ETA: 0s - loss: 0.7482 - accuracy: 0.7188 - precision: 0.8435 - recall: 0.606 - ETA: 0s - loss: 0.7457 - accuracy: 0.7098 - precision: 0.8323 - recall: 0.598 - ETA: 0s - loss: 0.7740 - accuracy: 0.6910 - precision: 0.8058 - recall: 0.576 - ETA: 0s - loss: 0.7809 - accuracy: 0.6875 - precision: 0.7984 - recall: 0.585 - ETA: 0s - loss: 0.7920 - accuracy: 0.6731 - precision: 0.7862 - recall: 0.574 - 1s 1ms/sample - loss: 0.7986 - accuracy: 0.6667 - precision: 0.7764 - recall: 0.5704 - val_loss: 1.1208 - val_accuracy: 0.5423 - val_precision: 0.6632 - val_recall: 0.4437\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9026 - accuracy: 0.6562 - precision: 0.7619 - recall: 0.500 - ETA: 0s - loss: 0.8888 - accuracy: 0.6562 - precision: 0.7571 - recall: 0.552 - ETA: 0s - loss: 0.9002 - accuracy: 0.6875 - precision: 0.7917 - recall: 0.593 - ETA: 0s - loss: 0.8540 - accuracy: 0.6964 - precision: 0.7895 - recall: 0.602 - ETA: 0s - loss: 0.8347 - accuracy: 0.6944 - precision: 0.8009 - recall: 0.586 - ETA: 0s - loss: 0.8366 - accuracy: 0.6847 - precision: 0.7761 - recall: 0.571 - ETA: 0s - loss: 0.8453 - accuracy: 0.6779 - precision: 0.7664 - recall: 0.560 - 1s 1ms/sample - loss: 0.8537 - accuracy: 0.6761 - precision: 0.7670 - recall: 0.5563 - val_loss: 1.1450 - val_accuracy: 0.5352 - val_precision: 0.5816 - val_recall: 0.4014\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8093 - accuracy: 0.6562 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.7250 - accuracy: 0.7188 - precision: 0.7941 - recall: 0.562 - ETA: 0s - loss: 0.7187 - accuracy: 0.7125 - precision: 0.7967 - recall: 0.612 - ETA: 0s - loss: 0.6872 - accuracy: 0.7321 - precision: 0.8079 - recall: 0.638 - ETA: 0s - loss: 0.7252 - accuracy: 0.7153 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.7511 - accuracy: 0.7074 - precision: 0.7962 - recall: 0.599 - ETA: 0s - loss: 0.7722 - accuracy: 0.6947 - precision: 0.7830 - recall: 0.598 - 1s 1ms/sample - loss: 0.7713 - accuracy: 0.6948 - precision: 0.7853 - recall: 0.6009 - val_loss: 1.0812 - val_accuracy: 0.5493 - val_precision: 0.6286 - val_recall: 0.4648\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8247 - accuracy: 0.6875 - precision: 0.6667 - recall: 0.500 - ETA: 0s - loss: 0.8130 - accuracy: 0.6667 - precision: 0.7432 - recall: 0.572 - ETA: 0s - loss: 0.7707 - accuracy: 0.6625 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.7698 - accuracy: 0.6830 - precision: 0.7740 - recall: 0.611 - ETA: 0s - loss: 0.7794 - accuracy: 0.6840 - precision: 0.7589 - recall: 0.590 - ETA: 0s - loss: 0.7845 - accuracy: 0.6847 - precision: 0.7614 - recall: 0.571 - ETA: 0s - loss: 0.7735 - accuracy: 0.6923 - precision: 0.7767 - recall: 0.576 - 1s 1ms/sample - loss: 0.7723 - accuracy: 0.6901 - precision: 0.7753 - recall: 0.5751 - val_loss: 0.9870 - val_accuracy: 0.6056 - val_precision: 0.6733 - val_recall: 0.4789\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.8125 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.5665 - accuracy: 0.7708 - precision: 0.8193 - recall: 0.708 - ETA: 0s - loss: 0.7158 - accuracy: 0.6938 - precision: 0.7463 - recall: 0.625 - ETA: 0s - loss: 0.7373 - accuracy: 0.7054 - precision: 0.7553 - recall: 0.633 - ETA: 0s - loss: 0.7225 - accuracy: 0.7257 - precision: 0.7754 - recall: 0.635 - ETA: 0s - loss: 0.7433 - accuracy: 0.7216 - precision: 0.7578 - recall: 0.622 - ETA: 0s - loss: 0.7549 - accuracy: 0.7043 - precision: 0.7419 - recall: 0.608 - 1s 1ms/sample - loss: 0.7515 - accuracy: 0.7066 - precision: 0.7443 - recall: 0.6080 - val_loss: 1.0669 - val_accuracy: 0.5423 - val_precision: 0.6117 - val_recall: 0.4437\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.7188 - precision: 0.7917 - recall: 0.593 - ETA: 0s - loss: 0.6941 - accuracy: 0.7188 - precision: 0.8056 - recall: 0.604 - ETA: 0s - loss: 0.7214 - accuracy: 0.7188 - precision: 0.7869 - recall: 0.600 - ETA: 0s - loss: 0.7084 - accuracy: 0.7277 - precision: 0.7953 - recall: 0.607 - ETA: 0s - loss: 0.6944 - accuracy: 0.7361 - precision: 0.7913 - recall: 0.631 - ETA: 0s - loss: 0.7098 - accuracy: 0.7273 - precision: 0.7837 - recall: 0.627 - ETA: 0s - loss: 0.7157 - accuracy: 0.7188 - precision: 0.7851 - recall: 0.632 - 1s 1ms/sample - loss: 0.7196 - accuracy: 0.7160 - precision: 0.7813 - recall: 0.6291 - val_loss: 0.9935 - val_accuracy: 0.5986 - val_precision: 0.6637 - val_recall: 0.5282\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.8125 - precision: 0.9200 - recall: 0.718 - ETA: 0s - loss: 0.7092 - accuracy: 0.7500 - precision: 0.8400 - recall: 0.656 - ETA: 0s - loss: 0.6751 - accuracy: 0.7437 - precision: 0.8559 - recall: 0.631 - ETA: 0s - loss: 0.7181 - accuracy: 0.7411 - precision: 0.8303 - recall: 0.611 - ETA: 0s - loss: 0.6780 - accuracy: 0.7569 - precision: 0.8433 - recall: 0.635 - ETA: 0s - loss: 0.6974 - accuracy: 0.7528 - precision: 0.8264 - recall: 0.622 - ETA: 0s - loss: 0.7003 - accuracy: 0.7404 - precision: 0.8190 - recall: 0.620 - 1s 1ms/sample - loss: 0.7063 - accuracy: 0.7347 - precision: 0.8137 - recall: 0.6150 - val_loss: 1.0191 - val_accuracy: 0.5986 - val_precision: 0.6916 - val_recall: 0.5211\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.7812 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.7839 - accuracy: 0.7083 - precision: 0.7439 - recall: 0.635 - ETA: 0s - loss: 0.7326 - accuracy: 0.7188 - precision: 0.7836 - recall: 0.656 - ETA: 0s - loss: 0.6957 - accuracy: 0.7321 - precision: 0.8022 - recall: 0.651 - ETA: 0s - loss: 0.6585 - accuracy: 0.7431 - precision: 0.8147 - recall: 0.656 - ETA: 0s - loss: 0.6589 - accuracy: 0.7443 - precision: 0.8099 - recall: 0.653 - ETA: 0s - loss: 0.6857 - accuracy: 0.7332 - precision: 0.8036 - recall: 0.639 - 1s 1ms/sample - loss: 0.6868 - accuracy: 0.7347 - precision: 0.8042 - recall: 0.6362 - val_loss: 0.9184 - val_accuracy: 0.5986 - val_precision: 0.7157 - val_recall: 0.5141\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8125 - precision: 0.9630 - recall: 0.812 - ETA: 0s - loss: 0.6247 - accuracy: 0.7812 - precision: 0.8553 - recall: 0.677 - ETA: 0s - loss: 0.7064 - accuracy: 0.7375 - precision: 0.8145 - recall: 0.631 - ETA: 0s - loss: 0.7555 - accuracy: 0.7098 - precision: 0.7874 - recall: 0.611 - ETA: 0s - loss: 0.7205 - accuracy: 0.7431 - precision: 0.8197 - recall: 0.663 - ETA: 0s - loss: 0.7294 - accuracy: 0.7358 - precision: 0.8149 - recall: 0.650 - ETA: 0s - loss: 0.7207 - accuracy: 0.7428 - precision: 0.8146 - recall: 0.644 - 1s 1ms/sample - loss: 0.7215 - accuracy: 0.7441 - precision: 0.8190 - recall: 0.6479 - val_loss: 1.1281 - val_accuracy: 0.5493 - val_precision: 0.6531 - val_recall: 0.4507\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6515 - accuracy: 0.6562 - precision: 0.7037 - recall: 0.593 - ETA: 0s - loss: 0.7334 - accuracy: 0.6875 - precision: 0.7368 - recall: 0.583 - ETA: 0s - loss: 0.7327 - accuracy: 0.7063 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.6878 - accuracy: 0.7366 - precision: 0.7943 - recall: 0.620 - ETA: 0s - loss: 0.6717 - accuracy: 0.7431 - precision: 0.8080 - recall: 0.628 - ETA: 0s - loss: 0.6822 - accuracy: 0.7273 - precision: 0.8043 - recall: 0.630 - ETA: 0s - loss: 0.6976 - accuracy: 0.7308 - precision: 0.8043 - recall: 0.632 - 1s 1ms/sample - loss: 0.6926 - accuracy: 0.7324 - precision: 0.8060 - recall: 0.6338 - val_loss: 0.9894 - val_accuracy: 0.5845 - val_precision: 0.6549 - val_recall: 0.5211\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.6562 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.6045 - accuracy: 0.7917 - precision: 0.8500 - recall: 0.708 - ETA: 0s - loss: 0.5637 - accuracy: 0.8062 - precision: 0.8489 - recall: 0.737 - ETA: 0s - loss: 0.6078 - accuracy: 0.7857 - precision: 0.8196 - recall: 0.709 - ETA: 0s - loss: 0.6054 - accuracy: 0.7847 - precision: 0.8167 - recall: 0.711 - ETA: 0s - loss: 0.6485 - accuracy: 0.7528 - precision: 0.7914 - recall: 0.679 - ETA: 0s - loss: 0.6900 - accuracy: 0.7308 - precision: 0.7712 - recall: 0.656 - 1s 1ms/sample - loss: 0.6850 - accuracy: 0.7324 - precision: 0.7720 - recall: 0.6596 - val_loss: 1.1953 - val_accuracy: 0.5141 - val_precision: 0.5929 - val_recall: 0.4718\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7292 - accuracy: 0.7500 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.8460 - accuracy: 0.6667 - precision: 0.7037 - recall: 0.593 - ETA: 0s - loss: 0.7674 - accuracy: 0.7063 - precision: 0.7537 - recall: 0.631 - ETA: 0s - loss: 0.8559 - accuracy: 0.6875 - precision: 0.7302 - recall: 0.616 - ETA: 0s - loss: 0.8700 - accuracy: 0.6771 - precision: 0.7083 - recall: 0.590 - ETA: 0s - loss: 0.8234 - accuracy: 0.6903 - precision: 0.7181 - recall: 0.608 - ETA: 0s - loss: 0.8204 - accuracy: 0.6947 - precision: 0.7301 - recall: 0.617 - 1s 1ms/sample - loss: 0.8232 - accuracy: 0.6925 - precision: 0.7285 - recall: 0.6174 - val_loss: 1.2225 - val_accuracy: 0.5423 - val_precision: 0.6058 - val_recall: 0.4437\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7500 - precision: 0.8400 - recall: 0.656 - ETA: 0s - loss: 0.8611 - accuracy: 0.7083 - precision: 0.7534 - recall: 0.572 - ETA: 0s - loss: 0.8492 - accuracy: 0.7063 - precision: 0.7603 - recall: 0.575 - ETA: 0s - loss: 0.8671 - accuracy: 0.6741 - precision: 0.7273 - recall: 0.571 - ETA: 0s - loss: 0.8402 - accuracy: 0.7014 - precision: 0.7544 - recall: 0.597 - ETA: 0s - loss: 0.8440 - accuracy: 0.6790 - precision: 0.7419 - recall: 0.588 - ETA: 0s - loss: 0.8514 - accuracy: 0.6707 - precision: 0.7414 - recall: 0.572 - 1s 1ms/sample - loss: 0.8564 - accuracy: 0.6690 - precision: 0.7409 - recall: 0.5704 - val_loss: 1.1525 - val_accuracy: 0.5352 - val_precision: 0.6517 - val_recall: 0.4085\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.8438 - precision: 0.9048 - recall: 0.593 - ETA: 0s - loss: 0.7976 - accuracy: 0.7188 - precision: 0.7941 - recall: 0.562 - ETA: 0s - loss: 0.9984 - accuracy: 0.6625 - precision: 0.7257 - recall: 0.512 - ETA: 0s - loss: 1.0257 - accuracy: 0.6429 - precision: 0.7089 - recall: 0.500 - ETA: 0s - loss: 0.9752 - accuracy: 0.6493 - precision: 0.7184 - recall: 0.513 - ETA: 0s - loss: 0.9451 - accuracy: 0.6506 - precision: 0.7103 - recall: 0.508 - ETA: 0s - loss: 0.9190 - accuracy: 0.6538 - precision: 0.7254 - recall: 0.514 - 0s 1ms/sample - loss: 0.9206 - accuracy: 0.6549 - precision: 0.7228 - recall: 0.5141 - val_loss: 1.0777 - val_accuracy: 0.5423 - val_precision: 0.7079 - val_recall: 0.4437\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8892 - accuracy: 0.6250 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.8468 - accuracy: 0.6562 - precision: 0.8125 - recall: 0.541 - ETA: 0s - loss: 0.8047 - accuracy: 0.6812 - precision: 0.8155 - recall: 0.525 - ETA: 0s - loss: 0.8309 - accuracy: 0.6786 - precision: 0.7945 - recall: 0.517 - ETA: 0s - loss: 0.8644 - accuracy: 0.6701 - precision: 0.7842 - recall: 0.517 - ETA: 0s - loss: 0.9220 - accuracy: 0.6619 - precision: 0.7645 - recall: 0.525 - ETA: 0s - loss: 0.9143 - accuracy: 0.6514 - precision: 0.7517 - recall: 0.524 - 0s 1ms/sample - loss: 0.9055 - accuracy: 0.6526 - precision: 0.7500 - recall: 0.5282 - val_loss: 1.1804 - val_accuracy: 0.5423 - val_precision: 0.6038 - val_recall: 0.4507\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1621 - accuracy: 0.6250 - precision: 0.6842 - recall: 0.406 - ETA: 0s - loss: 1.0055 - accuracy: 0.6146 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 0.9788 - accuracy: 0.6313 - precision: 0.7182 - recall: 0.493 - ETA: 0s - loss: 0.9724 - accuracy: 0.6339 - precision: 0.7197 - recall: 0.504 - ETA: 0s - loss: 0.9113 - accuracy: 0.6424 - precision: 0.7463 - recall: 0.531 - ETA: 0s - loss: 0.8827 - accuracy: 0.6534 - precision: 0.7579 - recall: 0.542 - ETA: 0s - loss: 0.8942 - accuracy: 0.6490 - precision: 0.7525 - recall: 0.533 - 1s 1ms/sample - loss: 0.9071 - accuracy: 0.6455 - precision: 0.7492 - recall: 0.5329 - val_loss: 1.1147 - val_accuracy: 0.5141 - val_precision: 0.6395 - val_recall: 0.3873\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.6875 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.7972 - accuracy: 0.6979 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.7963 - accuracy: 0.7000 - precision: 0.7459 - recall: 0.568 - ETA: 0s - loss: 0.8591 - accuracy: 0.6786 - precision: 0.7427 - recall: 0.567 - ETA: 0s - loss: 0.8489 - accuracy: 0.6840 - precision: 0.7593 - recall: 0.569 - ETA: 0s - loss: 0.8620 - accuracy: 0.6761 - precision: 0.7396 - recall: 0.556 - ETA: 0s - loss: 0.8424 - accuracy: 0.6875 - precision: 0.7476 - recall: 0.569 - 1s 1ms/sample - loss: 0.8445 - accuracy: 0.6878 - precision: 0.7469 - recall: 0.5681 - val_loss: 0.9327 - val_accuracy: 0.6127 - val_precision: 0.7157 - val_recall: 0.5141\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7500 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.7059 - accuracy: 0.7396 - precision: 0.7922 - recall: 0.635 - ETA: 0s - loss: 0.7432 - accuracy: 0.7125 - precision: 0.7742 - recall: 0.600 - ETA: 0s - loss: 0.7545 - accuracy: 0.6875 - precision: 0.7500 - recall: 0.589 - ETA: 0s - loss: 0.7051 - accuracy: 0.7222 - precision: 0.7879 - recall: 0.631 - ETA: 0s - loss: 0.7312 - accuracy: 0.6960 - precision: 0.7624 - recall: 0.610 - ETA: 0s - loss: 0.7049 - accuracy: 0.7115 - precision: 0.7761 - recall: 0.625 - 0s 1ms/sample - loss: 0.7064 - accuracy: 0.7136 - precision: 0.7778 - recall: 0.6244 - val_loss: 1.0041 - val_accuracy: 0.6056 - val_precision: 0.6633 - val_recall: 0.4577\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.7812 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 0.6220 - accuracy: 0.7812 - precision: 0.8611 - recall: 0.645 - ETA: 0s - loss: 0.6848 - accuracy: 0.7375 - precision: 0.8065 - recall: 0.625 - ETA: 0s - loss: 0.7015 - accuracy: 0.7232 - precision: 0.7753 - recall: 0.616 - ETA: 0s - loss: 0.6874 - accuracy: 0.7431 - precision: 0.7860 - recall: 0.625 - ETA: 0s - loss: 0.6813 - accuracy: 0.7301 - precision: 0.7817 - recall: 0.630 - ETA: 0s - loss: 0.6611 - accuracy: 0.7332 - precision: 0.7849 - recall: 0.649 - 1s 1ms/sample - loss: 0.6557 - accuracy: 0.7371 - precision: 0.7875 - recall: 0.6526 - val_loss: 1.1619 - val_accuracy: 0.5845 - val_precision: 0.6372 - val_recall: 0.5070\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.8125 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6897 - accuracy: 0.7604 - precision: 0.7765 - recall: 0.687 - ETA: 0s - loss: 0.6807 - accuracy: 0.7312 - precision: 0.7899 - recall: 0.681 - ETA: 0s - loss: 0.7723 - accuracy: 0.6830 - precision: 0.7407 - recall: 0.625 - ETA: 0s - loss: 0.8125 - accuracy: 0.6736 - precision: 0.7189 - recall: 0.621 - ETA: 0s - loss: 0.8132 - accuracy: 0.6733 - precision: 0.7162 - recall: 0.616 - ETA: 0s - loss: 0.7869 - accuracy: 0.6803 - precision: 0.7288 - recall: 0.620 - 1s 1ms/sample - loss: 0.7736 - accuracy: 0.6854 - precision: 0.7355 - recall: 0.6268 - val_loss: 0.9193 - val_accuracy: 0.6690 - val_precision: 0.7222 - val_recall: 0.5493\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9042 - accuracy: 0.6250 - precision: 0.6923 - recall: 0.562 - ETA: 0s - loss: 0.7446 - accuracy: 0.7083 - precision: 0.7949 - recall: 0.645 - ETA: 0s - loss: 0.7816 - accuracy: 0.6938 - precision: 0.7752 - recall: 0.625 - ETA: 0s - loss: 0.7332 - accuracy: 0.7143 - precision: 0.7849 - recall: 0.651 - ETA: 0s - loss: 0.7230 - accuracy: 0.7188 - precision: 0.7797 - recall: 0.638 - ETA: 0s - loss: 0.7014 - accuracy: 0.7273 - precision: 0.7847 - recall: 0.642 - ETA: 0s - loss: 0.6821 - accuracy: 0.7452 - precision: 0.7994 - recall: 0.651 - 0s 1ms/sample - loss: 0.6794 - accuracy: 0.7441 - precision: 0.8012 - recall: 0.6526 - val_loss: 0.9922 - val_accuracy: 0.6197 - val_precision: 0.7129 - val_recall: 0.5070\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.6562 - precision: 0.6667 - recall: 0.625 - ETA: 0s - loss: 0.7112 - accuracy: 0.6771 - precision: 0.7867 - recall: 0.614 - ETA: 0s - loss: 0.6580 - accuracy: 0.7312 - precision: 0.8231 - recall: 0.668 - ETA: 0s - loss: 0.6513 - accuracy: 0.7321 - precision: 0.8400 - recall: 0.656 - ETA: 0s - loss: 0.6547 - accuracy: 0.7326 - precision: 0.8348 - recall: 0.649 - ETA: 0s - loss: 0.6320 - accuracy: 0.7500 - precision: 0.8459 - recall: 0.670 - ETA: 0s - loss: 0.6418 - accuracy: 0.7596 - precision: 0.8450 - recall: 0.668 - 1s 1ms/sample - loss: 0.6369 - accuracy: 0.7629 - precision: 0.8487 - recall: 0.6714 - val_loss: 0.9643 - val_accuracy: 0.6338 - val_precision: 0.7075 - val_recall: 0.5282\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6917 - accuracy: 0.7083 - precision: 0.7763 - recall: 0.614 - ETA: 0s - loss: 0.6134 - accuracy: 0.7500 - precision: 0.8258 - recall: 0.681 - ETA: 0s - loss: 0.6056 - accuracy: 0.7634 - precision: 0.8261 - recall: 0.678 - ETA: 0s - loss: 0.5960 - accuracy: 0.7708 - precision: 0.8216 - recall: 0.687 - ETA: 0s - loss: 0.6158 - accuracy: 0.7642 - precision: 0.8121 - recall: 0.687 - ETA: 0s - loss: 0.6147 - accuracy: 0.7548 - precision: 0.8074 - recall: 0.685 - 1s 1ms/sample - loss: 0.6145 - accuracy: 0.7535 - precision: 0.8078 - recall: 0.6808 - val_loss: 1.0086 - val_accuracy: 0.6338 - val_precision: 0.7196 - val_recall: 0.5423\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.7188 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.5770 - accuracy: 0.7708 - precision: 0.8293 - recall: 0.708 - ETA: 0s - loss: 0.6484 - accuracy: 0.7500 - precision: 0.8056 - recall: 0.679 - ETA: 0s - loss: 0.6029 - accuracy: 0.7688 - precision: 0.8201 - recall: 0.712 - ETA: 0s - loss: 0.6254 - accuracy: 0.7656 - precision: 0.8144 - recall: 0.708 - ETA: 0s - loss: 0.6307 - accuracy: 0.7589 - precision: 0.8010 - recall: 0.700 - ETA: 0s - loss: 0.6945 - accuracy: 0.7292 - precision: 0.7831 - recall: 0.677 - ETA: 0s - loss: 0.6801 - accuracy: 0.7406 - precision: 0.7942 - recall: 0.687 - ETA: 0s - loss: 0.6699 - accuracy: 0.7422 - precision: 0.7957 - recall: 0.679 - 1s 2ms/sample - loss: 0.6450 - accuracy: 0.7535 - precision: 0.8055 - recall: 0.6901 - val_loss: 1.0129 - val_accuracy: 0.6408 - val_precision: 0.7257 - val_recall: 0.5775\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.7812 - precision: 0.9600 - recall: 0.750 - ETA: 0s - loss: 0.5810 - accuracy: 0.7500 - precision: 0.8293 - recall: 0.708 - ETA: 0s - loss: 0.5838 - accuracy: 0.7312 - precision: 0.8071 - recall: 0.706 - ETA: 0s - loss: 0.6248 - accuracy: 0.7188 - precision: 0.7850 - recall: 0.700 - ETA: 0s - loss: 0.5773 - accuracy: 0.7465 - precision: 0.8008 - recall: 0.725 - ETA: 0s - loss: 0.5710 - accuracy: 0.7614 - precision: 0.8050 - recall: 0.738 - ETA: 0s - loss: 0.5794 - accuracy: 0.7596 - precision: 0.8005 - recall: 0.733 - 1s 1ms/sample - loss: 0.5856 - accuracy: 0.7582 - precision: 0.8015 - recall: 0.7300 - val_loss: 0.9703 - val_accuracy: 0.6549 - val_precision: 0.7069 - val_recall: 0.5775\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7188 - precision: 0.7097 - recall: 0.687 - ETA: 0s - loss: 0.5274 - accuracy: 0.7812 - precision: 0.8313 - recall: 0.718 - ETA: 0s - loss: 0.5505 - accuracy: 0.7812 - precision: 0.8201 - recall: 0.712 - ETA: 0s - loss: 0.5506 - accuracy: 0.7991 - precision: 0.8434 - recall: 0.745 - ETA: 0s - loss: 0.5849 - accuracy: 0.7882 - precision: 0.8320 - recall: 0.739 - ETA: 0s - loss: 0.5909 - accuracy: 0.7841 - precision: 0.8243 - recall: 0.733 - ETA: 0s - loss: 0.5931 - accuracy: 0.7812 - precision: 0.8221 - recall: 0.733 - 1s 1ms/sample - loss: 0.5966 - accuracy: 0.7793 - precision: 0.8232 - recall: 0.7324 - val_loss: 0.9984 - val_accuracy: 0.6479 - val_precision: 0.7083 - val_recall: 0.5986\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.7500 - precision: 0.7667 - recall: 0.718 - ETA: 0s - loss: 0.5491 - accuracy: 0.7917 - precision: 0.8111 - recall: 0.760 - ETA: 0s - loss: 0.5643 - accuracy: 0.7688 - precision: 0.8041 - recall: 0.743 - ETA: 0s - loss: 0.5507 - accuracy: 0.7768 - precision: 0.8146 - recall: 0.745 - ETA: 0s - loss: 0.5540 - accuracy: 0.7778 - precision: 0.8203 - recall: 0.729 - ETA: 0s - loss: 0.5863 - accuracy: 0.7585 - precision: 0.8071 - recall: 0.713 - ETA: 0s - loss: 0.6510 - accuracy: 0.7404 - precision: 0.7886 - recall: 0.699 - 1s 1ms/sample - loss: 0.6571 - accuracy: 0.7347 - precision: 0.7810 - recall: 0.6948 - val_loss: 0.9474 - val_accuracy: 0.6549 - val_precision: 0.7119 - val_recall: 0.5915\n",
      "Epoch 127/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.7352 - accuracy: 0.7500 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6369 - accuracy: 0.8021 - precision: 0.8415 - recall: 0.718 - ETA: 0s - loss: 0.6344 - accuracy: 0.7812 - precision: 0.8188 - recall: 0.706 - ETA: 0s - loss: 0.6560 - accuracy: 0.7589 - precision: 0.8021 - recall: 0.687 - ETA: 0s - loss: 0.6179 - accuracy: 0.7604 - precision: 0.8008 - recall: 0.697 - ETA: 0s - loss: 0.6069 - accuracy: 0.7614 - precision: 0.8078 - recall: 0.704 - ETA: 0s - loss: 0.6125 - accuracy: 0.7644 - precision: 0.8072 - recall: 0.704 - 1s 1ms/sample - loss: 0.6153 - accuracy: 0.7629 - precision: 0.8059 - recall: 0.7019 - val_loss: 0.9484 - val_accuracy: 0.6549 - val_precision: 0.6960 - val_recall: 0.6127\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.875 - ETA: 0s - loss: 0.5088 - accuracy: 0.7917 - precision: 0.8313 - recall: 0.718 - ETA: 0s - loss: 0.5048 - accuracy: 0.8062 - precision: 0.8500 - recall: 0.743 - ETA: 0s - loss: 0.5313 - accuracy: 0.7902 - precision: 0.8367 - recall: 0.732 - ETA: 0s - loss: 0.5694 - accuracy: 0.7708 - precision: 0.8167 - recall: 0.711 - ETA: 0s - loss: 0.5929 - accuracy: 0.7670 - precision: 0.8117 - recall: 0.710 - ETA: 0s - loss: 0.5862 - accuracy: 0.7644 - precision: 0.8115 - recall: 0.713 - 1s 1ms/sample - loss: 0.5884 - accuracy: 0.7653 - precision: 0.8128 - recall: 0.7136 - val_loss: 0.9986 - val_accuracy: 0.5915 - val_precision: 0.6522 - val_recall: 0.5282\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.8438 - precision: 0.9643 - recall: 0.843 - ETA: 0s - loss: 0.5516 - accuracy: 0.8125 - precision: 0.8765 - recall: 0.739 - ETA: 0s - loss: 0.5849 - accuracy: 0.7688 - precision: 0.8333 - recall: 0.718 - ETA: 0s - loss: 0.5942 - accuracy: 0.7679 - precision: 0.8290 - recall: 0.714 - ETA: 0s - loss: 0.5687 - accuracy: 0.7778 - precision: 0.8333 - recall: 0.729 - ETA: 0s - loss: 0.5745 - accuracy: 0.7756 - precision: 0.8284 - recall: 0.713 - ETA: 0s - loss: 0.5677 - accuracy: 0.7788 - precision: 0.8319 - recall: 0.713 - 1s 1ms/sample - loss: 0.5718 - accuracy: 0.7770 - precision: 0.8329 - recall: 0.7136 - val_loss: 1.0232 - val_accuracy: 0.6197 - val_precision: 0.7143 - val_recall: 0.5282\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8125 - precision: 0.8387 - recall: 0.812 - ETA: 0s - loss: 0.5302 - accuracy: 0.8021 - precision: 0.8409 - recall: 0.770 - ETA: 0s - loss: 0.5357 - accuracy: 0.7875 - precision: 0.8392 - recall: 0.750 - ETA: 0s - loss: 0.5557 - accuracy: 0.7857 - precision: 0.8358 - recall: 0.750 - ETA: 0s - loss: 0.5439 - accuracy: 0.7882 - precision: 0.8372 - recall: 0.750 - ETA: 0s - loss: 0.5268 - accuracy: 0.8011 - precision: 0.8423 - recall: 0.758 - ETA: 0s - loss: 0.5499 - accuracy: 0.7885 - precision: 0.8259 - recall: 0.752 - 1s 1ms/sample - loss: 0.5500 - accuracy: 0.7887 - precision: 0.8252 - recall: 0.7535 - val_loss: 1.0360 - val_accuracy: 0.6901 - val_precision: 0.7236 - val_recall: 0.6268\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.8438 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.5895 - accuracy: 0.7917 - precision: 0.8222 - recall: 0.770 - ETA: 0s - loss: 0.6250 - accuracy: 0.7812 - precision: 0.8207 - recall: 0.743 - ETA: 0s - loss: 0.5707 - accuracy: 0.7946 - precision: 0.8342 - recall: 0.741 - ETA: 0s - loss: 0.5870 - accuracy: 0.7847 - precision: 0.8307 - recall: 0.732 - ETA: 0s - loss: 0.5785 - accuracy: 0.7869 - precision: 0.8264 - recall: 0.730 - ETA: 0s - loss: 0.5787 - accuracy: 0.7837 - precision: 0.8221 - recall: 0.733 - 1s 1ms/sample - loss: 0.5820 - accuracy: 0.7817 - precision: 0.8211 - recall: 0.7324 - val_loss: 0.9948 - val_accuracy: 0.6197 - val_precision: 0.6587 - val_recall: 0.5845\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.6875 - precision: 0.7333 - recall: 0.687 - ETA: 0s - loss: 0.6204 - accuracy: 0.7188 - precision: 0.7841 - recall: 0.718 - ETA: 0s - loss: 0.6035 - accuracy: 0.7625 - precision: 0.7986 - recall: 0.718 - ETA: 0s - loss: 0.6141 - accuracy: 0.7634 - precision: 0.7921 - recall: 0.714 - ETA: 0s - loss: 0.5909 - accuracy: 0.7778 - precision: 0.8140 - recall: 0.729 - ETA: 0s - loss: 0.5906 - accuracy: 0.7784 - precision: 0.8139 - recall: 0.733 - ETA: 0s - loss: 0.5653 - accuracy: 0.7981 - precision: 0.8267 - recall: 0.745 - 1s 1ms/sample - loss: 0.5588 - accuracy: 0.8005 - precision: 0.8286 - recall: 0.7488 - val_loss: 0.9854 - val_accuracy: 0.6620 - val_precision: 0.7156 - val_recall: 0.5493\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.7812 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.5362 - accuracy: 0.7917 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.5129 - accuracy: 0.8000 - precision: 0.8741 - recall: 0.737 - ETA: 0s - loss: 0.5280 - accuracy: 0.7812 - precision: 0.8474 - recall: 0.718 - ETA: 0s - loss: 0.5056 - accuracy: 0.7882 - precision: 0.8446 - recall: 0.736 - ETA: 0s - loss: 0.5476 - accuracy: 0.7784 - precision: 0.8264 - recall: 0.730 - ETA: 0s - loss: 0.5685 - accuracy: 0.7668 - precision: 0.8157 - recall: 0.723 - 1s 1ms/sample - loss: 0.5686 - accuracy: 0.7653 - precision: 0.8148 - recall: 0.7230 - val_loss: 0.9011 - val_accuracy: 0.6620 - val_precision: 0.7317 - val_recall: 0.6338\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.7500 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.5917 - accuracy: 0.7708 - precision: 0.8046 - recall: 0.729 - ETA: 0s - loss: 0.5947 - accuracy: 0.7812 - precision: 0.8176 - recall: 0.756 - ETA: 0s - loss: 0.5830 - accuracy: 0.8036 - precision: 0.8350 - recall: 0.767 - ETA: 0s - loss: 0.6227 - accuracy: 0.8021 - precision: 0.8284 - recall: 0.770 - ETA: 0s - loss: 0.6151 - accuracy: 0.7955 - precision: 0.8215 - recall: 0.758 - ETA: 0s - loss: 0.6387 - accuracy: 0.7885 - precision: 0.8094 - recall: 0.745 - 1s 1ms/sample - loss: 0.6320 - accuracy: 0.7887 - precision: 0.8092 - recall: 0.7465 - val_loss: 0.9681 - val_accuracy: 0.6479 - val_precision: 0.7025 - val_recall: 0.5986\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8750 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.3968 - accuracy: 0.8958 - precision: 0.9213 - recall: 0.854 - ETA: 0s - loss: 0.4777 - accuracy: 0.8438 - precision: 0.8784 - recall: 0.812 - ETA: 0s - loss: 0.5014 - accuracy: 0.8259 - precision: 0.8544 - recall: 0.785 - ETA: 0s - loss: 0.5511 - accuracy: 0.8160 - precision: 0.8352 - recall: 0.774 - ETA: 0s - loss: 0.5749 - accuracy: 0.8068 - precision: 0.8246 - recall: 0.761 - ETA: 0s - loss: 0.5678 - accuracy: 0.8077 - precision: 0.8269 - recall: 0.769 - 1s 1ms/sample - loss: 0.5676 - accuracy: 0.8028 - precision: 0.8253 - recall: 0.7653 - val_loss: 0.9458 - val_accuracy: 0.6479 - val_precision: 0.6960 - val_recall: 0.6127\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8125 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.6829 - accuracy: 0.7396 - precision: 0.7816 - recall: 0.708 - ETA: 0s - loss: 0.6909 - accuracy: 0.7437 - precision: 0.8028 - recall: 0.712 - ETA: 0s - loss: 0.6850 - accuracy: 0.7277 - precision: 0.7897 - recall: 0.687 - ETA: 0s - loss: 0.6708 - accuracy: 0.7326 - precision: 0.7897 - recall: 0.691 - ETA: 0s - loss: 0.6638 - accuracy: 0.7500 - precision: 0.8000 - recall: 0.704 - ETA: 0s - loss: 0.6504 - accuracy: 0.7524 - precision: 0.8027 - recall: 0.704 - 1s 1ms/sample - loss: 0.6468 - accuracy: 0.7535 - precision: 0.8027 - recall: 0.7066 - val_loss: 0.9979 - val_accuracy: 0.6338 - val_precision: 0.6923 - val_recall: 0.5704\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8438 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.4414 - accuracy: 0.8333 - precision: 0.8953 - recall: 0.802 - ETA: 0s - loss: 0.4503 - accuracy: 0.8188 - precision: 0.8819 - recall: 0.793 - ETA: 0s - loss: 0.4770 - accuracy: 0.8125 - precision: 0.8706 - recall: 0.781 - ETA: 0s - loss: 0.5079 - accuracy: 0.8021 - precision: 0.8571 - recall: 0.770 - ETA: 0s - loss: 0.5094 - accuracy: 0.8011 - precision: 0.8571 - recall: 0.767 - ETA: 0s - loss: 0.5176 - accuracy: 0.8005 - precision: 0.8518 - recall: 0.759 - 1s 1ms/sample - loss: 0.5217 - accuracy: 0.7958 - precision: 0.8451 - recall: 0.7559 - val_loss: 0.8994 - val_accuracy: 0.6549 - val_precision: 0.7097 - val_recall: 0.6197\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8125 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.5156 - accuracy: 0.8229 - precision: 0.8370 - recall: 0.802 - ETA: 0s - loss: 0.5298 - accuracy: 0.8125 - precision: 0.8301 - recall: 0.793 - ETA: 0s - loss: 0.5295 - accuracy: 0.8036 - precision: 0.8199 - recall: 0.772 - ETA: 0s - loss: 0.5027 - accuracy: 0.8125 - precision: 0.8327 - recall: 0.777 - ETA: 0s - loss: 0.5458 - accuracy: 0.7869 - precision: 0.8135 - recall: 0.755 - ETA: 0s - loss: 0.5765 - accuracy: 0.7740 - precision: 0.8042 - recall: 0.740 - 1s 1ms/sample - loss: 0.5841 - accuracy: 0.7723 - precision: 0.8015 - recall: 0.7394 - val_loss: 1.0176 - val_accuracy: 0.6620 - val_precision: 0.6905 - val_recall: 0.6127\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5844 - accuracy: 0.7188 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.5756 - accuracy: 0.7604 - precision: 0.8235 - recall: 0.729 - ETA: 0s - loss: 0.5941 - accuracy: 0.7500 - precision: 0.7959 - recall: 0.731 - ETA: 0s - loss: 0.5782 - accuracy: 0.7545 - precision: 0.8060 - recall: 0.723 - ETA: 0s - loss: 0.5893 - accuracy: 0.7535 - precision: 0.8038 - recall: 0.725 - ETA: 0s - loss: 0.6005 - accuracy: 0.7500 - precision: 0.8032 - recall: 0.718 - ETA: 0s - loss: 0.6192 - accuracy: 0.7452 - precision: 0.7946 - recall: 0.706 - 1s 1ms/sample - loss: 0.6135 - accuracy: 0.7488 - precision: 0.7974 - recall: 0.7113 - val_loss: 1.0426 - val_accuracy: 0.5845 - val_precision: 0.6476 - val_recall: 0.4789\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7812 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.5796 - accuracy: 0.7500 - precision: 0.8571 - recall: 0.687 - ETA: 0s - loss: 0.5969 - accuracy: 0.7688 - precision: 0.8571 - recall: 0.675 - ETA: 0s - loss: 0.5676 - accuracy: 0.7857 - precision: 0.8634 - recall: 0.705 - ETA: 0s - loss: 0.5857 - accuracy: 0.7743 - precision: 0.8475 - recall: 0.694 - ETA: 0s - loss: 0.5873 - accuracy: 0.7812 - precision: 0.8552 - recall: 0.704 - ETA: 0s - loss: 0.5877 - accuracy: 0.7788 - precision: 0.8464 - recall: 0.701 - 1s 1ms/sample - loss: 0.5808 - accuracy: 0.7840 - precision: 0.8503 - recall: 0.7066 - val_loss: 0.9297 - val_accuracy: 0.7042 - val_precision: 0.7373 - val_recall: 0.6127\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.8750 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.4780 - accuracy: 0.8750 - precision: 0.9167 - recall: 0.802 - ETA: 0s - loss: 0.5087 - accuracy: 0.8562 - precision: 0.8750 - recall: 0.787 - ETA: 0s - loss: 0.5020 - accuracy: 0.8482 - precision: 0.8756 - recall: 0.785 - ETA: 0s - loss: 0.5018 - accuracy: 0.8403 - precision: 0.8654 - recall: 0.781 - ETA: 0s - loss: 0.5235 - accuracy: 0.8239 - precision: 0.8469 - recall: 0.769 - ETA: 0s - loss: 0.5376 - accuracy: 0.8221 - precision: 0.8511 - recall: 0.769 - 1s 1ms/sample - loss: 0.5290 - accuracy: 0.8263 - precision: 0.8549 - recall: 0.7746 - val_loss: 1.0199 - val_accuracy: 0.6690 - val_precision: 0.7109 - val_recall: 0.6408\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8750 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.7958 - accuracy: 0.7917 - precision: 0.7826 - recall: 0.750 - ETA: 0s - loss: 0.6833 - accuracy: 0.7937 - precision: 0.8133 - recall: 0.762 - ETA: 0s - loss: 0.6719 - accuracy: 0.7857 - precision: 0.8038 - recall: 0.750 - ETA: 0s - loss: 0.6762 - accuracy: 0.7812 - precision: 0.7903 - recall: 0.732 - ETA: 0s - loss: 0.7524 - accuracy: 0.7528 - precision: 0.7640 - recall: 0.698 - ETA: 0s - loss: 0.8150 - accuracy: 0.7308 - precision: 0.7493 - recall: 0.682 - 1s 1ms/sample - loss: 0.8394 - accuracy: 0.7277 - precision: 0.7474 - recall: 0.6808 - val_loss: 1.8235 - val_accuracy: 0.4859 - val_precision: 0.5161 - val_recall: 0.4507\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1517 - accuracy: 0.5938 - precision: 0.6129 - recall: 0.593 - ETA: 0s - loss: 1.2742 - accuracy: 0.5625 - precision: 0.6071 - recall: 0.531 - ETA: 0s - loss: 1.3876 - accuracy: 0.5188 - precision: 0.5821 - recall: 0.487 - ETA: 0s - loss: 1.4358 - accuracy: 0.5179 - precision: 0.5676 - recall: 0.468 - ETA: 0s - loss: 1.3817 - accuracy: 0.5347 - precision: 0.5859 - recall: 0.461 - ETA: 0s - loss: 1.3518 - accuracy: 0.5341 - precision: 0.5839 - recall: 0.454 - ETA: 0s - loss: 1.3263 - accuracy: 0.5385 - precision: 0.6000 - recall: 0.461 - 1s 1ms/sample - loss: 1.3242 - accuracy: 0.5329 - precision: 0.5975 - recall: 0.4531 - val_loss: 1.3918 - val_accuracy: 0.4930 - val_precision: 0.5833 - val_recall: 0.3451\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8260 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 1.0626 - accuracy: 0.6042 - precision: 0.7101 - recall: 0.510 - ETA: 0s - loss: 1.2230 - accuracy: 0.5562 - precision: 0.6952 - recall: 0.456 - ETA: 0s - loss: 1.3117 - accuracy: 0.5268 - precision: 0.6691 - recall: 0.415 - ETA: 0s - loss: 1.3363 - accuracy: 0.5347 - precision: 0.6505 - recall: 0.420 - ETA: 0s - loss: 1.3851 - accuracy: 0.5199 - precision: 0.6128 - recall: 0.409 - ETA: 0s - loss: 1.3743 - accuracy: 0.5096 - precision: 0.5957 - recall: 0.403 - 1s 1ms/sample - loss: 1.3700 - accuracy: 0.5117 - precision: 0.5938 - recall: 0.4014 - val_loss: 1.5830 - val_accuracy: 0.4577 - val_precision: 0.5368 - val_recall: 0.3592\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5472 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.218 - ETA: 0s - loss: 1.2328 - accuracy: 0.5417 - precision: 0.6500 - recall: 0.406 - ETA: 0s - loss: 1.1960 - accuracy: 0.5750 - precision: 0.6476 - recall: 0.425 - ETA: 0s - loss: 1.1642 - accuracy: 0.5804 - precision: 0.6733 - recall: 0.450 - ETA: 0s - loss: 1.2322 - accuracy: 0.5486 - precision: 0.6302 - recall: 0.420 - ETA: 0s - loss: 1.2079 - accuracy: 0.5568 - precision: 0.6360 - recall: 0.431 - ETA: 0s - loss: 1.2029 - accuracy: 0.5625 - precision: 0.6607 - recall: 0.444 - 1s 1ms/sample - loss: 1.1946 - accuracy: 0.5610 - precision: 0.6597 - recall: 0.4460 - val_loss: 1.3093 - val_accuracy: 0.5141 - val_precision: 0.5567 - val_recall: 0.3803\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9143 - accuracy: 0.5938 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 0.8475 - accuracy: 0.6667 - precision: 0.7465 - recall: 0.552 - ETA: 0s - loss: 0.8688 - accuracy: 0.6812 - precision: 0.7545 - recall: 0.518 - ETA: 0s - loss: 0.9357 - accuracy: 0.6384 - precision: 0.7273 - recall: 0.464 - ETA: 0s - loss: 0.9460 - accuracy: 0.6389 - precision: 0.7283 - recall: 0.465 - ETA: 0s - loss: 0.9410 - accuracy: 0.6506 - precision: 0.7342 - recall: 0.463 - ETA: 0s - loss: 0.9539 - accuracy: 0.6322 - precision: 0.7214 - recall: 0.454 - 1s 1ms/sample - loss: 0.9578 - accuracy: 0.6315 - precision: 0.7164 - recall: 0.4507 - val_loss: 1.2106 - val_accuracy: 0.5423 - val_precision: 0.6413 - val_recall: 0.4155\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.8418 - accuracy: 0.6875 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.9245 - accuracy: 0.6354 - precision: 0.7344 - recall: 0.489 - ETA: 0s - loss: 0.8918 - accuracy: 0.6687 - precision: 0.7456 - recall: 0.531 - ETA: 0s - loss: 0.8570 - accuracy: 0.6920 - precision: 0.7975 - recall: 0.562 - ETA: 0s - loss: 0.8401 - accuracy: 0.6944 - precision: 0.8109 - recall: 0.566 - ETA: 0s - loss: 0.8688 - accuracy: 0.6761 - precision: 0.8050 - recall: 0.551 - ETA: 0s - loss: 0.8898 - accuracy: 0.6683 - precision: 0.7951 - recall: 0.540 - 1s 1ms/sample - loss: 0.8937 - accuracy: 0.6667 - precision: 0.7958 - recall: 0.5399 - val_loss: 1.2342 - val_accuracy: 0.5704 - val_precision: 0.6091 - val_recall: 0.4718\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.7500 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.7030 - accuracy: 0.7344 - precision: 0.7872 - recall: 0.578 - ETA: 0s - loss: 0.7978 - accuracy: 0.6875 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.8020 - accuracy: 0.6823 - precision: 0.7584 - recall: 0.588 - ETA: 0s - loss: 0.8329 - accuracy: 0.6875 - precision: 0.7488 - recall: 0.593 - ETA: 0s - loss: 0.8062 - accuracy: 0.6969 - precision: 0.7628 - recall: 0.603 - ETA: 0s - loss: 0.8038 - accuracy: 0.7005 - precision: 0.7614 - recall: 0.606 - 1s 1ms/sample - loss: 0.7948 - accuracy: 0.6972 - precision: 0.7573 - recall: 0.6080 - val_loss: 1.0473 - val_accuracy: 0.6338 - val_precision: 0.7103 - val_recall: 0.5352\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.6875 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.7671 - accuracy: 0.7292 - precision: 0.7792 - recall: 0.625 - ETA: 0s - loss: 0.6831 - accuracy: 0.7812 - precision: 0.8258 - recall: 0.681 - ETA: 0s - loss: 0.7053 - accuracy: 0.7455 - precision: 0.8098 - recall: 0.665 - ETA: 0s - loss: 0.6871 - accuracy: 0.7500 - precision: 0.8133 - recall: 0.680 - ETA: 0s - loss: 0.6924 - accuracy: 0.7415 - precision: 0.8000 - recall: 0.670 - ETA: 0s - loss: 0.7080 - accuracy: 0.7380 - precision: 0.7965 - recall: 0.658 - 1s 1ms/sample - loss: 0.7055 - accuracy: 0.7394 - precision: 0.7960 - recall: 0.6596 - val_loss: 1.0029 - val_accuracy: 0.6127 - val_precision: 0.6696 - val_recall: 0.5423\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8438 - precision: 0.8929 - recall: 0.781 - ETA: 0s - loss: 0.5663 - accuracy: 0.8021 - precision: 0.8452 - recall: 0.739 - ETA: 0s - loss: 0.5810 - accuracy: 0.7812 - precision: 0.8298 - recall: 0.731 - ETA: 0s - loss: 0.6224 - accuracy: 0.7812 - precision: 0.8325 - recall: 0.709 - ETA: 0s - loss: 0.6073 - accuracy: 0.7917 - precision: 0.8415 - recall: 0.718 - ETA: 0s - loss: 0.6093 - accuracy: 0.7812 - precision: 0.8317 - recall: 0.715 - ETA: 0s - loss: 0.6149 - accuracy: 0.7788 - precision: 0.8260 - recall: 0.718 - 1s 1ms/sample - loss: 0.6132 - accuracy: 0.7770 - precision: 0.8270 - recall: 0.7183 - val_loss: 1.0216 - val_accuracy: 0.6761 - val_precision: 0.7143 - val_recall: 0.6338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 0940dfd21db9193398ef98808267ab02</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7042253613471985</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_input: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           82176     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 256)          328704    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           82176     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 944,652\n",
      "Trainable params: 944,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:34 - loss: 2.4867 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 43s - loss: 2.4802 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 26s - loss: 2.4686 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 18s - loss: 2.4435 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 9s - loss: 2.4146 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 7s - loss: 2.4318 - accuracy: 0.0982 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 5s - loss: 2.4217 - accuracy: 0.0977 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 2s - loss: 2.4113 - accuracy: 0.1125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.4128 - accuracy: 0.1051 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3999 - accuracy: 0.1106 - precision: 0.0000e+00 - recall: 0.0000e+0 - 10s 24ms/sample - loss: 2.3949 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2642 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2579 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2370 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2190 - accuracy: 0.1875 - precision: 0.3333 - recall: 0.0125        - ETA: 0s - loss: 2.1744 - accuracy: 0.2188 - precision: 0.3333 - recall: 0.008 - ETA: 0s - loss: 2.1455 - accuracy: 0.2083 - precision: 0.3333 - recall: 0.006 - ETA: 0s - loss: 2.1211 - accuracy: 0.2159 - precision: 0.3333 - recall: 0.005 - ETA: 0s - loss: 2.0854 - accuracy: 0.2091 - precision: 0.3333 - recall: 0.004 - 1s 2ms/sample - loss: 2.0880 - accuracy: 0.2089 - precision: 0.3333 - recall: 0.0047 - val_loss: 2.2576 - val_accuracy: 0.1408 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9343 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0498 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0852 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0464 - accuracy: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0451 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9935 - accuracy: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9866 - accuracy: 0.2212 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9845 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8167 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8810 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7873 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7819 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8086 - accuracy: 0.2455 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8036 - accuracy: 0.2383 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8143 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8286 - accuracy: 0.2472 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9316 - accuracy: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9446 - accuracy: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2921 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.6405 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2241 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1052 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0822 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0735 - accuracy: 0.1910 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0574 - accuracy: 0.1818 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0382 - accuracy: 0.1827 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.0428 - accuracy: 0.1784 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9165 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7568 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8607 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.0104        - ETA: 0s - loss: 1.8666 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.006 - ETA: 0s - loss: 1.9064 - accuracy: 0.2366 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.9085 - accuracy: 0.2222 - precision: 0.5000 - recall: 0.003 - ETA: 0s - loss: 1.9199 - accuracy: 0.2159 - precision: 0.5000 - recall: 0.002 - ETA: 0s - loss: 1.9047 - accuracy: 0.2139 - precision: 0.5000 - recall: 0.002 - 1s 2ms/sample - loss: 1.9055 - accuracy: 0.2136 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.8478 - val_accuracy: 0.2183 - val_precision: 0.5000 - val_recall: 0.0070\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8381 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8076 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.0104        - ETA: 0s - loss: 1.7985 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.018 - ETA: 0s - loss: 1.8162 - accuracy: 0.2589 - precision: 0.5000 - recall: 0.017 - ETA: 0s - loss: 1.8875 - accuracy: 0.2326 - precision: 0.5000 - recall: 0.013 - ETA: 0s - loss: 1.9101 - accuracy: 0.2472 - precision: 0.5000 - recall: 0.011 - ETA: 0s - loss: 1.9091 - accuracy: 0.2452 - precision: 0.5000 - recall: 0.009 - 1s 2ms/sample - loss: 1.9085 - accuracy: 0.2441 - precision: 0.5000 - recall: 0.0094 - val_loss: 1.9347 - val_accuracy: 0.1831 - val_precision: 0.5000 - val_recall: 0.0070\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9233 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8937 - accuracy: 0.1979 - precision: 0.5000 - recall: 0.010 - ETA: 0s - loss: 1.8944 - accuracy: 0.1937 - precision: 0.5000 - recall: 0.006 - ETA: 0s - loss: 1.8355 - accuracy: 0.1964 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.8464 - accuracy: 0.2049 - precision: 0.5000 - recall: 0.003 - ETA: 0s - loss: 1.8376 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.002 - ETA: 0s - loss: 1.8289 - accuracy: 0.2236 - precision: 0.5000 - recall: 0.002 - 1s 2ms/sample - loss: 1.8245 - accuracy: 0.2277 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.8587 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7262 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7314 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8088 - accuracy: 0.2937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8198 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8500 - accuracy: 0.2578 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8530 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8412 - accuracy: 0.2358 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8354 - accuracy: 0.2332 - precision: 1.0000 - recall: 0.0024        - 1s 2ms/sample - loss: 1.8399 - accuracy: 0.2324 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.9020 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9983 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7982 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8123 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8083 - accuracy: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7962 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7988 - accuracy: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8021 - accuracy: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7927 - accuracy: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7890 - accuracy: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7984 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6267 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7278 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7675 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7516 - accuracy: 0.2634 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7526 - accuracy: 0.2847 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7659 - accuracy: 0.2699 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7697 - accuracy: 0.2861 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7687 - accuracy: 0.2793 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7721 - val_accuracy: 0.2606 - val_precision: 0.6667 - val_recall: 0.0141\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9066 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7908 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.0312        - ETA: 0s - loss: 1.7646 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.025 - ETA: 0s - loss: 1.7529 - accuracy: 0.3080 - precision: 0.5000 - recall: 0.017 - ETA: 0s - loss: 1.7515 - accuracy: 0.2812 - precision: 0.5556 - recall: 0.017 - ETA: 0s - loss: 1.7524 - accuracy: 0.2784 - precision: 0.5556 - recall: 0.014 - ETA: 0s - loss: 1.7712 - accuracy: 0.2692 - precision: 0.5556 - recall: 0.012 - 1s 2ms/sample - loss: 1.7704 - accuracy: 0.2700 - precision: 0.5556 - recall: 0.0117 - val_loss: 1.8872 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8076 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7702 - accuracy: 0.2969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7253 - accuracy: 0.2734 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7337 - accuracy: 0.2865 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7608 - accuracy: 0.2656 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7516 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7345 - accuracy: 0.2578 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7348 - accuracy: 0.2653 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7440 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8361 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7526 - accuracy: 0.2656 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7753 - accuracy: 0.2578 - precision: 0.5000 - recall: 0.0078        - ETA: 0s - loss: 1.8225 - accuracy: 0.2604 - precision: 0.5000 - recall: 0.005 - ETA: 0s - loss: 1.7940 - accuracy: 0.2679 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.7728 - accuracy: 0.2674 - precision: 0.5000 - recall: 0.003 - ETA: 0s - loss: 1.7954 - accuracy: 0.2670 - precision: 0.5000 - recall: 0.002 - ETA: 0s - loss: 1.7709 - accuracy: 0.2692 - precision: 0.5000 - recall: 0.002 - 1s 2ms/sample - loss: 1.7738 - accuracy: 0.2700 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.8468 - val_accuracy: 0.2535 - val_precision: 0.6667 - val_recall: 0.0141\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5097 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6683 - accuracy: 0.3021 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.6707 - accuracy: 0.3063 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.7123 - accuracy: 0.2902 - precision: 1.0000 - recall: 0.004 - ETA: 0s - loss: 1.7760 - accuracy: 0.2674 - precision: 1.0000 - recall: 0.003 - ETA: 0s - loss: 1.7971 - accuracy: 0.2585 - precision: 1.0000 - recall: 0.005 - ETA: 0s - loss: 1.7866 - accuracy: 0.2572 - precision: 1.0000 - recall: 0.004 - 1s 2ms/sample - loss: 1.7864 - accuracy: 0.2606 - precision: 1.0000 - recall: 0.0047 - val_loss: 1.6728 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6800 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7572 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6506 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6554 - accuracy: 0.3214 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6600 - accuracy: 0.3090 - precision: 0.6667 - recall: 0.0069        - ETA: 0s - loss: 1.6568 - accuracy: 0.3068 - precision: 0.5385 - recall: 0.019 - ETA: 0s - loss: 1.6323 - accuracy: 0.3077 - precision: 0.5385 - recall: 0.016 - 1s 2ms/sample - loss: 1.6317 - accuracy: 0.3122 - precision: 0.5385 - recall: 0.0164 - val_loss: 1.8270 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7092 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7057 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7135 - accuracy: 0.2891 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7332 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7329 - accuracy: 0.2857 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6961 - accuracy: 0.2847 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7028 - accuracy: 0.2642 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7020 - accuracy: 0.2740 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7024 - accuracy: 0.2700 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6809 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0563\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6743 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6718 - accuracy: 0.3333 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.6171 - accuracy: 0.3281 - precision: 1.0000 - recall: 0.046 - ETA: 0s - loss: 1.6461 - accuracy: 0.3333 - precision: 0.7500 - recall: 0.046 - ETA: 0s - loss: 1.6878 - accuracy: 0.3164 - precision: 0.6667 - recall: 0.046 - ETA: 0s - loss: 1.6632 - accuracy: 0.3313 - precision: 0.7000 - recall: 0.043 - ETA: 0s - loss: 1.6591 - accuracy: 0.3255 - precision: 0.7200 - recall: 0.046 - 1s 2ms/sample - loss: 1.6416 - accuracy: 0.3310 - precision: 0.7500 - recall: 0.0493 - val_loss: 1.6265 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0634\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6114 - accuracy: 0.3229 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6194 - accuracy: 0.3313 - precision: 0.9000 - recall: 0.056 - ETA: 0s - loss: 1.5852 - accuracy: 0.3348 - precision: 0.8750 - recall: 0.062 - ETA: 0s - loss: 1.5598 - accuracy: 0.3542 - precision: 0.9000 - recall: 0.062 - ETA: 0s - loss: 1.5859 - accuracy: 0.3466 - precision: 0.9000 - recall: 0.051 - ETA: 0s - loss: 1.5872 - accuracy: 0.3341 - precision: 0.9091 - recall: 0.048 - 1s 2ms/sample - loss: 1.6066 - accuracy: 0.3310 - precision: 0.9091 - recall: 0.0469 - val_loss: 1.6535 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0493\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5856 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.0312        - ETA: 0s - loss: 1.5191 - accuracy: 0.3750 - precision: 0.8750 - recall: 0.043 - ETA: 0s - loss: 1.5439 - accuracy: 0.3527 - precision: 0.9333 - recall: 0.062 - ETA: 0s - loss: 1.5709 - accuracy: 0.3403 - precision: 0.8421 - recall: 0.055 - ETA: 0s - loss: 1.5832 - accuracy: 0.3608 - precision: 0.8571 - recall: 0.051 - ETA: 0s - loss: 1.5711 - accuracy: 0.3558 - precision: 0.8846 - recall: 0.055 - 1s 2ms/sample - loss: 1.5655 - accuracy: 0.3592 - precision: 0.8846 - recall: 0.0540 - val_loss: 1.5518 - val_accuracy: 0.3732 - val_precision: 1.0000 - val_recall: 0.0775\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5705 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.5036 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.041 - ETA: 0s - loss: 1.4668 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.050 - ETA: 0s - loss: 1.4673 - accuracy: 0.4152 - precision: 0.8500 - recall: 0.075 - ETA: 0s - loss: 1.4581 - accuracy: 0.4340 - precision: 0.7742 - recall: 0.083 - ETA: 0s - loss: 1.5037 - accuracy: 0.4091 - precision: 0.6327 - recall: 0.088 - ETA: 0s - loss: 1.5281 - accuracy: 0.4062 - precision: 0.6032 - recall: 0.091 - 1s 2ms/sample - loss: 1.5481 - accuracy: 0.3991 - precision: 0.5821 - recall: 0.0915 - val_loss: 1.6153 - val_accuracy: 0.3803 - val_precision: 0.7826 - val_recall: 0.1268\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6528 - accuracy: 0.3750 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.7064 - accuracy: 0.3281 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6169 - accuracy: 0.3438 - precision: 0.6190 - recall: 0.101 - ETA: 0s - loss: 1.6053 - accuracy: 0.3438 - precision: 0.6800 - recall: 0.088 - ETA: 0s - loss: 1.6085 - accuracy: 0.3281 - precision: 0.6774 - recall: 0.082 - ETA: 0s - loss: 1.6016 - accuracy: 0.3375 - precision: 0.6857 - recall: 0.075 - ETA: 0s - loss: 1.5971 - accuracy: 0.3295 - precision: 0.7027 - recall: 0.073 - ETA: 0s - loss: 1.6035 - accuracy: 0.3173 - precision: 0.6383 - recall: 0.072 - 1s 2ms/sample - loss: 1.5950 - accuracy: 0.3192 - precision: 0.6667 - recall: 0.0798 - val_loss: 1.6120 - val_accuracy: 0.2887 - val_precision: 0.9091 - val_recall: 0.1408\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4434 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.5863 - accuracy: 0.4167 - precision: 0.8500 - recall: 0.177 - ETA: 0s - loss: 1.6110 - accuracy: 0.4000 - precision: 0.7419 - recall: 0.143 - ETA: 0s - loss: 1.6010 - accuracy: 0.4241 - precision: 0.7250 - recall: 0.129 - ETA: 0s - loss: 1.6362 - accuracy: 0.3924 - precision: 0.6800 - recall: 0.118 - ETA: 0s - loss: 1.6357 - accuracy: 0.3750 - precision: 0.6863 - recall: 0.099 - ETA: 0s - loss: 1.6424 - accuracy: 0.3606 - precision: 0.7037 - recall: 0.091 - 1s 2ms/sample - loss: 1.6416 - accuracy: 0.3568 - precision: 0.7037 - recall: 0.0892 - val_loss: 1.5798 - val_accuracy: 0.3662 - val_precision: 0.7500 - val_recall: 0.1056\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.9941 - accuracy: 0.3333 - precision: 0.3478 - recall: 0.083 - ETA: 0s - loss: 2.0474 - accuracy: 0.3000 - precision: 0.2766 - recall: 0.081 - ETA: 0s - loss: 2.0682 - accuracy: 0.2917 - precision: 0.2787 - recall: 0.088 - ETA: 0s - loss: 2.0470 - accuracy: 0.2695 - precision: 0.2787 - recall: 0.066 - ETA: 0s - loss: 2.0160 - accuracy: 0.2531 - precision: 0.2787 - recall: 0.053 - ETA: 0s - loss: 1.9476 - accuracy: 0.2630 - precision: 0.2787 - recall: 0.044 - 1s 2ms/sample - loss: 1.9385 - accuracy: 0.2653 - precision: 0.2857 - recall: 0.0423 - val_loss: 2.0236 - val_accuracy: 0.2465 - val_precision: 0.6471 - val_recall: 0.0775\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2975 - accuracy: 0.3438 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.9641 - accuracy: 0.2500 - precision: 0.2500 - recall: 0.031 - ETA: 0s - loss: 2.0081 - accuracy: 0.2562 - precision: 0.3125 - recall: 0.031 - ETA: 0s - loss: 2.0020 - accuracy: 0.2589 - precision: 0.3500 - recall: 0.031 - ETA: 0s - loss: 1.9705 - accuracy: 0.2500 - precision: 0.3913 - recall: 0.035 - ETA: 0s - loss: 1.9301 - accuracy: 0.2656 - precision: 0.4516 - recall: 0.043 - ETA: 0s - loss: 1.9213 - accuracy: 0.2682 - precision: 0.4375 - recall: 0.036 - ETA: 0s - loss: 1.9029 - accuracy: 0.2692 - precision: 0.4857 - recall: 0.040 - 1s 2ms/sample - loss: 1.9118 - accuracy: 0.2653 - precision: 0.4857 - recall: 0.0399 - val_loss: 1.8377 - val_accuracy: 0.2535 - val_precision: 0.4444 - val_recall: 0.0563\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8181 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8197 - accuracy: 0.2500 - precision: 0.6000 - recall: 0.0312        - ETA: 0s - loss: 1.8838 - accuracy: 0.2313 - precision: 0.4074 - recall: 0.068 - ETA: 0s - loss: 1.8770 - accuracy: 0.2455 - precision: 0.4222 - recall: 0.084 - ETA: 0s - loss: 1.8249 - accuracy: 0.2778 - precision: 0.4375 - recall: 0.097 - ETA: 0s - loss: 1.8079 - accuracy: 0.2812 - precision: 0.4304 - recall: 0.096 - ETA: 0s - loss: 1.7860 - accuracy: 0.2861 - precision: 0.4405 - recall: 0.088 - 1s 2ms/sample - loss: 1.7865 - accuracy: 0.2840 - precision: 0.4405 - recall: 0.0869 - val_loss: 1.6889 - val_accuracy: 0.3239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5592 - accuracy: 0.5312 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5643 - accuracy: 0.4583 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6534 - accuracy: 0.3938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6366 - accuracy: 0.3661 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6356 - accuracy: 0.3611 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6503 - accuracy: 0.3580 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6389 - accuracy: 0.3558 - precision: 0.4000 - recall: 0.0048        - 1s 2ms/sample - loss: 1.6459 - accuracy: 0.3498 - precision: 0.4000 - recall: 0.0047 - val_loss: 1.6841 - val_accuracy: 0.3239 - val_precision: 0.8667 - val_recall: 0.0915\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5630 - accuracy: 0.2500 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6390 - accuracy: 0.3438 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.5776 - accuracy: 0.3500 - precision: 0.7895 - recall: 0.093 - ETA: 0s - loss: 1.5979 - accuracy: 0.3438 - precision: 0.8000 - recall: 0.071 - ETA: 0s - loss: 1.5787 - accuracy: 0.3785 - precision: 0.8077 - recall: 0.072 - ETA: 0s - loss: 1.5904 - accuracy: 0.3781 - precision: 0.7931 - recall: 0.071 - ETA: 0s - loss: 1.5968 - accuracy: 0.3568 - precision: 0.7812 - recall: 0.065 - 1s 2ms/sample - loss: 1.5923 - accuracy: 0.3568 - precision: 0.7568 - recall: 0.0657 - val_loss: 1.5835 - val_accuracy: 0.3521 - val_precision: 0.8235 - val_recall: 0.0986\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.5782 - accuracy: 0.3854 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6329 - accuracy: 0.3625 - precision: 0.6842 - recall: 0.081 - ETA: 0s - loss: 1.6187 - accuracy: 0.3438 - precision: 0.6800 - recall: 0.075 - ETA: 0s - loss: 1.5767 - accuracy: 0.3576 - precision: 0.7097 - recall: 0.076 - ETA: 0s - loss: 1.5782 - accuracy: 0.3594 - precision: 0.7097 - recall: 0.068 - ETA: 0s - loss: 1.5810 - accuracy: 0.3594 - precision: 0.6923 - recall: 0.070 - 1s 2ms/sample - loss: 1.5755 - accuracy: 0.3592 - precision: 0.6829 - recall: 0.0657 - val_loss: 1.6788 - val_accuracy: 0.3592 - val_precision: 1.0000 - val_recall: 0.0563\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5707 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.5206 - accuracy: 0.3958 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.4941 - accuracy: 0.4125 - precision: 0.8571 - recall: 0.037 - ETA: 0s - loss: 1.5294 - accuracy: 0.3839 - precision: 0.8889 - recall: 0.035 - ETA: 0s - loss: 1.5685 - accuracy: 0.3715 - precision: 0.9000 - recall: 0.031 - ETA: 0s - loss: 1.5669 - accuracy: 0.3750 - precision: 0.8750 - recall: 0.039 - ETA: 0s - loss: 1.5769 - accuracy: 0.3822 - precision: 0.8571 - recall: 0.043 - 1s 2ms/sample - loss: 1.5800 - accuracy: 0.3756 - precision: 0.8571 - recall: 0.0423 - val_loss: 1.5536 - val_accuracy: 0.3873 - val_precision: 0.8667 - val_recall: 0.0915\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5467 - accuracy: 0.3333 - precision: 0.8182 - recall: 0.093 - ETA: 0s - loss: 1.4792 - accuracy: 0.4000 - precision: 0.8571 - recall: 0.075 - ETA: 0s - loss: 1.4997 - accuracy: 0.3750 - precision: 0.8333 - recall: 0.067 - ETA: 0s - loss: 1.5500 - accuracy: 0.3750 - precision: 0.6857 - recall: 0.083 - ETA: 0s - loss: 1.5621 - accuracy: 0.3835 - precision: 0.6667 - recall: 0.090 - ETA: 0s - loss: 1.5777 - accuracy: 0.3750 - precision: 0.6491 - recall: 0.088 - 1s 2ms/sample - loss: 1.5739 - accuracy: 0.3756 - precision: 0.6333 - recall: 0.0892 - val_loss: 1.5767 - val_accuracy: 0.3944 - val_precision: 0.8333 - val_recall: 0.1408\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4414 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5021 - accuracy: 0.4167 - precision: 0.7368 - recall: 0.145 - ETA: 0s - loss: 1.5036 - accuracy: 0.4062 - precision: 0.7500 - recall: 0.150 - ETA: 0s - loss: 1.4799 - accuracy: 0.4196 - precision: 0.7556 - recall: 0.151 - ETA: 0s - loss: 1.5287 - accuracy: 0.3854 - precision: 0.7000 - recall: 0.121 - ETA: 0s - loss: 1.5366 - accuracy: 0.3835 - precision: 0.7037 - recall: 0.108 - ETA: 0s - loss: 1.5326 - accuracy: 0.3870 - precision: 0.7213 - recall: 0.105 - 1s 2ms/sample - loss: 1.5334 - accuracy: 0.3850 - precision: 0.7213 - recall: 0.1033 - val_loss: 1.6209 - val_accuracy: 0.3592 - val_precision: 0.7778 - val_recall: 0.0986\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6761 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.6489 - accuracy: 0.3646 - precision: 0.6000 - recall: 0.031 - ETA: 0s - loss: 1.6754 - accuracy: 0.3375 - precision: 0.6000 - recall: 0.018 - ETA: 0s - loss: 1.6297 - accuracy: 0.3571 - precision: 0.7778 - recall: 0.031 - ETA: 0s - loss: 1.6024 - accuracy: 0.3542 - precision: 0.8571 - recall: 0.041 - ETA: 0s - loss: 1.5732 - accuracy: 0.3665 - precision: 0.8421 - recall: 0.045 - ETA: 0s - loss: 1.5726 - accuracy: 0.3606 - precision: 0.8750 - recall: 0.050 - 1s 2ms/sample - loss: 1.5662 - accuracy: 0.3615 - precision: 0.8519 - recall: 0.0540 - val_loss: 1.5574 - val_accuracy: 0.4014 - val_precision: 0.9000 - val_recall: 0.1268\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2047 - accuracy: 0.5312 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.4053 - accuracy: 0.4688 - precision: 0.5926 - recall: 0.166 - ETA: 0s - loss: 1.4892 - accuracy: 0.4437 - precision: 0.5319 - recall: 0.156 - ETA: 0s - loss: 1.4882 - accuracy: 0.4330 - precision: 0.5342 - recall: 0.174 - ETA: 0s - loss: 1.4888 - accuracy: 0.4340 - precision: 0.5192 - recall: 0.187 - ETA: 0s - loss: 1.4978 - accuracy: 0.4091 - precision: 0.5372 - recall: 0.184 - ETA: 0s - loss: 1.5215 - accuracy: 0.3966 - precision: 0.5255 - recall: 0.173 - 1s 2ms/sample - loss: 1.5187 - accuracy: 0.3944 - precision: 0.5248 - recall: 0.1737 - val_loss: 1.6537 - val_accuracy: 0.3451 - val_precision: 0.7619 - val_recall: 0.1127\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4682 - accuracy: 0.3594 - precision: 0.5714 - recall: 0.062 - ETA: 0s - loss: 1.5136 - accuracy: 0.3047 - precision: 0.6667 - recall: 0.078 - ETA: 0s - loss: 1.4845 - accuracy: 0.3333 - precision: 0.7500 - recall: 0.078 - ETA: 0s - loss: 1.4938 - accuracy: 0.3438 - precision: 0.7727 - recall: 0.066 - ETA: 0s - loss: 1.4917 - accuracy: 0.3438 - precision: 0.6316 - recall: 0.075 - ETA: 0s - loss: 1.5035 - accuracy: 0.3516 - precision: 0.6383 - recall: 0.078 - 1s 2ms/sample - loss: 1.5098 - accuracy: 0.3498 - precision: 0.6346 - recall: 0.0775 - val_loss: 1.7037 - val_accuracy: 0.3521 - val_precision: 0.8261 - val_recall: 0.1338\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7813 - accuracy: 0.4375 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.6693 - accuracy: 0.4375 - precision: 0.7857 - recall: 0.114 - ETA: 0s - loss: 1.7162 - accuracy: 0.4062 - precision: 0.7826 - recall: 0.112 - ETA: 0s - loss: 1.6463 - accuracy: 0.4018 - precision: 0.7333 - recall: 0.098 - ETA: 0s - loss: 1.6501 - accuracy: 0.3889 - precision: 0.6512 - recall: 0.097 - ETA: 0s - loss: 1.6191 - accuracy: 0.3977 - precision: 0.6724 - recall: 0.110 - ETA: 0s - loss: 1.5641 - accuracy: 0.4135 - precision: 0.6750 - recall: 0.129 - 1s 2ms/sample - loss: 1.5643 - accuracy: 0.4131 - precision: 0.6512 - recall: 0.1315 - val_loss: 1.4776 - val_accuracy: 0.4085 - val_precision: 0.6275 - val_recall: 0.2254\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5408 - accuracy: 0.4062 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.4912 - accuracy: 0.5000 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4764 - accuracy: 0.4812 - precision: 0.6667 - recall: 0.100 - ETA: 0s - loss: 1.4341 - accuracy: 0.4732 - precision: 0.7241 - recall: 0.093 - ETA: 0s - loss: 1.4201 - accuracy: 0.4722 - precision: 0.7568 - recall: 0.097 - ETA: 0s - loss: 1.4340 - accuracy: 0.4517 - precision: 0.7400 - recall: 0.105 - ETA: 0s - loss: 1.4233 - accuracy: 0.4495 - precision: 0.7302 - recall: 0.110 - 1s 2ms/sample - loss: 1.4242 - accuracy: 0.4484 - precision: 0.7385 - recall: 0.1127 - val_loss: 1.4810 - val_accuracy: 0.4225 - val_precision: 0.7419 - val_recall: 0.1620\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3677 - accuracy: 0.5312 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.4143 - accuracy: 0.4792 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.3987 - accuracy: 0.4812 - precision: 0.7419 - recall: 0.143 - ETA: 0s - loss: 1.3863 - accuracy: 0.4732 - precision: 0.7292 - recall: 0.156 - ETA: 0s - loss: 1.4079 - accuracy: 0.4583 - precision: 0.7581 - recall: 0.163 - ETA: 0s - loss: 1.4269 - accuracy: 0.4403 - precision: 0.7391 - recall: 0.144 - ETA: 0s - loss: 1.4235 - accuracy: 0.4423 - precision: 0.7317 - recall: 0.144 - 1s 2ms/sample - loss: 1.4199 - accuracy: 0.4437 - precision: 0.7349 - recall: 0.1432 - val_loss: 1.4525 - val_accuracy: 0.4014 - val_precision: 0.7931 - val_recall: 0.1620\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8101 - accuracy: 0.4062 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.5761 - accuracy: 0.4271 - precision: 0.6500 - recall: 0.135 - ETA: 0s - loss: 1.5414 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.137 - ETA: 0s - loss: 1.5494 - accuracy: 0.3884 - precision: 0.6829 - recall: 0.125 - ETA: 0s - loss: 1.5430 - accuracy: 0.3819 - precision: 0.7174 - recall: 0.114 - ETA: 0s - loss: 1.5100 - accuracy: 0.3949 - precision: 0.7273 - recall: 0.113 - ETA: 0s - loss: 1.5003 - accuracy: 0.4135 - precision: 0.7353 - recall: 0.120 - 1s 2ms/sample - loss: 1.5003 - accuracy: 0.4108 - precision: 0.7391 - recall: 0.1197 - val_loss: 1.4721 - val_accuracy: 0.4155 - val_precision: 0.8148 - val_recall: 0.1549\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5739 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.5823 - accuracy: 0.3646 - precision: 0.6111 - recall: 0.114 - ETA: 0s - loss: 1.4757 - accuracy: 0.3875 - precision: 0.7000 - recall: 0.131 - ETA: 0s - loss: 1.4743 - accuracy: 0.3839 - precision: 0.6410 - recall: 0.111 - ETA: 0s - loss: 1.4671 - accuracy: 0.3945 - precision: 0.6522 - recall: 0.117 - ETA: 0s - loss: 1.4658 - accuracy: 0.3969 - precision: 0.6774 - recall: 0.131 - ETA: 0s - loss: 1.4726 - accuracy: 0.3958 - precision: 0.6849 - recall: 0.130 - 1s 2ms/sample - loss: 1.4701 - accuracy: 0.4061 - precision: 0.6941 - recall: 0.1385 - val_loss: 1.5003 - val_accuracy: 0.4085 - val_precision: 0.6275 - val_recall: 0.2254\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2602 - accuracy: 0.5625 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3548 - accuracy: 0.4479 - precision: 0.5667 - recall: 0.177 - ETA: 0s - loss: 1.3715 - accuracy: 0.4437 - precision: 0.5517 - recall: 0.200 - ETA: 0s - loss: 1.4499 - accuracy: 0.4330 - precision: 0.5652 - recall: 0.174 - ETA: 0s - loss: 1.4142 - accuracy: 0.4444 - precision: 0.6265 - recall: 0.180 - ETA: 0s - loss: 1.4032 - accuracy: 0.4437 - precision: 0.6304 - recall: 0.181 - ETA: 0s - loss: 1.4221 - accuracy: 0.4375 - precision: 0.6346 - recall: 0.171 - 1s 2ms/sample - loss: 1.4234 - accuracy: 0.4390 - precision: 0.6167 - recall: 0.1737 - val_loss: 1.5648 - val_accuracy: 0.3873 - val_precision: 0.5849 - val_recall: 0.2183\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3113 - accuracy: 0.4062 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.3857 - accuracy: 0.4062 - precision: 0.6875 - recall: 0.229 - ETA: 0s - loss: 1.3849 - accuracy: 0.4187 - precision: 0.6939 - recall: 0.212 - ETA: 0s - loss: 1.4179 - accuracy: 0.4152 - precision: 0.6441 - recall: 0.169 - ETA: 0s - loss: 1.3972 - accuracy: 0.4340 - precision: 0.6462 - recall: 0.145 - ETA: 0s - loss: 1.3891 - accuracy: 0.4432 - precision: 0.6538 - recall: 0.144 - ETA: 0s - loss: 1.3796 - accuracy: 0.4471 - precision: 0.6627 - recall: 0.132 - 1s 2ms/sample - loss: 1.3936 - accuracy: 0.4390 - precision: 0.6667 - recall: 0.1315 - val_loss: 1.4589 - val_accuracy: 0.4155 - val_precision: 0.7143 - val_recall: 0.1761\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1255 - accuracy: 0.5625 - precision: 0.8182 - recall: 0.281 - ETA: 0s - loss: 1.2854 - accuracy: 0.5417 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.2877 - accuracy: 0.5000 - precision: 0.7442 - recall: 0.200 - ETA: 0s - loss: 1.3329 - accuracy: 0.4732 - precision: 0.6613 - recall: 0.183 - ETA: 0s - loss: 1.3372 - accuracy: 0.4826 - precision: 0.6667 - recall: 0.194 - ETA: 0s - loss: 1.3552 - accuracy: 0.4574 - precision: 0.6771 - recall: 0.184 - ETA: 0s - loss: 1.3721 - accuracy: 0.4423 - precision: 0.6726 - recall: 0.182 - 1s 2ms/sample - loss: 1.3652 - accuracy: 0.4460 - precision: 0.6752 - recall: 0.1854 - val_loss: 1.3994 - val_accuracy: 0.4507 - val_precision: 0.7000 - val_recall: 0.1972\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4185 - accuracy: 0.4375 - precision: 0.3750 - recall: 0.093 - ETA: 0s - loss: 1.4354 - accuracy: 0.4271 - precision: 0.5238 - recall: 0.114 - ETA: 0s - loss: 1.3918 - accuracy: 0.4625 - precision: 0.6667 - recall: 0.162 - ETA: 0s - loss: 1.3705 - accuracy: 0.4688 - precision: 0.7333 - recall: 0.196 - ETA: 0s - loss: 1.3690 - accuracy: 0.4618 - precision: 0.7397 - recall: 0.187 - ETA: 0s - loss: 1.3782 - accuracy: 0.4574 - precision: 0.7204 - recall: 0.190 - ETA: 0s - loss: 1.4364 - accuracy: 0.4423 - precision: 0.6522 - recall: 0.180 - 1s 2ms/sample - loss: 1.4323 - accuracy: 0.4437 - precision: 0.6471 - recall: 0.1808 - val_loss: 2.1426 - val_accuracy: 0.3873 - val_precision: 0.4000 - val_recall: 0.2113\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.8483 - accuracy: 0.3125 - precision: 0.2353 - recall: 0.125 - ETA: 0s - loss: 2.4200 - accuracy: 0.3333 - precision: 0.3276 - recall: 0.197 - ETA: 0s - loss: 2.1758 - accuracy: 0.3562 - precision: 0.3378 - recall: 0.156 - ETA: 0s - loss: 2.0581 - accuracy: 0.3438 - precision: 0.3452 - recall: 0.129 - ETA: 0s - loss: 1.9431 - accuracy: 0.3472 - precision: 0.3939 - recall: 0.135 - ETA: 0s - loss: 1.9013 - accuracy: 0.3580 - precision: 0.4224 - recall: 0.139 - ETA: 0s - loss: 1.9226 - accuracy: 0.3462 - precision: 0.4046 - recall: 0.127 - 1s 2ms/sample - loss: 1.9315 - accuracy: 0.3380 - precision: 0.4015 - recall: 0.1244 - val_loss: 1.9787 - val_accuracy: 0.2958 - val_precision: 0.5000 - val_recall: 0.0915\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5558 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.7094 - accuracy: 0.3333 - precision: 0.7000 - recall: 0.145 - ETA: 0s - loss: 1.8290 - accuracy: 0.2937 - precision: 0.5625 - recall: 0.112 - ETA: 0s - loss: 1.7688 - accuracy: 0.3125 - precision: 0.5625 - recall: 0.120 - ETA: 0s - loss: 1.7654 - accuracy: 0.3194 - precision: 0.5357 - recall: 0.104 - ETA: 0s - loss: 1.7761 - accuracy: 0.3097 - precision: 0.5224 - recall: 0.099 - ETA: 0s - loss: 1.7910 - accuracy: 0.2885 - precision: 0.5278 - recall: 0.091 - 1s 2ms/sample - loss: 1.7943 - accuracy: 0.2887 - precision: 0.5467 - recall: 0.0962 - val_loss: 1.6664 - val_accuracy: 0.2958 - val_precision: 0.6190 - val_recall: 0.0915\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9648 - accuracy: 0.1250 - precision: 0.2857 - recall: 0.062 - ETA: 0s - loss: 1.7681 - accuracy: 0.2604 - precision: 0.4737 - recall: 0.093 - ETA: 0s - loss: 1.6796 - accuracy: 0.3187 - precision: 0.5806 - recall: 0.112 - ETA: 0s - loss: 1.6293 - accuracy: 0.3438 - precision: 0.5682 - recall: 0.111 - ETA: 0s - loss: 1.6012 - accuracy: 0.3611 - precision: 0.6038 - recall: 0.111 - ETA: 0s - loss: 1.6193 - accuracy: 0.3494 - precision: 0.5714 - recall: 0.102 - ETA: 0s - loss: 1.6055 - accuracy: 0.3558 - precision: 0.6081 - recall: 0.108 - 1s 2ms/sample - loss: 1.6092 - accuracy: 0.3545 - precision: 0.6053 - recall: 0.1080 - val_loss: 1.6238 - val_accuracy: 0.3451 - val_precision: 0.5588 - val_recall: 0.1338\n",
      "Epoch 48/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1967 - accuracy: 0.5938 - precision: 1.0000 - recall: 0.250 - ETA: 0s - loss: 1.4930 - accuracy: 0.4167 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.6311 - accuracy: 0.3812 - precision: 0.6200 - recall: 0.193 - ETA: 0s - loss: 1.7070 - accuracy: 0.3348 - precision: 0.5067 - recall: 0.169 - ETA: 0s - loss: 1.7259 - accuracy: 0.3299 - precision: 0.4894 - recall: 0.159 - ETA: 0s - loss: 1.7517 - accuracy: 0.3295 - precision: 0.4775 - recall: 0.150 - ETA: 0s - loss: 1.7605 - accuracy: 0.3221 - precision: 0.4688 - recall: 0.144 - 1s 2ms/sample - loss: 1.7600 - accuracy: 0.3216 - precision: 0.4688 - recall: 0.1408 - val_loss: 1.6663 - val_accuracy: 0.3099 - val_precision: 0.5000 - val_recall: 0.0352\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9045 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7221 - accuracy: 0.3646 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.6869 - accuracy: 0.3187 - precision: 0.6000 - recall: 0.018 - ETA: 0s - loss: 1.7024 - accuracy: 0.3348 - precision: 0.6250 - recall: 0.022 - ETA: 0s - loss: 1.6882 - accuracy: 0.3368 - precision: 0.6250 - recall: 0.017 - ETA: 0s - loss: 1.7205 - accuracy: 0.3125 - precision: 0.5833 - recall: 0.019 - ETA: 0s - loss: 1.7179 - accuracy: 0.3029 - precision: 0.5714 - recall: 0.019 - 1s 2ms/sample - loss: 1.7155 - accuracy: 0.3052 - precision: 0.6000 - recall: 0.0211 - val_loss: 1.6845 - val_accuracy: 0.3451 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4747 - accuracy: 0.4688 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5924 - accuracy: 0.3646 - precision: 0.6000 - recall: 0.031 - ETA: 0s - loss: 1.6271 - accuracy: 0.3562 - precision: 0.6000 - recall: 0.037 - ETA: 0s - loss: 1.6161 - accuracy: 0.3616 - precision: 0.5000 - recall: 0.044 - ETA: 0s - loss: 1.6266 - accuracy: 0.3542 - precision: 0.5862 - recall: 0.059 - ETA: 0s - loss: 1.6373 - accuracy: 0.3494 - precision: 0.6154 - recall: 0.068 - ETA: 0s - loss: 1.6512 - accuracy: 0.3365 - precision: 0.5833 - recall: 0.067 - 1s 2ms/sample - loss: 1.6500 - accuracy: 0.3357 - precision: 0.5833 - recall: 0.0657 - val_loss: 1.6019 - val_accuracy: 0.3803 - val_precision: 0.6522 - val_recall: 0.1056\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5606 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6055 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6612 - accuracy: 0.3187 - precision: 0.6667 - recall: 0.100 - ETA: 0s - loss: 1.6742 - accuracy: 0.3259 - precision: 0.6176 - recall: 0.093 - ETA: 0s - loss: 1.6719 - accuracy: 0.3194 - precision: 0.5918 - recall: 0.100 - ETA: 0s - loss: 1.6694 - accuracy: 0.3182 - precision: 0.5571 - recall: 0.110 - ETA: 0s - loss: 1.7009 - accuracy: 0.3173 - precision: 0.5000 - recall: 0.108 - 1s 2ms/sample - loss: 1.7006 - accuracy: 0.3216 - precision: 0.5106 - recall: 0.1127 - val_loss: 1.6096 - val_accuracy: 0.3028 - val_precision: 0.5882 - val_recall: 0.1408\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7764 - accuracy: 0.1875 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.7043 - accuracy: 0.3021 - precision: 0.6471 - recall: 0.114 - ETA: 0s - loss: 1.7842 - accuracy: 0.2625 - precision: 0.6316 - recall: 0.075 - ETA: 0s - loss: 1.9271 - accuracy: 0.2500 - precision: 0.6316 - recall: 0.053 - ETA: 0s - loss: 1.9065 - accuracy: 0.2500 - precision: 0.5909 - recall: 0.045 - ETA: 0s - loss: 1.8751 - accuracy: 0.2594 - precision: 0.5652 - recall: 0.040 - ETA: 0s - loss: 1.8613 - accuracy: 0.2552 - precision: 0.5417 - recall: 0.033 - ETA: 0s - loss: 1.8738 - accuracy: 0.2500 - precision: 0.5600 - recall: 0.033 - 1s 2ms/sample - loss: 1.8605 - accuracy: 0.2559 - precision: 0.5556 - recall: 0.0352 - val_loss: 1.7223 - val_accuracy: 0.2817 - val_precision: 0.4615 - val_recall: 0.0423\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9628 - accuracy: 0.1562 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8749 - accuracy: 0.2500 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.8616 - accuracy: 0.2500 - precision: 0.7778 - recall: 0.054 - ETA: 0s - loss: 1.8316 - accuracy: 0.2656 - precision: 0.6364 - recall: 0.036 - ETA: 0s - loss: 1.8244 - accuracy: 0.2812 - precision: 0.6923 - recall: 0.035 - ETA: 0s - loss: 1.8419 - accuracy: 0.2688 - precision: 0.6667 - recall: 0.031 - ETA: 0s - loss: 1.8353 - accuracy: 0.2734 - precision: 0.5500 - recall: 0.028 - ETA: 0s - loss: 1.8498 - accuracy: 0.2644 - precision: 0.5000 - recall: 0.026 - 1s 2ms/sample - loss: 1.8448 - accuracy: 0.2676 - precision: 0.4783 - recall: 0.0258 - val_loss: 1.7555 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8058 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6862 - accuracy: 0.2708 - precision: 0.8889 - recall: 0.0833        - ETA: 0s - loss: 1.6529 - accuracy: 0.3063 - precision: 0.8421 - recall: 0.100 - ETA: 0s - loss: 1.6830 - accuracy: 0.2679 - precision: 0.7308 - recall: 0.084 - ETA: 0s - loss: 1.6851 - accuracy: 0.2847 - precision: 0.6667 - recall: 0.090 - ETA: 0s - loss: 1.7208 - accuracy: 0.2699 - precision: 0.5962 - recall: 0.088 - ETA: 0s - loss: 1.7308 - accuracy: 0.2620 - precision: 0.5862 - recall: 0.081 - 1s 2ms/sample - loss: 1.7340 - accuracy: 0.2629 - precision: 0.5833 - recall: 0.0822 - val_loss: 1.7571 - val_accuracy: 0.2324 - val_precision: 0.4667 - val_recall: 0.0493\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8137 - accuracy: 0.3125 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.6510 - accuracy: 0.2917 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6864 - accuracy: 0.2688 - precision: 0.7857 - recall: 0.068 - ETA: 0s - loss: 1.7895 - accuracy: 0.2545 - precision: 0.5714 - recall: 0.053 - ETA: 0s - loss: 1.8302 - accuracy: 0.2500 - precision: 0.5185 - recall: 0.048 - ETA: 0s - loss: 1.8340 - accuracy: 0.2386 - precision: 0.4839 - recall: 0.042 - ETA: 0s - loss: 1.8243 - accuracy: 0.2428 - precision: 0.5238 - recall: 0.052 - 1s 2ms/sample - loss: 1.8188 - accuracy: 0.2488 - precision: 0.5455 - recall: 0.0563 - val_loss: 1.7761 - val_accuracy: 0.2394 - val_precision: 0.5185 - val_recall: 0.0986\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9268 - accuracy: 0.2812 - precision: 0.2000 - recall: 0.031 - ETA: 0s - loss: 1.8229 - accuracy: 0.2812 - precision: 0.4000 - recall: 0.083 - ETA: 0s - loss: 1.7743 - accuracy: 0.2812 - precision: 0.4857 - recall: 0.106 - ETA: 0s - loss: 1.7493 - accuracy: 0.2946 - precision: 0.5333 - recall: 0.107 - ETA: 0s - loss: 1.7693 - accuracy: 0.2812 - precision: 0.5208 - recall: 0.086 - ETA: 0s - loss: 1.7522 - accuracy: 0.2812 - precision: 0.5490 - recall: 0.079 - ETA: 0s - loss: 1.7786 - accuracy: 0.2740 - precision: 0.5556 - recall: 0.072 - 1s 2ms/sample - loss: 1.7748 - accuracy: 0.2746 - precision: 0.5636 - recall: 0.0728 - val_loss: 1.7318 - val_accuracy: 0.2606 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7335 - accuracy: 0.4062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7816 - accuracy: 0.3542 - precision: 0.5000 - recall: 0.0312        - ETA: 0s - loss: 1.7554 - accuracy: 0.3125 - precision: 0.4375 - recall: 0.043 - ETA: 0s - loss: 1.7361 - accuracy: 0.2946 - precision: 0.4348 - recall: 0.044 - ETA: 0s - loss: 1.7364 - accuracy: 0.2778 - precision: 0.4348 - recall: 0.034 - ETA: 0s - loss: 1.7399 - accuracy: 0.2727 - precision: 0.4167 - recall: 0.028 - ETA: 0s - loss: 1.7397 - accuracy: 0.2716 - precision: 0.4000 - recall: 0.024 - 1s 2ms/sample - loss: 1.7390 - accuracy: 0.2770 - precision: 0.4000 - recall: 0.0235 - val_loss: 1.8042 - val_accuracy: 0.2394 - val_precision: 0.3333 - val_recall: 0.0282\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8081 - accuracy: 0.1875 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.9445 - accuracy: 0.2083 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.8887 - accuracy: 0.2750 - precision: 0.4667 - recall: 0.043 - ETA: 0s - loss: 1.9150 - accuracy: 0.2552 - precision: 0.4211 - recall: 0.041 - ETA: 0s - loss: 1.8973 - accuracy: 0.2634 - precision: 0.4783 - recall: 0.049 - ETA: 0s - loss: 1.8647 - accuracy: 0.2674 - precision: 0.4773 - recall: 0.072 - ETA: 0s - loss: 1.8641 - accuracy: 0.2557 - precision: 0.4844 - recall: 0.088 - ETA: 0s - loss: 1.8168 - accuracy: 0.2644 - precision: 0.5195 - recall: 0.096 - 1s 2ms/sample - loss: 1.8209 - accuracy: 0.2653 - precision: 0.5128 - recall: 0.0939 - val_loss: 1.7545 - val_accuracy: 0.2183 - val_precision: 0.5556 - val_recall: 0.1056\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7134 - accuracy: 0.2188 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.6489 - accuracy: 0.3021 - precision: 0.7059 - recall: 0.125 - ETA: 0s - loss: 1.6499 - accuracy: 0.2875 - precision: 0.7037 - recall: 0.118 - ETA: 0s - loss: 1.6335 - accuracy: 0.3170 - precision: 0.6765 - recall: 0.102 - ETA: 0s - loss: 1.6390 - accuracy: 0.3090 - precision: 0.6829 - recall: 0.097 - ETA: 0s - loss: 1.6719 - accuracy: 0.2898 - precision: 0.6327 - recall: 0.088 - ETA: 0s - loss: 1.7070 - accuracy: 0.2788 - precision: 0.6078 - recall: 0.074 - 1s 2ms/sample - loss: 1.7030 - accuracy: 0.2793 - precision: 0.6078 - recall: 0.0728 - val_loss: 1.8199 - val_accuracy: 0.2254 - val_precision: 0.3750 - val_recall: 0.0423\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6959 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7559 - accuracy: 0.2708 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.6752 - accuracy: 0.3313 - precision: 0.5833 - recall: 0.043 - ETA: 0s - loss: 1.6586 - accuracy: 0.3348 - precision: 0.6000 - recall: 0.053 - ETA: 0s - loss: 1.6363 - accuracy: 0.3438 - precision: 0.5405 - recall: 0.069 - ETA: 0s - loss: 1.6916 - accuracy: 0.3466 - precision: 0.5000 - recall: 0.073 - ETA: 0s - loss: 1.7015 - accuracy: 0.3486 - precision: 0.5000 - recall: 0.081 - 1s 2ms/sample - loss: 1.7047 - accuracy: 0.3498 - precision: 0.5070 - recall: 0.0845 - val_loss: 1.7887 - val_accuracy: 0.2324 - val_precision: 0.5385 - val_recall: 0.0986\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4921 - accuracy: 0.3438 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.6901 - accuracy: 0.3021 - precision: 0.5333 - recall: 0.083 - ETA: 0s - loss: 1.6661 - accuracy: 0.3125 - precision: 0.5789 - recall: 0.068 - ETA: 0s - loss: 1.6776 - accuracy: 0.3170 - precision: 0.5926 - recall: 0.071 - ETA: 0s - loss: 1.6658 - accuracy: 0.3056 - precision: 0.6286 - recall: 0.076 - ETA: 0s - loss: 1.6456 - accuracy: 0.3239 - precision: 0.6222 - recall: 0.079 - ETA: 0s - loss: 1.6627 - accuracy: 0.3269 - precision: 0.6346 - recall: 0.079 - 1s 2ms/sample - loss: 1.6743 - accuracy: 0.3216 - precision: 0.6182 - recall: 0.0798 - val_loss: 1.6628 - val_accuracy: 0.3521 - val_precision: 0.7000 - val_recall: 0.0986\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7625 - accuracy: 0.3750 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.6703 - accuracy: 0.3229 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.7331 - accuracy: 0.3187 - precision: 0.5385 - recall: 0.087 - ETA: 0s - loss: 1.6778 - accuracy: 0.3348 - precision: 0.5833 - recall: 0.093 - ETA: 0s - loss: 1.6532 - accuracy: 0.3299 - precision: 0.6222 - recall: 0.097 - ETA: 0s - loss: 1.7168 - accuracy: 0.3182 - precision: 0.5833 - recall: 0.079 - ETA: 0s - loss: 1.7088 - accuracy: 0.3245 - precision: 0.5962 - recall: 0.074 - 1s 2ms/sample - loss: 1.7088 - accuracy: 0.3263 - precision: 0.6038 - recall: 0.0751 - val_loss: 1.6463 - val_accuracy: 0.3239 - val_precision: 0.8571 - val_recall: 0.0423\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5707 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5456 - accuracy: 0.3646 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.6461 - accuracy: 0.3125 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.6367 - accuracy: 0.3170 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.6593 - accuracy: 0.3056 - precision: 0.7500 - recall: 0.031 - ETA: 0s - loss: 1.6775 - accuracy: 0.2926 - precision: 0.7857 - recall: 0.031 - ETA: 0s - loss: 1.6906 - accuracy: 0.2909 - precision: 0.8000 - recall: 0.028 - 1s 2ms/sample - loss: 1.6863 - accuracy: 0.2958 - precision: 0.8000 - recall: 0.0282 - val_loss: 1.6678 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0423\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2073 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9133 - accuracy: 0.2292 - precision: 0.5000 - recall: 0.0104        - ETA: 0s - loss: 1.8203 - accuracy: 0.2688 - precision: 0.6667 - recall: 0.025 - ETA: 0s - loss: 1.8074 - accuracy: 0.2768 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.7712 - accuracy: 0.2773 - precision: 0.6667 - recall: 0.031 - ETA: 0s - loss: 1.7349 - accuracy: 0.2906 - precision: 0.6667 - recall: 0.031 - ETA: 0s - loss: 1.7265 - accuracy: 0.2969 - precision: 0.6111 - recall: 0.028 - 1s 2ms/sample - loss: 1.7263 - accuracy: 0.3028 - precision: 0.5200 - recall: 0.0305 - val_loss: 1.9300 - val_accuracy: 0.2817 - val_precision: 0.4091 - val_recall: 0.0634\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6154 - accuracy: 0.4375 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.7884 - accuracy: 0.3542 - precision: 0.6923 - recall: 0.093 - ETA: 0s - loss: 1.8242 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.075 - ETA: 0s - loss: 1.7323 - accuracy: 0.3393 - precision: 0.5833 - recall: 0.062 - ETA: 0s - loss: 1.7275 - accuracy: 0.3203 - precision: 0.5833 - recall: 0.054 - ETA: 0s - loss: 1.7219 - accuracy: 0.3063 - precision: 0.5517 - recall: 0.050 - ETA: 0s - loss: 1.6909 - accuracy: 0.3203 - precision: 0.5938 - recall: 0.049 - 1s 2ms/sample - loss: 1.6946 - accuracy: 0.3169 - precision: 0.5789 - recall: 0.0516 - val_loss: 1.7886 - val_accuracy: 0.3028 - val_precision: 0.7500 - val_recall: 0.0423\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6183 - accuracy: 0.3125 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.6674 - accuracy: 0.3500 - precision: 0.7778 - recall: 0.043 - ETA: 0s - loss: 1.6316 - accuracy: 0.3705 - precision: 0.6429 - recall: 0.040 - ETA: 0s - loss: 1.6491 - accuracy: 0.3576 - precision: 0.6667 - recall: 0.048 - ETA: 0s - loss: 1.6513 - accuracy: 0.3500 - precision: 0.6957 - recall: 0.050 - ETA: 0s - loss: 1.6432 - accuracy: 0.3620 - precision: 0.7000 - recall: 0.054 - 1s 2ms/sample - loss: 1.6412 - accuracy: 0.3615 - precision: 0.6774 - recall: 0.0493 - val_loss: 1.6742 - val_accuracy: 0.3239 - val_precision: 0.6667 - val_recall: 0.0423\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7980 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6038 - accuracy: 0.3438 - precision: 0.6000 - recall: 0.0312        - ETA: 0s - loss: 1.6193 - accuracy: 0.3562 - precision: 0.4545 - recall: 0.031 - ETA: 0s - loss: 1.5943 - accuracy: 0.3705 - precision: 0.5714 - recall: 0.035 - ETA: 0s - loss: 1.5700 - accuracy: 0.3854 - precision: 0.6667 - recall: 0.048 - ETA: 0s - loss: 1.5695 - accuracy: 0.3750 - precision: 0.5588 - recall: 0.054 - ETA: 0s - loss: 1.5570 - accuracy: 0.3870 - precision: 0.5714 - recall: 0.057 - 1s 2ms/sample - loss: 1.5479 - accuracy: 0.3944 - precision: 0.6000 - recall: 0.0634 - val_loss: 1.6256 - val_accuracy: 0.3310 - val_precision: 0.7917 - val_recall: 0.1338\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5989 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.4781 - accuracy: 0.3854 - precision: 0.6429 - recall: 0.093 - ETA: 0s - loss: 1.4849 - accuracy: 0.3875 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4787 - accuracy: 0.4107 - precision: 0.6341 - recall: 0.116 - ETA: 0s - loss: 1.5012 - accuracy: 0.4028 - precision: 0.6207 - recall: 0.125 - ETA: 0s - loss: 1.4895 - accuracy: 0.3977 - precision: 0.6377 - recall: 0.125 - ETA: 0s - loss: 1.5058 - accuracy: 0.4014 - precision: 0.6438 - recall: 0.113 - 1s 2ms/sample - loss: 1.5153 - accuracy: 0.3967 - precision: 0.6486 - recall: 0.1127 - val_loss: 1.5739 - val_accuracy: 0.3662 - val_precision: 0.8750 - val_recall: 0.0986\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5865 - accuracy: 0.3333 - precision: 0.7500 - recall: 0.062 - ETA: 0s - loss: 1.6227 - accuracy: 0.3203 - precision: 0.8182 - recall: 0.070 - ETA: 0s - loss: 1.6240 - accuracy: 0.3333 - precision: 0.8125 - recall: 0.067 - ETA: 0s - loss: 1.5948 - accuracy: 0.3477 - precision: 0.7667 - recall: 0.089 - ETA: 0s - loss: 1.5778 - accuracy: 0.3594 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5569 - accuracy: 0.3568 - precision: 0.7200 - recall: 0.093 - ETA: 0s - loss: 1.5458 - accuracy: 0.3630 - precision: 0.7193 - recall: 0.098 - 1s 2ms/sample - loss: 1.5484 - accuracy: 0.3662 - precision: 0.7069 - recall: 0.0962 - val_loss: 1.5289 - val_accuracy: 0.3662 - val_precision: 0.8148 - val_recall: 0.1549\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2518 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.3894 - accuracy: 0.4583 - precision: 0.9333 - recall: 0.145 - ETA: 0s - loss: 1.3698 - accuracy: 0.4750 - precision: 0.7838 - recall: 0.181 - ETA: 0s - loss: 1.3822 - accuracy: 0.4732 - precision: 0.7321 - recall: 0.183 - ETA: 0s - loss: 1.4180 - accuracy: 0.4549 - precision: 0.7361 - recall: 0.184 - ETA: 0s - loss: 1.4423 - accuracy: 0.4489 - precision: 0.7160 - recall: 0.164 - ETA: 0s - loss: 1.4475 - accuracy: 0.4423 - precision: 0.7045 - recall: 0.149 - 1s 2ms/sample - loss: 1.4504 - accuracy: 0.4366 - precision: 0.7079 - recall: 0.1479 - val_loss: 1.5529 - val_accuracy: 0.3873 - val_precision: 0.8095 - val_recall: 0.1197\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5447 - accuracy: 0.4062 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.4529 - accuracy: 0.4479 - precision: 0.8462 - recall: 0.114 - ETA: 0s - loss: 1.4455 - accuracy: 0.4313 - precision: 0.8333 - recall: 0.093 - ETA: 0s - loss: 1.4437 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.107 - ETA: 0s - loss: 1.4625 - accuracy: 0.4062 - precision: 0.7907 - recall: 0.118 - ETA: 0s - loss: 1.4917 - accuracy: 0.4062 - precision: 0.7800 - recall: 0.110 - ETA: 0s - loss: 1.4976 - accuracy: 0.3966 - precision: 0.7288 - recall: 0.103 - 1s 2ms/sample - loss: 1.4903 - accuracy: 0.3991 - precision: 0.7333 - recall: 0.1033 - val_loss: 1.4755 - val_accuracy: 0.3944 - val_precision: 0.9091 - val_recall: 0.1408\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2152 - accuracy: 0.5312 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.4670 - accuracy: 0.4583 - precision: 0.6923 - recall: 0.093 - ETA: 0s - loss: 1.4492 - accuracy: 0.4375 - precision: 0.7826 - recall: 0.112 - ETA: 0s - loss: 1.4250 - accuracy: 0.4271 - precision: 0.8214 - recall: 0.119 - ETA: 0s - loss: 1.4303 - accuracy: 0.4375 - precision: 0.7750 - recall: 0.121 - ETA: 0s - loss: 1.4061 - accuracy: 0.4444 - precision: 0.7143 - recall: 0.138 - ETA: 0s - loss: 1.4261 - accuracy: 0.4347 - precision: 0.6800 - recall: 0.144 - ETA: 0s - loss: 1.4313 - accuracy: 0.4375 - precision: 0.6842 - recall: 0.156 - 1s 2ms/sample - loss: 1.4327 - accuracy: 0.4413 - precision: 0.6837 - recall: 0.1573 - val_loss: 1.4608 - val_accuracy: 0.3732 - val_precision: 0.7500 - val_recall: 0.1479\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4871 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4273 - accuracy: 0.3958 - precision: 0.7857 - recall: 0.114 - ETA: 0s - loss: 1.4055 - accuracy: 0.3906 - precision: 0.8421 - recall: 0.125 - ETA: 0s - loss: 1.4661 - accuracy: 0.3854 - precision: 0.7576 - recall: 0.130 - ETA: 0s - loss: 1.5075 - accuracy: 0.3984 - precision: 0.6383 - recall: 0.117 - ETA: 0s - loss: 1.4786 - accuracy: 0.4219 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.4803 - accuracy: 0.4219 - precision: 0.6667 - recall: 0.119 - 1s 2ms/sample - loss: 1.4569 - accuracy: 0.4249 - precision: 0.6883 - recall: 0.1244 - val_loss: 1.4644 - val_accuracy: 0.3732 - val_precision: 0.9167 - val_recall: 0.1549\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4507 - accuracy: 0.5312 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.4161 - accuracy: 0.4479 - precision: 0.8235 - recall: 0.145 - ETA: 0s - loss: 1.3973 - accuracy: 0.4500 - precision: 0.8800 - recall: 0.137 - ETA: 0s - loss: 1.4631 - accuracy: 0.4323 - precision: 0.7500 - recall: 0.125 - ETA: 0s - loss: 1.4462 - accuracy: 0.4258 - precision: 0.7727 - recall: 0.132 - ETA: 0s - loss: 1.4781 - accuracy: 0.4094 - precision: 0.7222 - recall: 0.121 - ETA: 0s - loss: 1.4769 - accuracy: 0.4091 - precision: 0.7188 - recall: 0.130 - ETA: 0s - loss: 1.4732 - accuracy: 0.3966 - precision: 0.7237 - recall: 0.132 - 1s 2ms/sample - loss: 1.4698 - accuracy: 0.4014 - precision: 0.7308 - recall: 0.1338 - val_loss: 1.5867 - val_accuracy: 0.3592 - val_precision: 0.8462 - val_recall: 0.1549\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5184 - accuracy: 0.5312 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.4964 - accuracy: 0.4271 - precision: 0.6957 - recall: 0.166 - ETA: 0s - loss: 1.4339 - accuracy: 0.4187 - precision: 0.7647 - recall: 0.162 - ETA: 0s - loss: 1.3908 - accuracy: 0.4241 - precision: 0.7619 - recall: 0.142 - ETA: 0s - loss: 1.3995 - accuracy: 0.4271 - precision: 0.7544 - recall: 0.149 - ETA: 0s - loss: 1.4036 - accuracy: 0.4347 - precision: 0.7500 - recall: 0.144 - ETA: 0s - loss: 1.4070 - accuracy: 0.4399 - precision: 0.7662 - recall: 0.141 - 1s 2ms/sample - loss: 1.4117 - accuracy: 0.4366 - precision: 0.7564 - recall: 0.1385 - val_loss: 1.6088 - val_accuracy: 0.3380 - val_precision: 0.7647 - val_recall: 0.1831\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5527 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4548 - accuracy: 0.4792 - precision: 0.7059 - recall: 0.125 - ETA: 0s - loss: 1.4042 - accuracy: 0.4812 - precision: 0.7742 - recall: 0.150 - ETA: 0s - loss: 1.4236 - accuracy: 0.4732 - precision: 0.7674 - recall: 0.147 - ETA: 0s - loss: 1.4000 - accuracy: 0.4653 - precision: 0.7857 - recall: 0.152 - ETA: 0s - loss: 1.4313 - accuracy: 0.4489 - precision: 0.7647 - recall: 0.147 - ETA: 0s - loss: 1.4469 - accuracy: 0.4375 - precision: 0.7407 - recall: 0.144 - 1s 2ms/sample - loss: 1.4437 - accuracy: 0.4366 - precision: 0.7349 - recall: 0.1432 - val_loss: 1.5451 - val_accuracy: 0.3873 - val_precision: 0.8696 - val_recall: 0.1408\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5571 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4884 - accuracy: 0.4479 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.4212 - accuracy: 0.4688 - precision: 0.8519 - recall: 0.143 - ETA: 0s - loss: 1.4164 - accuracy: 0.4509 - precision: 0.8974 - recall: 0.156 - ETA: 0s - loss: 1.4348 - accuracy: 0.4340 - precision: 0.7885 - recall: 0.142 - ETA: 0s - loss: 1.4758 - accuracy: 0.4261 - precision: 0.6712 - recall: 0.139 - ETA: 0s - loss: 1.4737 - accuracy: 0.4159 - precision: 0.6742 - recall: 0.144 - 1s 2ms/sample - loss: 1.4797 - accuracy: 0.4155 - precision: 0.6739 - recall: 0.1455 - val_loss: 1.5239 - val_accuracy: 0.3451 - val_precision: 0.8571 - val_recall: 0.1690\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3046 - accuracy: 0.4688 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.3231 - accuracy: 0.4896 - precision: 0.7600 - recall: 0.197 - ETA: 0s - loss: 1.3495 - accuracy: 0.4688 - precision: 0.7568 - recall: 0.175 - ETA: 0s - loss: 1.3525 - accuracy: 0.4732 - precision: 0.7500 - recall: 0.160 - ETA: 0s - loss: 1.3520 - accuracy: 0.4583 - precision: 0.7581 - recall: 0.163 - ETA: 0s - loss: 1.3613 - accuracy: 0.4489 - precision: 0.7532 - recall: 0.164 - ETA: 0s - loss: 1.3611 - accuracy: 0.4495 - precision: 0.7684 - recall: 0.175 - 1s 2ms/sample - loss: 1.3529 - accuracy: 0.4531 - precision: 0.7732 - recall: 0.1761 - val_loss: 1.5075 - val_accuracy: 0.3873 - val_precision: 0.7714 - val_recall: 0.1901\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2471 - accuracy: 0.4062 - precision: 0.8182 - recall: 0.281 - ETA: 0s - loss: 1.3091 - accuracy: 0.4479 - precision: 0.7692 - recall: 0.208 - ETA: 0s - loss: 1.3526 - accuracy: 0.4625 - precision: 0.7619 - recall: 0.200 - ETA: 0s - loss: 1.3215 - accuracy: 0.4821 - precision: 0.7302 - recall: 0.205 - ETA: 0s - loss: 1.3397 - accuracy: 0.4757 - precision: 0.7308 - recall: 0.197 - ETA: 0s - loss: 1.3307 - accuracy: 0.4773 - precision: 0.7527 - recall: 0.198 - ETA: 0s - loss: 1.3047 - accuracy: 0.5000 - precision: 0.7561 - recall: 0.223 - 1s 2ms/sample - loss: 1.2979 - accuracy: 0.5023 - precision: 0.7519 - recall: 0.2277 - val_loss: 1.5349 - val_accuracy: 0.3662 - val_precision: 0.6923 - val_recall: 0.1901\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4319 - accuracy: 0.3438 - precision: 0.3333 - recall: 0.093 - ETA: 0s - loss: 1.3679 - accuracy: 0.3958 - precision: 0.4848 - recall: 0.166 - ETA: 0s - loss: 1.2678 - accuracy: 0.4625 - precision: 0.6182 - recall: 0.212 - ETA: 0s - loss: 1.2878 - accuracy: 0.4598 - precision: 0.6286 - recall: 0.196 - ETA: 0s - loss: 1.2821 - accuracy: 0.4653 - precision: 0.6744 - recall: 0.201 - ETA: 0s - loss: 1.2943 - accuracy: 0.4631 - precision: 0.7048 - recall: 0.210 - ETA: 0s - loss: 1.3019 - accuracy: 0.4663 - precision: 0.7008 - recall: 0.213 - 1s 2ms/sample - loss: 1.3148 - accuracy: 0.4601 - precision: 0.6953 - recall: 0.2089 - val_loss: 1.4692 - val_accuracy: 0.3732 - val_precision: 0.6531 - val_recall: 0.2254\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2426 - accuracy: 0.5000 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.2495 - accuracy: 0.5625 - precision: 0.8261 - recall: 0.197 - ETA: 0s - loss: 1.3099 - accuracy: 0.4875 - precision: 0.7895 - recall: 0.187 - ETA: 0s - loss: 1.3396 - accuracy: 0.4777 - precision: 0.7368 - recall: 0.187 - ETA: 0s - loss: 1.3427 - accuracy: 0.4826 - precision: 0.7407 - recall: 0.208 - ETA: 0s - loss: 1.3420 - accuracy: 0.4830 - precision: 0.7071 - recall: 0.198 - ETA: 0s - loss: 1.3403 - accuracy: 0.4832 - precision: 0.7000 - recall: 0.201 - 1s 2ms/sample - loss: 1.3355 - accuracy: 0.4859 - precision: 0.6992 - recall: 0.2019 - val_loss: 1.4920 - val_accuracy: 0.4014 - val_precision: 0.6182 - val_recall: 0.2394\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2871 - accuracy: 0.5625 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.2764 - accuracy: 0.5000 - precision: 0.6471 - recall: 0.229 - ETA: 0s - loss: 1.2507 - accuracy: 0.5000 - precision: 0.6897 - recall: 0.250 - ETA: 0s - loss: 1.2659 - accuracy: 0.5045 - precision: 0.7250 - recall: 0.258 - ETA: 0s - loss: 1.2447 - accuracy: 0.5208 - precision: 0.6944 - recall: 0.260 - ETA: 0s - loss: 1.2424 - accuracy: 0.5114 - precision: 0.6960 - recall: 0.247 - ETA: 0s - loss: 1.2500 - accuracy: 0.5144 - precision: 0.6809 - recall: 0.230 - 1s 2ms/sample - loss: 1.2518 - accuracy: 0.5164 - precision: 0.6757 - recall: 0.2347 - val_loss: 1.4245 - val_accuracy: 0.4014 - val_precision: 0.6078 - val_recall: 0.2183\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4096 - accuracy: 0.5625 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.2776 - accuracy: 0.5208 - precision: 0.6875 - recall: 0.229 - ETA: 0s - loss: 1.2242 - accuracy: 0.5188 - precision: 0.7333 - recall: 0.275 - ETA: 0s - loss: 1.2768 - accuracy: 0.5000 - precision: 0.7200 - recall: 0.241 - ETA: 0s - loss: 1.2474 - accuracy: 0.5174 - precision: 0.7551 - recall: 0.256 - ETA: 0s - loss: 1.2268 - accuracy: 0.5284 - precision: 0.7520 - recall: 0.267 - ETA: 0s - loss: 1.2226 - accuracy: 0.5260 - precision: 0.7426 - recall: 0.263 - 1s 2ms/sample - loss: 1.2118 - accuracy: 0.5282 - precision: 0.7451 - recall: 0.2676 - val_loss: 1.3358 - val_accuracy: 0.4296 - val_precision: 0.6364 - val_recall: 0.2465\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2410 - accuracy: 0.5000 - precision: 0.5882 - recall: 0.312 - ETA: 0s - loss: 1.1565 - accuracy: 0.5104 - precision: 0.6809 - recall: 0.333 - ETA: 0s - loss: 1.1028 - accuracy: 0.5688 - precision: 0.7222 - recall: 0.325 - ETA: 0s - loss: 1.1238 - accuracy: 0.5536 - precision: 0.7234 - recall: 0.303 - ETA: 0s - loss: 1.1550 - accuracy: 0.5208 - precision: 0.6721 - recall: 0.284 - ETA: 0s - loss: 1.1849 - accuracy: 0.5057 - precision: 0.6577 - recall: 0.278 - ETA: 0s - loss: 1.2028 - accuracy: 0.5000 - precision: 0.6527 - recall: 0.262 - 1s 2ms/sample - loss: 1.2052 - accuracy: 0.5000 - precision: 0.6529 - recall: 0.2606 - val_loss: 1.4113 - val_accuracy: 0.4507 - val_precision: 0.7429 - val_recall: 0.1831\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3089 - accuracy: 0.3750 - precision: 0.3750 - recall: 0.093 - ETA: 0s - loss: 1.1160 - accuracy: 0.5312 - precision: 0.7692 - recall: 0.208 - ETA: 0s - loss: 1.1148 - accuracy: 0.5250 - precision: 0.7857 - recall: 0.206 - ETA: 0s - loss: 1.1738 - accuracy: 0.5045 - precision: 0.8000 - recall: 0.178 - ETA: 0s - loss: 1.1839 - accuracy: 0.4931 - precision: 0.7869 - recall: 0.166 - ETA: 0s - loss: 1.1855 - accuracy: 0.4875 - precision: 0.8030 - recall: 0.165 - ETA: 0s - loss: 1.2039 - accuracy: 0.4896 - precision: 0.7848 - recall: 0.161 - 1s 2ms/sample - loss: 1.2047 - accuracy: 0.4930 - precision: 0.7865 - recall: 0.1643 - val_loss: 1.3334 - val_accuracy: 0.4648 - val_precision: 0.5818 - val_recall: 0.2254\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2803 - accuracy: 0.3750 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.1705 - accuracy: 0.5104 - precision: 0.6757 - recall: 0.260 - ETA: 0s - loss: 1.0609 - accuracy: 0.5500 - precision: 0.7200 - recall: 0.337 - ETA: 0s - loss: 1.1373 - accuracy: 0.5402 - precision: 0.6607 - recall: 0.330 - ETA: 0s - loss: 1.1649 - accuracy: 0.5382 - precision: 0.6486 - recall: 0.333 - ETA: 0s - loss: 1.2040 - accuracy: 0.5227 - precision: 0.6313 - recall: 0.321 - ETA: 0s - loss: 1.2300 - accuracy: 0.5096 - precision: 0.6250 - recall: 0.312 - 1s 2ms/sample - loss: 1.2402 - accuracy: 0.5047 - precision: 0.6197 - recall: 0.3099 - val_loss: 1.5201 - val_accuracy: 0.4225 - val_precision: 0.5000 - val_recall: 0.2324\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6146 - accuracy: 0.2812 - precision: 0.3529 - recall: 0.187 - ETA: 0s - loss: 1.4501 - accuracy: 0.3542 - precision: 0.5000 - recall: 0.187 - ETA: 0s - loss: 1.4890 - accuracy: 0.3562 - precision: 0.5000 - recall: 0.193 - ETA: 0s - loss: 1.4692 - accuracy: 0.4062 - precision: 0.4943 - recall: 0.192 - ETA: 0s - loss: 1.4628 - accuracy: 0.4306 - precision: 0.5000 - recall: 0.187 - ETA: 0s - loss: 1.4512 - accuracy: 0.4375 - precision: 0.5250 - recall: 0.179 - ETA: 0s - loss: 1.4309 - accuracy: 0.4375 - precision: 0.5612 - recall: 0.187 - 1s 2ms/sample - loss: 1.4257 - accuracy: 0.4413 - precision: 0.5594 - recall: 0.1878 - val_loss: 1.4227 - val_accuracy: 0.4437 - val_precision: 0.7234 - val_recall: 0.2394\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4829 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.2088 - accuracy: 0.5000 - precision: 0.7714 - recall: 0.281 - ETA: 0s - loss: 1.2762 - accuracy: 0.4922 - precision: 0.7200 - recall: 0.281 - ETA: 0s - loss: 1.3150 - accuracy: 0.4740 - precision: 0.6842 - recall: 0.270 - ETA: 0s - loss: 1.3667 - accuracy: 0.4492 - precision: 0.6633 - recall: 0.253 - ETA: 0s - loss: 1.3628 - accuracy: 0.4625 - precision: 0.6560 - recall: 0.256 - ETA: 0s - loss: 1.3414 - accuracy: 0.4714 - precision: 0.6579 - recall: 0.260 - 1s 2ms/sample - loss: 1.3126 - accuracy: 0.4836 - precision: 0.6667 - recall: 0.2723 - val_loss: 1.6105 - val_accuracy: 0.3662 - val_precision: 0.4627 - val_recall: 0.2183\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4540 - accuracy: 0.4688 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.3421 - accuracy: 0.5208 - precision: 0.5897 - recall: 0.239 - ETA: 0s - loss: 1.3304 - accuracy: 0.4938 - precision: 0.6349 - recall: 0.250 - ETA: 0s - loss: 1.4358 - accuracy: 0.4554 - precision: 0.6136 - recall: 0.241 - ETA: 0s - loss: 1.4885 - accuracy: 0.4722 - precision: 0.5833 - recall: 0.243 - ETA: 0s - loss: 1.5479 - accuracy: 0.4545 - precision: 0.5694 - recall: 0.233 - ETA: 0s - loss: 1.6320 - accuracy: 0.4255 - precision: 0.5284 - recall: 0.223 - 1s 2ms/sample - loss: 1.6508 - accuracy: 0.4225 - precision: 0.5220 - recall: 0.2230 - val_loss: 1.7885 - val_accuracy: 0.3028 - val_precision: 0.4706 - val_recall: 0.1690\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5610 - accuracy: 0.4688 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.7222 - accuracy: 0.3958 - precision: 0.5333 - recall: 0.166 - ETA: 0s - loss: 1.6951 - accuracy: 0.3375 - precision: 0.5106 - recall: 0.150 - ETA: 0s - loss: 1.6645 - accuracy: 0.3393 - precision: 0.5500 - recall: 0.147 - ETA: 0s - loss: 1.6870 - accuracy: 0.3359 - precision: 0.5556 - recall: 0.136 - ETA: 0s - loss: 1.6611 - accuracy: 0.3500 - precision: 0.5867 - recall: 0.137 - ETA: 0s - loss: 1.6460 - accuracy: 0.3594 - precision: 0.5882 - recall: 0.130 - 1s 2ms/sample - loss: 1.6543 - accuracy: 0.3545 - precision: 0.5889 - recall: 0.1244 - val_loss: 1.6517 - val_accuracy: 0.3169 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5434 - accuracy: 0.4375 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.4781 - accuracy: 0.4583 - precision: 0.7368 - recall: 0.145 - ETA: 0s - loss: 1.4808 - accuracy: 0.4125 - precision: 0.7083 - recall: 0.106 - ETA: 0s - loss: 1.5558 - accuracy: 0.3973 - precision: 0.6897 - recall: 0.089 - ETA: 0s - loss: 1.5604 - accuracy: 0.3889 - precision: 0.6829 - recall: 0.097 - ETA: 0s - loss: 1.5347 - accuracy: 0.4006 - precision: 0.7292 - recall: 0.099 - ETA: 0s - loss: 1.5478 - accuracy: 0.3990 - precision: 0.6774 - recall: 0.101 - 1s 2ms/sample - loss: 1.5501 - accuracy: 0.3967 - precision: 0.6615 - recall: 0.1009 - val_loss: 1.5919 - val_accuracy: 0.3662 - val_precision: 0.5333 - val_recall: 0.1127\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3619 - accuracy: 0.5625 - precision: 0.8889 - recall: 0.250 - ETA: 0s - loss: 1.4457 - accuracy: 0.4792 - precision: 0.6429 - recall: 0.187 - ETA: 0s - loss: 1.4393 - accuracy: 0.4938 - precision: 0.6585 - recall: 0.168 - ETA: 0s - loss: 1.4811 - accuracy: 0.4330 - precision: 0.6346 - recall: 0.147 - ETA: 0s - loss: 1.4905 - accuracy: 0.4306 - precision: 0.6515 - recall: 0.149 - ETA: 0s - loss: 1.4751 - accuracy: 0.4318 - precision: 0.6750 - recall: 0.153 - ETA: 0s - loss: 1.4781 - accuracy: 0.4159 - precision: 0.6804 - recall: 0.158 - 1s 2ms/sample - loss: 1.4953 - accuracy: 0.4085 - precision: 0.6634 - recall: 0.1573 - val_loss: 1.5503 - val_accuracy: 0.3521 - val_precision: 0.5854 - val_recall: 0.1690\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4225 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4983 - accuracy: 0.3542 - precision: 0.5172 - recall: 0.156 - ETA: 0s - loss: 1.5476 - accuracy: 0.3812 - precision: 0.5577 - recall: 0.181 - ETA: 0s - loss: 1.5429 - accuracy: 0.3750 - precision: 0.5652 - recall: 0.174 - ETA: 0s - loss: 1.5045 - accuracy: 0.3889 - precision: 0.5833 - recall: 0.170 - ETA: 0s - loss: 1.5044 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.170 - ETA: 0s - loss: 1.4876 - accuracy: 0.4135 - precision: 0.5913 - recall: 0.163 - 1s 2ms/sample - loss: 1.5026 - accuracy: 0.4085 - precision: 0.5798 - recall: 0.1620 - val_loss: 1.5604 - val_accuracy: 0.3944 - val_precision: 0.5946 - val_recall: 0.1549\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5475 - accuracy: 0.3750 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.4100 - accuracy: 0.4062 - precision: 0.7200 - recall: 0.187 - ETA: 0s - loss: 1.3450 - accuracy: 0.4750 - precision: 0.7660 - recall: 0.225 - ETA: 0s - loss: 1.3480 - accuracy: 0.4911 - precision: 0.7647 - recall: 0.232 - ETA: 0s - loss: 1.3744 - accuracy: 0.4792 - precision: 0.7143 - recall: 0.225 - ETA: 0s - loss: 1.3626 - accuracy: 0.4886 - precision: 0.7009 - recall: 0.233 - ETA: 0s - loss: 1.3649 - accuracy: 0.4952 - precision: 0.6978 - recall: 0.233 - 1s 2ms/sample - loss: 1.3667 - accuracy: 0.4977 - precision: 0.6950 - recall: 0.2300 - val_loss: 1.4599 - val_accuracy: 0.4577 - val_precision: 0.5741 - val_recall: 0.2183\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5852 - accuracy: 0.3750 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.3328 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.312 - ETA: 0s - loss: 1.3092 - accuracy: 0.5125 - precision: 0.7344 - recall: 0.293 - ETA: 0s - loss: 1.3458 - accuracy: 0.4866 - precision: 0.7229 - recall: 0.267 - ETA: 0s - loss: 1.3267 - accuracy: 0.4931 - precision: 0.7117 - recall: 0.274 - ETA: 0s - loss: 1.3517 - accuracy: 0.4744 - precision: 0.7073 - recall: 0.247 - ETA: 0s - loss: 1.3357 - accuracy: 0.4784 - precision: 0.7101 - recall: 0.235 - 1s 2ms/sample - loss: 1.3310 - accuracy: 0.4836 - precision: 0.7092 - recall: 0.2347 - val_loss: 1.3959 - val_accuracy: 0.4507 - val_precision: 0.6500 - val_recall: 0.1831\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3997 - accuracy: 0.4062 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.2032 - accuracy: 0.5156 - precision: 0.8421 - recall: 0.250 - ETA: 0s - loss: 1.2267 - accuracy: 0.5234 - precision: 0.7857 - recall: 0.257 - ETA: 0s - loss: 1.2492 - accuracy: 0.5250 - precision: 0.7500 - recall: 0.262 - ETA: 0s - loss: 1.3180 - accuracy: 0.4821 - precision: 0.6235 - recall: 0.236 - ETA: 0s - loss: 1.3200 - accuracy: 0.4757 - precision: 0.5982 - recall: 0.232 - ETA: 0s - loss: 1.2911 - accuracy: 0.4972 - precision: 0.6202 - recall: 0.227 - ETA: 0s - loss: 1.3209 - accuracy: 0.4832 - precision: 0.6144 - recall: 0.226 - 1s 2ms/sample - loss: 1.3216 - accuracy: 0.4836 - precision: 0.6139 - recall: 0.2277 - val_loss: 1.4285 - val_accuracy: 0.4577 - val_precision: 0.6000 - val_recall: 0.1690\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0926 - accuracy: 0.4688 - precision: 0.7857 - recall: 0.343 - ETA: 0s - loss: 1.1155 - accuracy: 0.5521 - precision: 0.7297 - recall: 0.281 - ETA: 0s - loss: 1.1378 - accuracy: 0.5312 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.1820 - accuracy: 0.5223 - precision: 0.6800 - recall: 0.227 - ETA: 0s - loss: 1.2735 - accuracy: 0.5035 - precision: 0.6667 - recall: 0.201 - ETA: 0s - loss: 1.2545 - accuracy: 0.5057 - precision: 0.6696 - recall: 0.213 - ETA: 0s - loss: 1.2487 - accuracy: 0.5144 - precision: 0.6861 - recall: 0.226 - 1s 2ms/sample - loss: 1.2511 - accuracy: 0.5070 - precision: 0.6857 - recall: 0.2254 - val_loss: 1.3636 - val_accuracy: 0.4155 - val_precision: 0.6444 - val_recall: 0.2042\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1855 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.250 - ETA: 0s - loss: 1.2674 - accuracy: 0.4688 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.3115 - accuracy: 0.4375 - precision: 0.7778 - recall: 0.175 - ETA: 0s - loss: 1.2704 - accuracy: 0.4330 - precision: 0.7679 - recall: 0.192 - ETA: 0s - loss: 1.2734 - accuracy: 0.4306 - precision: 0.7857 - recall: 0.191 - ETA: 0s - loss: 1.2925 - accuracy: 0.4318 - precision: 0.8000 - recall: 0.193 - ETA: 0s - loss: 1.3068 - accuracy: 0.4375 - precision: 0.8077 - recall: 0.201 - 1s 2ms/sample - loss: 1.3037 - accuracy: 0.4413 - precision: 0.8148 - recall: 0.2066 - val_loss: 1.4859 - val_accuracy: 0.4225 - val_precision: 0.6327 - val_recall: 0.2183\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3549 - accuracy: 0.5625 - precision: 0.9167 - recall: 0.343 - ETA: 0s - loss: 1.1865 - accuracy: 0.5938 - precision: 0.9091 - recall: 0.312 - ETA: 0s - loss: 1.2305 - accuracy: 0.5312 - precision: 0.8000 - recall: 0.300 - ETA: 0s - loss: 1.2290 - accuracy: 0.5134 - precision: 0.7701 - recall: 0.299 - ETA: 0s - loss: 1.2261 - accuracy: 0.5156 - precision: 0.7426 - recall: 0.293 - ETA: 0s - loss: 1.1907 - accuracy: 0.5469 - precision: 0.7795 - recall: 0.309 - ETA: 0s - loss: 1.2231 - accuracy: 0.5234 - precision: 0.7550 - recall: 0.296 - 1s 2ms/sample - loss: 1.2044 - accuracy: 0.5329 - precision: 0.7429 - recall: 0.3052 - val_loss: 1.3186 - val_accuracy: 0.4296 - val_precision: 0.6415 - val_recall: 0.2394\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8827 - accuracy: 0.7812 - precision: 0.9333 - recall: 0.437 - ETA: 0s - loss: 1.2466 - accuracy: 0.5104 - precision: 0.6591 - recall: 0.302 - ETA: 0s - loss: 1.2533 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.312 - ETA: 0s - loss: 1.2144 - accuracy: 0.5156 - precision: 0.7011 - recall: 0.317 - ETA: 0s - loss: 1.1972 - accuracy: 0.5273 - precision: 0.7168 - recall: 0.316 - ETA: 0s - loss: 1.1714 - accuracy: 0.5486 - precision: 0.7344 - recall: 0.326 - ETA: 0s - loss: 1.1940 - accuracy: 0.5369 - precision: 0.7032 - recall: 0.309 - ETA: 0s - loss: 1.1706 - accuracy: 0.5505 - precision: 0.7211 - recall: 0.329 - 1s 2ms/sample - loss: 1.1783 - accuracy: 0.5446 - precision: 0.7179 - recall: 0.3286 - val_loss: 1.3785 - val_accuracy: 0.4225 - val_precision: 0.5672 - val_recall: 0.2676\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1892 - accuracy: 0.5000 - precision: 0.6875 - recall: 0.343 - ETA: 0s - loss: 1.0334 - accuracy: 0.6250 - precision: 0.8163 - recall: 0.416 - ETA: 0s - loss: 1.0549 - accuracy: 0.6250 - precision: 0.8228 - recall: 0.406 - ETA: 0s - loss: 1.0759 - accuracy: 0.6116 - precision: 0.7798 - recall: 0.379 - ETA: 0s - loss: 1.1603 - accuracy: 0.5486 - precision: 0.6959 - recall: 0.357 - ETA: 0s - loss: 1.2078 - accuracy: 0.5256 - precision: 0.6685 - recall: 0.343 - ETA: 0s - loss: 1.1793 - accuracy: 0.5264 - precision: 0.6829 - recall: 0.336 - 1s 2ms/sample - loss: 1.1689 - accuracy: 0.5352 - precision: 0.6890 - recall: 0.3380 - val_loss: 1.3619 - val_accuracy: 0.5352 - val_precision: 0.6825 - val_recall: 0.3028\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0615 - accuracy: 0.5625 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.5219 - accuracy: 0.4479 - precision: 0.6750 - recall: 0.281 - ETA: 0s - loss: 1.3192 - accuracy: 0.5000 - precision: 0.6849 - recall: 0.312 - ETA: 0s - loss: 1.3070 - accuracy: 0.4866 - precision: 0.6381 - recall: 0.299 - ETA: 0s - loss: 1.3714 - accuracy: 0.4653 - precision: 0.6029 - recall: 0.284 - ETA: 0s - loss: 1.3095 - accuracy: 0.4830 - precision: 0.6235 - recall: 0.301 - ETA: 0s - loss: 1.2833 - accuracy: 0.5048 - precision: 0.6389 - recall: 0.331 - 1s 2ms/sample - loss: 1.2945 - accuracy: 0.5000 - precision: 0.6290 - recall: 0.3263 - val_loss: 1.4527 - val_accuracy: 0.4507 - val_precision: 0.6056 - val_recall: 0.3028\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.6562 - precision: 0.7222 - recall: 0.406 - ETA: 0s - loss: 1.2220 - accuracy: 0.5104 - precision: 0.6531 - recall: 0.333 - ETA: 0s - loss: 1.2237 - accuracy: 0.5125 - precision: 0.6118 - recall: 0.325 - ETA: 0s - loss: 1.2066 - accuracy: 0.5045 - precision: 0.6161 - recall: 0.308 - ETA: 0s - loss: 1.2451 - accuracy: 0.5000 - precision: 0.6500 - recall: 0.316 - ETA: 0s - loss: 1.2382 - accuracy: 0.5085 - precision: 0.6792 - recall: 0.306 - ETA: 0s - loss: 1.2197 - accuracy: 0.5096 - precision: 0.6935 - recall: 0.310 - 1s 2ms/sample - loss: 1.2187 - accuracy: 0.5094 - precision: 0.6911 - recall: 0.3099 - val_loss: 1.3472 - val_accuracy: 0.4577 - val_precision: 0.6379 - val_recall: 0.2606\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.5312 - precision: 0.6429 - recall: 0.281 - ETA: 0s - loss: 1.1570 - accuracy: 0.5312 - precision: 0.6750 - recall: 0.281 - ETA: 0s - loss: 1.0611 - accuracy: 0.5375 - precision: 0.7246 - recall: 0.312 - ETA: 0s - loss: 1.0722 - accuracy: 0.5491 - precision: 0.6822 - recall: 0.325 - ETA: 0s - loss: 1.0924 - accuracy: 0.5417 - precision: 0.6947 - recall: 0.316 - ETA: 0s - loss: 1.1138 - accuracy: 0.5398 - precision: 0.6993 - recall: 0.304 - ETA: 0s - loss: 1.1202 - accuracy: 0.5361 - precision: 0.7219 - recall: 0.293 - 1s 2ms/sample - loss: 1.1246 - accuracy: 0.5352 - precision: 0.7209 - recall: 0.2911 - val_loss: 1.3045 - val_accuracy: 0.4789 - val_precision: 0.6724 - val_recall: 0.2746\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0996 - accuracy: 0.5938 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 0.9874 - accuracy: 0.6771 - precision: 0.8409 - recall: 0.385 - ETA: 0s - loss: 1.1014 - accuracy: 0.6125 - precision: 0.7237 - recall: 0.343 - ETA: 0s - loss: 1.1166 - accuracy: 0.5893 - precision: 0.6723 - recall: 0.357 - ETA: 0s - loss: 1.1165 - accuracy: 0.5764 - precision: 0.6774 - recall: 0.364 - ETA: 0s - loss: 1.1364 - accuracy: 0.5511 - precision: 0.6667 - recall: 0.346 - ETA: 0s - loss: 1.1177 - accuracy: 0.5481 - precision: 0.6938 - recall: 0.348 - 1s 2ms/sample - loss: 1.1262 - accuracy: 0.5446 - precision: 0.6948 - recall: 0.3474 - val_loss: 1.2508 - val_accuracy: 0.5070 - val_precision: 0.6406 - val_recall: 0.2887\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.6250 - precision: 0.7692 - recall: 0.312 - ETA: 0s - loss: 1.1772 - accuracy: 0.5625 - precision: 0.7750 - recall: 0.322 - ETA: 0s - loss: 1.2399 - accuracy: 0.5500 - precision: 0.7258 - recall: 0.281 - ETA: 0s - loss: 1.2668 - accuracy: 0.5089 - precision: 0.7093 - recall: 0.272 - ETA: 0s - loss: 1.2451 - accuracy: 0.5208 - precision: 0.7350 - recall: 0.298 - ETA: 0s - loss: 1.2707 - accuracy: 0.5028 - precision: 0.7111 - recall: 0.272 - ETA: 0s - loss: 1.2506 - accuracy: 0.5048 - precision: 0.7197 - recall: 0.271 - 1s 2ms/sample - loss: 1.2488 - accuracy: 0.5047 - precision: 0.7188 - recall: 0.2700 - val_loss: 1.4208 - val_accuracy: 0.4085 - val_precision: 0.5606 - val_recall: 0.2606\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1983 - accuracy: 0.5312 - precision: 0.6154 - recall: 0.250 - ETA: 0s - loss: 1.0455 - accuracy: 0.6354 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.0632 - accuracy: 0.6062 - precision: 0.7846 - recall: 0.318 - ETA: 0s - loss: 1.0698 - accuracy: 0.5804 - precision: 0.7742 - recall: 0.321 - ETA: 0s - loss: 1.0429 - accuracy: 0.5972 - precision: 0.7760 - recall: 0.336 - ETA: 0s - loss: 1.0574 - accuracy: 0.5906 - precision: 0.7681 - recall: 0.331 - ETA: 0s - loss: 1.0691 - accuracy: 0.5807 - precision: 0.7471 - recall: 0.330 - ETA: 0s - loss: 1.0720 - accuracy: 0.5769 - precision: 0.7446 - recall: 0.329 - 1s 2ms/sample - loss: 1.0801 - accuracy: 0.5751 - precision: 0.7433 - recall: 0.3263 - val_loss: 1.2749 - val_accuracy: 0.5352 - val_precision: 0.6515 - val_recall: 0.3028\n",
      "Epoch 108/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1570 - accuracy: 0.5625 - precision: 0.6000 - recall: 0.281 - ETA: 0s - loss: 1.0700 - accuracy: 0.5625 - precision: 0.6078 - recall: 0.322 - ETA: 0s - loss: 1.0214 - accuracy: 0.5859 - precision: 0.6667 - recall: 0.343 - ETA: 0s - loss: 1.0100 - accuracy: 0.6146 - precision: 0.7200 - recall: 0.375 - ETA: 0s - loss: 1.0390 - accuracy: 0.5938 - precision: 0.6934 - recall: 0.371 - ETA: 0s - loss: 1.0323 - accuracy: 0.5844 - precision: 0.6959 - recall: 0.371 - ETA: 0s - loss: 1.0638 - accuracy: 0.5703 - precision: 0.7079 - recall: 0.372 - 1s 2ms/sample - loss: 1.0622 - accuracy: 0.5845 - precision: 0.7257 - recall: 0.3850 - val_loss: 1.4032 - val_accuracy: 0.5000 - val_precision: 0.5846 - val_recall: 0.2676\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0709 - accuracy: 0.5625 - precision: 0.5882 - recall: 0.312 - ETA: 0s - loss: 1.0275 - accuracy: 0.6250 - precision: 0.7500 - recall: 0.406 - ETA: 0s - loss: 1.0616 - accuracy: 0.6250 - precision: 0.7692 - recall: 0.375 - ETA: 0s - loss: 1.0442 - accuracy: 0.6205 - precision: 0.7565 - recall: 0.388 - ETA: 0s - loss: 1.0770 - accuracy: 0.5972 - precision: 0.7255 - recall: 0.385 - ETA: 0s - loss: 1.0653 - accuracy: 0.5966 - precision: 0.7194 - recall: 0.400 - ETA: 0s - loss: 1.0398 - accuracy: 0.6034 - precision: 0.7313 - recall: 0.399 - 1s 2ms/sample - loss: 1.0427 - accuracy: 0.5986 - precision: 0.7284 - recall: 0.3967 - val_loss: 1.3022 - val_accuracy: 0.5141 - val_precision: 0.6375 - val_recall: 0.3592\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2683 - accuracy: 0.4688 - precision: 0.5294 - recall: 0.281 - ETA: 0s - loss: 1.0604 - accuracy: 0.5833 - precision: 0.6964 - recall: 0.406 - ETA: 0s - loss: 1.0135 - accuracy: 0.5813 - precision: 0.7010 - recall: 0.425 - ETA: 0s - loss: 0.9754 - accuracy: 0.6116 - precision: 0.7286 - recall: 0.455 - ETA: 0s - loss: 0.9637 - accuracy: 0.6111 - precision: 0.7268 - recall: 0.461 - ETA: 0s - loss: 0.9650 - accuracy: 0.6051 - precision: 0.7220 - recall: 0.457 - ETA: 0s - loss: 0.9702 - accuracy: 0.5913 - precision: 0.7170 - recall: 0.456 - 1s 2ms/sample - loss: 0.9671 - accuracy: 0.5962 - precision: 0.7243 - recall: 0.4624 - val_loss: 1.2850 - val_accuracy: 0.4859 - val_precision: 0.6081 - val_recall: 0.3169\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9667 - accuracy: 0.5938 - precision: 0.8125 - recall: 0.406 - ETA: 0s - loss: 0.9105 - accuracy: 0.6250 - precision: 0.8302 - recall: 0.458 - ETA: 0s - loss: 0.8930 - accuracy: 0.6375 - precision: 0.8000 - recall: 0.450 - ETA: 0s - loss: 0.9378 - accuracy: 0.6302 - precision: 0.8137 - recall: 0.432 - ETA: 0s - loss: 0.9031 - accuracy: 0.6289 - precision: 0.8143 - recall: 0.445 - ETA: 0s - loss: 0.9165 - accuracy: 0.6219 - precision: 0.7943 - recall: 0.434 - ETA: 0s - loss: 0.9358 - accuracy: 0.6068 - precision: 0.7617 - recall: 0.424 - 1s 2ms/sample - loss: 0.9541 - accuracy: 0.6103 - precision: 0.7490 - recall: 0.4272 - val_loss: 1.2740 - val_accuracy: 0.5070 - val_precision: 0.6386 - val_recall: 0.3732\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.7812 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.8265 - accuracy: 0.7083 - precision: 0.8197 - recall: 0.520 - ETA: 0s - loss: 0.8581 - accuracy: 0.6562 - precision: 0.7573 - recall: 0.487 - ETA: 0s - loss: 0.8620 - accuracy: 0.6696 - precision: 0.7682 - recall: 0.517 - ETA: 0s - loss: 0.8587 - accuracy: 0.6758 - precision: 0.7670 - recall: 0.527 - ETA: 0s - loss: 0.8740 - accuracy: 0.6531 - precision: 0.7466 - recall: 0.515 - ETA: 0s - loss: 0.9119 - accuracy: 0.6364 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 0.9539 - accuracy: 0.6130 - precision: 0.7153 - recall: 0.483 - 1s 2ms/sample - loss: 0.9439 - accuracy: 0.6174 - precision: 0.7213 - recall: 0.4859 - val_loss: 1.3167 - val_accuracy: 0.4859 - val_precision: 0.6098 - val_recall: 0.3521\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.6562 - precision: 0.7000 - recall: 0.437 - ETA: 0s - loss: 0.8720 - accuracy: 0.6562 - precision: 0.7455 - recall: 0.427 - ETA: 0s - loss: 0.8707 - accuracy: 0.6750 - precision: 0.7526 - recall: 0.456 - ETA: 0s - loss: 0.9041 - accuracy: 0.6384 - precision: 0.7090 - recall: 0.424 - ETA: 0s - loss: 0.9259 - accuracy: 0.6319 - precision: 0.7159 - recall: 0.437 - ETA: 0s - loss: 0.9571 - accuracy: 0.6165 - precision: 0.6978 - recall: 0.446 - ETA: 0s - loss: 0.9474 - accuracy: 0.6154 - precision: 0.7023 - recall: 0.442 - 1s 2ms/sample - loss: 0.9375 - accuracy: 0.6221 - precision: 0.7085 - recall: 0.4507 - val_loss: 1.2824 - val_accuracy: 0.5211 - val_precision: 0.6395 - val_recall: 0.3873\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2291 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.281 - ETA: 0s - loss: 1.0943 - accuracy: 0.5104 - precision: 0.6207 - recall: 0.375 - ETA: 0s - loss: 1.0299 - accuracy: 0.5813 - precision: 0.6915 - recall: 0.406 - ETA: 0s - loss: 0.9991 - accuracy: 0.6027 - precision: 0.7109 - recall: 0.406 - ETA: 0s - loss: 0.9911 - accuracy: 0.6111 - precision: 0.7176 - recall: 0.423 - ETA: 0s - loss: 0.9834 - accuracy: 0.6193 - precision: 0.7243 - recall: 0.440 - ETA: 0s - loss: 0.9669 - accuracy: 0.6346 - precision: 0.7297 - recall: 0.454 - 1s 2ms/sample - loss: 0.9698 - accuracy: 0.6268 - precision: 0.7218 - recall: 0.4507 - val_loss: 1.3009 - val_accuracy: 0.4930 - val_precision: 0.5882 - val_recall: 0.3521\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.6875 - precision: 0.7727 - recall: 0.531 - ETA: 0s - loss: 0.9865 - accuracy: 0.6458 - precision: 0.7344 - recall: 0.489 - ETA: 0s - loss: 1.0147 - accuracy: 0.6250 - precision: 0.7238 - recall: 0.475 - ETA: 0s - loss: 1.0500 - accuracy: 0.6071 - precision: 0.7103 - recall: 0.459 - ETA: 0s - loss: 1.0361 - accuracy: 0.6111 - precision: 0.7143 - recall: 0.468 - ETA: 0s - loss: 1.0077 - accuracy: 0.6278 - precision: 0.7331 - recall: 0.491 - ETA: 0s - loss: 1.0383 - accuracy: 0.6202 - precision: 0.7082 - recall: 0.478 - 1s 2ms/sample - loss: 1.0550 - accuracy: 0.6150 - precision: 0.7014 - recall: 0.4742 - val_loss: 1.4459 - val_accuracy: 0.4718 - val_precision: 0.5521 - val_recall: 0.3732\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9831 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.500 - ETA: 0s - loss: 0.9424 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.479 - ETA: 0s - loss: 0.9277 - accuracy: 0.6625 - precision: 0.7000 - recall: 0.525 - ETA: 0s - loss: 0.9055 - accuracy: 0.6652 - precision: 0.7160 - recall: 0.517 - ETA: 0s - loss: 0.9686 - accuracy: 0.6354 - precision: 0.7065 - recall: 0.493 - ETA: 0s - loss: 0.9897 - accuracy: 0.6136 - precision: 0.6840 - recall: 0.485 - ETA: 0s - loss: 0.9851 - accuracy: 0.6226 - precision: 0.6942 - recall: 0.485 - 1s 2ms/sample - loss: 0.9829 - accuracy: 0.6244 - precision: 0.6913 - recall: 0.4836 - val_loss: 1.3572 - val_accuracy: 0.5141 - val_precision: 0.5349 - val_recall: 0.3239\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0513 - accuracy: 0.5938 - precision: 0.7059 - recall: 0.375 - ETA: 0s - loss: 1.0135 - accuracy: 0.5729 - precision: 0.6885 - recall: 0.437 - ETA: 0s - loss: 0.9591 - accuracy: 0.5938 - precision: 0.7108 - recall: 0.460 - ETA: 0s - loss: 0.8916 - accuracy: 0.6198 - precision: 0.7339 - recall: 0.474 - ETA: 0s - loss: 0.9023 - accuracy: 0.6367 - precision: 0.7485 - recall: 0.476 - ETA: 0s - loss: 0.9287 - accuracy: 0.6313 - precision: 0.7463 - recall: 0.478 - ETA: 0s - loss: 0.9271 - accuracy: 0.6354 - precision: 0.7500 - recall: 0.492 - 1s 2ms/sample - loss: 0.9415 - accuracy: 0.6268 - precision: 0.7357 - recall: 0.4836 - val_loss: 1.2783 - val_accuracy: 0.5211 - val_precision: 0.5978 - val_recall: 0.3873\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8018 - accuracy: 0.6562 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 0.9752 - accuracy: 0.6146 - precision: 0.6667 - recall: 0.437 - ETA: 0s - loss: 0.9602 - accuracy: 0.6313 - precision: 0.6972 - recall: 0.475 - ETA: 0s - loss: 0.9496 - accuracy: 0.6339 - precision: 0.7230 - recall: 0.477 - ETA: 0s - loss: 0.9581 - accuracy: 0.6354 - precision: 0.7165 - recall: 0.482 - ETA: 0s - loss: 0.9407 - accuracy: 0.6364 - precision: 0.7241 - recall: 0.477 - ETA: 0s - loss: 0.9401 - accuracy: 0.6418 - precision: 0.7240 - recall: 0.485 - 1s 2ms/sample - loss: 0.9295 - accuracy: 0.6479 - precision: 0.7292 - recall: 0.4930 - val_loss: 1.2229 - val_accuracy: 0.5000 - val_precision: 0.6292 - val_recall: 0.3944\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9812 - accuracy: 0.5000 - precision: 0.7000 - recall: 0.437 - ETA: 0s - loss: 0.9765 - accuracy: 0.6042 - precision: 0.7213 - recall: 0.458 - ETA: 0s - loss: 0.8936 - accuracy: 0.6562 - precision: 0.7434 - recall: 0.525 - ETA: 0s - loss: 0.8616 - accuracy: 0.6652 - precision: 0.7546 - recall: 0.549 - ETA: 0s - loss: 0.8454 - accuracy: 0.6719 - precision: 0.7730 - recall: 0.558 - ETA: 0s - loss: 0.8446 - accuracy: 0.6594 - precision: 0.7636 - recall: 0.525 - ETA: 0s - loss: 0.8711 - accuracy: 0.6406 - precision: 0.7416 - recall: 0.515 - 1s 2ms/sample - loss: 0.8804 - accuracy: 0.6408 - precision: 0.7356 - recall: 0.5094 - val_loss: 1.2559 - val_accuracy: 0.5141 - val_precision: 0.5631 - val_recall: 0.4085\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9545 - accuracy: 0.6250 - precision: 0.6000 - recall: 0.281 - ETA: 0s - loss: 0.9695 - accuracy: 0.5521 - precision: 0.6094 - recall: 0.406 - ETA: 0s - loss: 0.9256 - accuracy: 0.6062 - precision: 0.6667 - recall: 0.462 - ETA: 0s - loss: 0.9092 - accuracy: 0.6429 - precision: 0.7063 - recall: 0.504 - ETA: 0s - loss: 0.9124 - accuracy: 0.6285 - precision: 0.7186 - recall: 0.496 - ETA: 0s - loss: 0.9076 - accuracy: 0.6307 - precision: 0.7250 - recall: 0.494 - ETA: 0s - loss: 0.8842 - accuracy: 0.6466 - precision: 0.7352 - recall: 0.507 - 1s 2ms/sample - loss: 0.8836 - accuracy: 0.6502 - precision: 0.7365 - recall: 0.5117 - val_loss: 1.2350 - val_accuracy: 0.5282 - val_precision: 0.6044 - val_recall: 0.3873\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0518 - accuracy: 0.5312 - precision: 0.6111 - recall: 0.343 - ETA: 0s - loss: 0.9009 - accuracy: 0.6042 - precision: 0.6923 - recall: 0.468 - ETA: 0s - loss: 0.8894 - accuracy: 0.6062 - precision: 0.6916 - recall: 0.462 - ETA: 0s - loss: 0.8387 - accuracy: 0.6518 - precision: 0.7308 - recall: 0.508 - ETA: 0s - loss: 0.8068 - accuracy: 0.6806 - precision: 0.7536 - recall: 0.541 - ETA: 0s - loss: 0.8086 - accuracy: 0.6761 - precision: 0.7519 - recall: 0.551 - ETA: 0s - loss: 0.8190 - accuracy: 0.6803 - precision: 0.7492 - recall: 0.552 - 1s 2ms/sample - loss: 0.8208 - accuracy: 0.6784 - precision: 0.7484 - recall: 0.5516 - val_loss: 1.1677 - val_accuracy: 0.5775 - val_precision: 0.6283 - val_recall: 0.5000\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.8125 - precision: 0.8750 - recall: 0.656 - ETA: 0s - loss: 0.7492 - accuracy: 0.7031 - precision: 0.7551 - recall: 0.578 - ETA: 0s - loss: 0.7674 - accuracy: 0.6719 - precision: 0.7234 - recall: 0.531 - ETA: 0s - loss: 0.9007 - accuracy: 0.6146 - precision: 0.6552 - recall: 0.494 - ETA: 0s - loss: 0.8819 - accuracy: 0.6328 - precision: 0.6842 - recall: 0.507 - ETA: 0s - loss: 0.8774 - accuracy: 0.6406 - precision: 0.7009 - recall: 0.512 - ETA: 0s - loss: 0.8577 - accuracy: 0.6536 - precision: 0.7230 - recall: 0.523 - 1s 2ms/sample - loss: 0.8369 - accuracy: 0.6596 - precision: 0.7311 - recall: 0.5235 - val_loss: 1.1673 - val_accuracy: 0.5211 - val_precision: 0.6082 - val_recall: 0.4155\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.7500 - precision: 0.9091 - recall: 0.625 - ETA: 0s - loss: 0.7164 - accuracy: 0.7292 - precision: 0.8143 - recall: 0.593 - ETA: 0s - loss: 0.7353 - accuracy: 0.7125 - precision: 0.8017 - recall: 0.581 - ETA: 0s - loss: 0.7644 - accuracy: 0.7143 - precision: 0.8113 - recall: 0.575 - ETA: 0s - loss: 0.7710 - accuracy: 0.7083 - precision: 0.8077 - recall: 0.583 - ETA: 0s - loss: 0.7765 - accuracy: 0.7017 - precision: 0.7946 - recall: 0.582 - ETA: 0s - loss: 0.7777 - accuracy: 0.7043 - precision: 0.7885 - recall: 0.591 - 1s 2ms/sample - loss: 0.7751 - accuracy: 0.7042 - precision: 0.7906 - recall: 0.5939 - val_loss: 1.1255 - val_accuracy: 0.5986 - val_precision: 0.6195 - val_recall: 0.4930\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.7188 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.7432 - accuracy: 0.7083 - precision: 0.7922 - recall: 0.635 - ETA: 0s - loss: 0.7642 - accuracy: 0.6812 - precision: 0.7920 - recall: 0.618 - ETA: 0s - loss: 0.7994 - accuracy: 0.6652 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.8192 - accuracy: 0.6597 - precision: 0.7534 - recall: 0.583 - ETA: 0s - loss: 0.8285 - accuracy: 0.6449 - precision: 0.7454 - recall: 0.573 - ETA: 0s - loss: 0.8317 - accuracy: 0.6406 - precision: 0.7358 - recall: 0.572 - ETA: 0s - loss: 0.8153 - accuracy: 0.6466 - precision: 0.7414 - recall: 0.572 - 1s 2ms/sample - loss: 0.8237 - accuracy: 0.6455 - precision: 0.7356 - recall: 0.5681 - val_loss: 1.2330 - val_accuracy: 0.5211 - val_precision: 0.6237 - val_recall: 0.4085\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9181 - accuracy: 0.7188 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.7568 - accuracy: 0.7292 - precision: 0.8358 - recall: 0.583 - ETA: 0s - loss: 0.6991 - accuracy: 0.7375 - precision: 0.8403 - recall: 0.625 - ETA: 0s - loss: 0.7371 - accuracy: 0.7143 - precision: 0.8012 - recall: 0.611 - ETA: 0s - loss: 0.7415 - accuracy: 0.7188 - precision: 0.7902 - recall: 0.614 - ETA: 0s - loss: 0.7682 - accuracy: 0.7045 - precision: 0.7802 - recall: 0.605 - ETA: 0s - loss: 0.7748 - accuracy: 0.6995 - precision: 0.7631 - recall: 0.596 - 1s 2ms/sample - loss: 0.7741 - accuracy: 0.6995 - precision: 0.7635 - recall: 0.5986 - val_loss: 1.2746 - val_accuracy: 0.5352 - val_precision: 0.5981 - val_recall: 0.4507\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1904 - accuracy: 0.4688 - precision: 0.5357 - recall: 0.468 - ETA: 0s - loss: 1.0290 - accuracy: 0.5938 - precision: 0.6145 - recall: 0.531 - ETA: 0s - loss: 0.8717 - accuracy: 0.6500 - precision: 0.6963 - recall: 0.587 - ETA: 0s - loss: 0.8380 - accuracy: 0.6652 - precision: 0.7204 - recall: 0.598 - ETA: 0s - loss: 0.8403 - accuracy: 0.6562 - precision: 0.7265 - recall: 0.590 - ETA: 0s - loss: 0.8277 - accuracy: 0.6562 - precision: 0.7338 - recall: 0.579 - ETA: 0s - loss: 0.8233 - accuracy: 0.6514 - precision: 0.7399 - recall: 0.574 - 1s 2ms/sample - loss: 0.8220 - accuracy: 0.6526 - precision: 0.7416 - recall: 0.5728 - val_loss: 1.2988 - val_accuracy: 0.5282 - val_precision: 0.6058 - val_recall: 0.4437\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8332 - accuracy: 0.6562 - precision: 0.7500 - recall: 0.656 - ETA: 0s - loss: 0.8747 - accuracy: 0.6562 - precision: 0.7170 - recall: 0.593 - ETA: 0s - loss: 1.1275 - accuracy: 0.5547 - precision: 0.6500 - recall: 0.507 - ETA: 0s - loss: 1.1340 - accuracy: 0.5437 - precision: 0.6290 - recall: 0.487 - ETA: 0s - loss: 1.0686 - accuracy: 0.5670 - precision: 0.6509 - recall: 0.491 - ETA: 0s - loss: 1.0579 - accuracy: 0.5764 - precision: 0.6745 - recall: 0.496 - ETA: 0s - loss: 1.0349 - accuracy: 0.5824 - precision: 0.6795 - recall: 0.500 - ETA: 0s - loss: 1.0645 - accuracy: 0.5745 - precision: 0.6634 - recall: 0.483 - 1s 2ms/sample - loss: 1.0527 - accuracy: 0.5822 - precision: 0.6710 - recall: 0.4883 - val_loss: 1.2693 - val_accuracy: 0.5352 - val_precision: 0.6264 - val_recall: 0.4014\n",
      "Epoch 128/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.7917 - accuracy: 0.6875 - precision: 0.8333 - recall: 0.625 - ETA: 0s - loss: 0.9346 - accuracy: 0.5938 - precision: 0.7576 - recall: 0.520 - ETA: 0s - loss: 0.8737 - accuracy: 0.6062 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.8840 - accuracy: 0.5938 - precision: 0.7278 - recall: 0.513 - ETA: 0s - loss: 0.9026 - accuracy: 0.6042 - precision: 0.7238 - recall: 0.527 - ETA: 0s - loss: 0.8734 - accuracy: 0.6222 - precision: 0.7297 - recall: 0.536 - ETA: 0s - loss: 0.8772 - accuracy: 0.6226 - precision: 0.7134 - recall: 0.526 - 1s 2ms/sample - loss: 0.8651 - accuracy: 0.6291 - precision: 0.7206 - recall: 0.5329 - val_loss: 1.2801 - val_accuracy: 0.5282 - val_precision: 0.5842 - val_recall: 0.4155\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8527 - accuracy: 0.6250 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.8535 - accuracy: 0.6458 - precision: 0.7424 - recall: 0.510 - ETA: 0s - loss: 0.8597 - accuracy: 0.6375 - precision: 0.7387 - recall: 0.512 - ETA: 0s - loss: 0.8909 - accuracy: 0.6116 - precision: 0.6951 - recall: 0.508 - ETA: 0s - loss: 0.9022 - accuracy: 0.6111 - precision: 0.6952 - recall: 0.506 - ETA: 0s - loss: 0.8739 - accuracy: 0.6193 - precision: 0.7154 - recall: 0.528 - ETA: 0s - loss: 0.8611 - accuracy: 0.6250 - precision: 0.7255 - recall: 0.533 - 1s 2ms/sample - loss: 0.8574 - accuracy: 0.6291 - precision: 0.7261 - recall: 0.5352 - val_loss: 1.2150 - val_accuracy: 0.5352 - val_precision: 0.6237 - val_recall: 0.4085\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7812 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.6190 - accuracy: 0.7604 - precision: 0.8714 - recall: 0.635 - ETA: 0s - loss: 0.6126 - accuracy: 0.7656 - precision: 0.8646 - recall: 0.648 - ETA: 0s - loss: 0.6946 - accuracy: 0.7240 - precision: 0.7947 - recall: 0.625 - ETA: 0s - loss: 0.7257 - accuracy: 0.7031 - precision: 0.7805 - recall: 0.625 - ETA: 0s - loss: 0.7004 - accuracy: 0.7188 - precision: 0.7907 - recall: 0.637 - ETA: 0s - loss: 0.7194 - accuracy: 0.7109 - precision: 0.7841 - recall: 0.614 - 1s 2ms/sample - loss: 0.7551 - accuracy: 0.6972 - precision: 0.7768 - recall: 0.5962 - val_loss: 1.2640 - val_accuracy: 0.5563 - val_precision: 0.5714 - val_recall: 0.4225\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8524 - accuracy: 0.7812 - precision: 0.8750 - recall: 0.656 - ETA: 0s - loss: 0.9415 - accuracy: 0.6979 - precision: 0.7160 - recall: 0.604 - ETA: 0s - loss: 0.8965 - accuracy: 0.6938 - precision: 0.7442 - recall: 0.600 - ETA: 0s - loss: 0.8557 - accuracy: 0.6875 - precision: 0.7654 - recall: 0.611 - ETA: 0s - loss: 0.8120 - accuracy: 0.7014 - precision: 0.7807 - recall: 0.618 - ETA: 0s - loss: 0.8181 - accuracy: 0.6960 - precision: 0.7624 - recall: 0.610 - ETA: 0s - loss: 0.7926 - accuracy: 0.7139 - precision: 0.7738 - recall: 0.625 - 1s 2ms/sample - loss: 0.7890 - accuracy: 0.7136 - precision: 0.7717 - recall: 0.6268 - val_loss: 1.1205 - val_accuracy: 0.5845 - val_precision: 0.6075 - val_recall: 0.4577\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8821 - accuracy: 0.6562 - precision: 0.6207 - recall: 0.562 - ETA: 0s - loss: 0.6757 - accuracy: 0.7708 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.6936 - accuracy: 0.7375 - precision: 0.7669 - recall: 0.637 - ETA: 0s - loss: 0.6877 - accuracy: 0.7321 - precision: 0.7619 - recall: 0.642 - ETA: 0s - loss: 0.6864 - accuracy: 0.7257 - precision: 0.7615 - recall: 0.631 - ETA: 0s - loss: 0.7178 - accuracy: 0.7159 - precision: 0.7568 - recall: 0.627 - ETA: 0s - loss: 0.7222 - accuracy: 0.7188 - precision: 0.7697 - recall: 0.634 - 1s 2ms/sample - loss: 0.7224 - accuracy: 0.7207 - precision: 0.7686 - recall: 0.6315 - val_loss: 1.1648 - val_accuracy: 0.5986 - val_precision: 0.6239 - val_recall: 0.4789\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8962 - accuracy: 0.5938 - precision: 0.7778 - recall: 0.437 - ETA: 0s - loss: 0.6910 - accuracy: 0.7083 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.6813 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.6586 - accuracy: 0.7411 - precision: 0.8111 - recall: 0.651 - ETA: 0s - loss: 0.7063 - accuracy: 0.7188 - precision: 0.7897 - recall: 0.638 - ETA: 0s - loss: 0.6972 - accuracy: 0.7312 - precision: 0.7931 - recall: 0.646 - ETA: 0s - loss: 0.7020 - accuracy: 0.7214 - precision: 0.7832 - recall: 0.630 - 1s 2ms/sample - loss: 0.7064 - accuracy: 0.7207 - precision: 0.7870 - recall: 0.6244 - val_loss: 1.1778 - val_accuracy: 0.5845 - val_precision: 0.6389 - val_recall: 0.4859\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7500 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.5834 - accuracy: 0.8125 - precision: 0.8718 - recall: 0.708 - ETA: 0s - loss: 0.5924 - accuracy: 0.7812 - precision: 0.8385 - recall: 0.681 - ETA: 0s - loss: 0.6780 - accuracy: 0.7321 - precision: 0.7735 - recall: 0.625 - ETA: 0s - loss: 0.6503 - accuracy: 0.7500 - precision: 0.7943 - recall: 0.648 - ETA: 0s - loss: 0.6771 - accuracy: 0.7375 - precision: 0.7863 - recall: 0.643 - ETA: 0s - loss: 0.6735 - accuracy: 0.7396 - precision: 0.7880 - recall: 0.648 - 1s 2ms/sample - loss: 0.6893 - accuracy: 0.7371 - precision: 0.7875 - recall: 0.6526 - val_loss: 1.3143 - val_accuracy: 0.5070 - val_precision: 0.5536 - val_recall: 0.4366\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.8438 - precision: 0.8387 - recall: 0.812 - ETA: 0s - loss: 0.7080 - accuracy: 0.6979 - precision: 0.7558 - recall: 0.677 - ETA: 0s - loss: 0.7030 - accuracy: 0.6938 - precision: 0.7643 - recall: 0.668 - ETA: 0s - loss: 0.7010 - accuracy: 0.6964 - precision: 0.7668 - recall: 0.660 - ETA: 0s - loss: 0.7181 - accuracy: 0.6979 - precision: 0.7664 - recall: 0.649 - ETA: 0s - loss: 0.6955 - accuracy: 0.7102 - precision: 0.7752 - recall: 0.656 - ETA: 0s - loss: 0.6887 - accuracy: 0.7057 - precision: 0.7706 - recall: 0.656 - 1s 2ms/sample - loss: 0.7039 - accuracy: 0.7019 - precision: 0.7703 - recall: 0.6455 - val_loss: 1.2520 - val_accuracy: 0.5563 - val_precision: 0.5826 - val_recall: 0.4718\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7500 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.5276 - accuracy: 0.8333 - precision: 0.8816 - recall: 0.697 - ETA: 0s - loss: 0.5595 - accuracy: 0.8000 - precision: 0.8485 - recall: 0.700 - ETA: 0s - loss: 0.6152 - accuracy: 0.7812 - precision: 0.8306 - recall: 0.678 - ETA: 0s - loss: 0.6202 - accuracy: 0.7708 - precision: 0.8186 - recall: 0.673 - ETA: 0s - loss: 0.6696 - accuracy: 0.7557 - precision: 0.8028 - recall: 0.659 - ETA: 0s - loss: 0.7123 - accuracy: 0.7428 - precision: 0.7861 - recall: 0.653 - 1s 2ms/sample - loss: 0.7173 - accuracy: 0.7394 - precision: 0.7809 - recall: 0.6526 - val_loss: 1.3599 - val_accuracy: 0.5282 - val_precision: 0.5965 - val_recall: 0.4789\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.8754 - accuracy: 0.6875 - precision: 0.7722 - recall: 0.635 - ETA: 0s - loss: 0.8606 - accuracy: 0.6812 - precision: 0.7445 - recall: 0.637 - ETA: 0s - loss: 0.9095 - accuracy: 0.6518 - precision: 0.7031 - recall: 0.602 - ETA: 0s - loss: 0.9011 - accuracy: 0.6597 - precision: 0.7177 - recall: 0.618 - ETA: 0s - loss: 0.8689 - accuracy: 0.6790 - precision: 0.7351 - recall: 0.630 - ETA: 0s - loss: 0.8643 - accuracy: 0.6803 - precision: 0.7486 - recall: 0.629 - 1s 2ms/sample - loss: 0.8604 - accuracy: 0.6808 - precision: 0.7486 - recall: 0.6291 - val_loss: 1.3077 - val_accuracy: 0.5634 - val_precision: 0.5888 - val_recall: 0.4437\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.7188 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.7871 - accuracy: 0.6979 - precision: 0.7468 - recall: 0.614 - ETA: 0s - loss: 0.7681 - accuracy: 0.7188 - precision: 0.7596 - recall: 0.617 - ETA: 0s - loss: 0.6924 - accuracy: 0.7448 - precision: 0.7962 - recall: 0.651 - ETA: 0s - loss: 0.7341 - accuracy: 0.7232 - precision: 0.7701 - recall: 0.642 - ETA: 0s - loss: 0.7454 - accuracy: 0.7049 - precision: 0.7731 - recall: 0.638 - ETA: 0s - loss: 0.7705 - accuracy: 0.6969 - precision: 0.7652 - recall: 0.631 - ETA: 0s - loss: 0.7806 - accuracy: 0.6797 - precision: 0.7484 - recall: 0.619 - 1s 2ms/sample - loss: 0.7803 - accuracy: 0.6854 - precision: 0.7586 - recall: 0.6197 - val_loss: 1.3292 - val_accuracy: 0.5845 - val_precision: 0.5789 - val_recall: 0.4648\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.7322 - accuracy: 0.7188 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.8935 - accuracy: 0.6687 - precision: 0.7188 - recall: 0.575 - ETA: 0s - loss: 0.9661 - accuracy: 0.6384 - precision: 0.6821 - recall: 0.526 - ETA: 0s - loss: 0.9408 - accuracy: 0.6445 - precision: 0.6990 - recall: 0.535 - ETA: 0s - loss: 0.9963 - accuracy: 0.6250 - precision: 0.6735 - recall: 0.515 - ETA: 0s - loss: 0.9563 - accuracy: 0.6449 - precision: 0.6971 - recall: 0.542 - ETA: 0s - loss: 0.9139 - accuracy: 0.6587 - precision: 0.7086 - recall: 0.555 - 1s 2ms/sample - loss: 0.9050 - accuracy: 0.6620 - precision: 0.7134 - recall: 0.5610 - val_loss: 1.2730 - val_accuracy: 0.5211 - val_precision: 0.5804 - val_recall: 0.4577\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0496 - accuracy: 0.5938 - precision: 0.6522 - recall: 0.468 - ETA: 0s - loss: 0.8373 - accuracy: 0.6771 - precision: 0.7403 - recall: 0.593 - ETA: 0s - loss: 0.7334 - accuracy: 0.7375 - precision: 0.7891 - recall: 0.631 - ETA: 0s - loss: 0.7077 - accuracy: 0.7455 - precision: 0.7826 - recall: 0.642 - ETA: 0s - loss: 0.7099 - accuracy: 0.7361 - precision: 0.7881 - recall: 0.645 - ETA: 0s - loss: 0.7013 - accuracy: 0.7386 - precision: 0.7951 - recall: 0.650 - ETA: 0s - loss: 0.7147 - accuracy: 0.7260 - precision: 0.7893 - recall: 0.639 - 1s 2ms/sample - loss: 0.7140 - accuracy: 0.7254 - precision: 0.7867 - recall: 0.6408 - val_loss: 1.2266 - val_accuracy: 0.5845 - val_precision: 0.6271 - val_recall: 0.5211\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.6875 - precision: 0.6897 - recall: 0.625 - ETA: 0s - loss: 0.7535 - accuracy: 0.6771 - precision: 0.7093 - recall: 0.635 - ETA: 0s - loss: 0.7173 - accuracy: 0.7312 - precision: 0.7744 - recall: 0.643 - ETA: 0s - loss: 0.7372 - accuracy: 0.7455 - precision: 0.7819 - recall: 0.656 - ETA: 0s - loss: 0.7356 - accuracy: 0.7326 - precision: 0.7797 - recall: 0.638 - ETA: 0s - loss: 0.7553 - accuracy: 0.7188 - precision: 0.7637 - recall: 0.633 - ETA: 0s - loss: 0.7458 - accuracy: 0.7212 - precision: 0.7666 - recall: 0.639 - 1s 2ms/sample - loss: 0.7588 - accuracy: 0.7160 - precision: 0.7614 - recall: 0.6291 - val_loss: 1.2226 - val_accuracy: 0.5352 - val_precision: 0.5528 - val_recall: 0.4789\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.8438 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.5971 - accuracy: 0.7812 - precision: 0.8415 - recall: 0.718 - ETA: 0s - loss: 0.6950 - accuracy: 0.7437 - precision: 0.7986 - recall: 0.693 - ETA: 0s - loss: 0.8226 - accuracy: 0.6875 - precision: 0.7540 - recall: 0.629 - ETA: 0s - loss: 0.8493 - accuracy: 0.6597 - precision: 0.7273 - recall: 0.611 - ETA: 0s - loss: 0.8473 - accuracy: 0.6591 - precision: 0.7205 - recall: 0.608 - ETA: 0s - loss: 0.8404 - accuracy: 0.6587 - precision: 0.7184 - recall: 0.601 - 1s 2ms/sample - loss: 0.8407 - accuracy: 0.6596 - precision: 0.7191 - recall: 0.6009 - val_loss: 1.2711 - val_accuracy: 0.5070 - val_precision: 0.5922 - val_recall: 0.4296\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8757 - accuracy: 0.6562 - precision: 0.7037 - recall: 0.593 - ETA: 0s - loss: 0.7750 - accuracy: 0.6979 - precision: 0.7532 - recall: 0.604 - ETA: 0s - loss: 0.8375 - accuracy: 0.6687 - precision: 0.7176 - recall: 0.587 - ETA: 0s - loss: 0.9966 - accuracy: 0.6250 - precision: 0.6704 - recall: 0.535 - ETA: 0s - loss: 1.0132 - accuracy: 0.6146 - precision: 0.6579 - recall: 0.520 - ETA: 0s - loss: 0.9962 - accuracy: 0.6156 - precision: 0.6587 - recall: 0.518 - ETA: 0s - loss: 0.9328 - accuracy: 0.6406 - precision: 0.6885 - recall: 0.546 - 1s 2ms/sample - loss: 0.9148 - accuracy: 0.6408 - precision: 0.6923 - recall: 0.5493 - val_loss: 1.4829 - val_accuracy: 0.4718 - val_precision: 0.5250 - val_recall: 0.4437\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.5625 - precision: 0.6400 - recall: 0.500 - ETA: 0s - loss: 1.0009 - accuracy: 0.6250 - precision: 0.6711 - recall: 0.531 - ETA: 0s - loss: 0.9324 - accuracy: 0.6625 - precision: 0.7239 - recall: 0.606 - ETA: 0s - loss: 0.9169 - accuracy: 0.6562 - precision: 0.7268 - recall: 0.593 - ETA: 0s - loss: 0.8766 - accuracy: 0.6667 - precision: 0.7339 - recall: 0.593 - ETA: 0s - loss: 0.9220 - accuracy: 0.6591 - precision: 0.7298 - recall: 0.590 - ETA: 0s - loss: 0.9032 - accuracy: 0.6587 - precision: 0.7319 - recall: 0.584 - 1s 2ms/sample - loss: 0.9091 - accuracy: 0.6596 - precision: 0.7294 - recall: 0.5822 - val_loss: 1.2723 - val_accuracy: 0.5845 - val_precision: 0.6238 - val_recall: 0.4437\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7517 - accuracy: 0.7500 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.7996 - accuracy: 0.7188 - precision: 0.7821 - recall: 0.635 - ETA: 0s - loss: 0.8234 - accuracy: 0.6938 - precision: 0.7405 - recall: 0.606 - ETA: 0s - loss: 0.8168 - accuracy: 0.6786 - precision: 0.7111 - recall: 0.571 - ETA: 0s - loss: 0.8115 - accuracy: 0.6840 - precision: 0.7222 - recall: 0.586 - ETA: 0s - loss: 0.8162 - accuracy: 0.6932 - precision: 0.7263 - recall: 0.588 - ETA: 0s - loss: 0.8143 - accuracy: 0.6899 - precision: 0.7257 - recall: 0.591 - 1s 2ms/sample - loss: 0.8037 - accuracy: 0.6925 - precision: 0.7299 - recall: 0.5962 - val_loss: 1.3661 - val_accuracy: 0.5282 - val_precision: 0.5508 - val_recall: 0.4577\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4764 - accuracy: 0.4375 - precision: 0.4815 - recall: 0.406 - ETA: 0s - loss: 1.1954 - accuracy: 0.5000 - precision: 0.5385 - recall: 0.437 - ETA: 0s - loss: 0.9681 - accuracy: 0.5938 - precision: 0.6591 - recall: 0.543 - ETA: 0s - loss: 0.9041 - accuracy: 0.6205 - precision: 0.6882 - recall: 0.571 - ETA: 0s - loss: 0.8537 - accuracy: 0.6424 - precision: 0.7119 - recall: 0.583 - ETA: 0s - loss: 0.8697 - accuracy: 0.6307 - precision: 0.7003 - recall: 0.571 - ETA: 0s - loss: 0.8106 - accuracy: 0.6707 - precision: 0.7362 - recall: 0.610 - 1s 2ms/sample - loss: 0.8156 - accuracy: 0.6690 - precision: 0.7358 - recall: 0.6080 - val_loss: 1.4039 - val_accuracy: 0.5282 - val_precision: 0.5545 - val_recall: 0.4296\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.5625 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.9684 - accuracy: 0.5938 - precision: 0.7361 - recall: 0.552 - ETA: 0s - loss: 0.9254 - accuracy: 0.6172 - precision: 0.7500 - recall: 0.562 - ETA: 0s - loss: 0.9057 - accuracy: 0.6198 - precision: 0.7379 - recall: 0.557 - ETA: 0s - loss: 0.8967 - accuracy: 0.6161 - precision: 0.7294 - recall: 0.553 - ETA: 0s - loss: 0.9234 - accuracy: 0.6042 - precision: 0.7209 - recall: 0.538 - ETA: 0s - loss: 0.8950 - accuracy: 0.6222 - precision: 0.7331 - recall: 0.554 - ETA: 0s - loss: 0.8731 - accuracy: 0.6298 - precision: 0.7327 - recall: 0.560 - 1s 2ms/sample - loss: 0.8592 - accuracy: 0.6362 - precision: 0.7378 - recall: 0.5681 - val_loss: 1.1220 - val_accuracy: 0.5563 - val_precision: 0.5946 - val_recall: 0.4648\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.6875 - precision: 0.7200 - recall: 0.562 - ETA: 0s - loss: 0.7191 - accuracy: 0.6771 - precision: 0.7308 - recall: 0.593 - ETA: 0s - loss: 0.7775 - accuracy: 0.6875 - precision: 0.7500 - recall: 0.600 - ETA: 0s - loss: 0.7399 - accuracy: 0.6920 - precision: 0.7611 - recall: 0.611 - ETA: 0s - loss: 0.7327 - accuracy: 0.7014 - precision: 0.7686 - recall: 0.611 - ETA: 0s - loss: 0.7323 - accuracy: 0.7017 - precision: 0.7606 - recall: 0.613 - ETA: 0s - loss: 0.7268 - accuracy: 0.7043 - precision: 0.7566 - recall: 0.620 - 1s 2ms/sample - loss: 0.7311 - accuracy: 0.7066 - precision: 0.7564 - recall: 0.6197 - val_loss: 1.2180 - val_accuracy: 0.5915 - val_precision: 0.6423 - val_recall: 0.5563\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8125 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.5915 - accuracy: 0.8125 - precision: 0.8434 - recall: 0.729 - ETA: 0s - loss: 0.6132 - accuracy: 0.7750 - precision: 0.7972 - recall: 0.712 - ETA: 0s - loss: 0.6271 - accuracy: 0.7708 - precision: 0.7907 - recall: 0.708 - ETA: 0s - loss: 0.6485 - accuracy: 0.7656 - precision: 0.7817 - recall: 0.699 - ETA: 0s - loss: 0.6536 - accuracy: 0.7469 - precision: 0.7631 - recall: 0.684 - ETA: 0s - loss: 0.6538 - accuracy: 0.7474 - precision: 0.7668 - recall: 0.684 - 1s 2ms/sample - loss: 0.6646 - accuracy: 0.7394 - precision: 0.7612 - recall: 0.6808 - val_loss: 1.1532 - val_accuracy: 0.5775 - val_precision: 0.6293 - val_recall: 0.5141\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.7500 - precision: 0.8276 - recall: 0.750 - ETA: 0s - loss: 0.5822 - accuracy: 0.7708 - precision: 0.8481 - recall: 0.697 - ETA: 0s - loss: 0.6066 - accuracy: 0.7812 - precision: 0.8370 - recall: 0.706 - ETA: 0s - loss: 0.6243 - accuracy: 0.7604 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.5986 - accuracy: 0.7773 - precision: 0.8257 - recall: 0.703 - ETA: 0s - loss: 0.6803 - accuracy: 0.7406 - precision: 0.7955 - recall: 0.668 - ETA: 0s - loss: 0.7471 - accuracy: 0.7135 - precision: 0.7669 - recall: 0.651 - ETA: 0s - loss: 0.7659 - accuracy: 0.7019 - precision: 0.7528 - recall: 0.637 - 1s 2ms/sample - loss: 0.7858 - accuracy: 0.6972 - precision: 0.7472 - recall: 0.6315 - val_loss: 1.3681 - val_accuracy: 0.5000 - val_precision: 0.5556 - val_recall: 0.4577\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 84b8380cbe7fbf0696fce4fbccea05e9</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5985915660858154</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                28800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 385,804\n",
      "Trainable params: 385,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 50s - loss: 2.4841 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 14s - loss: 2.4671 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 7s - loss: 2.4587 - accuracy: 0.1500 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 3s - loss: 2.4641 - accuracy: 0.1384 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 2s - loss: 2.4391 - accuracy: 0.1528 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4264 - accuracy: 0.1420 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4105 - accuracy: 0.1538 - precision: 0.0000e+00 - recall: 0.0000e+0 - 6s 15ms/sample - loss: 2.4083 - accuracy: 0.1549 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3433 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2678 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2678 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2173 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1740 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1410 - accuracy: 0.2361 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1368 - accuracy: 0.2415 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1296 - accuracy: 0.2284 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.1319 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1027 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1347 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0555 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0500 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0444 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0328 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0372 - accuracy: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0313 - accuracy: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 2.0282 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9790 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8659 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8723 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9052 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9117 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9212 - accuracy: 0.2222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9251 - accuracy: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9087 - accuracy: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.9150 - accuracy: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9568 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9718 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0499 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0005 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0224 - accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9840 - accuracy: 0.2222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9562 - accuracy: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9497 - accuracy: 0.2236 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.9518 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8938 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9164 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7976 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8260 - accuracy: 0.2688 - precision: 1.0000 - recall: 0.0063        - ETA: 0s - loss: 1.8546 - accuracy: 0.2723 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.8825 - accuracy: 0.2639 - precision: 0.5000 - recall: 0.003 - ETA: 0s - loss: 1.8944 - accuracy: 0.2614 - precision: 0.5000 - recall: 0.002 - ETA: 0s - loss: 1.8871 - accuracy: 0.2620 - precision: 0.5000 - recall: 0.002 - 0s 1ms/sample - loss: 1.8879 - accuracy: 0.2582 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.8805 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7810 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9128 - accuracy: 0.2969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9643 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9846 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9882 - accuracy: 0.1823 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9314 - accuracy: 0.2227 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9040 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8833 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8738 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8589 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9147 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8121 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8097 - accuracy: 0.2969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8315 - accuracy: 0.2760 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8589 - accuracy: 0.2617 - precision: 1.0000 - recall: 0.0078        - ETA: 0s - loss: 1.8964 - accuracy: 0.2469 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.9036 - accuracy: 0.2422 - precision: 1.0000 - recall: 0.005 - ETA: 0s - loss: 1.9019 - accuracy: 0.2476 - precision: 1.0000 - recall: 0.004 - 1s 1ms/sample - loss: 1.9038 - accuracy: 0.2441 - precision: 1.0000 - recall: 0.0047 - val_loss: 2.0537 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9921 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1981 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1790 - accuracy: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1885 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1753 - accuracy: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1101 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0935 - accuracy: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0748 - accuracy: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0683 - accuracy: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1126 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0519 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1467 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1451 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2015 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2109 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2058 - accuracy: 0.2049 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2736 - accuracy: 0.1790 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2695 - accuracy: 0.1779 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2796 - accuracy: 0.1784 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3170 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.5587 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3683 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3758 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3556 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3434 - accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3115 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3120 - accuracy: 0.1534 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3101 - accuracy: 0.1510 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3051 - accuracy: 0.1549 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2710 - val_accuracy: 0.1127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2856 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3433 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3249 - accuracy: 0.1375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2737 - accuracy: 0.1741 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2691 - accuracy: 0.1701 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2679 - accuracy: 0.1594 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2637 - accuracy: 0.1510 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.2584 - accuracy: 0.1549 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2356 - val_accuracy: 0.1408 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2144 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1919 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1615 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1364 - accuracy: 0.2545 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1244 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1210 - accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1144 - accuracy: 0.2266 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1181 - accuracy: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.1135 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0184 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0308 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0603 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0323 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0237 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0327 - accuracy: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0381 - accuracy: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0147 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0069 - accuracy: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9383 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0449 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9967 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9793 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9570 - accuracy: 0.2589 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9672 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9877 - accuracy: 0.2358 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9815 - accuracy: 0.2284 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9843 - accuracy: 0.2254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8795 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8818 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9771 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0210 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0293 - accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9991 - accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0102 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9990 - accuracy: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9993 - accuracy: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0069 - val_accuracy: 0.1408 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9706 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0300 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9878 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9609 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9350 - accuracy: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9267 - accuracy: 0.1733 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9177 - accuracy: 0.1779 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.9184 - accuracy: 0.1761 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8619 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.7927 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8515 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8368 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8667 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8534 - accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8734 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8585 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.8611 - accuracy: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8516 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9028 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8674 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8674 - accuracy: 0.1750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8908 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8966 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8930 - accuracy: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8958 - accuracy: 0.1923 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.8906 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0086 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8788 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9242 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9627 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9500 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9081 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9086 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8964 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9122 - accuracy: 0.1643 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8550 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9704 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9801 - accuracy: 0.1771 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9265 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9091 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9104 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8985 - accuracy: 0.1818 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8782 - accuracy: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.8764 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7994 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8809 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8436 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8835 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8553 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8432 - accuracy: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8444 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8582 - accuracy: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.8514 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7895 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8833 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8775 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8607 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8625 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8410 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8271 - accuracy: 0.2386 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7990 - accuracy: 0.2524 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7940 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7194 - val_accuracy: 0.2887 - val_precision: 0.5000 - val_recall: 0.0070\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7589 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6974 - accuracy: 0.3021 - precision: 0.5000 - recall: 0.0104        - ETA: 0s - loss: 1.7224 - accuracy: 0.3063 - precision: 0.5714 - recall: 0.025 - ETA: 0s - loss: 1.7388 - accuracy: 0.2723 - precision: 0.4444 - recall: 0.017 - ETA: 0s - loss: 1.7360 - accuracy: 0.2639 - precision: 0.5000 - recall: 0.017 - ETA: 0s - loss: 1.7593 - accuracy: 0.2557 - precision: 0.4615 - recall: 0.017 - ETA: 0s - loss: 1.7795 - accuracy: 0.2476 - precision: 0.4615 - recall: 0.014 - 0s 1ms/sample - loss: 1.7831 - accuracy: 0.2418 - precision: 0.4615 - recall: 0.0141 - val_loss: 1.9262 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0158 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9330 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9139 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8957 - accuracy: 0.2679 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8858 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8271 - accuracy: 0.2898 - precision: 0.2000 - recall: 0.0028        - ETA: 0s - loss: 1.8284 - accuracy: 0.2861 - precision: 0.1429 - recall: 0.002 - 1s 1ms/sample - loss: 1.8307 - accuracy: 0.2864 - precision: 0.1429 - recall: 0.0023 - val_loss: 1.8042 - val_accuracy: 0.3169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6829 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7101 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6916 - accuracy: 0.3000 - precision: 0.5000 - recall: 0.0125        - ETA: 0s - loss: 1.8046 - accuracy: 0.2500 - precision: 0.4286 - recall: 0.013 - ETA: 0s - loss: 1.7738 - accuracy: 0.2743 - precision: 0.5000 - recall: 0.013 - ETA: 0s - loss: 1.7762 - accuracy: 0.2670 - precision: 0.5000 - recall: 0.011 - ETA: 0s - loss: 1.7944 - accuracy: 0.2692 - precision: 0.5000 - recall: 0.009 - 0s 1ms/sample - loss: 1.7900 - accuracy: 0.2723 - precision: 0.5000 - recall: 0.0094 - val_loss: 1.8571 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5614 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6750 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6668 - accuracy: 0.3313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7281 - accuracy: 0.3393 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7431 - accuracy: 0.3368 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7706 - accuracy: 0.3182 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7684 - accuracy: 0.3101 - precision: 0.0000e+00 - recall: 0.0000e+0 - 0s 1ms/sample - loss: 1.7607 - accuracy: 0.3052 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9693 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5846 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8371 - accuracy: 0.2708 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.8265 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.7796 - accuracy: 0.2723 - precision: 0.7500 - recall: 0.013 - ETA: 0s - loss: 1.7820 - accuracy: 0.2847 - precision: 0.6000 - recall: 0.010 - ETA: 0s - loss: 1.7363 - accuracy: 0.3068 - precision: 0.6667 - recall: 0.011 - ETA: 0s - loss: 1.7297 - accuracy: 0.3101 - precision: 0.5714 - recall: 0.009 - 1s 1ms/sample - loss: 1.7291 - accuracy: 0.3122 - precision: 0.5714 - recall: 0.0094 - val_loss: 1.7886 - val_accuracy: 0.2746 - val_precision: 0.7500 - val_recall: 0.0211\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7908 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8277 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7832 - accuracy: 0.3438 - precision: 0.2500 - recall: 0.0063        - ETA: 0s - loss: 1.8205 - accuracy: 0.3170 - precision: 0.2500 - recall: 0.004 - ETA: 0s - loss: 1.8296 - accuracy: 0.3090 - precision: 0.4000 - recall: 0.006 - ETA: 0s - loss: 1.8609 - accuracy: 0.2955 - precision: 0.5000 - recall: 0.008 - ETA: 0s - loss: 1.8702 - accuracy: 0.2933 - precision: 0.5714 - recall: 0.009 - 0s 1ms/sample - loss: 1.8741 - accuracy: 0.2981 - precision: 0.5714 - recall: 0.0094 - val_loss: 1.7457 - val_accuracy: 0.3099 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9153 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7307 - accuracy: 0.2708 - precision: 1.0000 - recall: 0.0104        - ETA: 0s - loss: 1.8076 - accuracy: 0.2375 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.7775 - accuracy: 0.2545 - precision: 1.0000 - recall: 0.004 - ETA: 0s - loss: 1.7435 - accuracy: 0.2743 - precision: 1.0000 - recall: 0.003 - ETA: 0s - loss: 1.7140 - accuracy: 0.2869 - precision: 1.0000 - recall: 0.002 - ETA: 0s - loss: 1.6929 - accuracy: 0.3077 - precision: 1.0000 - recall: 0.004 - 1s 1ms/sample - loss: 1.6996 - accuracy: 0.3028 - precision: 1.0000 - recall: 0.0047 - val_loss: 1.6231 - val_accuracy: 0.3028 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4808 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5069 - accuracy: 0.4062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5440 - accuracy: 0.3688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5974 - accuracy: 0.3661 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6170 - accuracy: 0.3611 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6284 - accuracy: 0.3608 - precision: 0.3333 - recall: 0.0028        - ETA: 0s - loss: 1.6132 - accuracy: 0.3606 - precision: 0.3333 - recall: 0.002 - 0s 1ms/sample - loss: 1.6178 - accuracy: 0.3568 - precision: 0.5000 - recall: 0.0047 - val_loss: 1.6486 - val_accuracy: 0.3169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5079 - accuracy: 0.4688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6812 - accuracy: 0.3646 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6700 - accuracy: 0.3562 - precision: 1.0000 - recall: 0.0063        - ETA: 0s - loss: 1.6657 - accuracy: 0.3348 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.6414 - accuracy: 0.3507 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.6118 - accuracy: 0.3693 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.5936 - accuracy: 0.3702 - precision: 1.0000 - recall: 0.009 - 1s 1ms/sample - loss: 1.5923 - accuracy: 0.3709 - precision: 1.0000 - recall: 0.0094 - val_loss: 1.6067 - val_accuracy: 0.3239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.4836 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.4861 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.012 - ETA: 0s - loss: 1.5590 - accuracy: 0.3839 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.5577 - accuracy: 0.3819 - precision: 0.7500 - recall: 0.010 - ETA: 0s - loss: 1.5654 - accuracy: 0.3722 - precision: 0.7500 - recall: 0.008 - ETA: 0s - loss: 1.5641 - accuracy: 0.3702 - precision: 0.7143 - recall: 0.012 - 0s 1ms/sample - loss: 1.5677 - accuracy: 0.3732 - precision: 0.7143 - recall: 0.0117 - val_loss: 1.6490 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5777 - accuracy: 0.3958 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5388 - accuracy: 0.4000 - precision: 0.6000 - recall: 0.0188        - ETA: 0s - loss: 1.5360 - accuracy: 0.3973 - precision: 0.6364 - recall: 0.031 - ETA: 0s - loss: 1.5326 - accuracy: 0.3889 - precision: 0.5185 - recall: 0.048 - ETA: 0s - loss: 1.5254 - accuracy: 0.3949 - precision: 0.5897 - recall: 0.065 - ETA: 0s - loss: 1.5450 - accuracy: 0.3798 - precision: 0.5745 - recall: 0.064 - 0s 1ms/sample - loss: 1.5457 - accuracy: 0.3779 - precision: 0.5833 - recall: 0.0657 - val_loss: 1.5968 - val_accuracy: 0.3028 - val_precision: 0.6190 - val_recall: 0.0915\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4732 - accuracy: 0.2188 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5922 - accuracy: 0.2604 - precision: 0.5556 - recall: 0.052 - ETA: 0s - loss: 1.5482 - accuracy: 0.3438 - precision: 0.5909 - recall: 0.081 - ETA: 0s - loss: 1.5550 - accuracy: 0.3527 - precision: 0.5862 - recall: 0.075 - ETA: 0s - loss: 1.5990 - accuracy: 0.3368 - precision: 0.5806 - recall: 0.062 - ETA: 0s - loss: 1.5815 - accuracy: 0.3466 - precision: 0.6216 - recall: 0.065 - ETA: 0s - loss: 1.5795 - accuracy: 0.3510 - precision: 0.6500 - recall: 0.062 - 0s 1ms/sample - loss: 1.5762 - accuracy: 0.3568 - precision: 0.6585 - recall: 0.0634 - val_loss: 1.5993 - val_accuracy: 0.3239 - val_precision: 0.9000 - val_recall: 0.0634\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4310 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.5999 - accuracy: 0.4271 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.6391 - accuracy: 0.4000 - precision: 0.5000 - recall: 0.043 - ETA: 0s - loss: 1.5825 - accuracy: 0.4062 - precision: 0.5238 - recall: 0.049 - ETA: 0s - loss: 1.6211 - accuracy: 0.3785 - precision: 0.5862 - recall: 0.059 - ETA: 0s - loss: 1.6057 - accuracy: 0.3920 - precision: 0.5476 - recall: 0.065 - ETA: 0s - loss: 1.6149 - accuracy: 0.3870 - precision: 0.5660 - recall: 0.072 - 0s 1ms/sample - loss: 1.6291 - accuracy: 0.3779 - precision: 0.5660 - recall: 0.0704 - val_loss: 1.7158 - val_accuracy: 0.2746 - val_precision: 0.9231 - val_recall: 0.0845\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6185 - accuracy: 0.3333 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.5878 - accuracy: 0.3625 - precision: 0.8889 - recall: 0.050 - ETA: 0s - loss: 1.5976 - accuracy: 0.3705 - precision: 0.6471 - recall: 0.049 - ETA: 0s - loss: 1.6019 - accuracy: 0.3542 - precision: 0.6207 - recall: 0.062 - ETA: 0s - loss: 1.5814 - accuracy: 0.3608 - precision: 0.6053 - recall: 0.065 - ETA: 0s - loss: 1.5819 - accuracy: 0.3630 - precision: 0.5745 - recall: 0.064 - 0s 1ms/sample - loss: 1.5752 - accuracy: 0.3638 - precision: 0.5745 - recall: 0.0634 - val_loss: 1.7192 - val_accuracy: 0.3028 - val_precision: 0.8333 - val_recall: 0.1056\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5218 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5923 - accuracy: 0.3229 - precision: 0.7692 - recall: 0.104 - ETA: 0s - loss: 1.6293 - accuracy: 0.3313 - precision: 0.7273 - recall: 0.100 - ETA: 0s - loss: 1.5810 - accuracy: 0.3125 - precision: 0.5946 - recall: 0.098 - ETA: 0s - loss: 1.5725 - accuracy: 0.3194 - precision: 0.5600 - recall: 0.097 - ETA: 0s - loss: 1.5542 - accuracy: 0.3182 - precision: 0.5333 - recall: 0.090 - ETA: 0s - loss: 1.5407 - accuracy: 0.3317 - precision: 0.5694 - recall: 0.098 - 1s 1ms/sample - loss: 1.5336 - accuracy: 0.3357 - precision: 0.5867 - recall: 0.1033 - val_loss: 1.5416 - val_accuracy: 0.3310 - val_precision: 0.6087 - val_recall: 0.0986\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3762 - accuracy: 0.4375 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.5528 - accuracy: 0.3854 - precision: 0.5000 - recall: 0.072 - ETA: 0s - loss: 1.5261 - accuracy: 0.3812 - precision: 0.4286 - recall: 0.056 - ETA: 0s - loss: 1.5223 - accuracy: 0.3929 - precision: 0.4783 - recall: 0.049 - ETA: 0s - loss: 1.5121 - accuracy: 0.3924 - precision: 0.5333 - recall: 0.055 - ETA: 0s - loss: 1.5271 - accuracy: 0.3977 - precision: 0.5000 - recall: 0.051 - ETA: 0s - loss: 1.5251 - accuracy: 0.3822 - precision: 0.5366 - recall: 0.052 - 0s 1ms/sample - loss: 1.5191 - accuracy: 0.3779 - precision: 0.5366 - recall: 0.0516 - val_loss: 1.6061 - val_accuracy: 0.3169 - val_precision: 0.6875 - val_recall: 0.0775\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3281 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5726 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.6296 - accuracy: 0.3375 - precision: 0.4667 - recall: 0.043 - ETA: 0s - loss: 1.5619 - accuracy: 0.3616 - precision: 0.5238 - recall: 0.049 - ETA: 0s - loss: 1.5240 - accuracy: 0.3750 - precision: 0.6071 - recall: 0.059 - ETA: 0s - loss: 1.5322 - accuracy: 0.3665 - precision: 0.6286 - recall: 0.062 - ETA: 0s - loss: 1.5236 - accuracy: 0.3774 - precision: 0.6341 - recall: 0.062 - 1s 1ms/sample - loss: 1.5223 - accuracy: 0.3803 - precision: 0.6591 - recall: 0.0681 - val_loss: 1.6567 - val_accuracy: 0.3028 - val_precision: 0.7647 - val_recall: 0.0915\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6595 - accuracy: 0.2812 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.5088 - accuracy: 0.3646 - precision: 0.5000 - recall: 0.083 - ETA: 0s - loss: 1.5181 - accuracy: 0.3812 - precision: 0.5556 - recall: 0.093 - ETA: 0s - loss: 1.4722 - accuracy: 0.3973 - precision: 0.6341 - recall: 0.116 - ETA: 0s - loss: 1.4526 - accuracy: 0.4132 - precision: 0.6481 - recall: 0.121 - ETA: 0s - loss: 1.4674 - accuracy: 0.4091 - precision: 0.6667 - recall: 0.113 - ETA: 0s - loss: 1.4646 - accuracy: 0.3870 - precision: 0.6197 - recall: 0.105 - 1s 1ms/sample - loss: 1.4584 - accuracy: 0.3920 - precision: 0.6364 - recall: 0.1150 - val_loss: 1.4709 - val_accuracy: 0.3873 - val_precision: 0.6562 - val_recall: 0.1479\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5442 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4741 - accuracy: 0.4062 - precision: 0.5455 - recall: 0.125 - ETA: 0s - loss: 1.4226 - accuracy: 0.4062 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.4385 - accuracy: 0.3750 - precision: 0.5306 - recall: 0.116 - ETA: 0s - loss: 1.4603 - accuracy: 0.3819 - precision: 0.5902 - recall: 0.125 - ETA: 0s - loss: 1.4682 - accuracy: 0.3636 - precision: 0.5882 - recall: 0.113 - ETA: 0s - loss: 1.4552 - accuracy: 0.3774 - precision: 0.6104 - recall: 0.113 - 0s 1ms/sample - loss: 1.4486 - accuracy: 0.3897 - precision: 0.6154 - recall: 0.1127 - val_loss: 1.5259 - val_accuracy: 0.3239 - val_precision: 0.7826 - val_recall: 0.1268\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4962 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.3514 - accuracy: 0.5417 - precision: 0.8462 - recall: 0.114 - ETA: 0s - loss: 1.3960 - accuracy: 0.4563 - precision: 0.6562 - recall: 0.131 - ETA: 0s - loss: 1.3766 - accuracy: 0.4509 - precision: 0.6875 - recall: 0.147 - ETA: 0s - loss: 1.3994 - accuracy: 0.4410 - precision: 0.6833 - recall: 0.142 - ETA: 0s - loss: 1.4073 - accuracy: 0.4290 - precision: 0.6800 - recall: 0.144 - ETA: 0s - loss: 1.4096 - accuracy: 0.4135 - precision: 0.6517 - recall: 0.139 - 0s 1ms/sample - loss: 1.4085 - accuracy: 0.4131 - precision: 0.6444 - recall: 0.1362 - val_loss: 1.5018 - val_accuracy: 0.3169 - val_precision: 0.7143 - val_recall: 0.1408\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1045 - accuracy: 0.4688 - precision: 0.5385 - recall: 0.218 - ETA: 0s - loss: 1.2633 - accuracy: 0.4688 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.3771 - accuracy: 0.4375 - precision: 0.6486 - recall: 0.150 - ETA: 0s - loss: 1.3683 - accuracy: 0.4420 - precision: 0.6379 - recall: 0.165 - ETA: 0s - loss: 1.3526 - accuracy: 0.4444 - precision: 0.6892 - recall: 0.177 - ETA: 0s - loss: 1.4010 - accuracy: 0.4261 - precision: 0.6744 - recall: 0.164 - ETA: 0s - loss: 1.4023 - accuracy: 0.4231 - precision: 0.6566 - recall: 0.156 - 1s 1ms/sample - loss: 1.4066 - accuracy: 0.4178 - precision: 0.6600 - recall: 0.1549 - val_loss: 1.5555 - val_accuracy: 0.3732 - val_precision: 0.7586 - val_recall: 0.1549\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3674 - accuracy: 0.5312 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.5530 - accuracy: 0.4271 - precision: 0.5556 - recall: 0.104 - ETA: 0s - loss: 1.4850 - accuracy: 0.4500 - precision: 0.6571 - recall: 0.143 - ETA: 0s - loss: 1.4668 - accuracy: 0.4286 - precision: 0.6250 - recall: 0.133 - ETA: 0s - loss: 1.4442 - accuracy: 0.4236 - precision: 0.6176 - recall: 0.145 - ETA: 0s - loss: 1.4542 - accuracy: 0.4290 - precision: 0.6190 - recall: 0.147 - ETA: 0s - loss: 1.4412 - accuracy: 0.4303 - precision: 0.6211 - recall: 0.141 - 0s 1ms/sample - loss: 1.4396 - accuracy: 0.4343 - precision: 0.6186 - recall: 0.1408 - val_loss: 1.4485 - val_accuracy: 0.3873 - val_precision: 0.6286 - val_recall: 0.1549\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2545 - accuracy: 0.5000 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.3162 - accuracy: 0.4688 - precision: 0.7200 - recall: 0.187 - ETA: 0s - loss: 1.2682 - accuracy: 0.5000 - precision: 0.7209 - recall: 0.193 - ETA: 0s - loss: 1.3103 - accuracy: 0.4509 - precision: 0.6508 - recall: 0.183 - ETA: 0s - loss: 1.3490 - accuracy: 0.4306 - precision: 0.6712 - recall: 0.170 - ETA: 0s - loss: 1.3565 - accuracy: 0.4375 - precision: 0.6790 - recall: 0.156 - ETA: 0s - loss: 1.3794 - accuracy: 0.4303 - precision: 0.6771 - recall: 0.156 - 1s 1ms/sample - loss: 1.3772 - accuracy: 0.4272 - precision: 0.6804 - recall: 0.1549 - val_loss: 1.3971 - val_accuracy: 0.4225 - val_precision: 0.7000 - val_recall: 0.1479\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4351 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.3139 - accuracy: 0.4688 - precision: 0.8421 - recall: 0.166 - ETA: 0s - loss: 1.2951 - accuracy: 0.4688 - precision: 0.8250 - recall: 0.206 - ETA: 0s - loss: 1.3097 - accuracy: 0.4598 - precision: 0.8269 - recall: 0.192 - ETA: 0s - loss: 1.3337 - accuracy: 0.4514 - precision: 0.7746 - recall: 0.191 - ETA: 0s - loss: 1.3390 - accuracy: 0.4489 - precision: 0.7159 - recall: 0.179 - ETA: 0s - loss: 1.3467 - accuracy: 0.4495 - precision: 0.6847 - recall: 0.182 - 1s 1ms/sample - loss: 1.3495 - accuracy: 0.4484 - precision: 0.6814 - recall: 0.1808 - val_loss: 1.3418 - val_accuracy: 0.3944 - val_precision: 0.7174 - val_recall: 0.2324\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2826 - accuracy: 0.5000 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3275 - accuracy: 0.4479 - precision: 0.5185 - recall: 0.145 - ETA: 0s - loss: 1.3494 - accuracy: 0.4313 - precision: 0.5778 - recall: 0.162 - ETA: 0s - loss: 1.3528 - accuracy: 0.4330 - precision: 0.6140 - recall: 0.156 - ETA: 0s - loss: 1.3300 - accuracy: 0.4653 - precision: 0.6486 - recall: 0.166 - ETA: 0s - loss: 1.3424 - accuracy: 0.4545 - precision: 0.6477 - recall: 0.161 - ETA: 0s - loss: 1.3485 - accuracy: 0.4427 - precision: 0.6354 - recall: 0.158 - ETA: 0s - loss: 1.3624 - accuracy: 0.4375 - precision: 0.6535 - recall: 0.158 - 1s 1ms/sample - loss: 1.3703 - accuracy: 0.4343 - precision: 0.6602 - recall: 0.1596 - val_loss: 1.4822 - val_accuracy: 0.3662 - val_precision: 0.7222 - val_recall: 0.1831\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4547 - accuracy: 0.4375 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.2337 - accuracy: 0.5417 - precision: 0.7895 - recall: 0.156 - ETA: 0s - loss: 1.1993 - accuracy: 0.5375 - precision: 0.7429 - recall: 0.162 - ETA: 0s - loss: 1.2437 - accuracy: 0.5000 - precision: 0.7826 - recall: 0.160 - ETA: 0s - loss: 1.2896 - accuracy: 0.4757 - precision: 0.7627 - recall: 0.156 - ETA: 0s - loss: 1.3056 - accuracy: 0.4744 - precision: 0.7436 - recall: 0.164 - ETA: 0s - loss: 1.3188 - accuracy: 0.4567 - precision: 0.7419 - recall: 0.165 - 1s 1ms/sample - loss: 1.3202 - accuracy: 0.4601 - precision: 0.7447 - recall: 0.1643 - val_loss: 1.4674 - val_accuracy: 0.3873 - val_precision: 0.7667 - val_recall: 0.1620\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1993 - accuracy: 0.6250 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.3184 - accuracy: 0.5104 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.3033 - accuracy: 0.4938 - precision: 0.6750 - recall: 0.168 - ETA: 0s - loss: 1.2810 - accuracy: 0.4911 - precision: 0.6923 - recall: 0.160 - ETA: 0s - loss: 1.2789 - accuracy: 0.5069 - precision: 0.7027 - recall: 0.180 - ETA: 0s - loss: 1.2929 - accuracy: 0.5000 - precision: 0.7011 - recall: 0.173 - ETA: 0s - loss: 1.3016 - accuracy: 0.4904 - precision: 0.7172 - recall: 0.170 - 1s 2ms/sample - loss: 1.3060 - accuracy: 0.4859 - precision: 0.7200 - recall: 0.1690 - val_loss: 1.3828 - val_accuracy: 0.3944 - val_precision: 0.7143 - val_recall: 0.1761\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5127 - accuracy: 0.3750 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.3237 - accuracy: 0.4583 - precision: 0.7619 - recall: 0.166 - ETA: 0s - loss: 1.3350 - accuracy: 0.4812 - precision: 0.7297 - recall: 0.168 - ETA: 0s - loss: 1.3540 - accuracy: 0.4732 - precision: 0.6909 - recall: 0.169 - ETA: 0s - loss: 1.3855 - accuracy: 0.4653 - precision: 0.7015 - recall: 0.163 - ETA: 0s - loss: 1.3841 - accuracy: 0.4688 - precision: 0.6932 - recall: 0.173 - ETA: 0s - loss: 1.3933 - accuracy: 0.4712 - precision: 0.6893 - recall: 0.170 - 1s 1ms/sample - loss: 1.3915 - accuracy: 0.4742 - precision: 0.6698 - recall: 0.1667 - val_loss: 1.4342 - val_accuracy: 0.4155 - val_precision: 0.6585 - val_recall: 0.1901\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 0.4062 - precision: 0.4444 - recall: 0.125 - ETA: 0s - loss: 1.4270 - accuracy: 0.4531 - precision: 0.5333 - recall: 0.125 - ETA: 0s - loss: 1.3962 - accuracy: 0.4531 - precision: 0.6207 - recall: 0.140 - ETA: 0s - loss: 1.3258 - accuracy: 0.4844 - precision: 0.6957 - recall: 0.166 - ETA: 0s - loss: 1.3649 - accuracy: 0.4531 - precision: 0.6769 - recall: 0.171 - ETA: 0s - loss: 1.3969 - accuracy: 0.4344 - precision: 0.6538 - recall: 0.159 - ETA: 0s - loss: 1.4181 - accuracy: 0.4167 - precision: 0.6129 - recall: 0.148 - ETA: 0s - loss: 1.4073 - accuracy: 0.4183 - precision: 0.6214 - recall: 0.153 - 1s 2ms/sample - loss: 1.4033 - accuracy: 0.4225 - precision: 0.6226 - recall: 0.1549 - val_loss: 1.5053 - val_accuracy: 0.3662 - val_precision: 0.7500 - val_recall: 0.1690\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0689 - accuracy: 0.5312 - precision: 1.0000 - recall: 0.312 - ETA: 0s - loss: 1.2376 - accuracy: 0.5000 - precision: 0.6250 - recall: 0.208 - ETA: 0s - loss: 1.3633 - accuracy: 0.4625 - precision: 0.6600 - recall: 0.206 - ETA: 0s - loss: 1.4362 - accuracy: 0.4152 - precision: 0.5672 - recall: 0.169 - ETA: 0s - loss: 1.4735 - accuracy: 0.4097 - precision: 0.5513 - recall: 0.149 - ETA: 0s - loss: 1.4895 - accuracy: 0.4062 - precision: 0.5684 - recall: 0.153 - ETA: 0s - loss: 1.4834 - accuracy: 0.3942 - precision: 0.5688 - recall: 0.149 - 1s 1ms/sample - loss: 1.4830 - accuracy: 0.3944 - precision: 0.5676 - recall: 0.1479 - val_loss: 1.6317 - val_accuracy: 0.3310 - val_precision: 0.6452 - val_recall: 0.1408\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3292 - accuracy: 0.4688 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.4127 - accuracy: 0.3750 - precision: 0.7391 - recall: 0.177 - ETA: 0s - loss: 1.4490 - accuracy: 0.3562 - precision: 0.4894 - recall: 0.143 - ETA: 0s - loss: 1.4498 - accuracy: 0.3482 - precision: 0.4865 - recall: 0.160 - ETA: 0s - loss: 1.4001 - accuracy: 0.3889 - precision: 0.5200 - recall: 0.180 - ETA: 0s - loss: 1.4061 - accuracy: 0.4006 - precision: 0.5210 - recall: 0.176 - ETA: 0s - loss: 1.4022 - accuracy: 0.4087 - precision: 0.5188 - recall: 0.165 - 1s 2ms/sample - loss: 1.4064 - accuracy: 0.4108 - precision: 0.5182 - recall: 0.1667 - val_loss: 1.4136 - val_accuracy: 0.3592 - val_precision: 0.5833 - val_recall: 0.0986\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.5312 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.5145 - accuracy: 0.3958 - precision: 0.5217 - recall: 0.125 - ETA: 0s - loss: 1.6179 - accuracy: 0.3625 - precision: 0.4762 - recall: 0.125 - ETA: 0s - loss: 1.6862 - accuracy: 0.3393 - precision: 0.4237 - recall: 0.111 - ETA: 0s - loss: 1.6580 - accuracy: 0.3229 - precision: 0.4237 - recall: 0.086 - ETA: 0s - loss: 1.6644 - accuracy: 0.3187 - precision: 0.4426 - recall: 0.084 - ETA: 0s - loss: 1.6683 - accuracy: 0.3151 - precision: 0.4412 - recall: 0.078 - ETA: 0s - loss: 1.6663 - accuracy: 0.3197 - precision: 0.4648 - recall: 0.079 - 1s 2ms/sample - loss: 1.6786 - accuracy: 0.3169 - precision: 0.4648 - recall: 0.0775 - val_loss: 1.6686 - val_accuracy: 0.2887 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7318 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7144 - accuracy: 0.2604 - precision: 0.6667 - recall: 0.0417        - ETA: 0s - loss: 1.6584 - accuracy: 0.2937 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.6528 - accuracy: 0.3170 - precision: 0.6250 - recall: 0.022 - ETA: 0s - loss: 1.6044 - accuracy: 0.3299 - precision: 0.4762 - recall: 0.034 - ETA: 0s - loss: 1.6102 - accuracy: 0.3313 - precision: 0.4783 - recall: 0.034 - ETA: 0s - loss: 1.6254 - accuracy: 0.3385 - precision: 0.5000 - recall: 0.044 - ETA: 0s - loss: 1.6314 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.043 - 1s 2ms/sample - loss: 1.6358 - accuracy: 0.3404 - precision: 0.5128 - recall: 0.0469 - val_loss: 1.6191 - val_accuracy: 0.3028 - val_precision: 0.7333 - val_recall: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.4222 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5931 - accuracy: 0.3625 - precision: 0.5385 - recall: 0.043 - ETA: 0s - loss: 1.5597 - accuracy: 0.3839 - precision: 0.5294 - recall: 0.040 - ETA: 0s - loss: 1.5285 - accuracy: 0.4028 - precision: 0.5714 - recall: 0.041 - ETA: 0s - loss: 1.4971 - accuracy: 0.4375 - precision: 0.5926 - recall: 0.045 - ETA: 0s - loss: 1.4736 - accuracy: 0.4471 - precision: 0.6071 - recall: 0.040 - 1s 1ms/sample - loss: 1.4642 - accuracy: 0.4507 - precision: 0.6071 - recall: 0.0399 - val_loss: 1.5152 - val_accuracy: 0.3310 - val_precision: 0.8333 - val_recall: 0.0352\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4974 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5452 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.0417        - ETA: 0s - loss: 1.4648 - accuracy: 0.4500 - precision: 0.8235 - recall: 0.087 - ETA: 0s - loss: 1.4513 - accuracy: 0.4330 - precision: 0.8077 - recall: 0.093 - ETA: 0s - loss: 1.4149 - accuracy: 0.4479 - precision: 0.8421 - recall: 0.111 - ETA: 0s - loss: 1.4210 - accuracy: 0.4460 - precision: 0.8261 - recall: 0.108 - ETA: 0s - loss: 1.4200 - accuracy: 0.4375 - precision: 0.7541 - recall: 0.110 - 1s 2ms/sample - loss: 1.4198 - accuracy: 0.4366 - precision: 0.7541 - recall: 0.1080 - val_loss: 1.5025 - val_accuracy: 0.4296 - val_precision: 0.9000 - val_recall: 0.1268\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1820 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.2803 - accuracy: 0.5000 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.3109 - accuracy: 0.5063 - precision: 0.8519 - recall: 0.143 - ETA: 0s - loss: 1.3262 - accuracy: 0.4688 - precision: 0.7949 - recall: 0.138 - ETA: 0s - loss: 1.3011 - accuracy: 0.4965 - precision: 0.7500 - recall: 0.125 - ETA: 0s - loss: 1.3140 - accuracy: 0.4830 - precision: 0.7167 - recall: 0.122 - ETA: 0s - loss: 1.3353 - accuracy: 0.4663 - precision: 0.6667 - recall: 0.120 - 1s 1ms/sample - loss: 1.3324 - accuracy: 0.4695 - precision: 0.6623 - recall: 0.1197 - val_loss: 1.4166 - val_accuracy: 0.3803 - val_precision: 0.6000 - val_recall: 0.1268\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3969 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.3685 - accuracy: 0.4375 - precision: 0.7200 - recall: 0.187 - ETA: 0s - loss: 1.2981 - accuracy: 0.4812 - precision: 0.7674 - recall: 0.206 - ETA: 0s - loss: 1.2787 - accuracy: 0.5089 - precision: 0.7193 - recall: 0.183 - ETA: 0s - loss: 1.2929 - accuracy: 0.5000 - precision: 0.6753 - recall: 0.180 - ETA: 0s - loss: 1.3289 - accuracy: 0.4943 - precision: 0.6897 - recall: 0.170 - ETA: 0s - loss: 1.3413 - accuracy: 0.4832 - precision: 0.6863 - recall: 0.168 - 1s 1ms/sample - loss: 1.3449 - accuracy: 0.4812 - precision: 0.6857 - recall: 0.1690 - val_loss: 1.5839 - val_accuracy: 0.3803 - val_precision: 0.5641 - val_recall: 0.1549\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4125 - accuracy: 0.4375 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.3480 - accuracy: 0.4896 - precision: 0.5926 - recall: 0.166 - ETA: 0s - loss: 1.2711 - accuracy: 0.5250 - precision: 0.6304 - recall: 0.181 - ETA: 0s - loss: 1.2897 - accuracy: 0.4866 - precision: 0.6393 - recall: 0.174 - ETA: 0s - loss: 1.3244 - accuracy: 0.4722 - precision: 0.6707 - recall: 0.191 - ETA: 0s - loss: 1.3141 - accuracy: 0.4744 - precision: 0.6907 - recall: 0.190 - ETA: 0s - loss: 1.3184 - accuracy: 0.4712 - precision: 0.6842 - recall: 0.187 - 1s 2ms/sample - loss: 1.3130 - accuracy: 0.4765 - precision: 0.6923 - recall: 0.1901 - val_loss: 1.3238 - val_accuracy: 0.4577 - val_precision: 0.6957 - val_recall: 0.2254\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9776 - accuracy: 0.5625 - precision: 0.9167 - recall: 0.343 - ETA: 0s - loss: 1.2157 - accuracy: 0.5312 - precision: 0.7838 - recall: 0.302 - ETA: 0s - loss: 1.3001 - accuracy: 0.4812 - precision: 0.7167 - recall: 0.268 - ETA: 0s - loss: 1.3265 - accuracy: 0.4777 - precision: 0.6818 - recall: 0.267 - ETA: 0s - loss: 1.3531 - accuracy: 0.4757 - precision: 0.6759 - recall: 0.253 - ETA: 0s - loss: 1.4119 - accuracy: 0.4688 - precision: 0.6512 - recall: 0.238 - ETA: 0s - loss: 1.4121 - accuracy: 0.4736 - precision: 0.6395 - recall: 0.226 - 0s 1ms/sample - loss: 1.4083 - accuracy: 0.4718 - precision: 0.6424 - recall: 0.2277 - val_loss: 1.6196 - val_accuracy: 0.3099 - val_precision: 0.7188 - val_recall: 0.1620\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8901 - accuracy: 0.3125 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.6349 - accuracy: 0.3125 - precision: 0.6111 - recall: 0.114 - ETA: 0s - loss: 1.5210 - accuracy: 0.3875 - precision: 0.6071 - recall: 0.106 - ETA: 0s - loss: 1.5101 - accuracy: 0.3884 - precision: 0.5952 - recall: 0.111 - ETA: 0s - loss: 1.4542 - accuracy: 0.4062 - precision: 0.6154 - recall: 0.111 - ETA: 0s - loss: 1.4372 - accuracy: 0.4148 - precision: 0.6143 - recall: 0.122 - ETA: 0s - loss: 1.4350 - accuracy: 0.4087 - precision: 0.5934 - recall: 0.129 - 1s 1ms/sample - loss: 1.4372 - accuracy: 0.4085 - precision: 0.5914 - recall: 0.1291 - val_loss: 1.4332 - val_accuracy: 0.4085 - val_precision: 0.6757 - val_recall: 0.1761\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3651 - accuracy: 0.5312 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.3891 - accuracy: 0.4375 - precision: 0.5455 - recall: 0.187 - ETA: 0s - loss: 1.4072 - accuracy: 0.4500 - precision: 0.5714 - recall: 0.175 - ETA: 0s - loss: 1.3712 - accuracy: 0.4688 - precision: 0.6269 - recall: 0.187 - ETA: 0s - loss: 1.3821 - accuracy: 0.4653 - precision: 0.6216 - recall: 0.159 - ETA: 0s - loss: 1.3571 - accuracy: 0.4602 - precision: 0.6222 - recall: 0.159 - ETA: 0s - loss: 1.3633 - accuracy: 0.4543 - precision: 0.6038 - recall: 0.153 - 1s 1ms/sample - loss: 1.3630 - accuracy: 0.4577 - precision: 0.6111 - recall: 0.1549 - val_loss: 1.5267 - val_accuracy: 0.3944 - val_precision: 0.7027 - val_recall: 0.1831\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2912 - accuracy: 0.3438 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.3103 - accuracy: 0.4271 - precision: 0.6667 - recall: 0.166 - ETA: 0s - loss: 1.2952 - accuracy: 0.4812 - precision: 0.6087 - recall: 0.175 - ETA: 0s - loss: 1.2812 - accuracy: 0.4955 - precision: 0.6769 - recall: 0.196 - ETA: 0s - loss: 1.2794 - accuracy: 0.4965 - precision: 0.6463 - recall: 0.184 - ETA: 0s - loss: 1.2877 - accuracy: 0.4915 - precision: 0.6863 - recall: 0.198 - ETA: 0s - loss: 1.2843 - accuracy: 0.4784 - precision: 0.7034 - recall: 0.199 - 0s 1ms/sample - loss: 1.2902 - accuracy: 0.4765 - precision: 0.7107 - recall: 0.2019 - val_loss: 1.3561 - val_accuracy: 0.4225 - val_precision: 0.7381 - val_recall: 0.2183\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5354 - accuracy: 0.3438 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.4097 - accuracy: 0.4792 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.3363 - accuracy: 0.4875 - precision: 0.6087 - recall: 0.175 - ETA: 0s - loss: 1.3518 - accuracy: 0.4821 - precision: 0.6418 - recall: 0.192 - ETA: 0s - loss: 1.3339 - accuracy: 0.4792 - precision: 0.6264 - recall: 0.197 - ETA: 0s - loss: 1.3139 - accuracy: 0.4801 - precision: 0.6446 - recall: 0.221 - ETA: 0s - loss: 1.3292 - accuracy: 0.4784 - precision: 0.6294 - recall: 0.216 - 0s 1ms/sample - loss: 1.3234 - accuracy: 0.4765 - precision: 0.6294 - recall: 0.2113 - val_loss: 1.3866 - val_accuracy: 0.4437 - val_precision: 0.6383 - val_recall: 0.2113\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2001 - accuracy: 0.5625 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.2866 - accuracy: 0.5312 - precision: 0.6571 - recall: 0.239 - ETA: 0s - loss: 1.3654 - accuracy: 0.5063 - precision: 0.6250 - recall: 0.218 - ETA: 0s - loss: 1.3035 - accuracy: 0.5179 - precision: 0.6184 - recall: 0.209 - ETA: 0s - loss: 1.3298 - accuracy: 0.5069 - precision: 0.6139 - recall: 0.215 - ETA: 0s - loss: 1.3290 - accuracy: 0.4943 - precision: 0.5984 - recall: 0.207 - ETA: 0s - loss: 1.3167 - accuracy: 0.4856 - precision: 0.6028 - recall: 0.204 - 0s 1ms/sample - loss: 1.3114 - accuracy: 0.4906 - precision: 0.6138 - recall: 0.2089 - val_loss: 1.6608 - val_accuracy: 0.3803 - val_precision: 0.5814 - val_recall: 0.1761\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3164 - accuracy: 0.4062 - precision: 0.8889 - recall: 0.250 - ETA: 0s - loss: 1.3231 - accuracy: 0.4375 - precision: 0.7241 - recall: 0.218 - ETA: 0s - loss: 1.2369 - accuracy: 0.5063 - precision: 0.7800 - recall: 0.243 - ETA: 0s - loss: 1.2335 - accuracy: 0.4821 - precision: 0.7125 - recall: 0.254 - ETA: 0s - loss: 1.2804 - accuracy: 0.4722 - precision: 0.6731 - recall: 0.243 - ETA: 0s - loss: 1.2501 - accuracy: 0.4943 - precision: 0.6875 - recall: 0.250 - ETA: 0s - loss: 1.2647 - accuracy: 0.4880 - precision: 0.6513 - recall: 0.238 - 0s 1ms/sample - loss: 1.2687 - accuracy: 0.4883 - precision: 0.6494 - recall: 0.2347 - val_loss: 1.4206 - val_accuracy: 0.3944 - val_precision: 0.5484 - val_recall: 0.2394\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4876 - accuracy: 0.3438 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.4142 - accuracy: 0.3750 - precision: 0.5581 - recall: 0.250 - ETA: 0s - loss: 1.3892 - accuracy: 0.4313 - precision: 0.5672 - recall: 0.237 - ETA: 0s - loss: 1.3592 - accuracy: 0.4554 - precision: 0.6044 - recall: 0.245 - ETA: 0s - loss: 1.3372 - accuracy: 0.4618 - precision: 0.6216 - recall: 0.239 - ETA: 0s - loss: 1.2860 - accuracy: 0.4943 - precision: 0.6522 - recall: 0.255 - ETA: 0s - loss: 1.2640 - accuracy: 0.5072 - precision: 0.6628 - recall: 0.274 - 0s 1ms/sample - loss: 1.2622 - accuracy: 0.5094 - precision: 0.6648 - recall: 0.2746 - val_loss: 1.3525 - val_accuracy: 0.4507 - val_precision: 0.6800 - val_recall: 0.2394\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.5625 - precision: 0.9091 - recall: 0.312 - ETA: 0s - loss: 1.1606 - accuracy: 0.5104 - precision: 0.8621 - recall: 0.260 - ETA: 0s - loss: 1.2116 - accuracy: 0.4812 - precision: 0.7593 - recall: 0.256 - ETA: 0s - loss: 1.2079 - accuracy: 0.5000 - precision: 0.7895 - recall: 0.267 - ETA: 0s - loss: 1.2291 - accuracy: 0.5104 - precision: 0.7400 - recall: 0.256 - ETA: 0s - loss: 1.2318 - accuracy: 0.5057 - precision: 0.7398 - recall: 0.258 - ETA: 0s - loss: 1.2220 - accuracy: 0.5144 - precision: 0.7432 - recall: 0.264 - 0s 1ms/sample - loss: 1.2236 - accuracy: 0.5141 - precision: 0.7338 - recall: 0.2653 - val_loss: 1.4961 - val_accuracy: 0.3732 - val_precision: 0.5893 - val_recall: 0.2324\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2577 - accuracy: 0.5312 - precision: 0.9167 - recall: 0.343 - ETA: 0s - loss: 1.2600 - accuracy: 0.5417 - precision: 0.7111 - recall: 0.333 - ETA: 0s - loss: 1.2637 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.337 - ETA: 0s - loss: 1.2393 - accuracy: 0.5402 - precision: 0.6491 - recall: 0.330 - ETA: 0s - loss: 1.2466 - accuracy: 0.5382 - precision: 0.6483 - recall: 0.326 - ETA: 0s - loss: 1.3348 - accuracy: 0.5114 - precision: 0.6080 - recall: 0.304 - ETA: 0s - loss: 1.3669 - accuracy: 0.4952 - precision: 0.6000 - recall: 0.281 - 1s 1ms/sample - loss: 1.3684 - accuracy: 0.4953 - precision: 0.6020 - recall: 0.2840 - val_loss: 1.3371 - val_accuracy: 0.4648 - val_precision: 0.6136 - val_recall: 0.1901\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2487 - accuracy: 0.5312 - precision: 0.6154 - recall: 0.250 - ETA: 0s - loss: 1.2995 - accuracy: 0.4688 - precision: 0.5938 - recall: 0.197 - ETA: 0s - loss: 1.2909 - accuracy: 0.4688 - precision: 0.6200 - recall: 0.193 - ETA: 0s - loss: 1.2997 - accuracy: 0.4732 - precision: 0.7042 - recall: 0.223 - ETA: 0s - loss: 1.3126 - accuracy: 0.4688 - precision: 0.6941 - recall: 0.204 - ETA: 0s - loss: 1.3188 - accuracy: 0.4858 - precision: 0.7000 - recall: 0.198 - ETA: 0s - loss: 1.3653 - accuracy: 0.4712 - precision: 0.6964 - recall: 0.187 - 0s 1ms/sample - loss: 1.3693 - accuracy: 0.4671 - precision: 0.6903 - recall: 0.1831 - val_loss: 1.6491 - val_accuracy: 0.3451 - val_precision: 0.4688 - val_recall: 0.1056\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2194 - accuracy: 0.3438 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.2832 - accuracy: 0.4583 - precision: 0.7143 - recall: 0.208 - ETA: 0s - loss: 1.3473 - accuracy: 0.4688 - precision: 0.7111 - recall: 0.200 - ETA: 0s - loss: 1.3958 - accuracy: 0.4375 - precision: 0.6610 - recall: 0.174 - ETA: 0s - loss: 1.3814 - accuracy: 0.4583 - precision: 0.6866 - recall: 0.159 - ETA: 0s - loss: 1.3554 - accuracy: 0.4688 - precision: 0.7176 - recall: 0.173 - ETA: 0s - loss: 1.3974 - accuracy: 0.4447 - precision: 0.6731 - recall: 0.168 - 0s 1ms/sample - loss: 1.4064 - accuracy: 0.4413 - precision: 0.6604 - recall: 0.1643 - val_loss: 1.3821 - val_accuracy: 0.4225 - val_precision: 0.6522 - val_recall: 0.2113\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4829 - accuracy: 0.4688 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.3837 - accuracy: 0.4896 - precision: 0.5882 - recall: 0.208 - ETA: 0s - loss: 1.3587 - accuracy: 0.5000 - precision: 0.6491 - recall: 0.231 - ETA: 0s - loss: 1.3142 - accuracy: 0.5000 - precision: 0.6709 - recall: 0.236 - ETA: 0s - loss: 1.3181 - accuracy: 0.4896 - precision: 0.6771 - recall: 0.225 - ETA: 0s - loss: 1.2862 - accuracy: 0.5028 - precision: 0.7034 - recall: 0.235 - ETA: 0s - loss: 1.2788 - accuracy: 0.5168 - precision: 0.7111 - recall: 0.230 - 0s 1ms/sample - loss: 1.2868 - accuracy: 0.5164 - precision: 0.7101 - recall: 0.2300 - val_loss: 1.4493 - val_accuracy: 0.4366 - val_precision: 0.7647 - val_recall: 0.1831\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1578 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.218 - ETA: 0s - loss: 1.2896 - accuracy: 0.4792 - precision: 0.8421 - recall: 0.166 - ETA: 0s - loss: 1.2161 - accuracy: 0.4938 - precision: 0.8421 - recall: 0.200 - ETA: 0s - loss: 1.1996 - accuracy: 0.5045 - precision: 0.8627 - recall: 0.196 - ETA: 0s - loss: 1.2118 - accuracy: 0.5312 - precision: 0.8333 - recall: 0.191 - ETA: 0s - loss: 1.2291 - accuracy: 0.5284 - precision: 0.8514 - recall: 0.179 - ETA: 0s - loss: 1.2335 - accuracy: 0.5264 - precision: 0.8000 - recall: 0.182 - 0s 1ms/sample - loss: 1.2290 - accuracy: 0.5305 - precision: 0.8061 - recall: 0.1854 - val_loss: 1.5042 - val_accuracy: 0.4155 - val_precision: 0.5526 - val_recall: 0.1479\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4139 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.4886 - accuracy: 0.4583 - precision: 0.6154 - recall: 0.166 - ETA: 0s - loss: 1.4378 - accuracy: 0.5063 - precision: 0.5909 - recall: 0.162 - ETA: 0s - loss: 1.3427 - accuracy: 0.5268 - precision: 0.6667 - recall: 0.205 - ETA: 0s - loss: 1.2912 - accuracy: 0.5451 - precision: 0.6667 - recall: 0.201 - ETA: 0s - loss: 1.2869 - accuracy: 0.5369 - precision: 0.6569 - recall: 0.190 - ETA: 0s - loss: 1.2941 - accuracy: 0.5240 - precision: 0.6557 - recall: 0.192 - 0s 1ms/sample - loss: 1.2901 - accuracy: 0.5282 - precision: 0.6614 - recall: 0.1972 - val_loss: 1.3673 - val_accuracy: 0.4437 - val_precision: 0.6250 - val_recall: 0.2113\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1945 - accuracy: 0.5312 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.1590 - accuracy: 0.5417 - precision: 0.7500 - recall: 0.250 - ETA: 0s - loss: 1.1898 - accuracy: 0.5250 - precision: 0.6923 - recall: 0.225 - ETA: 0s - loss: 1.2185 - accuracy: 0.5089 - precision: 0.6400 - recall: 0.214 - ETA: 0s - loss: 1.2509 - accuracy: 0.5035 - precision: 0.6495 - recall: 0.218 - ETA: 0s - loss: 1.2242 - accuracy: 0.5227 - precision: 0.6694 - recall: 0.230 - ETA: 0s - loss: 1.2209 - accuracy: 0.5312 - precision: 0.6966 - recall: 0.242 - 0s 1ms/sample - loss: 1.2272 - accuracy: 0.5305 - precision: 0.6913 - recall: 0.2418 - val_loss: 1.3522 - val_accuracy: 0.4437 - val_precision: 0.6800 - val_recall: 0.2394\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3458 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.3048 - accuracy: 0.5000 - precision: 0.5909 - recall: 0.270 - ETA: 0s - loss: 1.2396 - accuracy: 0.5500 - precision: 0.6567 - recall: 0.275 - ETA: 0s - loss: 1.2873 - accuracy: 0.5312 - precision: 0.6437 - recall: 0.250 - ETA: 0s - loss: 1.2738 - accuracy: 0.5139 - precision: 0.6636 - recall: 0.246 - ETA: 0s - loss: 1.2864 - accuracy: 0.5227 - precision: 0.6639 - recall: 0.224 - ETA: 0s - loss: 1.2921 - accuracy: 0.5240 - precision: 0.6912 - recall: 0.226 - 0s 1ms/sample - loss: 1.3093 - accuracy: 0.5188 - precision: 0.6884 - recall: 0.2230 - val_loss: 1.5783 - val_accuracy: 0.4225 - val_precision: 0.6500 - val_recall: 0.1831\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3764 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.2367 - accuracy: 0.5208 - precision: 0.7045 - recall: 0.322 - ETA: 0s - loss: 1.2372 - accuracy: 0.5188 - precision: 0.7143 - recall: 0.312 - ETA: 0s - loss: 1.2135 - accuracy: 0.5402 - precision: 0.6832 - recall: 0.308 - ETA: 0s - loss: 1.2358 - accuracy: 0.5278 - precision: 0.6825 - recall: 0.298 - ETA: 0s - loss: 1.2737 - accuracy: 0.5114 - precision: 0.6438 - recall: 0.292 - ETA: 0s - loss: 1.2730 - accuracy: 0.5048 - precision: 0.6339 - recall: 0.278 - 0s 1ms/sample - loss: 1.2688 - accuracy: 0.5070 - precision: 0.6330 - recall: 0.2793 - val_loss: 1.5168 - val_accuracy: 0.4437 - val_precision: 0.6154 - val_recall: 0.2817\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1444 - accuracy: 0.6562 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.1681 - accuracy: 0.5729 - precision: 0.7368 - recall: 0.291 - ETA: 0s - loss: 1.1845 - accuracy: 0.5312 - precision: 0.7231 - recall: 0.293 - ETA: 0s - loss: 1.2072 - accuracy: 0.5625 - precision: 0.7174 - recall: 0.294 - ETA: 0s - loss: 1.2371 - accuracy: 0.5486 - precision: 0.7049 - recall: 0.298 - ETA: 0s - loss: 1.2318 - accuracy: 0.5568 - precision: 0.6959 - recall: 0.292 - ETA: 0s - loss: 1.2294 - accuracy: 0.5697 - precision: 0.7168 - recall: 0.298 - 1s 1ms/sample - loss: 1.2328 - accuracy: 0.5704 - precision: 0.7126 - recall: 0.2911 - val_loss: 1.4355 - val_accuracy: 0.4859 - val_precision: 0.6557 - val_recall: 0.2817\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0465 - accuracy: 0.6562 - precision: 0.8667 - recall: 0.406 - ETA: 0s - loss: 1.0571 - accuracy: 0.5938 - precision: 0.9000 - recall: 0.375 - ETA: 0s - loss: 1.0866 - accuracy: 0.6313 - precision: 0.8451 - recall: 0.375 - ETA: 0s - loss: 1.0760 - accuracy: 0.6384 - precision: 0.8447 - recall: 0.388 - ETA: 0s - loss: 1.0896 - accuracy: 0.6146 - precision: 0.8308 - recall: 0.375 - ETA: 0s - loss: 1.1380 - accuracy: 0.6051 - precision: 0.8041 - recall: 0.338 - ETA: 0s - loss: 1.1473 - accuracy: 0.5913 - precision: 0.7989 - recall: 0.334 - 1s 1ms/sample - loss: 1.1360 - accuracy: 0.5962 - precision: 0.8056 - recall: 0.3404 - val_loss: 1.3468 - val_accuracy: 0.5211 - val_precision: 0.7049 - val_recall: 0.3028\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.5625 - precision: 0.8750 - recall: 0.437 - ETA: 0s - loss: 1.0449 - accuracy: 0.6562 - precision: 0.8077 - recall: 0.437 - ETA: 0s - loss: 1.0655 - accuracy: 0.6375 - precision: 0.7640 - recall: 0.425 - ETA: 0s - loss: 1.0997 - accuracy: 0.6116 - precision: 0.7333 - recall: 0.392 - ETA: 0s - loss: 1.1196 - accuracy: 0.5903 - precision: 0.7226 - recall: 0.388 - ETA: 0s - loss: 1.1593 - accuracy: 0.5767 - precision: 0.7097 - recall: 0.375 - ETA: 0s - loss: 1.1643 - accuracy: 0.5673 - precision: 0.6927 - recall: 0.363 - 0s 1ms/sample - loss: 1.1666 - accuracy: 0.5610 - precision: 0.6941 - recall: 0.3568 - val_loss: 1.3069 - val_accuracy: 0.4859 - val_precision: 0.6290 - val_recall: 0.2746\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2145 - accuracy: 0.5625 - precision: 0.8462 - recall: 0.343 - ETA: 0s - loss: 1.2890 - accuracy: 0.5208 - precision: 0.6667 - recall: 0.270 - ETA: 0s - loss: 1.2294 - accuracy: 0.5500 - precision: 0.7206 - recall: 0.306 - ETA: 0s - loss: 1.2061 - accuracy: 0.5580 - precision: 0.7172 - recall: 0.317 - ETA: 0s - loss: 1.1793 - accuracy: 0.5590 - precision: 0.7231 - recall: 0.326 - ETA: 0s - loss: 1.1934 - accuracy: 0.5426 - precision: 0.7108 - recall: 0.335 - ETA: 0s - loss: 1.2067 - accuracy: 0.5216 - precision: 0.6768 - recall: 0.322 - 1s 1ms/sample - loss: 1.2105 - accuracy: 0.5235 - precision: 0.6814 - recall: 0.3263 - val_loss: 1.3580 - val_accuracy: 0.5070 - val_precision: 0.5556 - val_recall: 0.2817\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1089 - accuracy: 0.6250 - precision: 0.6667 - recall: 0.437 - ETA: 0s - loss: 1.2077 - accuracy: 0.5312 - precision: 0.6800 - recall: 0.354 - ETA: 0s - loss: 1.1047 - accuracy: 0.5938 - precision: 0.7614 - recall: 0.418 - ETA: 0s - loss: 1.1717 - accuracy: 0.5714 - precision: 0.7203 - recall: 0.379 - ETA: 0s - loss: 1.1472 - accuracy: 0.5625 - precision: 0.7379 - recall: 0.371 - ETA: 0s - loss: 1.1443 - accuracy: 0.5710 - precision: 0.7427 - recall: 0.360 - ETA: 0s - loss: 1.1607 - accuracy: 0.5577 - precision: 0.7268 - recall: 0.358 - 0s 1ms/sample - loss: 1.1536 - accuracy: 0.5610 - precision: 0.7299 - recall: 0.3615 - val_loss: 1.4562 - val_accuracy: 0.4648 - val_precision: 0.5873 - val_recall: 0.2606\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1327 - accuracy: 0.5625 - precision: 0.8182 - recall: 0.281 - ETA: 0s - loss: 1.0602 - accuracy: 0.6042 - precision: 0.8500 - recall: 0.354 - ETA: 0s - loss: 1.1046 - accuracy: 0.6062 - precision: 0.8154 - recall: 0.331 - ETA: 0s - loss: 1.0649 - accuracy: 0.6205 - precision: 0.8191 - recall: 0.343 - ETA: 0s - loss: 1.0888 - accuracy: 0.6215 - precision: 0.7812 - recall: 0.347 - ETA: 0s - loss: 1.0868 - accuracy: 0.6165 - precision: 0.7683 - recall: 0.358 - ETA: 0s - loss: 1.0919 - accuracy: 0.6202 - precision: 0.7665 - recall: 0.363 - 1s 1ms/sample - loss: 1.0930 - accuracy: 0.6197 - precision: 0.7598 - recall: 0.3638 - val_loss: 1.3275 - val_accuracy: 0.4859 - val_precision: 0.6567 - val_recall: 0.3099\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2866 - accuracy: 0.5938 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.2096 - accuracy: 0.5729 - precision: 0.7727 - recall: 0.354 - ETA: 0s - loss: 1.1573 - accuracy: 0.5688 - precision: 0.7237 - recall: 0.343 - ETA: 0s - loss: 1.1041 - accuracy: 0.5938 - precision: 0.7545 - recall: 0.370 - ETA: 0s - loss: 1.0794 - accuracy: 0.5868 - precision: 0.7589 - recall: 0.371 - ETA: 0s - loss: 1.1181 - accuracy: 0.5909 - precision: 0.7674 - recall: 0.375 - ETA: 0s - loss: 1.0822 - accuracy: 0.6178 - precision: 0.7861 - recall: 0.379 - 0s 1ms/sample - loss: 1.0793 - accuracy: 0.6197 - precision: 0.7864 - recall: 0.3803 - val_loss: 1.2448 - val_accuracy: 0.4930 - val_precision: 0.6667 - val_recall: 0.2676\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9849 - accuracy: 0.5312 - precision: 0.6000 - recall: 0.281 - ETA: 0s - loss: 1.2004 - accuracy: 0.4896 - precision: 0.5349 - recall: 0.239 - ETA: 0s - loss: 1.0528 - accuracy: 0.5938 - precision: 0.6579 - recall: 0.312 - ETA: 0s - loss: 1.0480 - accuracy: 0.5982 - precision: 0.6972 - recall: 0.339 - ETA: 0s - loss: 1.0552 - accuracy: 0.6042 - precision: 0.7171 - recall: 0.378 - ETA: 0s - loss: 1.0429 - accuracy: 0.6108 - precision: 0.7135 - recall: 0.389 - ETA: 0s - loss: 1.0324 - accuracy: 0.6082 - precision: 0.7325 - recall: 0.401 - 0s 1ms/sample - loss: 1.0287 - accuracy: 0.6127 - precision: 0.7371 - recall: 0.4014 - val_loss: 1.3109 - val_accuracy: 0.5211 - val_precision: 0.6250 - val_recall: 0.3169\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1525 - accuracy: 0.6250 - precision: 0.7857 - recall: 0.343 - ETA: 0s - loss: 0.9947 - accuracy: 0.5833 - precision: 0.7692 - recall: 0.416 - ETA: 0s - loss: 0.9529 - accuracy: 0.6313 - precision: 0.8276 - recall: 0.450 - ETA: 0s - loss: 0.9508 - accuracy: 0.6473 - precision: 0.8045 - recall: 0.477 - ETA: 0s - loss: 0.9978 - accuracy: 0.6250 - precision: 0.7692 - recall: 0.451 - ETA: 0s - loss: 0.9910 - accuracy: 0.6250 - precision: 0.7653 - recall: 0.463 - ETA: 0s - loss: 1.0432 - accuracy: 0.6130 - precision: 0.7440 - recall: 0.447 - 0s 1ms/sample - loss: 1.0611 - accuracy: 0.6080 - precision: 0.7422 - recall: 0.4460 - val_loss: 1.4989 - val_accuracy: 0.4859 - val_precision: 0.5600 - val_recall: 0.3944\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2410 - accuracy: 0.5625 - precision: 0.5714 - recall: 0.375 - ETA: 0s - loss: 1.1431 - accuracy: 0.6146 - precision: 0.6613 - recall: 0.427 - ETA: 0s - loss: 1.1563 - accuracy: 0.5688 - precision: 0.6373 - recall: 0.406 - ETA: 0s - loss: 1.1423 - accuracy: 0.5670 - precision: 0.6525 - recall: 0.410 - ETA: 0s - loss: 1.1691 - accuracy: 0.5590 - precision: 0.6517 - recall: 0.402 - ETA: 0s - loss: 1.1556 - accuracy: 0.5597 - precision: 0.6588 - recall: 0.394 - ETA: 0s - loss: 1.1327 - accuracy: 0.5601 - precision: 0.6805 - recall: 0.394 - 0s 1ms/sample - loss: 1.1348 - accuracy: 0.5610 - precision: 0.6802 - recall: 0.3944 - val_loss: 1.3551 - val_accuracy: 0.4930 - val_precision: 0.5696 - val_recall: 0.3169\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.7188 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 1.1029 - accuracy: 0.6771 - precision: 0.7500 - recall: 0.437 - ETA: 0s - loss: 1.1128 - accuracy: 0.6375 - precision: 0.7444 - recall: 0.418 - ETA: 0s - loss: 1.0954 - accuracy: 0.6205 - precision: 0.7422 - recall: 0.424 - ETA: 0s - loss: 1.1374 - accuracy: 0.6076 - precision: 0.7176 - recall: 0.423 - ETA: 0s - loss: 1.1387 - accuracy: 0.5938 - precision: 0.7150 - recall: 0.406 - ETA: 0s - loss: 1.1369 - accuracy: 0.5865 - precision: 0.6992 - recall: 0.396 - 0s 1ms/sample - loss: 1.1424 - accuracy: 0.5869 - precision: 0.7042 - recall: 0.3967 - val_loss: 1.3956 - val_accuracy: 0.4859 - val_precision: 0.6234 - val_recall: 0.3380\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2826 - accuracy: 0.5625 - precision: 0.6250 - recall: 0.468 - ETA: 0s - loss: 1.1161 - accuracy: 0.5729 - precision: 0.7049 - recall: 0.447 - ETA: 0s - loss: 1.2121 - accuracy: 0.5437 - precision: 0.6932 - recall: 0.381 - ETA: 0s - loss: 1.1782 - accuracy: 0.5804 - precision: 0.7167 - recall: 0.383 - ETA: 0s - loss: 1.1662 - accuracy: 0.5972 - precision: 0.7400 - recall: 0.385 - ETA: 0s - loss: 1.1960 - accuracy: 0.5710 - precision: 0.7074 - recall: 0.377 - ETA: 0s - loss: 1.2212 - accuracy: 0.5673 - precision: 0.7078 - recall: 0.372 - 0s 1ms/sample - loss: 1.2165 - accuracy: 0.5704 - precision: 0.7117 - recall: 0.3709 - val_loss: 1.3892 - val_accuracy: 0.4789 - val_precision: 0.5811 - val_recall: 0.3028\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2580 - accuracy: 0.4375 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.1934 - accuracy: 0.5312 - precision: 0.7447 - recall: 0.364 - ETA: 0s - loss: 1.1872 - accuracy: 0.5125 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 1.2509 - accuracy: 0.5000 - precision: 0.7048 - recall: 0.330 - ETA: 0s - loss: 1.2852 - accuracy: 0.5035 - precision: 0.6934 - recall: 0.329 - ETA: 0s - loss: 1.2407 - accuracy: 0.5341 - precision: 0.7251 - recall: 0.352 - ETA: 0s - loss: 1.2092 - accuracy: 0.5577 - precision: 0.7340 - recall: 0.358 - 0s 1ms/sample - loss: 1.2068 - accuracy: 0.5634 - precision: 0.7330 - recall: 0.3545 - val_loss: 1.3544 - val_accuracy: 0.4296 - val_precision: 0.6111 - val_recall: 0.2324\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0657 - accuracy: 0.5938 - precision: 1.0000 - recall: 0.406 - ETA: 0s - loss: 1.1151 - accuracy: 0.5938 - precision: 0.8095 - recall: 0.354 - ETA: 0s - loss: 1.0631 - accuracy: 0.6313 - precision: 0.7838 - recall: 0.362 - ETA: 0s - loss: 1.0382 - accuracy: 0.6607 - precision: 0.8036 - recall: 0.401 - ETA: 0s - loss: 1.0718 - accuracy: 0.6493 - precision: 0.7917 - recall: 0.395 - ETA: 0s - loss: 1.1108 - accuracy: 0.6307 - precision: 0.7829 - recall: 0.389 - ETA: 0s - loss: 1.1179 - accuracy: 0.6082 - precision: 0.7778 - recall: 0.387 - 0s 1ms/sample - loss: 1.1184 - accuracy: 0.6056 - precision: 0.7710 - recall: 0.3873 - val_loss: 1.2773 - val_accuracy: 0.4437 - val_precision: 0.6389 - val_recall: 0.3239\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1610 - accuracy: 0.5312 - precision: 0.8000 - recall: 0.500 - ETA: 0s - loss: 1.0273 - accuracy: 0.5938 - precision: 0.7963 - recall: 0.447 - ETA: 0s - loss: 1.0285 - accuracy: 0.6000 - precision: 0.8023 - recall: 0.431 - ETA: 0s - loss: 1.0439 - accuracy: 0.6116 - precision: 0.7903 - recall: 0.437 - ETA: 0s - loss: 1.0149 - accuracy: 0.6215 - precision: 0.8013 - recall: 0.434 - ETA: 0s - loss: 1.0563 - accuracy: 0.6222 - precision: 0.7906 - recall: 0.429 - ETA: 0s - loss: 1.0558 - accuracy: 0.6202 - precision: 0.7955 - recall: 0.420 - 0s 1ms/sample - loss: 1.0622 - accuracy: 0.6197 - precision: 0.7885 - recall: 0.4202 - val_loss: 1.2589 - val_accuracy: 0.4366 - val_precision: 0.6528 - val_recall: 0.3310\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1487 - accuracy: 0.6250 - precision: 0.6111 - recall: 0.343 - ETA: 0s - loss: 0.9607 - accuracy: 0.6979 - precision: 0.8235 - recall: 0.437 - ETA: 0s - loss: 0.9150 - accuracy: 0.7063 - precision: 0.8161 - recall: 0.443 - ETA: 0s - loss: 0.9330 - accuracy: 0.6964 - precision: 0.7907 - recall: 0.455 - ETA: 0s - loss: 0.9608 - accuracy: 0.6736 - precision: 0.7738 - recall: 0.451 - ETA: 0s - loss: 0.9694 - accuracy: 0.6619 - precision: 0.7816 - recall: 0.457 - ETA: 0s - loss: 0.9848 - accuracy: 0.6466 - precision: 0.7692 - recall: 0.456 - 0s 1ms/sample - loss: 0.9855 - accuracy: 0.6455 - precision: 0.7708 - recall: 0.4577 - val_loss: 1.1724 - val_accuracy: 0.5000 - val_precision: 0.6235 - val_recall: 0.3732\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9936 - accuracy: 0.6562 - precision: 0.7368 - recall: 0.437 - ETA: 0s - loss: 1.0609 - accuracy: 0.5521 - precision: 0.6721 - recall: 0.427 - ETA: 0s - loss: 1.0161 - accuracy: 0.5938 - precision: 0.7429 - recall: 0.487 - ETA: 0s - loss: 0.9599 - accuracy: 0.6518 - precision: 0.7632 - recall: 0.517 - ETA: 0s - loss: 0.9369 - accuracy: 0.6632 - precision: 0.7737 - recall: 0.510 - ETA: 0s - loss: 0.9220 - accuracy: 0.6733 - precision: 0.7806 - recall: 0.525 - ETA: 0s - loss: 0.9388 - accuracy: 0.6611 - precision: 0.7818 - recall: 0.516 - 0s 1ms/sample - loss: 0.9392 - accuracy: 0.6620 - precision: 0.7794 - recall: 0.5141 - val_loss: 1.1617 - val_accuracy: 0.5000 - val_precision: 0.6494 - val_recall: 0.3521\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.6562 - precision: 0.8421 - recall: 0.500 - ETA: 0s - loss: 0.9007 - accuracy: 0.6875 - precision: 0.8750 - recall: 0.510 - ETA: 0s - loss: 0.9247 - accuracy: 0.6375 - precision: 0.8409 - recall: 0.462 - ETA: 0s - loss: 0.9233 - accuracy: 0.6250 - precision: 0.8583 - recall: 0.459 - ETA: 0s - loss: 0.9302 - accuracy: 0.6354 - precision: 0.8506 - recall: 0.454 - ETA: 0s - loss: 0.8975 - accuracy: 0.6449 - precision: 0.8549 - recall: 0.468 - ETA: 0s - loss: 0.9055 - accuracy: 0.6466 - precision: 0.8419 - recall: 0.473 - 0s 1ms/sample - loss: 0.8994 - accuracy: 0.6479 - precision: 0.8430 - recall: 0.4789 - val_loss: 1.2089 - val_accuracy: 0.5000 - val_precision: 0.6835 - val_recall: 0.3803\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.6250 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 0.8353 - accuracy: 0.6562 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.8545 - accuracy: 0.6562 - precision: 0.8019 - recall: 0.531 - ETA: 0s - loss: 0.8621 - accuracy: 0.6607 - precision: 0.8151 - recall: 0.531 - ETA: 0s - loss: 0.8675 - accuracy: 0.6632 - precision: 0.8226 - recall: 0.531 - ETA: 0s - loss: 0.8788 - accuracy: 0.6562 - precision: 0.8243 - recall: 0.519 - ETA: 0s - loss: 0.8808 - accuracy: 0.6587 - precision: 0.8209 - recall: 0.528 - 1s 1ms/sample - loss: 0.8880 - accuracy: 0.6549 - precision: 0.8139 - recall: 0.5235 - val_loss: 1.0998 - val_accuracy: 0.5493 - val_precision: 0.6897 - val_recall: 0.4225\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7500 - precision: 0.7917 - recall: 0.593 - ETA: 0s - loss: 0.7443 - accuracy: 0.6875 - precision: 0.7746 - recall: 0.572 - ETA: 0s - loss: 0.7424 - accuracy: 0.7125 - precision: 0.7899 - recall: 0.587 - ETA: 0s - loss: 0.7554 - accuracy: 0.7143 - precision: 0.8110 - recall: 0.593 - ETA: 0s - loss: 0.8102 - accuracy: 0.6979 - precision: 0.8009 - recall: 0.586 - ETA: 0s - loss: 0.8381 - accuracy: 0.6790 - precision: 0.8000 - recall: 0.568 - ETA: 0s - loss: 0.8554 - accuracy: 0.6755 - precision: 0.7933 - recall: 0.572 - 0s 1ms/sample - loss: 0.8556 - accuracy: 0.6737 - precision: 0.7890 - recall: 0.5704 - val_loss: 1.1309 - val_accuracy: 0.5352 - val_precision: 0.6437 - val_recall: 0.3944\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.8125 - precision: 0.9130 - recall: 0.656 - ETA: 0s - loss: 0.7535 - accuracy: 0.7188 - precision: 0.8235 - recall: 0.583 - ETA: 0s - loss: 0.7824 - accuracy: 0.7250 - precision: 0.8407 - recall: 0.593 - ETA: 0s - loss: 0.8029 - accuracy: 0.7188 - precision: 0.8280 - recall: 0.580 - ETA: 0s - loss: 0.8166 - accuracy: 0.7222 - precision: 0.8218 - recall: 0.576 - ETA: 0s - loss: 0.8131 - accuracy: 0.7216 - precision: 0.8189 - recall: 0.565 - ETA: 0s - loss: 0.7995 - accuracy: 0.7236 - precision: 0.8262 - recall: 0.560 - 0s 1ms/sample - loss: 0.8089 - accuracy: 0.7207 - precision: 0.8213 - recall: 0.5610 - val_loss: 1.1165 - val_accuracy: 0.5282 - val_precision: 0.6630 - val_recall: 0.4296\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.7188 - precision: 0.9048 - recall: 0.593 - ETA: 0s - loss: 0.8568 - accuracy: 0.7083 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.8575 - accuracy: 0.6687 - precision: 0.8073 - recall: 0.550 - ETA: 0s - loss: 0.7897 - accuracy: 0.7054 - precision: 0.8221 - recall: 0.598 - ETA: 0s - loss: 0.8174 - accuracy: 0.6875 - precision: 0.8068 - recall: 0.579 - ETA: 0s - loss: 0.8026 - accuracy: 0.6960 - precision: 0.8147 - recall: 0.599 - ETA: 0s - loss: 0.7953 - accuracy: 0.6971 - precision: 0.8133 - recall: 0.586 - 0s 1ms/sample - loss: 0.8112 - accuracy: 0.6925 - precision: 0.8105 - recall: 0.5822 - val_loss: 1.1691 - val_accuracy: 0.5070 - val_precision: 0.6105 - val_recall: 0.4085\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8215 - accuracy: 0.6875 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.7691 - accuracy: 0.7083 - precision: 0.8382 - recall: 0.593 - ETA: 0s - loss: 0.8300 - accuracy: 0.6812 - precision: 0.8051 - recall: 0.593 - ETA: 0s - loss: 0.8302 - accuracy: 0.6830 - precision: 0.7746 - recall: 0.598 - ETA: 0s - loss: 0.7875 - accuracy: 0.7049 - precision: 0.8018 - recall: 0.618 - ETA: 0s - loss: 0.7809 - accuracy: 0.7074 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.7881 - accuracy: 0.7043 - precision: 0.7896 - recall: 0.622 - 1s 1ms/sample - loss: 0.7907 - accuracy: 0.7019 - precision: 0.7864 - recall: 0.6221 - val_loss: 1.1556 - val_accuracy: 0.5493 - val_precision: 0.5714 - val_recall: 0.4507\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7882 - accuracy: 0.7812 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.7611 - accuracy: 0.7188 - precision: 0.8219 - recall: 0.625 - ETA: 0s - loss: 0.7826 - accuracy: 0.6938 - precision: 0.8115 - recall: 0.618 - ETA: 0s - loss: 0.7896 - accuracy: 0.6830 - precision: 0.7953 - recall: 0.607 - ETA: 0s - loss: 0.8300 - accuracy: 0.6806 - precision: 0.7808 - recall: 0.593 - ETA: 0s - loss: 0.8408 - accuracy: 0.6903 - precision: 0.7770 - recall: 0.593 - ETA: 0s - loss: 0.8350 - accuracy: 0.6995 - precision: 0.7760 - recall: 0.591 - 0s 1ms/sample - loss: 0.8376 - accuracy: 0.6972 - precision: 0.7733 - recall: 0.5845 - val_loss: 1.8565 - val_accuracy: 0.4155 - val_precision: 0.4674 - val_recall: 0.3028\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2708 - accuracy: 0.5000 - precision: 0.6190 - recall: 0.406 - ETA: 0s - loss: 1.4856 - accuracy: 0.4792 - precision: 0.5873 - recall: 0.385 - ETA: 0s - loss: 1.5873 - accuracy: 0.4938 - precision: 0.5856 - recall: 0.406 - ETA: 0s - loss: 1.4887 - accuracy: 0.5402 - precision: 0.6266 - recall: 0.442 - ETA: 0s - loss: 1.3871 - accuracy: 0.5556 - precision: 0.6313 - recall: 0.434 - ETA: 0s - loss: 1.3197 - accuracy: 0.5540 - precision: 0.6265 - recall: 0.443 - ETA: 0s - loss: 1.2616 - accuracy: 0.5721 - precision: 0.6553 - recall: 0.461 - 0s 1ms/sample - loss: 1.2589 - accuracy: 0.5728 - precision: 0.6555 - recall: 0.4601 - val_loss: 1.4150 - val_accuracy: 0.5141 - val_precision: 0.5463 - val_recall: 0.4155\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.6875 - precision: 0.6818 - recall: 0.468 - ETA: 0s - loss: 1.0097 - accuracy: 0.6771 - precision: 0.7429 - recall: 0.541 - ETA: 0s - loss: 1.0622 - accuracy: 0.6125 - precision: 0.7321 - recall: 0.512 - ETA: 0s - loss: 0.9791 - accuracy: 0.6295 - precision: 0.7500 - recall: 0.535 - ETA: 0s - loss: 1.0103 - accuracy: 0.6285 - precision: 0.7366 - recall: 0.524 - ETA: 0s - loss: 1.0323 - accuracy: 0.6193 - precision: 0.7375 - recall: 0.502 - ETA: 0s - loss: 1.0149 - accuracy: 0.6274 - precision: 0.7500 - recall: 0.490 - 0s 1ms/sample - loss: 1.0183 - accuracy: 0.6291 - precision: 0.7455 - recall: 0.4883 - val_loss: 1.1062 - val_accuracy: 0.5423 - val_precision: 0.6341 - val_recall: 0.3662\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0148 - accuracy: 0.7188 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 1.0913 - accuracy: 0.5938 - precision: 0.8163 - recall: 0.416 - ETA: 0s - loss: 1.0255 - accuracy: 0.6125 - precision: 0.8022 - recall: 0.456 - ETA: 0s - loss: 1.0013 - accuracy: 0.6161 - precision: 0.7863 - recall: 0.459 - ETA: 0s - loss: 0.9791 - accuracy: 0.6285 - precision: 0.7719 - recall: 0.458 - ETA: 0s - loss: 0.9584 - accuracy: 0.6392 - precision: 0.7840 - recall: 0.474 - ETA: 0s - loss: 0.9299 - accuracy: 0.6562 - precision: 0.7946 - recall: 0.492 - 0s 1ms/sample - loss: 0.9284 - accuracy: 0.6549 - precision: 0.7903 - recall: 0.4953 - val_loss: 1.1319 - val_accuracy: 0.5000 - val_precision: 0.6087 - val_recall: 0.3944\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.7188 - precision: 0.8095 - recall: 0.531 - ETA: 0s - loss: 0.8492 - accuracy: 0.6562 - precision: 0.8125 - recall: 0.541 - ETA: 0s - loss: 0.8155 - accuracy: 0.6938 - precision: 0.8142 - recall: 0.575 - ETA: 0s - loss: 0.8003 - accuracy: 0.7098 - precision: 0.8323 - recall: 0.598 - ETA: 0s - loss: 0.8008 - accuracy: 0.6979 - precision: 0.8048 - recall: 0.586 - ETA: 0s - loss: 0.8325 - accuracy: 0.6790 - precision: 0.7960 - recall: 0.565 - ETA: 0s - loss: 0.8424 - accuracy: 0.6827 - precision: 0.7926 - recall: 0.569 - 0s 1ms/sample - loss: 0.8517 - accuracy: 0.6808 - precision: 0.7928 - recall: 0.5657 - val_loss: 1.2471 - val_accuracy: 0.4577 - val_precision: 0.5474 - val_recall: 0.3662\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9633 - accuracy: 0.6875 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.9407 - accuracy: 0.6458 - precision: 0.7361 - recall: 0.552 - ETA: 0s - loss: 0.8433 - accuracy: 0.6687 - precision: 0.7647 - recall: 0.568 - ETA: 0s - loss: 0.8088 - accuracy: 0.6741 - precision: 0.7744 - recall: 0.567 - ETA: 0s - loss: 0.8210 - accuracy: 0.6736 - precision: 0.7725 - recall: 0.566 - ETA: 0s - loss: 0.8067 - accuracy: 0.6733 - precision: 0.7717 - recall: 0.556 - ETA: 0s - loss: 0.7956 - accuracy: 0.6827 - precision: 0.7862 - recall: 0.574 - 0s 1ms/sample - loss: 0.7909 - accuracy: 0.6878 - precision: 0.7896 - recall: 0.5728 - val_loss: 1.1814 - val_accuracy: 0.5211 - val_precision: 0.6139 - val_recall: 0.4366\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8496 - accuracy: 0.7500 - precision: 0.7917 - recall: 0.593 - ETA: 0s - loss: 0.8878 - accuracy: 0.6354 - precision: 0.7286 - recall: 0.531 - ETA: 0s - loss: 0.8200 - accuracy: 0.6812 - precision: 0.7769 - recall: 0.587 - ETA: 0s - loss: 0.7884 - accuracy: 0.7054 - precision: 0.7976 - recall: 0.598 - ETA: 0s - loss: 0.7591 - accuracy: 0.7118 - precision: 0.8056 - recall: 0.604 - ETA: 0s - loss: 0.7515 - accuracy: 0.7159 - precision: 0.8140 - recall: 0.596 - ETA: 0s - loss: 0.7479 - accuracy: 0.7115 - precision: 0.8078 - recall: 0.596 - 1s 1ms/sample - loss: 0.7421 - accuracy: 0.7160 - precision: 0.8095 - recall: 0.5986 - val_loss: 1.2092 - val_accuracy: 0.5070 - val_precision: 0.6078 - val_recall: 0.4366\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.6562 - precision: 0.8125 - recall: 0.406 - ETA: 0s - loss: 0.7686 - accuracy: 0.7344 - precision: 0.8333 - recall: 0.546 - ETA: 0s - loss: 0.7301 - accuracy: 0.7344 - precision: 0.8043 - recall: 0.578 - ETA: 0s - loss: 0.7083 - accuracy: 0.7375 - precision: 0.8190 - recall: 0.593 - ETA: 0s - loss: 0.7817 - accuracy: 0.7188 - precision: 0.7892 - recall: 0.584 - ETA: 0s - loss: 0.7697 - accuracy: 0.7188 - precision: 0.8042 - recall: 0.593 - ETA: 0s - loss: 0.8019 - accuracy: 0.6969 - precision: 0.7966 - recall: 0.587 - ETA: 0s - loss: 0.8047 - accuracy: 0.6927 - precision: 0.7923 - recall: 0.585 - 1s 2ms/sample - loss: 0.7791 - accuracy: 0.7019 - precision: 0.7957 - recall: 0.6033 - val_loss: 1.1054 - val_accuracy: 0.5845 - val_precision: 0.6698 - val_recall: 0.5000\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9455 - accuracy: 0.5625 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.8355 - accuracy: 0.6875 - precision: 0.8028 - recall: 0.593 - ETA: 0s - loss: 0.7740 - accuracy: 0.7125 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.7396 - accuracy: 0.7098 - precision: 0.7955 - recall: 0.625 - ETA: 0s - loss: 0.7426 - accuracy: 0.7083 - precision: 0.7911 - recall: 0.618 - ETA: 0s - loss: 0.7206 - accuracy: 0.7102 - precision: 0.8043 - recall: 0.630 - ETA: 0s - loss: 0.7275 - accuracy: 0.7115 - precision: 0.8006 - recall: 0.627 - 1s 1ms/sample - loss: 0.7258 - accuracy: 0.7113 - precision: 0.8000 - recall: 0.6291 - val_loss: 1.2544 - val_accuracy: 0.5141 - val_precision: 0.5545 - val_recall: 0.4296\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.6875 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.6536 - accuracy: 0.7292 - precision: 0.8158 - recall: 0.645 - ETA: 0s - loss: 0.7626 - accuracy: 0.7125 - precision: 0.8000 - recall: 0.650 - ETA: 0s - loss: 0.7017 - accuracy: 0.7321 - precision: 0.8066 - recall: 0.651 - ETA: 0s - loss: 0.6939 - accuracy: 0.7361 - precision: 0.8122 - recall: 0.645 - ETA: 0s - loss: 0.7028 - accuracy: 0.7301 - precision: 0.8058 - recall: 0.636 - ETA: 0s - loss: 0.6893 - accuracy: 0.7404 - precision: 0.8084 - recall: 0.649 - 1s 1ms/sample - loss: 0.6924 - accuracy: 0.7371 - precision: 0.8047 - recall: 0.6479 - val_loss: 1.0653 - val_accuracy: 0.5986 - val_precision: 0.6068 - val_recall: 0.5000\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7254 - accuracy: 0.6875 - precision: 0.7407 - recall: 0.625 - ETA: 0s - loss: 0.6039 - accuracy: 0.7604 - precision: 0.8235 - recall: 0.729 - ETA: 0s - loss: 0.6350 - accuracy: 0.7500 - precision: 0.8102 - recall: 0.693 - ETA: 0s - loss: 0.6582 - accuracy: 0.7500 - precision: 0.8095 - recall: 0.683 - ETA: 0s - loss: 0.6985 - accuracy: 0.7292 - precision: 0.7901 - recall: 0.666 - ETA: 0s - loss: 0.6830 - accuracy: 0.7301 - precision: 0.7898 - recall: 0.661 - ETA: 0s - loss: 0.7119 - accuracy: 0.7188 - precision: 0.7826 - recall: 0.649 - 0s 1ms/sample - loss: 0.7094 - accuracy: 0.7183 - precision: 0.7847 - recall: 0.6502 - val_loss: 1.2104 - val_accuracy: 0.5563 - val_precision: 0.6140 - val_recall: 0.4930\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7500 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6892 - accuracy: 0.7083 - precision: 0.8194 - recall: 0.614 - ETA: 0s - loss: 0.7018 - accuracy: 0.7250 - precision: 0.8175 - recall: 0.643 - ETA: 0s - loss: 0.7707 - accuracy: 0.6830 - precision: 0.7765 - recall: 0.589 - ETA: 0s - loss: 0.7242 - accuracy: 0.7118 - precision: 0.8054 - recall: 0.618 - ETA: 0s - loss: 0.7245 - accuracy: 0.7216 - precision: 0.8081 - recall: 0.622 - ETA: 0s - loss: 0.7472 - accuracy: 0.7139 - precision: 0.7956 - recall: 0.608 - 1s 1ms/sample - loss: 0.7449 - accuracy: 0.7160 - precision: 0.7975 - recall: 0.6103 - val_loss: 1.1572 - val_accuracy: 0.5775 - val_precision: 0.6250 - val_recall: 0.4225\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8570 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.7644 - accuracy: 0.6979 - precision: 0.7632 - recall: 0.604 - ETA: 0s - loss: 0.7222 - accuracy: 0.7125 - precision: 0.7953 - recall: 0.631 - ETA: 0s - loss: 0.7124 - accuracy: 0.7321 - precision: 0.8103 - recall: 0.629 - ETA: 0s - loss: 0.7137 - accuracy: 0.7326 - precision: 0.8089 - recall: 0.631 - ETA: 0s - loss: 0.7384 - accuracy: 0.7159 - precision: 0.7978 - recall: 0.605 - ETA: 0s - loss: 0.7365 - accuracy: 0.7212 - precision: 0.7994 - recall: 0.613 - 0s 1ms/sample - loss: 0.7353 - accuracy: 0.7230 - precision: 0.8000 - recall: 0.6103 - val_loss: 1.2065 - val_accuracy: 0.5070 - val_precision: 0.6040 - val_recall: 0.4296\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8438 - precision: 0.8800 - recall: 0.687 - ETA: 0s - loss: 0.7235 - accuracy: 0.7188 - precision: 0.7595 - recall: 0.625 - ETA: 0s - loss: 0.7787 - accuracy: 0.6938 - precision: 0.7519 - recall: 0.606 - ETA: 0s - loss: 0.8005 - accuracy: 0.6786 - precision: 0.7528 - recall: 0.598 - ETA: 0s - loss: 0.7574 - accuracy: 0.7049 - precision: 0.7817 - recall: 0.621 - ETA: 0s - loss: 0.7744 - accuracy: 0.6989 - precision: 0.7690 - recall: 0.605 - ETA: 0s - loss: 0.8022 - accuracy: 0.6971 - precision: 0.7803 - recall: 0.588 - 1s 1ms/sample - loss: 0.7988 - accuracy: 0.6948 - precision: 0.7795 - recall: 0.5892 - val_loss: 1.0557 - val_accuracy: 0.6056 - val_precision: 0.6952 - val_recall: 0.5141\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7812 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.6146 - accuracy: 0.7812 - precision: 0.8182 - recall: 0.703 - ETA: 0s - loss: 0.6556 - accuracy: 0.7422 - precision: 0.7890 - recall: 0.671 - ETA: 0s - loss: 0.6428 - accuracy: 0.7656 - precision: 0.8062 - recall: 0.671 - ETA: 0s - loss: 0.6423 - accuracy: 0.7578 - precision: 0.8230 - recall: 0.671 - ETA: 0s - loss: 0.6472 - accuracy: 0.7563 - precision: 0.8327 - recall: 0.684 - ETA: 0s - loss: 0.6704 - accuracy: 0.7500 - precision: 0.8217 - recall: 0.671 - 0s 1ms/sample - loss: 0.7013 - accuracy: 0.7394 - precision: 0.8081 - recall: 0.6526 - val_loss: 1.0950 - val_accuracy: 0.5845 - val_precision: 0.6316 - val_recall: 0.5070\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7619 - accuracy: 0.7812 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.6296 - accuracy: 0.8021 - precision: 0.8701 - recall: 0.697 - ETA: 0s - loss: 0.6873 - accuracy: 0.7750 - precision: 0.8372 - recall: 0.675 - ETA: 0s - loss: 0.6722 - accuracy: 0.7679 - precision: 0.8555 - recall: 0.660 - ETA: 0s - loss: 0.7238 - accuracy: 0.7431 - precision: 0.8378 - recall: 0.645 - ETA: 0s - loss: 0.7636 - accuracy: 0.7301 - precision: 0.8246 - recall: 0.627 - ETA: 0s - loss: 0.7673 - accuracy: 0.7332 - precision: 0.8170 - recall: 0.622 - 1s 1ms/sample - loss: 0.7718 - accuracy: 0.7300 - precision: 0.8148 - recall: 0.6197 - val_loss: 1.1195 - val_accuracy: 0.6197 - val_precision: 0.6733 - val_recall: 0.4789\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9133 - accuracy: 0.6875 - precision: 0.7500 - recall: 0.562 - ETA: 0s - loss: 0.9320 - accuracy: 0.6667 - precision: 0.7969 - recall: 0.531 - ETA: 0s - loss: 0.8692 - accuracy: 0.6875 - precision: 0.8000 - recall: 0.575 - ETA: 0s - loss: 0.9159 - accuracy: 0.6652 - precision: 0.7862 - recall: 0.558 - ETA: 0s - loss: 0.9186 - accuracy: 0.6736 - precision: 0.7921 - recall: 0.555 - ETA: 0s - loss: 0.9393 - accuracy: 0.6676 - precision: 0.7805 - recall: 0.545 - ETA: 0s - loss: 0.9765 - accuracy: 0.6514 - precision: 0.7569 - recall: 0.524 - 0s 1ms/sample - loss: 0.9704 - accuracy: 0.6549 - precision: 0.7619 - recall: 0.5258 - val_loss: 1.4127 - val_accuracy: 0.4789 - val_precision: 0.5542 - val_recall: 0.3239\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.6250 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 1.1296 - accuracy: 0.6146 - precision: 0.7460 - recall: 0.489 - ETA: 0s - loss: 1.0436 - accuracy: 0.6000 - precision: 0.7222 - recall: 0.487 - ETA: 0s - loss: 1.0289 - accuracy: 0.6071 - precision: 0.7320 - recall: 0.500 - ETA: 0s - loss: 1.0345 - accuracy: 0.5938 - precision: 0.7421 - recall: 0.489 - ETA: 0s - loss: 1.0176 - accuracy: 0.6108 - precision: 0.7542 - recall: 0.505 - ETA: 0s - loss: 1.0244 - accuracy: 0.6154 - precision: 0.7737 - recall: 0.509 - 0s 1ms/sample - loss: 1.0123 - accuracy: 0.6221 - precision: 0.7801 - recall: 0.5164 - val_loss: 1.1695 - val_accuracy: 0.5493 - val_precision: 0.6211 - val_recall: 0.4155\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.7188 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.8467 - accuracy: 0.7083 - precision: 0.8485 - recall: 0.583 - ETA: 0s - loss: 0.8478 - accuracy: 0.6875 - precision: 0.7982 - recall: 0.568 - ETA: 0s - loss: 0.8330 - accuracy: 0.6875 - precision: 0.8026 - recall: 0.544 - ETA: 0s - loss: 0.8773 - accuracy: 0.6736 - precision: 0.7846 - recall: 0.531 - ETA: 0s - loss: 0.8612 - accuracy: 0.6903 - precision: 0.8091 - recall: 0.554 - ETA: 0s - loss: 0.8601 - accuracy: 0.6851 - precision: 0.7944 - recall: 0.548 - 1s 1ms/sample - loss: 0.8543 - accuracy: 0.6925 - precision: 0.7993 - recall: 0.5516 - val_loss: 1.1470 - val_accuracy: 0.6268 - val_precision: 0.6733 - val_recall: 0.4789\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9901 - accuracy: 0.5938 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.8129 - accuracy: 0.7083 - precision: 0.8116 - recall: 0.583 - ETA: 0s - loss: 0.8340 - accuracy: 0.7000 - precision: 0.7627 - recall: 0.562 - ETA: 0s - loss: 0.8166 - accuracy: 0.6964 - precision: 0.7730 - recall: 0.562 - ETA: 0s - loss: 0.8449 - accuracy: 0.6910 - precision: 0.7523 - recall: 0.559 - ETA: 0s - loss: 0.8591 - accuracy: 0.6847 - precision: 0.7472 - recall: 0.562 - ETA: 0s - loss: 0.8127 - accuracy: 0.6995 - precision: 0.7664 - recall: 0.591 - 0s 1ms/sample - loss: 0.8228 - accuracy: 0.6972 - precision: 0.7652 - recall: 0.5892 - val_loss: 1.0836 - val_accuracy: 0.6127 - val_precision: 0.6303 - val_recall: 0.5282\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.7812 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.7247 - accuracy: 0.7188 - precision: 0.7922 - recall: 0.635 - ETA: 0s - loss: 0.6517 - accuracy: 0.7688 - precision: 0.8209 - recall: 0.687 - ETA: 0s - loss: 0.6596 - accuracy: 0.7723 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6810 - accuracy: 0.7535 - precision: 0.7901 - recall: 0.666 - ETA: 0s - loss: 0.6946 - accuracy: 0.7528 - precision: 0.7872 - recall: 0.661 - ETA: 0s - loss: 0.7486 - accuracy: 0.7188 - precision: 0.7616 - recall: 0.629 - 1s 1ms/sample - loss: 0.7475 - accuracy: 0.7183 - precision: 0.7642 - recall: 0.6315 - val_loss: 1.0997 - val_accuracy: 0.6127 - val_precision: 0.6281 - val_recall: 0.5352\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.7500 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.7081 - accuracy: 0.7500 - precision: 0.8171 - recall: 0.697 - ETA: 0s - loss: 0.6742 - accuracy: 0.7812 - precision: 0.8296 - recall: 0.700 - ETA: 0s - loss: 0.6656 - accuracy: 0.7679 - precision: 0.8229 - recall: 0.705 - ETA: 0s - loss: 0.6858 - accuracy: 0.7569 - precision: 0.8112 - recall: 0.701 - ETA: 0s - loss: 0.6670 - accuracy: 0.7614 - precision: 0.8173 - recall: 0.698 - ETA: 0s - loss: 0.6742 - accuracy: 0.7524 - precision: 0.8208 - recall: 0.682 - 0s 1ms/sample - loss: 0.6798 - accuracy: 0.7488 - precision: 0.8187 - recall: 0.6784 - val_loss: 1.0830 - val_accuracy: 0.6127 - val_precision: 0.6496 - val_recall: 0.5352\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.8125 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.7220 - accuracy: 0.7708 - precision: 0.8049 - recall: 0.687 - ETA: 0s - loss: 0.6517 - accuracy: 0.7875 - precision: 0.8201 - recall: 0.712 - ETA: 0s - loss: 0.6575 - accuracy: 0.7723 - precision: 0.8103 - recall: 0.705 - ETA: 0s - loss: 0.6551 - accuracy: 0.7812 - precision: 0.8127 - recall: 0.708 - ETA: 0s - loss: 0.6499 - accuracy: 0.7812 - precision: 0.8146 - recall: 0.698 - ETA: 0s - loss: 0.6731 - accuracy: 0.7668 - precision: 0.8056 - recall: 0.687 - 1s 1ms/sample - loss: 0.6702 - accuracy: 0.7676 - precision: 0.8049 - recall: 0.6878 - val_loss: 1.1607 - val_accuracy: 0.6056 - val_precision: 0.6033 - val_recall: 0.5141\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.6875 - precision: 0.7500 - recall: 0.656 - ETA: 0s - loss: 0.6278 - accuracy: 0.7708 - precision: 0.8049 - recall: 0.687 - ETA: 0s - loss: 0.6426 - accuracy: 0.7312 - precision: 0.7721 - recall: 0.656 - ETA: 0s - loss: 0.6329 - accuracy: 0.7321 - precision: 0.7884 - recall: 0.665 - ETA: 0s - loss: 0.6362 - accuracy: 0.7326 - precision: 0.8075 - recall: 0.670 - ETA: 0s - loss: 0.6571 - accuracy: 0.7273 - precision: 0.8007 - recall: 0.661 - ETA: 0s - loss: 0.7037 - accuracy: 0.7212 - precision: 0.7901 - recall: 0.651 - 0s 1ms/sample - loss: 0.7088 - accuracy: 0.7207 - precision: 0.7920 - recall: 0.6526 - val_loss: 1.2534 - val_accuracy: 0.5282 - val_precision: 0.5818 - val_recall: 0.4507\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.8034 - accuracy: 0.7292 - precision: 0.7949 - recall: 0.645 - ETA: 0s - loss: 0.7788 - accuracy: 0.7188 - precision: 0.7863 - recall: 0.643 - ETA: 0s - loss: 0.7521 - accuracy: 0.7321 - precision: 0.7944 - recall: 0.638 - ETA: 0s - loss: 0.7255 - accuracy: 0.7292 - precision: 0.8072 - recall: 0.625 - ETA: 0s - loss: 0.7364 - accuracy: 0.7188 - precision: 0.7985 - recall: 0.619 - ETA: 0s - loss: 0.7089 - accuracy: 0.7332 - precision: 0.8156 - recall: 0.627 - 0s 1ms/sample - loss: 0.7119 - accuracy: 0.7277 - precision: 0.8160 - recall: 0.6244 - val_loss: 1.0510 - val_accuracy: 0.6268 - val_precision: 0.7473 - val_recall: 0.4789\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7500 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.5757 - accuracy: 0.8021 - precision: 0.9200 - recall: 0.718 - ETA: 0s - loss: 0.6087 - accuracy: 0.7937 - precision: 0.9016 - recall: 0.687 - ETA: 0s - loss: 0.6245 - accuracy: 0.7902 - precision: 0.8909 - recall: 0.656 - ETA: 0s - loss: 0.6291 - accuracy: 0.7847 - precision: 0.8738 - recall: 0.649 - ETA: 0s - loss: 0.6375 - accuracy: 0.7784 - precision: 0.8664 - recall: 0.644 - ETA: 0s - loss: 0.6401 - accuracy: 0.7716 - precision: 0.8549 - recall: 0.651 - 0s 1ms/sample - loss: 0.6463 - accuracy: 0.7653 - precision: 0.8514 - recall: 0.6455 - val_loss: 1.0518 - val_accuracy: 0.6127 - val_precision: 0.6786 - val_recall: 0.5352\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.7500 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.5972 - accuracy: 0.7812 - precision: 0.8333 - recall: 0.729 - ETA: 0s - loss: 0.5388 - accuracy: 0.8188 - precision: 0.8705 - recall: 0.756 - ETA: 0s - loss: 0.5880 - accuracy: 0.7857 - precision: 0.8394 - recall: 0.723 - ETA: 0s - loss: 0.6050 - accuracy: 0.7778 - precision: 0.8320 - recall: 0.722 - ETA: 0s - loss: 0.6273 - accuracy: 0.7699 - precision: 0.8378 - recall: 0.704 - ETA: 0s - loss: 0.6151 - accuracy: 0.7692 - precision: 0.8348 - recall: 0.704 - 0s 1ms/sample - loss: 0.6135 - accuracy: 0.7723 - precision: 0.8375 - recall: 0.7019 - val_loss: 1.1091 - val_accuracy: 0.5634 - val_precision: 0.6186 - val_recall: 0.5141\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8438 - precision: 0.9565 - recall: 0.687 - ETA: 0s - loss: 0.5629 - accuracy: 0.8125 - precision: 0.8919 - recall: 0.687 - ETA: 0s - loss: 0.5520 - accuracy: 0.7937 - precision: 0.8702 - recall: 0.712 - ETA: 0s - loss: 0.5665 - accuracy: 0.7946 - precision: 0.8587 - recall: 0.705 - ETA: 0s - loss: 0.6096 - accuracy: 0.7708 - precision: 0.8285 - recall: 0.687 - ETA: 0s - loss: 0.6141 - accuracy: 0.7642 - precision: 0.8339 - recall: 0.684 - ETA: 0s - loss: 0.6371 - accuracy: 0.7596 - precision: 0.8222 - recall: 0.677 - 0s 1ms/sample - loss: 0.6380 - accuracy: 0.7582 - precision: 0.8234 - recall: 0.6784 - val_loss: 1.1181 - val_accuracy: 0.6056 - val_precision: 0.6667 - val_recall: 0.5211\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6403 - accuracy: 0.7812 - precision: 0.9091 - recall: 0.625 - ETA: 0s - loss: 0.6346 - accuracy: 0.8021 - precision: 0.8553 - recall: 0.677 - ETA: 0s - loss: 0.6520 - accuracy: 0.7688 - precision: 0.8189 - recall: 0.650 - ETA: 0s - loss: 0.6236 - accuracy: 0.7679 - precision: 0.8216 - recall: 0.678 - ETA: 0s - loss: 0.6271 - accuracy: 0.7743 - precision: 0.8362 - recall: 0.673 - ETA: 0s - loss: 0.6197 - accuracy: 0.7756 - precision: 0.8299 - recall: 0.693 - ETA: 0s - loss: 0.6313 - accuracy: 0.7764 - precision: 0.8319 - recall: 0.701 - 0s 1ms/sample - loss: 0.6255 - accuracy: 0.7793 - precision: 0.8357 - recall: 0.7042 - val_loss: 1.0804 - val_accuracy: 0.6056 - val_precision: 0.6404 - val_recall: 0.5141\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.7188 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.6186 - accuracy: 0.7604 - precision: 0.8101 - recall: 0.666 - ETA: 0s - loss: 0.6338 - accuracy: 0.7688 - precision: 0.8154 - recall: 0.662 - ETA: 0s - loss: 0.5968 - accuracy: 0.7768 - precision: 0.8263 - recall: 0.700 - ETA: 0s - loss: 0.6160 - accuracy: 0.7778 - precision: 0.8200 - recall: 0.711 - ETA: 0s - loss: 0.6142 - accuracy: 0.7841 - precision: 0.8306 - recall: 0.724 - ETA: 0s - loss: 0.6565 - accuracy: 0.7572 - precision: 0.8066 - recall: 0.701 - 0s 1ms/sample - loss: 0.6569 - accuracy: 0.7559 - precision: 0.8071 - recall: 0.6972 - val_loss: 1.1246 - val_accuracy: 0.6268 - val_precision: 0.6864 - val_recall: 0.5704\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7543 - accuracy: 0.6562 - precision: 0.8333 - recall: 0.625 - ETA: 0s - loss: 0.5486 - accuracy: 0.7917 - precision: 0.8659 - recall: 0.739 - ETA: 0s - loss: 0.6201 - accuracy: 0.7563 - precision: 0.8188 - recall: 0.706 - ETA: 0s - loss: 0.6321 - accuracy: 0.7545 - precision: 0.8115 - recall: 0.692 - ETA: 0s - loss: 0.6754 - accuracy: 0.7500 - precision: 0.7984 - recall: 0.673 - ETA: 0s - loss: 0.7134 - accuracy: 0.7386 - precision: 0.7864 - recall: 0.659 - ETA: 0s - loss: 0.7533 - accuracy: 0.7260 - precision: 0.7705 - recall: 0.653 - 0s 1ms/sample - loss: 0.7437 - accuracy: 0.7324 - precision: 0.7756 - recall: 0.6573 - val_loss: 1.0102 - val_accuracy: 0.6268 - val_precision: 0.6780 - val_recall: 0.5634\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6961 - accuracy: 0.7292 - precision: 0.7765 - recall: 0.687 - ETA: 0s - loss: 0.6799 - accuracy: 0.7000 - precision: 0.7660 - recall: 0.675 - ETA: 0s - loss: 0.6580 - accuracy: 0.7277 - precision: 0.7835 - recall: 0.678 - ETA: 0s - loss: 0.6704 - accuracy: 0.7257 - precision: 0.7886 - recall: 0.673 - ETA: 0s - loss: 0.6778 - accuracy: 0.7188 - precision: 0.7759 - recall: 0.659 - ETA: 0s - loss: 0.6644 - accuracy: 0.7284 - precision: 0.7863 - recall: 0.663 - 0s 1ms/sample - loss: 0.6657 - accuracy: 0.7277 - precision: 0.7855 - recall: 0.6620 - val_loss: 1.3014 - val_accuracy: 0.5704 - val_precision: 0.6148 - val_recall: 0.5282\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.8125 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.9043 - accuracy: 0.6354 - precision: 0.6707 - recall: 0.572 - ETA: 0s - loss: 0.8756 - accuracy: 0.6438 - precision: 0.6716 - recall: 0.562 - ETA: 0s - loss: 0.8674 - accuracy: 0.6473 - precision: 0.6848 - recall: 0.562 - ETA: 0s - loss: 0.8502 - accuracy: 0.6632 - precision: 0.7143 - recall: 0.590 - ETA: 0s - loss: 0.8238 - accuracy: 0.6733 - precision: 0.7345 - recall: 0.605 - ETA: 0s - loss: 0.8469 - accuracy: 0.6707 - precision: 0.7367 - recall: 0.598 - 1s 1ms/sample - loss: 0.8463 - accuracy: 0.6714 - precision: 0.7349 - recall: 0.5986 - val_loss: 1.0030 - val_accuracy: 0.6620 - val_precision: 0.6606 - val_recall: 0.5070\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.6562 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.5812 - accuracy: 0.7500 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 0.6166 - accuracy: 0.7375 - precision: 0.8443 - recall: 0.643 - ETA: 0s - loss: 0.7467 - accuracy: 0.7098 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.8088 - accuracy: 0.6944 - precision: 0.7822 - recall: 0.611 - ETA: 0s - loss: 0.7781 - accuracy: 0.7074 - precision: 0.8015 - recall: 0.619 - ETA: 0s - loss: 0.7871 - accuracy: 0.6971 - precision: 0.7913 - recall: 0.610 - 0s 1ms/sample - loss: 0.7870 - accuracy: 0.6972 - precision: 0.7909 - recall: 0.6127 - val_loss: 1.1283 - val_accuracy: 0.6197 - val_precision: 0.6696 - val_recall: 0.5282\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.9171 - accuracy: 0.6562 - precision: 0.6667 - recall: 0.500 - ETA: 0s - loss: 0.7520 - accuracy: 0.7500 - precision: 0.7922 - recall: 0.635 - ETA: 0s - loss: 0.7274 - accuracy: 0.7375 - precision: 0.8031 - recall: 0.637 - ETA: 0s - loss: 0.7468 - accuracy: 0.7277 - precision: 0.7857 - recall: 0.638 - ETA: 0s - loss: 0.7323 - accuracy: 0.7500 - precision: 0.8018 - recall: 0.631 - ETA: 0s - loss: 0.7073 - accuracy: 0.7528 - precision: 0.8129 - recall: 0.642 - ETA: 0s - loss: 0.6847 - accuracy: 0.7524 - precision: 0.8221 - recall: 0.644 - 0s 1ms/sample - loss: 0.6788 - accuracy: 0.7559 - precision: 0.8263 - recall: 0.6479 - val_loss: 1.1064 - val_accuracy: 0.5986 - val_precision: 0.6636 - val_recall: 0.5141\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8438 - precision: 0.9200 - recall: 0.718 - ETA: 0s - loss: 0.5343 - accuracy: 0.8542 - precision: 0.9241 - recall: 0.760 - ETA: 0s - loss: 0.6042 - accuracy: 0.8000 - precision: 0.8661 - recall: 0.687 - ETA: 0s - loss: 0.6069 - accuracy: 0.7857 - precision: 0.8556 - recall: 0.687 - ETA: 0s - loss: 0.6291 - accuracy: 0.7743 - precision: 0.8398 - recall: 0.673 - ETA: 0s - loss: 0.6148 - accuracy: 0.7784 - precision: 0.8445 - recall: 0.679 - ETA: 0s - loss: 0.6025 - accuracy: 0.7764 - precision: 0.8520 - recall: 0.677 - 1s 1ms/sample - loss: 0.5968 - accuracy: 0.7793 - precision: 0.8529 - recall: 0.6808 - val_loss: 1.1577 - val_accuracy: 0.5915 - val_precision: 0.6422 - val_recall: 0.4930\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0240 - accuracy: 0.6875 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.7056 - accuracy: 0.8021 - precision: 0.8375 - recall: 0.697 - ETA: 0s - loss: 0.6090 - accuracy: 0.8250 - precision: 0.8667 - recall: 0.731 - ETA: 0s - loss: 0.6086 - accuracy: 0.8214 - precision: 0.8639 - recall: 0.736 - ETA: 0s - loss: 0.5830 - accuracy: 0.8229 - precision: 0.8640 - recall: 0.750 - ETA: 0s - loss: 0.6119 - accuracy: 0.8040 - precision: 0.8523 - recall: 0.721 - ETA: 0s - loss: 0.6373 - accuracy: 0.7909 - precision: 0.8420 - recall: 0.704 - 1s 1ms/sample - loss: 0.6423 - accuracy: 0.7887 - precision: 0.8375 - recall: 0.7019 - val_loss: 1.0333 - val_accuracy: 0.6690 - val_precision: 0.7207 - val_recall: 0.5634\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.8125 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.5353 - accuracy: 0.8229 - precision: 0.8750 - recall: 0.729 - ETA: 0s - loss: 0.6023 - accuracy: 0.7875 - precision: 0.8538 - recall: 0.693 - ETA: 0s - loss: 0.5914 - accuracy: 0.7902 - precision: 0.8641 - recall: 0.709 - ETA: 0s - loss: 0.5991 - accuracy: 0.7917 - precision: 0.8596 - recall: 0.701 - ETA: 0s - loss: 0.6183 - accuracy: 0.7727 - precision: 0.8511 - recall: 0.681 - ETA: 0s - loss: 0.6356 - accuracy: 0.7644 - precision: 0.8429 - recall: 0.670 - 0s 1ms/sample - loss: 0.6307 - accuracy: 0.7653 - precision: 0.8441 - recall: 0.6737 - val_loss: 1.1116 - val_accuracy: 0.5986 - val_precision: 0.6759 - val_recall: 0.5141\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8125 - precision: 0.9583 - recall: 0.718 - ETA: 0s - loss: 0.5357 - accuracy: 0.7917 - precision: 0.8987 - recall: 0.739 - ETA: 0s - loss: 0.5505 - accuracy: 0.7625 - precision: 0.8740 - recall: 0.693 - ETA: 0s - loss: 0.5441 - accuracy: 0.7768 - precision: 0.8659 - recall: 0.692 - ETA: 0s - loss: 0.5735 - accuracy: 0.7639 - precision: 0.8603 - recall: 0.684 - ETA: 0s - loss: 0.5674 - accuracy: 0.7756 - precision: 0.8662 - recall: 0.698 - ETA: 0s - loss: 0.5388 - accuracy: 0.7957 - precision: 0.8850 - recall: 0.721 - 0s 1ms/sample - loss: 0.5400 - accuracy: 0.7958 - precision: 0.8825 - recall: 0.7230 - val_loss: 1.0733 - val_accuracy: 0.6056 - val_precision: 0.6581 - val_recall: 0.5423\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8438 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.4879 - accuracy: 0.8125 - precision: 0.8675 - recall: 0.750 - ETA: 0s - loss: 0.4725 - accuracy: 0.8250 - precision: 0.8815 - recall: 0.743 - ETA: 0s - loss: 0.4789 - accuracy: 0.8259 - precision: 0.8750 - recall: 0.750 - ETA: 0s - loss: 0.4634 - accuracy: 0.8368 - precision: 0.8862 - recall: 0.756 - ETA: 0s - loss: 0.4594 - accuracy: 0.8381 - precision: 0.8930 - recall: 0.758 - ETA: 0s - loss: 0.4971 - accuracy: 0.8245 - precision: 0.8750 - recall: 0.740 - 0s 1ms/sample - loss: 0.5040 - accuracy: 0.8239 - precision: 0.8729 - recall: 0.7418 - val_loss: 1.1047 - val_accuracy: 0.6479 - val_precision: 0.6780 - val_recall: 0.5634\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8125 - precision: 0.8571 - recall: 0.750 - ETA: 0s - loss: 0.4123 - accuracy: 0.8438 - precision: 0.8929 - recall: 0.781 - ETA: 0s - loss: 0.4520 - accuracy: 0.8375 - precision: 0.8767 - recall: 0.800 - ETA: 0s - loss: 0.4961 - accuracy: 0.8170 - precision: 0.8607 - recall: 0.772 - ETA: 0s - loss: 0.5241 - accuracy: 0.8090 - precision: 0.8516 - recall: 0.756 - ETA: 0s - loss: 0.5036 - accuracy: 0.8210 - precision: 0.8635 - recall: 0.772 - ETA: 0s - loss: 0.5108 - accuracy: 0.8173 - precision: 0.8606 - recall: 0.771 - 0s 1ms/sample - loss: 0.5037 - accuracy: 0.8216 - precision: 0.8642 - recall: 0.7770 - val_loss: 1.0255 - val_accuracy: 0.6690 - val_precision: 0.7154 - val_recall: 0.6197\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.8125 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.4605 - accuracy: 0.8438 - precision: 0.8706 - recall: 0.770 - ETA: 0s - loss: 0.4846 - accuracy: 0.8250 - precision: 0.8562 - recall: 0.781 - ETA: 0s - loss: 0.4425 - accuracy: 0.8393 - precision: 0.8647 - recall: 0.799 - ETA: 0s - loss: 0.4538 - accuracy: 0.8403 - precision: 0.8669 - recall: 0.791 - ETA: 0s - loss: 0.4559 - accuracy: 0.8352 - precision: 0.8679 - recall: 0.784 - ETA: 0s - loss: 0.4545 - accuracy: 0.8365 - precision: 0.8658 - recall: 0.790 - 0s 1ms/sample - loss: 0.4596 - accuracy: 0.8357 - precision: 0.8660 - recall: 0.7887 - val_loss: 1.1748 - val_accuracy: 0.5915 - val_precision: 0.6639 - val_recall: 0.5704\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8438 - precision: 0.9615 - recall: 0.781 - ETA: 0s - loss: 0.3882 - accuracy: 0.8750 - precision: 0.9405 - recall: 0.822 - ETA: 0s - loss: 0.4058 - accuracy: 0.8438 - precision: 0.8951 - recall: 0.800 - ETA: 0s - loss: 0.3968 - accuracy: 0.8527 - precision: 0.8960 - recall: 0.808 - ETA: 0s - loss: 0.4086 - accuracy: 0.8507 - precision: 0.8919 - recall: 0.802 - ETA: 0s - loss: 0.4160 - accuracy: 0.8608 - precision: 0.8994 - recall: 0.812 - ETA: 0s - loss: 0.4407 - accuracy: 0.8534 - precision: 0.8889 - recall: 0.807 - 0s 1ms/sample - loss: 0.4444 - accuracy: 0.8521 - precision: 0.8863 - recall: 0.8052 - val_loss: 1.0344 - val_accuracy: 0.6620 - val_precision: 0.7008 - val_recall: 0.6268\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8438 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.4139 - accuracy: 0.8229 - precision: 0.8370 - recall: 0.802 - ETA: 0s - loss: 0.3871 - accuracy: 0.8625 - precision: 0.8816 - recall: 0.837 - ETA: 0s - loss: 0.4166 - accuracy: 0.8527 - precision: 0.8841 - recall: 0.817 - ETA: 0s - loss: 0.4097 - accuracy: 0.8542 - precision: 0.8939 - recall: 0.819 - ETA: 0s - loss: 0.4214 - accuracy: 0.8438 - precision: 0.8879 - recall: 0.809 - ETA: 0s - loss: 0.4131 - accuracy: 0.8486 - precision: 0.8924 - recall: 0.817 - 0s 1ms/sample - loss: 0.4195 - accuracy: 0.8474 - precision: 0.8897 - recall: 0.8146 - val_loss: 1.1595 - val_accuracy: 0.6338 - val_precision: 0.6589 - val_recall: 0.5986\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7812 - precision: 0.8065 - recall: 0.781 - ETA: 0s - loss: 0.4596 - accuracy: 0.8125 - precision: 0.8539 - recall: 0.791 - ETA: 0s - loss: 0.4600 - accuracy: 0.8313 - precision: 0.8609 - recall: 0.812 - ETA: 0s - loss: 0.4398 - accuracy: 0.8393 - precision: 0.8673 - recall: 0.817 - ETA: 0s - loss: 0.4163 - accuracy: 0.8507 - precision: 0.8819 - recall: 0.829 - ETA: 0s - loss: 0.4347 - accuracy: 0.8352 - precision: 0.8701 - recall: 0.818 - ETA: 0s - loss: 0.4745 - accuracy: 0.8221 - precision: 0.8579 - recall: 0.798 - 0s 1ms/sample - loss: 0.4723 - accuracy: 0.8239 - precision: 0.8608 - recall: 0.7981 - val_loss: 1.2214 - val_accuracy: 0.6127 - val_precision: 0.6535 - val_recall: 0.5845\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.7812 - precision: 0.8929 - recall: 0.781 - ETA: 0s - loss: 0.5327 - accuracy: 0.7812 - precision: 0.8295 - recall: 0.760 - ETA: 0s - loss: 0.4955 - accuracy: 0.8062 - precision: 0.8493 - recall: 0.775 - ETA: 0s - loss: 0.4628 - accuracy: 0.8170 - precision: 0.8551 - recall: 0.790 - ETA: 0s - loss: 0.4746 - accuracy: 0.8056 - precision: 0.8491 - recall: 0.781 - ETA: 0s - loss: 0.5320 - accuracy: 0.7869 - precision: 0.8255 - recall: 0.752 - ETA: 0s - loss: 0.5322 - accuracy: 0.7885 - precision: 0.8228 - recall: 0.747 - 0s 1ms/sample - loss: 0.5353 - accuracy: 0.7887 - precision: 0.8243 - recall: 0.7488 - val_loss: 1.3837 - val_accuracy: 0.5845 - val_precision: 0.5906 - val_recall: 0.5282\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9463 - accuracy: 0.7500 - precision: 0.7419 - recall: 0.718 - ETA: 0s - loss: 0.5504 - accuracy: 0.8333 - precision: 0.8462 - recall: 0.802 - ETA: 0s - loss: 0.6757 - accuracy: 0.7688 - precision: 0.8028 - recall: 0.712 - ETA: 0s - loss: 0.7191 - accuracy: 0.7723 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.7761 - accuracy: 0.7465 - precision: 0.7976 - recall: 0.697 - ETA: 0s - loss: 0.8075 - accuracy: 0.7358 - precision: 0.7846 - recall: 0.693 - ETA: 0s - loss: 0.8108 - accuracy: 0.7308 - precision: 0.7839 - recall: 0.680 - 1s 1ms/sample - loss: 0.7996 - accuracy: 0.7324 - precision: 0.7865 - recall: 0.6831 - val_loss: 1.2855 - val_accuracy: 0.5352 - val_precision: 0.6034 - val_recall: 0.4930\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1030 - accuracy: 0.5938 - precision: 0.6429 - recall: 0.562 - ETA: 0s - loss: 0.8172 - accuracy: 0.6771 - precision: 0.7595 - recall: 0.625 - ETA: 0s - loss: 0.7095 - accuracy: 0.7250 - precision: 0.7826 - recall: 0.675 - ETA: 0s - loss: 0.6990 - accuracy: 0.7321 - precision: 0.7835 - recall: 0.678 - ETA: 0s - loss: 0.6323 - accuracy: 0.7535 - precision: 0.8056 - recall: 0.704 - ETA: 0s - loss: 0.6070 - accuracy: 0.7642 - precision: 0.8091 - recall: 0.710 - ETA: 0s - loss: 0.6256 - accuracy: 0.7572 - precision: 0.8099 - recall: 0.706 - 0s 1ms/sample - loss: 0.6160 - accuracy: 0.7629 - precision: 0.8145 - recall: 0.7113 - val_loss: 1.1139 - val_accuracy: 0.6056 - val_precision: 0.6475 - val_recall: 0.5563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5994cfa032b44477ef896da8300bb26f</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6690140962600708</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                65792     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 554,764\n",
      "Trainable params: 554,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:14 - loss: 2.4914 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 21s - loss: 2.4757 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+00    - ETA: 10s - loss: 2.4600 - accuracy: 0.0688 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 5s - loss: 2.4356 - accuracy: 0.0804 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 3s - loss: 2.3930 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.3629 - accuracy: 0.1222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3289 - accuracy: 0.1394 - precision: 0.0000e+00 - recall: 0.0000e+0 - 8s 20ms/sample - loss: 2.3196 - accuracy: 0.1455 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1222 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0763 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0790 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0586 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0498 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0146 - accuracy: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9813 - accuracy: 0.2045 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9940 - accuracy: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9898 - accuracy: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8872 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8030 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9295 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9511 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9116 - accuracy: 0.2634 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9214 - accuracy: 0.2569 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9237 - accuracy: 0.2614 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9271 - accuracy: 0.2476 - precision: 1.0000 - recall: 0.0024        - 1s 1ms/sample - loss: 1.9245 - accuracy: 0.2488 - precision: 1.0000 - recall: 0.0023 - val_loss: 2.2348 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8594 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 2.1419 - accuracy: 0.2396 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 2.0300 - accuracy: 0.2313 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 2.0039 - accuracy: 0.2232 - precision: 1.0000 - recall: 0.004 - ETA: 0s - loss: 1.9860 - accuracy: 0.2326 - precision: 1.0000 - recall: 0.003 - ETA: 0s - loss: 1.9745 - accuracy: 0.2273 - precision: 1.0000 - recall: 0.002 - ETA: 0s - loss: 1.9818 - accuracy: 0.2161 - precision: 1.0000 - recall: 0.002 - 1s 2ms/sample - loss: 1.9599 - accuracy: 0.2300 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.8871 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8911 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8379 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.0312        - ETA: 0s - loss: 1.8093 - accuracy: 0.3000 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.8588 - accuracy: 0.2768 - precision: 0.5000 - recall: 0.022 - ETA: 0s - loss: 1.8708 - accuracy: 0.2500 - precision: 0.4091 - recall: 0.031 - ETA: 0s - loss: 1.8265 - accuracy: 0.2727 - precision: 0.3714 - recall: 0.036 - ETA: 0s - loss: 1.8105 - accuracy: 0.3053 - precision: 0.4103 - recall: 0.038 - 1s 1ms/sample - loss: 1.8083 - accuracy: 0.3052 - precision: 0.4103 - recall: 0.0376 - val_loss: 1.9511 - val_accuracy: 0.3028 - val_precision: 0.6000 - val_recall: 0.0211\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8291 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7250 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.0208        - ETA: 0s - loss: 1.7762 - accuracy: 0.2688 - precision: 0.5000 - recall: 0.012 - ETA: 0s - loss: 1.7810 - accuracy: 0.2768 - precision: 0.5000 - recall: 0.008 - ETA: 0s - loss: 1.7853 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.006 - ETA: 0s - loss: 1.7814 - accuracy: 0.2898 - precision: 0.5000 - recall: 0.005 - ETA: 0s - loss: 1.8029 - accuracy: 0.2788 - precision: 0.5000 - recall: 0.004 - 1s 1ms/sample - loss: 1.8359 - accuracy: 0.2723 - precision: 0.5000 - recall: 0.0047 - val_loss: 2.4610 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1716 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2151 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0774 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0975 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0286 - accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0649 - accuracy: 0.2443 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0751 - accuracy: 0.2452 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0636 - accuracy: 0.2441 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9827 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9544 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9338 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8292 - accuracy: 0.3063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8651 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8574 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8446 - accuracy: 0.2898 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8531 - accuracy: 0.2861 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8564 - accuracy: 0.2864 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8987 - val_accuracy: 0.3099 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0700 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9985 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8956 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8328 - accuracy: 0.2768 - precision: 0.2857 - recall: 0.0089        - ETA: 0s - loss: 1.8175 - accuracy: 0.2604 - precision: 0.3000 - recall: 0.020 - ETA: 0s - loss: 1.8132 - accuracy: 0.2756 - precision: 0.2895 - recall: 0.031 - ETA: 0s - loss: 1.8177 - accuracy: 0.2812 - precision: 0.3171 - recall: 0.031 - 1s 1ms/sample - loss: 1.8224 - accuracy: 0.2817 - precision: 0.3171 - recall: 0.0305 - val_loss: 1.6998 - val_accuracy: 0.3169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6623 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6649 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7590 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7403 - accuracy: 0.3259 - precision: 0.2500 - recall: 0.0045        - ETA: 0s - loss: 1.7564 - accuracy: 0.3160 - precision: 0.2500 - recall: 0.003 - ETA: 0s - loss: 1.7638 - accuracy: 0.3125 - precision: 0.2500 - recall: 0.002 - ETA: 0s - loss: 1.7849 - accuracy: 0.3149 - precision: 0.2500 - recall: 0.002 - 1s 1ms/sample - loss: 1.7791 - accuracy: 0.3216 - precision: 0.2500 - recall: 0.0023 - val_loss: 1.7755 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8566 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7649 - accuracy: 0.3854 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7769 - accuracy: 0.3562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7848 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7614 - accuracy: 0.3264 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7847 - accuracy: 0.3040 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7879 - accuracy: 0.3029 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7952 - accuracy: 0.3052 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6731 - val_accuracy: 0.3662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7072 - accuracy: 0.4688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6083 - accuracy: 0.3854 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7154 - accuracy: 0.3187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6981 - accuracy: 0.3214 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6906 - accuracy: 0.3194 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7244 - accuracy: 0.3182 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7130 - accuracy: 0.3149 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7121 - accuracy: 0.3146 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6395 - val_accuracy: 0.3732 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7281 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6721 - accuracy: 0.3333 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5994 - accuracy: 0.3625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6390 - accuracy: 0.3571 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6574 - accuracy: 0.3611 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6479 - accuracy: 0.3551 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6388 - accuracy: 0.3558 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.6463 - accuracy: 0.3545 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6158 - val_accuracy: 0.3662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6000 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6537 - accuracy: 0.3542 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6288 - accuracy: 0.3313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5867 - accuracy: 0.3482 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6309 - accuracy: 0.3368 - precision: 0.6667 - recall: 0.0069        - ETA: 0s - loss: 1.6222 - accuracy: 0.3523 - precision: 0.5385 - recall: 0.019 - ETA: 0s - loss: 1.6437 - accuracy: 0.3510 - precision: 0.5000 - recall: 0.026 - 1s 1ms/sample - loss: 1.6444 - accuracy: 0.3498 - precision: 0.5000 - recall: 0.0258 - val_loss: 1.7067 - val_accuracy: 0.3380 - val_precision: 0.7500 - val_recall: 0.0211\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7041 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5893 - accuracy: 0.4375 - precision: 0.6000 - recall: 0.0312        - ETA: 0s - loss: 1.5967 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.025 - ETA: 0s - loss: 1.6707 - accuracy: 0.3661 - precision: 0.4286 - recall: 0.026 - ETA: 0s - loss: 1.6653 - accuracy: 0.3819 - precision: 0.4286 - recall: 0.031 - ETA: 0s - loss: 1.6395 - accuracy: 0.3892 - precision: 0.5000 - recall: 0.034 - ETA: 0s - loss: 1.6437 - accuracy: 0.3822 - precision: 0.5625 - recall: 0.043 - 1s 1ms/sample - loss: 1.6450 - accuracy: 0.3826 - precision: 0.5625 - recall: 0.0423 - val_loss: 1.5819 - val_accuracy: 0.3521 - val_precision: 1.0000 - val_recall: 0.0493\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3592 - accuracy: 0.5938 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5696 - accuracy: 0.3958 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.5186 - accuracy: 0.4062 - precision: 0.7778 - recall: 0.043 - ETA: 0s - loss: 1.5213 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.035 - ETA: 0s - loss: 1.5648 - accuracy: 0.3993 - precision: 0.6667 - recall: 0.034 - ETA: 0s - loss: 1.5739 - accuracy: 0.4034 - precision: 0.7000 - recall: 0.039 - ETA: 0s - loss: 1.5739 - accuracy: 0.3990 - precision: 0.7037 - recall: 0.045 - 1s 2ms/sample - loss: 1.5726 - accuracy: 0.3991 - precision: 0.7037 - recall: 0.0446 - val_loss: 1.5954 - val_accuracy: 0.3873 - val_precision: 0.7143 - val_recall: 0.0704\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5641 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5955 - accuracy: 0.3958 - precision: 0.7273 - recall: 0.083 - ETA: 0s - loss: 1.5545 - accuracy: 0.4250 - precision: 0.7368 - recall: 0.087 - ETA: 0s - loss: 1.5624 - accuracy: 0.3929 - precision: 0.7200 - recall: 0.080 - ETA: 0s - loss: 1.5637 - accuracy: 0.4132 - precision: 0.7333 - recall: 0.076 - ETA: 0s - loss: 1.5816 - accuracy: 0.3977 - precision: 0.7353 - recall: 0.071 - ETA: 0s - loss: 1.5857 - accuracy: 0.3880 - precision: 0.7222 - recall: 0.067 - 1s 1ms/sample - loss: 1.5749 - accuracy: 0.3920 - precision: 0.7000 - recall: 0.0657 - val_loss: 1.5015 - val_accuracy: 0.3662 - val_precision: 0.8750 - val_recall: 0.0493\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5189 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6524 - accuracy: 0.3333 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.6940 - accuracy: 0.3438 - precision: 0.6154 - recall: 0.050 - ETA: 0s - loss: 1.7002 - accuracy: 0.3304 - precision: 0.5500 - recall: 0.049 - ETA: 0s - loss: 1.6826 - accuracy: 0.3438 - precision: 0.5600 - recall: 0.048 - ETA: 0s - loss: 1.7219 - accuracy: 0.3125 - precision: 0.5806 - recall: 0.051 - ETA: 0s - loss: 1.7333 - accuracy: 0.3125 - precision: 0.5952 - recall: 0.060 - 1s 1ms/sample - loss: 1.7286 - accuracy: 0.3146 - precision: 0.6047 - recall: 0.0610 - val_loss: 1.7532 - val_accuracy: 0.3099 - val_precision: 0.8000 - val_recall: 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6903 - accuracy: 0.3125 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.8449 - accuracy: 0.2917 - precision: 0.4545 - recall: 0.052 - ETA: 0s - loss: 1.7804 - accuracy: 0.3375 - precision: 0.4211 - recall: 0.050 - ETA: 0s - loss: 1.7366 - accuracy: 0.3348 - precision: 0.5333 - recall: 0.071 - ETA: 0s - loss: 1.7300 - accuracy: 0.3368 - precision: 0.5366 - recall: 0.076 - ETA: 0s - loss: 1.7051 - accuracy: 0.3494 - precision: 0.5686 - recall: 0.082 - ETA: 0s - loss: 1.6798 - accuracy: 0.3510 - precision: 0.5645 - recall: 0.084 - 1s 1ms/sample - loss: 1.6821 - accuracy: 0.3498 - precision: 0.5625 - recall: 0.0845 - val_loss: 1.7538 - val_accuracy: 0.3310 - val_precision: 0.6190 - val_recall: 0.0915\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4368 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.5483 - accuracy: 0.3854 - precision: 0.6957 - recall: 0.166 - ETA: 0s - loss: 1.7871 - accuracy: 0.3250 - precision: 0.6452 - recall: 0.125 - ETA: 0s - loss: 2.0790 - accuracy: 0.2679 - precision: 0.5897 - recall: 0.102 - ETA: 0s - loss: 2.3039 - accuracy: 0.2361 - precision: 0.6000 - recall: 0.083 - ETA: 0s - loss: 2.4729 - accuracy: 0.2188 - precision: 0.6000 - recall: 0.068 - ETA: 0s - loss: 2.5507 - accuracy: 0.2043 - precision: 0.6000 - recall: 0.057 - 1s 1ms/sample - loss: 2.5568 - accuracy: 0.2042 - precision: 0.6000 - recall: 0.0563 - val_loss: 2.7887 - val_accuracy: 0.1338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4674 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5598 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5211 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5391 - accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5158 - accuracy: 0.1701 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5087 - accuracy: 0.1534 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4971 - accuracy: 0.1418 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4976 - accuracy: 0.1408 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4769 - val_accuracy: 0.1056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3828 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4252 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3915 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3956 - accuracy: 0.1071 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3958 - accuracy: 0.1111 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3991 - accuracy: 0.0994 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4068 - accuracy: 0.0962 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4081 - accuracy: 0.0962 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4150 - val_accuracy: 0.0986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4329 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3978 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3944 - accuracy: 0.1312 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4004 - accuracy: 0.1161 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4118 - accuracy: 0.1007 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4030 - accuracy: 0.0994 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4100 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4088 - accuracy: 0.1056 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4230 - val_accuracy: 0.1338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4134 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3785 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3653 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3765 - accuracy: 0.1339 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3867 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3907 - accuracy: 0.1136 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3929 - accuracy: 0.1106 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3941 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4179 - val_accuracy: 0.1127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3777 - accuracy: 0.0312 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3502 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3698 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3686 - accuracy: 0.1161 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3764 - accuracy: 0.1111 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3803 - accuracy: 0.0994 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3820 - accuracy: 0.1010 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3820 - accuracy: 0.1033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3975 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3834 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3625 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3649 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3745 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3801 - accuracy: 0.1389 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3782 - accuracy: 0.1449 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3750 - accuracy: 0.1418 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3768 - accuracy: 0.1385 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4006 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3224 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3414 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3630 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3536 - accuracy: 0.1473 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3564 - accuracy: 0.1424 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3534 - accuracy: 0.1449 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3515 - accuracy: 0.1466 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3508 - accuracy: 0.1479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3783 - val_accuracy: 0.1056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3309 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3397 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3342 - accuracy: 0.1063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3313 - accuracy: 0.1161 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3242 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3172 - accuracy: 0.1136 - precision: 1.0000 - recall: 0.0028        - ETA: 0s - loss: 2.3194 - accuracy: 0.1082 - precision: 1.0000 - recall: 0.002 - 1s 1ms/sample - loss: 2.3188 - accuracy: 0.1056 - precision: 1.0000 - recall: 0.0023 - val_loss: 2.4168 - val_accuracy: 0.1127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3144 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3094 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2961 - accuracy: 0.1437 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3061 - accuracy: 0.1429 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3043 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3336 - accuracy: 0.1307 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3562 - accuracy: 0.1298 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3564 - accuracy: 0.1268 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3437 - val_accuracy: 0.1479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2791 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3020 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3179 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2930 - accuracy: 0.1518 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2996 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3000 - accuracy: 0.1307 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2934 - accuracy: 0.1274 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2938 - accuracy: 0.1268 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3201 - val_accuracy: 0.0986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2706 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2656 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2511 - accuracy: 0.1375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2401 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2368 - accuracy: 0.1701 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2642 - accuracy: 0.1591 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2663 - accuracy: 0.1587 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2623 - accuracy: 0.1573 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2688 - val_accuracy: 0.1479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1411 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2362 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2485 - accuracy: 0.1625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2555 - accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2429 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2389 - accuracy: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2325 - accuracy: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2303 - accuracy: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2640 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1198 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2540 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2599 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2075 - accuracy: 0.1429 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1861 - accuracy: 0.1597 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1663 - accuracy: 0.1591 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1654 - accuracy: 0.1731 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.1677 - accuracy: 0.1714 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0904 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0444 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0029 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0288 - accuracy: 0.2250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0554 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0856 - accuracy: 0.2049 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0814 - accuracy: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0794 - accuracy: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0750 - accuracy: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0086 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0136 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9836 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0539 - accuracy: 0.1312 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0323 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9990 - accuracy: 0.1701 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9929 - accuracy: 0.1790 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9802 - accuracy: 0.1779 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9832 - accuracy: 0.1761 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9470 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9051 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9149 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9341 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9608 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9521 - accuracy: 0.2361 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9427 - accuracy: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9342 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9377 - accuracy: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8542 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.8478 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9440 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9568 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9173 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9103 - accuracy: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9303 - accuracy: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9222 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9145 - accuracy: 0.2183 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8583 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9907 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8972 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8765 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8872 - accuracy: 0.2545 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9114 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8663 - accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8732 - accuracy: 0.2260 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8719 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8609 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8991 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8946 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9026 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8699 - accuracy: 0.2634 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8407 - accuracy: 0.2639 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8190 - accuracy: 0.2670 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8212 - accuracy: 0.2620 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8269 - accuracy: 0.2606 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8096 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8764 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7893 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7853 - accuracy: 0.2625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8235 - accuracy: 0.2455 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8207 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8820 - accuracy: 0.2330 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8964 - accuracy: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8960 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8897 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9639 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9789 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9653 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0568 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1461 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1155 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0984 - accuracy: 0.1683 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0926 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8331 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7837 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8034 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8107 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8502 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8905 - accuracy: 0.2049 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8885 - accuracy: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8956 - accuracy: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8900 - accuracy: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9268 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8498 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9219 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9871 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9560 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9170 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9021 - accuracy: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9093 - accuracy: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9005 - accuracy: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8542 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7508 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7951 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7982 - accuracy: 0.2875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7810 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7919 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8232 - accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8242 - accuracy: 0.2380 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8271 - accuracy: 0.2418 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8837 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8298 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8841 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8738 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8631 - accuracy: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8752 - accuracy: 0.1840 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8872 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8768 - accuracy: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8698 - accuracy: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8741 - accuracy: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7913 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7054 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6992 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7638 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7840 - accuracy: 0.2448 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8091 - accuracy: 0.2383 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8200 - accuracy: 0.2375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8180 - accuracy: 0.2318 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8249 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8332 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9904 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9261 - accuracy: 0.2344 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8582 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8319 - accuracy: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7768 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8364 - accuracy: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8702 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8825 - accuracy: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8689 - accuracy: 0.1808 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8644 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7998 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7721 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7589 - accuracy: 0.2875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7751 - accuracy: 0.2857 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7899 - accuracy: 0.2569 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7920 - accuracy: 0.2472 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8037 - accuracy: 0.2356 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8038 - accuracy: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7941 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7453 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7814 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7842 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8136 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7856 - accuracy: 0.2569 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7771 - accuracy: 0.2585 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7710 - accuracy: 0.2692 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7777 - accuracy: 0.2746 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7700 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7653 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7268 - accuracy: 0.3854 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7450 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7448 - accuracy: 0.2902 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7440 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7333 - accuracy: 0.2869 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7478 - accuracy: 0.2861 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7546 - accuracy: 0.2817 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7988 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7256 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7361 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7590 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7448 - accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7525 - accuracy: 0.2361 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7476 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7529 - accuracy: 0.2596 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7507 - accuracy: 0.2606 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7605 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8006 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7469 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7765 - accuracy: 0.3187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7458 - accuracy: 0.3036 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7356 - accuracy: 0.2986 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7452 - accuracy: 0.2869 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7461 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7402 - accuracy: 0.2793 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7633 - val_accuracy: 0.3028 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6765 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7668 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7752 - accuracy: 0.2750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7899 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8176 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8180 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8155 - accuracy: 0.2596 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8168 - accuracy: 0.2582 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7788 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7762 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8214 - accuracy: 0.2625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7743 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7757 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7822 - accuracy: 0.2528 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7736 - accuracy: 0.2524 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7709 - accuracy: 0.2488 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7804 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5613 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6352 - accuracy: 0.3021 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.6946 - accuracy: 0.2875 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.7025 - accuracy: 0.2857 - precision: 1.0000 - recall: 0.004 - ETA: 0s - loss: 1.7107 - accuracy: 0.2882 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.7343 - accuracy: 0.2841 - precision: 1.0000 - recall: 0.011 - ETA: 0s - loss: 1.7418 - accuracy: 0.2861 - precision: 1.0000 - recall: 0.014 - 1s 1ms/sample - loss: 1.7359 - accuracy: 0.2840 - precision: 1.0000 - recall: 0.0164 - val_loss: 1.7140 - val_accuracy: 0.2746 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6042 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.7114 - accuracy: 0.3438 - precision: 0.5385 - recall: 0.072 - ETA: 0s - loss: 1.8388 - accuracy: 0.2937 - precision: 0.3548 - recall: 0.068 - ETA: 0s - loss: 1.7987 - accuracy: 0.3170 - precision: 0.4167 - recall: 0.067 - ETA: 0s - loss: 1.7509 - accuracy: 0.3264 - precision: 0.4324 - recall: 0.055 - ETA: 0s - loss: 1.7365 - accuracy: 0.3210 - precision: 0.4474 - recall: 0.048 - ETA: 0s - loss: 1.7447 - accuracy: 0.3029 - precision: 0.4615 - recall: 0.043 - 1s 1ms/sample - loss: 1.7512 - accuracy: 0.2958 - precision: 0.4615 - recall: 0.0423 - val_loss: 1.8327 - val_accuracy: 0.2113 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4836 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6273 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.6678 - accuracy: 0.3250 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.6974 - accuracy: 0.3036 - precision: 0.6667 - recall: 0.008 - ETA: 0s - loss: 1.6862 - accuracy: 0.3125 - precision: 0.7500 - recall: 0.010 - ETA: 0s - loss: 1.6818 - accuracy: 0.3267 - precision: 0.8333 - recall: 0.014 - ETA: 0s - loss: 1.6913 - accuracy: 0.3077 - precision: 0.8333 - recall: 0.012 - 1s 1ms/sample - loss: 1.6849 - accuracy: 0.3099 - precision: 0.8333 - recall: 0.0117 - val_loss: 1.6580 - val_accuracy: 0.2676 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6204 - accuracy: 0.3125 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.7257 - accuracy: 0.2708 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.7355 - accuracy: 0.2688 - precision: 0.8000 - recall: 0.050 - ETA: 0s - loss: 1.7485 - accuracy: 0.2768 - precision: 0.7500 - recall: 0.053 - ETA: 0s - loss: 1.7206 - accuracy: 0.2951 - precision: 0.7619 - recall: 0.055 - ETA: 0s - loss: 1.7053 - accuracy: 0.3040 - precision: 0.7143 - recall: 0.056 - ETA: 0s - loss: 1.7336 - accuracy: 0.3029 - precision: 0.6970 - recall: 0.055 - 1s 1ms/sample - loss: 1.7391 - accuracy: 0.2981 - precision: 0.7059 - recall: 0.0563 - val_loss: 1.9932 - val_accuracy: 0.2676 - val_precision: 0.6000 - val_recall: 0.0423\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0442 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8301 - accuracy: 0.2292 - precision: 0.8333 - recall: 0.052 - ETA: 0s - loss: 1.8751 - accuracy: 0.2625 - precision: 0.9000 - recall: 0.056 - ETA: 0s - loss: 1.8343 - accuracy: 0.2857 - precision: 0.8462 - recall: 0.049 - ETA: 0s - loss: 1.8153 - accuracy: 0.2812 - precision: 0.8462 - recall: 0.038 - ETA: 0s - loss: 1.8065 - accuracy: 0.3011 - precision: 0.8000 - recall: 0.034 - ETA: 0s - loss: 1.7766 - accuracy: 0.2981 - precision: 0.7895 - recall: 0.036 - 1s 1ms/sample - loss: 1.7707 - accuracy: 0.3005 - precision: 0.7895 - recall: 0.0352 - val_loss: 1.6710 - val_accuracy: 0.2676 - val_precision: 0.8750 - val_recall: 0.0493\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8875 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7069 - accuracy: 0.2917 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.6298 - accuracy: 0.2875 - precision: 0.7778 - recall: 0.043 - ETA: 0s - loss: 1.6308 - accuracy: 0.2902 - precision: 0.7500 - recall: 0.040 - ETA: 0s - loss: 1.6625 - accuracy: 0.2951 - precision: 0.7500 - recall: 0.031 - ETA: 0s - loss: 1.6558 - accuracy: 0.3097 - precision: 0.7500 - recall: 0.034 - ETA: 0s - loss: 1.6475 - accuracy: 0.3245 - precision: 0.7895 - recall: 0.036 - 1s 1ms/sample - loss: 1.6435 - accuracy: 0.3263 - precision: 0.8000 - recall: 0.0376 - val_loss: 1.5772 - val_accuracy: 0.3592 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7073 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6392 - accuracy: 0.2708 - precision: 0.8000 - recall: 0.0417        - ETA: 0s - loss: 1.6183 - accuracy: 0.3125 - precision: 0.7778 - recall: 0.043 - ETA: 0s - loss: 1.6118 - accuracy: 0.3080 - precision: 0.8333 - recall: 0.044 - ETA: 0s - loss: 1.6383 - accuracy: 0.3194 - precision: 0.8462 - recall: 0.038 - ETA: 0s - loss: 1.6298 - accuracy: 0.3324 - precision: 0.8824 - recall: 0.042 - ETA: 0s - loss: 1.6590 - accuracy: 0.3197 - precision: 0.8824 - recall: 0.036 - 1s 1ms/sample - loss: 1.6535 - accuracy: 0.3239 - precision: 0.8824 - recall: 0.0352 - val_loss: 1.7847 - val_accuracy: 0.2183 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7178 - accuracy: 0.3021 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.6948 - accuracy: 0.3500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6764 - accuracy: 0.3259 - precision: 0.8889 - recall: 0.035 - ETA: 0s - loss: 1.6710 - accuracy: 0.3056 - precision: 0.8182 - recall: 0.031 - ETA: 0s - loss: 1.6594 - accuracy: 0.2983 - precision: 0.7500 - recall: 0.034 - ETA: 0s - loss: 1.6318 - accuracy: 0.3197 - precision: 0.8095 - recall: 0.040 - 1s 1ms/sample - loss: 1.6388 - accuracy: 0.3192 - precision: 0.8095 - recall: 0.0399 - val_loss: 1.6321 - val_accuracy: 0.3028 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5583 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5451 - accuracy: 0.3750 - precision: 0.8889 - recall: 0.083 - ETA: 0s - loss: 1.5589 - accuracy: 0.3625 - precision: 0.9231 - recall: 0.075 - ETA: 0s - loss: 1.6183 - accuracy: 0.3661 - precision: 0.8750 - recall: 0.062 - ETA: 0s - loss: 1.5924 - accuracy: 0.3542 - precision: 0.8500 - recall: 0.059 - ETA: 0s - loss: 1.6039 - accuracy: 0.3381 - precision: 0.7500 - recall: 0.051 - ETA: 0s - loss: 1.5907 - accuracy: 0.3413 - precision: 0.7931 - recall: 0.055 - 1s 1ms/sample - loss: 1.5885 - accuracy: 0.3404 - precision: 0.7667 - recall: 0.0540 - val_loss: 1.6640 - val_accuracy: 0.3239 - val_precision: 0.9167 - val_recall: 0.0775\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6519 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4763 - accuracy: 0.3281 - precision: 1.0000 - recall: 0.109 - ETA: 0s - loss: 1.5677 - accuracy: 0.3203 - precision: 1.0000 - recall: 0.085 - ETA: 0s - loss: 1.6664 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.067 - ETA: 0s - loss: 1.6560 - accuracy: 0.3203 - precision: 0.9474 - recall: 0.070 - ETA: 0s - loss: 1.6486 - accuracy: 0.3250 - precision: 0.8148 - recall: 0.068 - ETA: 0s - loss: 1.6364 - accuracy: 0.3255 - precision: 0.8125 - recall: 0.067 - 1s 1ms/sample - loss: 1.6227 - accuracy: 0.3239 - precision: 0.8235 - recall: 0.0657 - val_loss: 1.7146 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5707 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5530 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.052 - ETA: 0s - loss: 1.6164 - accuracy: 0.3500 - precision: 1.0000 - recall: 0.050 - ETA: 0s - loss: 1.6483 - accuracy: 0.3348 - precision: 0.9091 - recall: 0.044 - ETA: 0s - loss: 1.6388 - accuracy: 0.3229 - precision: 0.8947 - recall: 0.059 - ETA: 0s - loss: 1.6433 - accuracy: 0.3153 - precision: 0.8261 - recall: 0.054 - ETA: 0s - loss: 1.6605 - accuracy: 0.3125 - precision: 0.8077 - recall: 0.050 - 1s 1ms/sample - loss: 1.6544 - accuracy: 0.3146 - precision: 0.8148 - recall: 0.0516 - val_loss: 1.7301 - val_accuracy: 0.2817 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4735 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6475 - accuracy: 0.3646 - precision: 0.9000 - recall: 0.093 - ETA: 0s - loss: 1.6210 - accuracy: 0.3187 - precision: 0.9091 - recall: 0.062 - ETA: 0s - loss: 1.5750 - accuracy: 0.3661 - precision: 0.9412 - recall: 0.071 - ETA: 0s - loss: 1.5571 - accuracy: 0.3715 - precision: 0.9474 - recall: 0.062 - ETA: 0s - loss: 1.5614 - accuracy: 0.3580 - precision: 0.9583 - recall: 0.065 - ETA: 0s - loss: 1.5683 - accuracy: 0.3486 - precision: 0.8966 - recall: 0.062 - 1s 1ms/sample - loss: 1.5800 - accuracy: 0.3404 - precision: 0.8966 - recall: 0.0610 - val_loss: 1.6272 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0775\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4153 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4949 - accuracy: 0.3646 - precision: 1.0000 - recall: 0.072 - ETA: 0s - loss: 1.5075 - accuracy: 0.3313 - precision: 0.8889 - recall: 0.050 - ETA: 0s - loss: 1.5508 - accuracy: 0.3482 - precision: 0.8571 - recall: 0.053 - ETA: 0s - loss: 1.5417 - accuracy: 0.3507 - precision: 0.8333 - recall: 0.052 - ETA: 0s - loss: 1.5417 - accuracy: 0.3352 - precision: 0.8500 - recall: 0.048 - ETA: 0s - loss: 1.5702 - accuracy: 0.3269 - precision: 0.7917 - recall: 0.045 - 1s 1ms/sample - loss: 1.5717 - accuracy: 0.3310 - precision: 0.8000 - recall: 0.0469 - val_loss: 1.6470 - val_accuracy: 0.3169 - val_precision: 0.7692 - val_recall: 0.0704\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5075 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5106 - accuracy: 0.3750 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.5689 - accuracy: 0.3938 - precision: 0.8333 - recall: 0.062 - ETA: 0s - loss: 1.5731 - accuracy: 0.3571 - precision: 0.7647 - recall: 0.058 - ETA: 0s - loss: 1.5692 - accuracy: 0.3264 - precision: 0.7391 - recall: 0.059 - ETA: 0s - loss: 1.5828 - accuracy: 0.3125 - precision: 0.7407 - recall: 0.056 - ETA: 0s - loss: 1.5959 - accuracy: 0.3173 - precision: 0.7742 - recall: 0.057 - 1s 1ms/sample - loss: 1.5928 - accuracy: 0.3169 - precision: 0.7879 - recall: 0.0610 - val_loss: 1.7095 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6194 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.5677 - accuracy: 0.3854 - precision: 0.8333 - recall: 0.052 - ETA: 0s - loss: 1.5743 - accuracy: 0.3562 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.5889 - accuracy: 0.3616 - precision: 0.7500 - recall: 0.040 - ETA: 0s - loss: 1.5942 - accuracy: 0.3576 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.5666 - accuracy: 0.3466 - precision: 0.8500 - recall: 0.048 - ETA: 0s - loss: 1.5899 - accuracy: 0.3438 - precision: 0.8400 - recall: 0.050 - 1s 1ms/sample - loss: 1.5954 - accuracy: 0.3451 - precision: 0.8462 - recall: 0.0516 - val_loss: 1.6591 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0634\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5700 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6327 - accuracy: 0.2812 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.8297 - accuracy: 0.2000 - precision: 0.6667 - recall: 0.037 - ETA: 0s - loss: 2.0486 - accuracy: 0.2143 - precision: 0.6667 - recall: 0.044 - ETA: 0s - loss: 2.1654 - accuracy: 0.2292 - precision: 0.6316 - recall: 0.041 - ETA: 0s - loss: 2.1804 - accuracy: 0.2216 - precision: 0.6071 - recall: 0.048 - ETA: 0s - loss: 2.1666 - accuracy: 0.2188 - precision: 0.6176 - recall: 0.050 - 1s 1ms/sample - loss: 2.1556 - accuracy: 0.2183 - precision: 0.6176 - recall: 0.0493 - val_loss: 2.0884 - val_accuracy: 0.2606 - val_precision: 1.0000 - val_recall: 0.0915\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4321 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1021 - accuracy: 0.2604 - precision: 0.4286 - recall: 0.0312        - ETA: 0s - loss: 1.9471 - accuracy: 0.2625 - precision: 0.6154 - recall: 0.050 - ETA: 0s - loss: 1.9286 - accuracy: 0.2634 - precision: 0.6190 - recall: 0.058 - ETA: 0s - loss: 1.8935 - accuracy: 0.2674 - precision: 0.6786 - recall: 0.066 - ETA: 0s - loss: 1.8865 - accuracy: 0.2642 - precision: 0.6471 - recall: 0.062 - ETA: 0s - loss: 1.8739 - accuracy: 0.2572 - precision: 0.6486 - recall: 0.057 - 1s 1ms/sample - loss: 1.8785 - accuracy: 0.2535 - precision: 0.6486 - recall: 0.0563 - val_loss: 1.9612 - val_accuracy: 0.2113 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0731 - accuracy: 0.1562 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.9159 - accuracy: 0.2292 - precision: 1.0000 - recall: 0.020 - ETA: 0s - loss: 1.8241 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.018 - ETA: 0s - loss: 1.8260 - accuracy: 0.2679 - precision: 1.0000 - recall: 0.026 - ETA: 0s - loss: 1.8044 - accuracy: 0.2847 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8098 - accuracy: 0.2642 - precision: 1.0000 - recall: 0.025 - ETA: 0s - loss: 1.7910 - accuracy: 0.2572 - precision: 1.0000 - recall: 0.024 - 1s 1ms/sample - loss: 1.7995 - accuracy: 0.2535 - precision: 1.0000 - recall: 0.0235 - val_loss: 1.6980 - val_accuracy: 0.2535 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8709 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7800 - accuracy: 0.2708 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6806 - accuracy: 0.2875 - precision: 1.0000 - recall: 0.037 - ETA: 0s - loss: 1.6716 - accuracy: 0.3348 - precision: 1.0000 - recall: 0.035 - ETA: 0s - loss: 1.7032 - accuracy: 0.3090 - precision: 1.0000 - recall: 0.034 - ETA: 0s - loss: 1.6790 - accuracy: 0.3068 - precision: 0.9333 - recall: 0.039 - ETA: 0s - loss: 1.6862 - accuracy: 0.3053 - precision: 0.8333 - recall: 0.036 - 1s 1ms/sample - loss: 1.6774 - accuracy: 0.3028 - precision: 0.8500 - recall: 0.0399 - val_loss: 1.5931 - val_accuracy: 0.3803 - val_precision: 1.0000 - val_recall: 0.0563\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6193 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6686 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6594 - accuracy: 0.2875 - precision: 1.0000 - recall: 0.037 - ETA: 0s - loss: 1.7186 - accuracy: 0.2857 - precision: 0.7778 - recall: 0.031 - ETA: 0s - loss: 1.6885 - accuracy: 0.3056 - precision: 0.6667 - recall: 0.034 - ETA: 0s - loss: 1.6820 - accuracy: 0.3068 - precision: 0.6190 - recall: 0.036 - ETA: 0s - loss: 1.6918 - accuracy: 0.2909 - precision: 0.6333 - recall: 0.045 - 1s 1ms/sample - loss: 1.6933 - accuracy: 0.2911 - precision: 0.6452 - recall: 0.0469 - val_loss: 1.7161 - val_accuracy: 0.2394 - val_precision: 0.9091 - val_recall: 0.0704\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6080 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6015 - accuracy: 0.3542 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.5982 - accuracy: 0.3375 - precision: 0.8333 - recall: 0.031 - ETA: 0s - loss: 1.6719 - accuracy: 0.3304 - precision: 0.8889 - recall: 0.035 - ETA: 0s - loss: 1.7125 - accuracy: 0.3203 - precision: 0.8889 - recall: 0.031 - ETA: 0s - loss: 1.7174 - accuracy: 0.3125 - precision: 0.9167 - recall: 0.034 - ETA: 0s - loss: 1.7401 - accuracy: 0.3047 - precision: 0.9375 - recall: 0.039 - 1s 1ms/sample - loss: 1.7178 - accuracy: 0.3052 - precision: 0.8571 - recall: 0.0423 - val_loss: 1.6078 - val_accuracy: 0.3169 - val_precision: 0.6842 - val_recall: 0.0915\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7421 - accuracy: 0.3438 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.8192 - accuracy: 0.2812 - precision: 0.4737 - recall: 0.093 - ETA: 0s - loss: 1.8304 - accuracy: 0.2625 - precision: 0.4828 - recall: 0.087 - ETA: 0s - loss: 1.8091 - accuracy: 0.2500 - precision: 0.4474 - recall: 0.075 - ETA: 0s - loss: 1.7565 - accuracy: 0.2431 - precision: 0.4615 - recall: 0.062 - ETA: 0s - loss: 1.7194 - accuracy: 0.2557 - precision: 0.4878 - recall: 0.056 - ETA: 0s - loss: 1.6957 - accuracy: 0.2644 - precision: 0.5227 - recall: 0.055 - 1s 1ms/sample - loss: 1.7019 - accuracy: 0.2653 - precision: 0.5227 - recall: 0.0540 - val_loss: 1.6362 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4072 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.5302 - accuracy: 0.3646 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5303 - accuracy: 0.3688 - precision: 1.0000 - recall: 0.050 - ETA: 0s - loss: 1.5661 - accuracy: 0.3661 - precision: 1.0000 - recall: 0.040 - ETA: 0s - loss: 1.5915 - accuracy: 0.3542 - precision: 1.0000 - recall: 0.038 - ETA: 0s - loss: 1.5925 - accuracy: 0.3608 - precision: 1.0000 - recall: 0.034 - ETA: 0s - loss: 1.5918 - accuracy: 0.3534 - precision: 1.0000 - recall: 0.031 - 1s 1ms/sample - loss: 1.5981 - accuracy: 0.3521 - precision: 1.0000 - recall: 0.0305 - val_loss: 1.6615 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0352\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7686 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.020 - ETA: 0s - loss: 1.8627 - accuracy: 0.3063 - precision: 1.0000 - recall: 0.025 - ETA: 0s - loss: 1.7969 - accuracy: 0.3259 - precision: 1.0000 - recall: 0.040 - ETA: 0s - loss: 1.7276 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.038 - ETA: 0s - loss: 1.6995 - accuracy: 0.3267 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7052 - accuracy: 0.3125 - precision: 0.9333 - recall: 0.033 - 1s 1ms/sample - loss: 1.7119 - accuracy: 0.3075 - precision: 0.9333 - recall: 0.0329 - val_loss: 1.6355 - val_accuracy: 0.3592 - val_precision: 1.0000 - val_recall: 0.0493\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7080 - accuracy: 0.2917 - precision: 1.0000 - recall: 0.020 - ETA: 0s - loss: 1.6486 - accuracy: 0.3187 - precision: 0.8571 - recall: 0.037 - ETA: 0s - loss: 1.6157 - accuracy: 0.3661 - precision: 0.7500 - recall: 0.040 - ETA: 0s - loss: 1.6430 - accuracy: 0.3403 - precision: 0.7059 - recall: 0.041 - ETA: 0s - loss: 1.6503 - accuracy: 0.3295 - precision: 0.7222 - recall: 0.036 - ETA: 0s - loss: 1.6339 - accuracy: 0.3389 - precision: 0.7619 - recall: 0.038 - 1s 1ms/sample - loss: 1.6295 - accuracy: 0.3427 - precision: 0.7727 - recall: 0.0399 - val_loss: 1.5840 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8282 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.6274 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.083 - ETA: 0s - loss: 1.5938 - accuracy: 0.3812 - precision: 0.7692 - recall: 0.062 - ETA: 0s - loss: 1.5610 - accuracy: 0.3750 - precision: 0.8125 - recall: 0.058 - ETA: 0s - loss: 1.5391 - accuracy: 0.3889 - precision: 0.8000 - recall: 0.055 - ETA: 0s - loss: 1.5434 - accuracy: 0.3977 - precision: 0.7931 - recall: 0.065 - ETA: 0s - loss: 1.5726 - accuracy: 0.4038 - precision: 0.7576 - recall: 0.060 - 1s 1ms/sample - loss: 1.5786 - accuracy: 0.3991 - precision: 0.7647 - recall: 0.0610 - val_loss: 1.5338 - val_accuracy: 0.3803 - val_precision: 0.8333 - val_recall: 0.1056\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.4540 - accuracy: 0.4167 - precision: 0.5833 - recall: 0.072 - ETA: 0s - loss: 1.5887 - accuracy: 0.3812 - precision: 0.6250 - recall: 0.062 - ETA: 0s - loss: 1.5628 - accuracy: 0.3929 - precision: 0.7391 - recall: 0.075 - ETA: 0s - loss: 1.5597 - accuracy: 0.3958 - precision: 0.7037 - recall: 0.066 - ETA: 0s - loss: 1.5659 - accuracy: 0.3665 - precision: 0.7000 - recall: 0.059 - ETA: 0s - loss: 1.5579 - accuracy: 0.3828 - precision: 0.7353 - recall: 0.065 - 1s 1ms/sample - loss: 1.5548 - accuracy: 0.3920 - precision: 0.7143 - recall: 0.0587 - val_loss: 1.5638 - val_accuracy: 0.3732 - val_precision: 1.0000 - val_recall: 0.0845\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5412 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4415 - accuracy: 0.4375 - precision: 0.9000 - recall: 0.093 - ETA: 0s - loss: 1.4376 - accuracy: 0.4219 - precision: 0.9167 - recall: 0.085 - ETA: 0s - loss: 1.4570 - accuracy: 0.4010 - precision: 0.8750 - recall: 0.072 - ETA: 0s - loss: 1.5347 - accuracy: 0.3672 - precision: 0.8235 - recall: 0.054 - ETA: 0s - loss: 1.5541 - accuracy: 0.3469 - precision: 0.8421 - recall: 0.050 - ETA: 0s - loss: 1.5511 - accuracy: 0.3568 - precision: 0.8400 - recall: 0.054 - 1s 1ms/sample - loss: 1.5294 - accuracy: 0.3638 - precision: 0.8710 - recall: 0.0634 - val_loss: 1.5939 - val_accuracy: 0.2817 - val_precision: 1.0000 - val_recall: 0.0915\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3520 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5003 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.062 - ETA: 0s - loss: 1.5512 - accuracy: 0.3250 - precision: 0.6667 - recall: 0.050 - ETA: 0s - loss: 1.5494 - accuracy: 0.3393 - precision: 0.7391 - recall: 0.075 - ETA: 0s - loss: 1.5262 - accuracy: 0.3555 - precision: 0.7778 - recall: 0.082 - ETA: 0s - loss: 1.5041 - accuracy: 0.3750 - precision: 0.8000 - recall: 0.075 - ETA: 0s - loss: 1.5112 - accuracy: 0.3802 - precision: 0.7812 - recall: 0.065 - 1s 2ms/sample - loss: 1.5282 - accuracy: 0.3732 - precision: 0.7647 - recall: 0.0610 - val_loss: 1.5274 - val_accuracy: 0.4014 - val_precision: 0.9231 - val_recall: 0.0845\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5251 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4294 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.072 - ETA: 0s - loss: 1.4750 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.043 - ETA: 0s - loss: 1.6470 - accuracy: 0.3839 - precision: 0.7273 - recall: 0.035 - ETA: 0s - loss: 1.7013 - accuracy: 0.3194 - precision: 0.5333 - recall: 0.027 - ETA: 0s - loss: 1.7307 - accuracy: 0.3182 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7114 - accuracy: 0.3317 - precision: 0.4839 - recall: 0.036 - 1s 1ms/sample - loss: 1.7107 - accuracy: 0.3310 - precision: 0.4839 - recall: 0.0352 - val_loss: 1.7249 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9033 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7796 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.7125 - accuracy: 0.3313 - precision: 1.0000 - recall: 0.012 - ETA: 0s - loss: 1.6675 - accuracy: 0.3259 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.6572 - accuracy: 0.3229 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.6488 - accuracy: 0.3210 - precision: 1.0000 - recall: 0.005 - ETA: 0s - loss: 1.6587 - accuracy: 0.3099 - precision: 1.0000 - recall: 0.007 - 1s 1ms/sample - loss: 1.6623 - accuracy: 0.3146 - precision: 1.0000 - recall: 0.0070 - val_loss: 1.8115 - val_accuracy: 0.2746 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6888 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7210 - accuracy: 0.3229 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.6528 - accuracy: 0.3375 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.6471 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.5951 - accuracy: 0.3264 - precision: 0.7500 - recall: 0.010 - ETA: 0s - loss: 1.5846 - accuracy: 0.3239 - precision: 0.8333 - recall: 0.014 - ETA: 0s - loss: 1.5796 - accuracy: 0.3173 - precision: 0.6667 - recall: 0.014 - 1s 1ms/sample - loss: 1.5800 - accuracy: 0.3239 - precision: 0.7000 - recall: 0.0164 - val_loss: 1.5432 - val_accuracy: 0.3451 - val_precision: 1.0000 - val_recall: 0.0493\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4510 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.4034 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.4194 - accuracy: 0.4000 - precision: 1.0000 - recall: 0.037 - ETA: 0s - loss: 1.4681 - accuracy: 0.3795 - precision: 1.0000 - recall: 0.026 - ETA: 0s - loss: 1.4530 - accuracy: 0.4028 - precision: 0.8750 - recall: 0.024 - ETA: 0s - loss: 1.4679 - accuracy: 0.3977 - precision: 0.8182 - recall: 0.025 - ETA: 0s - loss: 1.4834 - accuracy: 0.3942 - precision: 0.8333 - recall: 0.024 - 1s 1ms/sample - loss: 1.4944 - accuracy: 0.3897 - precision: 0.7692 - recall: 0.0235 - val_loss: 1.5505 - val_accuracy: 0.3169 - val_precision: 1.0000 - val_recall: 0.0493\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4159 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.4293 - accuracy: 0.4896 - precision: 1.0000 - recall: 0.0417        - ETA: 0s - loss: 1.4483 - accuracy: 0.4531 - precision: 1.0000 - recall: 0.039 - ETA: 0s - loss: 1.4758 - accuracy: 0.4479 - precision: 0.8182 - recall: 0.046 - ETA: 0s - loss: 1.5325 - accuracy: 0.3828 - precision: 0.6667 - recall: 0.039 - ETA: 0s - loss: 1.5299 - accuracy: 0.3625 - precision: 0.6667 - recall: 0.043 - ETA: 0s - loss: 1.5427 - accuracy: 0.3542 - precision: 0.6667 - recall: 0.036 - 1s 1ms/sample - loss: 1.5494 - accuracy: 0.3568 - precision: 0.6818 - recall: 0.0352 - val_loss: 1.5780 - val_accuracy: 0.3944 - val_precision: 0.8750 - val_recall: 0.0493\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4824 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.4794 - accuracy: 0.3750 - precision: 0.8333 - recall: 0.0521        - ETA: 0s - loss: 1.4511 - accuracy: 0.3938 - precision: 0.7500 - recall: 0.056 - ETA: 0s - loss: 1.5122 - accuracy: 0.3750 - precision: 0.7059 - recall: 0.053 - ETA: 0s - loss: 1.5072 - accuracy: 0.3854 - precision: 0.7273 - recall: 0.055 - ETA: 0s - loss: 1.5152 - accuracy: 0.3807 - precision: 0.6667 - recall: 0.056 - ETA: 0s - loss: 1.5112 - accuracy: 0.3828 - precision: 0.6970 - recall: 0.059 - 1s 3ms/sample - loss: 1.4846 - accuracy: 0.3920 - precision: 0.6667 - recall: 0.0610 - val_loss: 1.5615 - val_accuracy: 0.3239 - val_precision: 0.5625 - val_recall: 0.0634\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4405 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.5717 - accuracy: 0.3542 - precision: 0.5455 - recall: 0.062 - ETA: 0s - loss: 1.5143 - accuracy: 0.3938 - precision: 0.6875 - recall: 0.068 - ETA: 0s - loss: 1.5115 - accuracy: 0.3906 - precision: 0.6111 - recall: 0.057 - ETA: 0s - loss: 1.5027 - accuracy: 0.3929 - precision: 0.6500 - recall: 0.058 - ETA: 0s - loss: 1.5097 - accuracy: 0.3867 - precision: 0.6364 - recall: 0.054 - ETA: 0s - loss: 1.4938 - accuracy: 0.3993 - precision: 0.6667 - recall: 0.055 - ETA: 0s - loss: 1.4829 - accuracy: 0.4031 - precision: 0.6400 - recall: 0.050 - ETA: 0s - loss: 1.4655 - accuracy: 0.4148 - precision: 0.6667 - recall: 0.051 - ETA: 0s - loss: 1.4460 - accuracy: 0.4279 - precision: 0.6786 - recall: 0.045 - 1s 2ms/sample - loss: 1.4401 - accuracy: 0.4296 - precision: 0.7000 - recall: 0.0493 - val_loss: 1.5129 - val_accuracy: 0.3099 - val_precision: 0.6923 - val_recall: 0.0634\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2967 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.3625 - accuracy: 0.4479 - precision: 0.7778 - recall: 0.072 - ETA: 0s - loss: 1.3637 - accuracy: 0.4625 - precision: 0.7778 - recall: 0.087 - ETA: 0s - loss: 1.3771 - accuracy: 0.4598 - precision: 0.6364 - recall: 0.093 - ETA: 0s - loss: 1.3736 - accuracy: 0.4583 - precision: 0.7045 - recall: 0.107 - ETA: 0s - loss: 1.3819 - accuracy: 0.4489 - precision: 0.6923 - recall: 0.102 - ETA: 0s - loss: 1.3992 - accuracy: 0.4495 - precision: 0.7241 - recall: 0.101 - 1s 1ms/sample - loss: 1.4002 - accuracy: 0.4437 - precision: 0.7000 - recall: 0.0986 - val_loss: 1.4685 - val_accuracy: 0.3592 - val_precision: 0.9000 - val_recall: 0.0634\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1746 - accuracy: 0.6562 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.4616 - accuracy: 0.3854 - precision: 0.8333 - recall: 0.052 - ETA: 0s - loss: 1.4194 - accuracy: 0.3938 - precision: 0.8571 - recall: 0.037 - ETA: 0s - loss: 1.4017 - accuracy: 0.3839 - precision: 0.8571 - recall: 0.026 - ETA: 0s - loss: 1.4212 - accuracy: 0.3819 - precision: 0.7500 - recall: 0.020 - ETA: 0s - loss: 1.4596 - accuracy: 0.3693 - precision: 0.7000 - recall: 0.019 - ETA: 0s - loss: 1.4617 - accuracy: 0.3726 - precision: 0.7273 - recall: 0.019 - 1s 1ms/sample - loss: 1.4623 - accuracy: 0.3709 - precision: 0.7273 - recall: 0.0188 - val_loss: 1.5362 - val_accuracy: 0.3451 - val_precision: 0.6667 - val_recall: 0.0141\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.4688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.3344 - accuracy: 0.5000 - precision: 0.6000 - recall: 0.0312        - ETA: 0s - loss: 1.4133 - accuracy: 0.4625 - precision: 0.7500 - recall: 0.037 - ETA: 0s - loss: 1.4607 - accuracy: 0.4375 - precision: 0.6154 - recall: 0.035 - ETA: 0s - loss: 1.4688 - accuracy: 0.4201 - precision: 0.4583 - recall: 0.038 - ETA: 0s - loss: 1.4286 - accuracy: 0.4489 - precision: 0.6098 - recall: 0.071 - ETA: 0s - loss: 1.4308 - accuracy: 0.4447 - precision: 0.6170 - recall: 0.069 - 1s 1ms/sample - loss: 1.4273 - accuracy: 0.4460 - precision: 0.6170 - recall: 0.0681 - val_loss: 1.5673 - val_accuracy: 0.3521 - val_precision: 0.6957 - val_recall: 0.1127\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2935 - accuracy: 0.4688 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.3643 - accuracy: 0.5000 - precision: 0.8421 - recall: 0.166 - ETA: 0s - loss: 1.3834 - accuracy: 0.5000 - precision: 0.8519 - recall: 0.143 - ETA: 0s - loss: 1.3688 - accuracy: 0.4955 - precision: 0.8182 - recall: 0.120 - ETA: 0s - loss: 1.3412 - accuracy: 0.5000 - precision: 0.8409 - recall: 0.128 - ETA: 0s - loss: 1.3544 - accuracy: 0.4972 - precision: 0.8136 - recall: 0.136 - ETA: 0s - loss: 1.3745 - accuracy: 0.4832 - precision: 0.7746 - recall: 0.132 - 1s 1ms/sample - loss: 1.3700 - accuracy: 0.4836 - precision: 0.7808 - recall: 0.1338 - val_loss: 1.5110 - val_accuracy: 0.3662 - val_precision: 0.7308 - val_recall: 0.1338\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4609 - accuracy: 0.5312 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.2733 - accuracy: 0.4896 - precision: 0.7143 - recall: 0.208 - ETA: 0s - loss: 1.3037 - accuracy: 0.4750 - precision: 0.7209 - recall: 0.193 - ETA: 0s - loss: 1.3118 - accuracy: 0.4509 - precision: 0.7119 - recall: 0.187 - ETA: 0s - loss: 1.3603 - accuracy: 0.4410 - precision: 0.6806 - recall: 0.170 - ETA: 0s - loss: 1.3388 - accuracy: 0.4716 - precision: 0.7093 - recall: 0.173 - ETA: 0s - loss: 1.3324 - accuracy: 0.4639 - precision: 0.7292 - recall: 0.168 - 1s 1ms/sample - loss: 1.3259 - accuracy: 0.4695 - precision: 0.7320 - recall: 0.1667 - val_loss: 1.4532 - val_accuracy: 0.3732 - val_precision: 0.7500 - val_recall: 0.1690\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4816 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.3776 - accuracy: 0.4688 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.3255 - accuracy: 0.4938 - precision: 0.7714 - recall: 0.168 - ETA: 0s - loss: 1.3031 - accuracy: 0.4911 - precision: 0.7609 - recall: 0.156 - ETA: 0s - loss: 1.2567 - accuracy: 0.5174 - precision: 0.7681 - recall: 0.184 - ETA: 0s - loss: 1.2909 - accuracy: 0.5000 - precision: 0.7209 - recall: 0.176 - ETA: 0s - loss: 1.3045 - accuracy: 0.4952 - precision: 0.7080 - recall: 0.192 - 1s 1ms/sample - loss: 1.3014 - accuracy: 0.4977 - precision: 0.7009 - recall: 0.1925 - val_loss: 1.4362 - val_accuracy: 0.3873 - val_precision: 0.5833 - val_recall: 0.1972\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3381 - accuracy: 0.4688 - precision: 0.5333 - recall: 0.250 - ETA: 0s - loss: 1.2648 - accuracy: 0.5469 - precision: 0.5385 - recall: 0.218 - ETA: 0s - loss: 1.3231 - accuracy: 0.4844 - precision: 0.5455 - recall: 0.187 - ETA: 0s - loss: 1.3551 - accuracy: 0.4740 - precision: 0.6167 - recall: 0.192 - ETA: 0s - loss: 1.3262 - accuracy: 0.4883 - precision: 0.6269 - recall: 0.164 - ETA: 0s - loss: 1.3033 - accuracy: 0.4906 - precision: 0.6506 - recall: 0.168 - ETA: 0s - loss: 1.2881 - accuracy: 0.4948 - precision: 0.6633 - recall: 0.169 - 1s 1ms/sample - loss: 1.2984 - accuracy: 0.4977 - precision: 0.6542 - recall: 0.1643 - val_loss: 1.5278 - val_accuracy: 0.3873 - val_precision: 0.6389 - val_recall: 0.1620\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3630 - accuracy: 0.5000 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.3068 - accuracy: 0.4896 - precision: 0.7391 - recall: 0.177 - ETA: 0s - loss: 1.2136 - accuracy: 0.5312 - precision: 0.7551 - recall: 0.231 - ETA: 0s - loss: 1.2321 - accuracy: 0.5000 - precision: 0.7324 - recall: 0.232 - ETA: 0s - loss: 1.2676 - accuracy: 0.4826 - precision: 0.7021 - recall: 0.229 - ETA: 0s - loss: 1.2858 - accuracy: 0.4744 - precision: 0.6780 - recall: 0.227 - ETA: 0s - loss: 1.2696 - accuracy: 0.4856 - precision: 0.6940 - recall: 0.223 - 1s 1ms/sample - loss: 1.2749 - accuracy: 0.4883 - precision: 0.6963 - recall: 0.2207 - val_loss: 1.3782 - val_accuracy: 0.4366 - val_precision: 0.7368 - val_recall: 0.1972\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2235 - accuracy: 0.4688 - precision: 0.3636 - recall: 0.125 - ETA: 0s - loss: 1.1598 - accuracy: 0.5417 - precision: 0.6071 - recall: 0.177 - ETA: 0s - loss: 1.1622 - accuracy: 0.5562 - precision: 0.6000 - recall: 0.168 - ETA: 0s - loss: 1.1920 - accuracy: 0.5312 - precision: 0.5789 - recall: 0.171 - ETA: 0s - loss: 1.2430 - accuracy: 0.5156 - precision: 0.5753 - recall: 0.164 - ETA: 0s - loss: 1.2801 - accuracy: 0.5125 - precision: 0.5814 - recall: 0.156 - ETA: 0s - loss: 1.2910 - accuracy: 0.5052 - precision: 0.6262 - recall: 0.174 - 1s 1ms/sample - loss: 1.3306 - accuracy: 0.4906 - precision: 0.6032 - recall: 0.1784 - val_loss: 1.4479 - val_accuracy: 0.3592 - val_precision: 0.5614 - val_recall: 0.2254\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2070 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.2786 - accuracy: 0.4479 - precision: 0.5641 - recall: 0.229 - ETA: 0s - loss: 1.2720 - accuracy: 0.4625 - precision: 0.5857 - recall: 0.256 - ETA: 0s - loss: 1.3628 - accuracy: 0.4241 - precision: 0.5474 - recall: 0.232 - ETA: 0s - loss: 1.3572 - accuracy: 0.4410 - precision: 0.5528 - recall: 0.236 - ETA: 0s - loss: 1.3302 - accuracy: 0.4489 - precision: 0.5714 - recall: 0.238 - ETA: 0s - loss: 1.3249 - accuracy: 0.4609 - precision: 0.5839 - recall: 0.244 - ETA: 0s - loss: 1.3065 - accuracy: 0.4736 - precision: 0.6000 - recall: 0.245 - 1s 2ms/sample - loss: 1.3107 - accuracy: 0.4718 - precision: 0.6069 - recall: 0.2465 - val_loss: 1.4956 - val_accuracy: 0.3944 - val_precision: 0.5333 - val_recall: 0.1690\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2750 - accuracy: 0.4688 - precision: 0.5882 - recall: 0.312 - ETA: 0s - loss: 1.4092 - accuracy: 0.4479 - precision: 0.5122 - recall: 0.218 - ETA: 0s - loss: 1.3910 - accuracy: 0.4375 - precision: 0.5102 - recall: 0.195 - ETA: 0s - loss: 1.3565 - accuracy: 0.4583 - precision: 0.5915 - recall: 0.218 - ETA: 0s - loss: 1.3462 - accuracy: 0.4648 - precision: 0.6265 - recall: 0.203 - ETA: 0s - loss: 1.3418 - accuracy: 0.4688 - precision: 0.6489 - recall: 0.190 - ETA: 0s - loss: 1.3117 - accuracy: 0.4792 - precision: 0.6538 - recall: 0.177 - 1s 2ms/sample - loss: 1.2983 - accuracy: 0.4812 - precision: 0.6667 - recall: 0.1737 - val_loss: 1.3839 - val_accuracy: 0.4366 - val_precision: 0.7727 - val_recall: 0.1197\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2925 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.1953 - accuracy: 0.6042 - precision: 0.7619 - recall: 0.166 - ETA: 0s - loss: 1.1782 - accuracy: 0.5500 - precision: 0.7879 - recall: 0.162 - ETA: 0s - loss: 1.1655 - accuracy: 0.5536 - precision: 0.7966 - recall: 0.209 - ETA: 0s - loss: 1.1788 - accuracy: 0.5417 - precision: 0.7619 - recall: 0.222 - ETA: 0s - loss: 1.1656 - accuracy: 0.5398 - precision: 0.7400 - recall: 0.210 - ETA: 0s - loss: 1.1792 - accuracy: 0.5385 - precision: 0.7381 - recall: 0.223 - 1s 2ms/sample - loss: 1.1805 - accuracy: 0.5352 - precision: 0.7252 - recall: 0.2230 - val_loss: 1.3745 - val_accuracy: 0.4437 - val_precision: 0.7200 - val_recall: 0.2535\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1885 - accuracy: 0.5000 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.1086 - accuracy: 0.5417 - precision: 0.6667 - recall: 0.208 - ETA: 0s - loss: 1.1807 - accuracy: 0.4875 - precision: 0.6481 - recall: 0.218 - ETA: 0s - loss: 1.2112 - accuracy: 0.5045 - precision: 0.7073 - recall: 0.258 - ETA: 0s - loss: 1.2149 - accuracy: 0.5243 - precision: 0.7064 - recall: 0.267 - ETA: 0s - loss: 1.1994 - accuracy: 0.5281 - precision: 0.7040 - recall: 0.275 - ETA: 0s - loss: 1.1922 - accuracy: 0.5312 - precision: 0.6981 - recall: 0.289 - 1s 1ms/sample - loss: 1.2037 - accuracy: 0.5164 - precision: 0.7000 - recall: 0.2793 - val_loss: 1.3810 - val_accuracy: 0.4437 - val_precision: 0.6341 - val_recall: 0.1831\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1520 - accuracy: 0.3750 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.1718 - accuracy: 0.5312 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.1965 - accuracy: 0.5250 - precision: 0.7872 - recall: 0.231 - ETA: 0s - loss: 1.1654 - accuracy: 0.5402 - precision: 0.7846 - recall: 0.227 - ETA: 0s - loss: 1.1494 - accuracy: 0.5486 - precision: 0.7778 - recall: 0.243 - ETA: 0s - loss: 1.1822 - accuracy: 0.5256 - precision: 0.7664 - recall: 0.233 - ETA: 0s - loss: 1.1786 - accuracy: 0.5361 - precision: 0.7734 - recall: 0.238 - 1s 1ms/sample - loss: 1.1784 - accuracy: 0.5376 - precision: 0.7744 - recall: 0.2418 - val_loss: 1.2454 - val_accuracy: 0.4930 - val_precision: 0.7447 - val_recall: 0.2465\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0244 - accuracy: 0.6875 - precision: 0.6923 - recall: 0.281 - ETA: 0s - loss: 1.0650 - accuracy: 0.6354 - precision: 0.7714 - recall: 0.281 - ETA: 0s - loss: 1.0498 - accuracy: 0.6187 - precision: 0.8167 - recall: 0.306 - ETA: 0s - loss: 1.0542 - accuracy: 0.6071 - precision: 0.7738 - recall: 0.290 - ETA: 0s - loss: 1.0467 - accuracy: 0.5938 - precision: 0.7456 - recall: 0.295 - ETA: 0s - loss: 1.0706 - accuracy: 0.5852 - precision: 0.7338 - recall: 0.321 - ETA: 0s - loss: 1.0877 - accuracy: 0.5817 - precision: 0.7158 - recall: 0.326 - 1s 1ms/sample - loss: 1.0942 - accuracy: 0.5775 - precision: 0.7092 - recall: 0.3263 - val_loss: 1.3359 - val_accuracy: 0.4366 - val_precision: 0.5672 - val_recall: 0.2676\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9879 - accuracy: 0.5938 - precision: 0.6667 - recall: 0.375 - ETA: 0s - loss: 1.1697 - accuracy: 0.5312 - precision: 0.6250 - recall: 0.312 - ETA: 0s - loss: 1.1689 - accuracy: 0.5625 - precision: 0.6716 - recall: 0.281 - ETA: 0s - loss: 1.1405 - accuracy: 0.5714 - precision: 0.7089 - recall: 0.250 - ETA: 0s - loss: 1.0879 - accuracy: 0.5868 - precision: 0.7596 - recall: 0.274 - ETA: 0s - loss: 1.0909 - accuracy: 0.5682 - precision: 0.7840 - recall: 0.278 - ETA: 0s - loss: 1.1015 - accuracy: 0.5601 - precision: 0.7671 - recall: 0.269 - 1s 2ms/sample - loss: 1.0992 - accuracy: 0.5610 - precision: 0.7703 - recall: 0.2676 - val_loss: 1.2597 - val_accuracy: 0.5141 - val_precision: 0.6809 - val_recall: 0.2254\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 2s - loss: 1.2050 - accuracy: 0.4688 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.1651 - accuracy: 0.5312 - precision: 0.6471 - recall: 0.229 - ETA: 0s - loss: 1.1226 - accuracy: 0.5688 - precision: 0.6923 - recall: 0.281 - ETA: 0s - loss: 1.0919 - accuracy: 0.5670 - precision: 0.6869 - recall: 0.303 - ETA: 0s - loss: 1.0941 - accuracy: 0.5764 - precision: 0.6894 - recall: 0.316 - ETA: 0s - loss: 1.1120 - accuracy: 0.5653 - precision: 0.6748 - recall: 0.312 - ETA: 0s - loss: 1.1383 - accuracy: 0.5553 - precision: 0.6634 - recall: 0.322 - 1s 2ms/sample - loss: 1.1449 - accuracy: 0.5563 - precision: 0.6603 - recall: 0.3239 - val_loss: 1.4116 - val_accuracy: 0.4718 - val_precision: 0.5867 - val_recall: 0.3099\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0423 - accuracy: 0.6250 - precision: 0.7143 - recall: 0.468 - ETA: 0s - loss: 1.1040 - accuracy: 0.5521 - precision: 0.6875 - recall: 0.343 - ETA: 0s - loss: 1.1132 - accuracy: 0.5500 - precision: 0.7000 - recall: 0.350 - ETA: 0s - loss: 1.1322 - accuracy: 0.5446 - precision: 0.6923 - recall: 0.321 - ETA: 0s - loss: 1.1424 - accuracy: 0.5417 - precision: 0.7165 - recall: 0.316 - ETA: 0s - loss: 1.1647 - accuracy: 0.5398 - precision: 0.7078 - recall: 0.309 - ETA: 0s - loss: 1.1259 - accuracy: 0.5553 - precision: 0.7174 - recall: 0.317 - 1s 1ms/sample - loss: 1.1322 - accuracy: 0.5516 - precision: 0.7105 - recall: 0.3169 - val_loss: 1.2971 - val_accuracy: 0.5000 - val_precision: 0.6607 - val_recall: 0.2606\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1399 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.3591 - accuracy: 0.4583 - precision: 0.6486 - recall: 0.250 - ETA: 0s - loss: 1.5530 - accuracy: 0.4125 - precision: 0.5625 - recall: 0.225 - ETA: 0s - loss: 1.5587 - accuracy: 0.4196 - precision: 0.5663 - recall: 0.209 - ETA: 0s - loss: 1.5732 - accuracy: 0.4141 - precision: 0.5532 - recall: 0.203 - ETA: 0s - loss: 1.6104 - accuracy: 0.4094 - precision: 0.5385 - recall: 0.196 - ETA: 0s - loss: 1.5666 - accuracy: 0.4193 - precision: 0.5214 - recall: 0.190 - 1s 1ms/sample - loss: 1.5344 - accuracy: 0.4296 - precision: 0.5337 - recall: 0.2042 - val_loss: 1.4593 - val_accuracy: 0.4577 - val_precision: 0.5455 - val_recall: 0.2958\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2478 - accuracy: 0.5312 - precision: 0.6111 - recall: 0.343 - ETA: 0s - loss: 1.4458 - accuracy: 0.4688 - precision: 0.5636 - recall: 0.322 - ETA: 0s - loss: 1.4123 - accuracy: 0.4750 - precision: 0.5638 - recall: 0.331 - ETA: 0s - loss: 1.4336 - accuracy: 0.4643 - precision: 0.5520 - recall: 0.308 - ETA: 0s - loss: 1.4108 - accuracy: 0.4653 - precision: 0.5478 - recall: 0.298 - ETA: 0s - loss: 1.3875 - accuracy: 0.4688 - precision: 0.5655 - recall: 0.296 - ETA: 0s - loss: 1.3461 - accuracy: 0.4830 - precision: 0.5824 - recall: 0.301 - ETA: 0s - loss: 1.3298 - accuracy: 0.4922 - precision: 0.5970 - recall: 0.312 - ETA: 0s - loss: 1.3117 - accuracy: 0.5000 - precision: 0.6083 - recall: 0.317 - 1s 2ms/sample - loss: 1.3077 - accuracy: 0.5023 - precision: 0.6126 - recall: 0.3192 - val_loss: 1.3288 - val_accuracy: 0.4225 - val_precision: 0.6833 - val_recall: 0.2887\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1119 - accuracy: 0.6562 - precision: 0.6154 - recall: 0.250 - ETA: 0s - loss: 1.1552 - accuracy: 0.5312 - precision: 0.6216 - recall: 0.239 - ETA: 0s - loss: 1.1462 - accuracy: 0.5375 - precision: 0.6406 - recall: 0.256 - ETA: 0s - loss: 1.1592 - accuracy: 0.5268 - precision: 0.6556 - recall: 0.263 - ETA: 0s - loss: 1.1630 - accuracy: 0.5347 - precision: 0.6514 - recall: 0.246 - ETA: 0s - loss: 1.1565 - accuracy: 0.5500 - precision: 0.6694 - recall: 0.259 - ETA: 0s - loss: 1.1562 - accuracy: 0.5511 - precision: 0.6667 - recall: 0.267 - ETA: 0s - loss: 1.1522 - accuracy: 0.5577 - precision: 0.6790 - recall: 0.264 - 1s 2ms/sample - loss: 1.1500 - accuracy: 0.5610 - precision: 0.6848 - recall: 0.2653 - val_loss: 1.2907 - val_accuracy: 0.5000 - val_precision: 0.6406 - val_recall: 0.2887\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1652 - accuracy: 0.5625 - precision: 0.8571 - recall: 0.375 - ETA: 0s - loss: 1.1872 - accuracy: 0.5469 - precision: 0.6667 - recall: 0.343 - ETA: 0s - loss: 1.1404 - accuracy: 0.5417 - precision: 0.6667 - recall: 0.333 - ETA: 0s - loss: 1.1567 - accuracy: 0.5437 - precision: 0.6538 - recall: 0.318 - ETA: 0s - loss: 1.1377 - accuracy: 0.5573 - precision: 0.6374 - recall: 0.302 - ETA: 0s - loss: 1.1557 - accuracy: 0.5508 - precision: 0.6303 - recall: 0.293 - ETA: 0s - loss: 1.1580 - accuracy: 0.5556 - precision: 0.6343 - recall: 0.295 - ETA: 0s - loss: 1.1414 - accuracy: 0.5568 - precision: 0.6503 - recall: 0.301 - ETA: 0s - loss: 1.1149 - accuracy: 0.5841 - precision: 0.6804 - recall: 0.317 - 1s 2ms/sample - loss: 1.1162 - accuracy: 0.5845 - precision: 0.6869 - recall: 0.3192 - val_loss: 1.2338 - val_accuracy: 0.5282 - val_precision: 0.7660 - val_recall: 0.2535\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5224 - accuracy: 0.4062 - precision: 0.3333 - recall: 0.125 - ETA: 0s - loss: 1.2237 - accuracy: 0.5208 - precision: 0.6970 - recall: 0.239 - ETA: 0s - loss: 1.1833 - accuracy: 0.5250 - precision: 0.7037 - recall: 0.237 - ETA: 0s - loss: 1.1357 - accuracy: 0.5469 - precision: 0.7429 - recall: 0.270 - ETA: 0s - loss: 1.1647 - accuracy: 0.5391 - precision: 0.7143 - recall: 0.273 - ETA: 0s - loss: 1.1121 - accuracy: 0.5719 - precision: 0.7463 - recall: 0.312 - ETA: 0s - loss: 1.1147 - accuracy: 0.5755 - precision: 0.7284 - recall: 0.307 - 1s 2ms/sample - loss: 1.1169 - accuracy: 0.5775 - precision: 0.7189 - recall: 0.3122 - val_loss: 1.2466 - val_accuracy: 0.5352 - val_precision: 0.6716 - val_recall: 0.3169\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.0645 - accuracy: 0.5625 - precision: 0.7222 - recall: 0.406 - ETA: 0s - loss: 0.9851 - accuracy: 0.6250 - precision: 0.8182 - recall: 0.421 - ETA: 0s - loss: 1.1160 - accuracy: 0.6094 - precision: 0.6986 - recall: 0.398 - ETA: 0s - loss: 1.1077 - accuracy: 0.5938 - precision: 0.6989 - recall: 0.406 - ETA: 0s - loss: 1.0711 - accuracy: 0.6071 - precision: 0.6970 - recall: 0.410 - ETA: 0s - loss: 1.0706 - accuracy: 0.6042 - precision: 0.6826 - recall: 0.395 - ETA: 0s - loss: 1.0641 - accuracy: 0.6094 - precision: 0.6813 - recall: 0.387 - ETA: 0s - loss: 1.0477 - accuracy: 0.6193 - precision: 0.6829 - recall: 0.397 - ETA: 0s - loss: 1.0508 - accuracy: 0.6178 - precision: 0.6851 - recall: 0.387 - 1s 3ms/sample - loss: 1.0508 - accuracy: 0.6150 - precision: 0.6888 - recall: 0.3897 - val_loss: 1.2039 - val_accuracy: 0.5563 - val_precision: 0.6757 - val_recall: 0.3521\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0660 - accuracy: 0.6250 - precision: 0.7368 - recall: 0.437 - ETA: 0s - loss: 1.0735 - accuracy: 0.6042 - precision: 0.7241 - recall: 0.437 - ETA: 0s - loss: 0.9457 - accuracy: 0.6625 - precision: 0.8041 - recall: 0.487 - ETA: 0s - loss: 0.9815 - accuracy: 0.6473 - precision: 0.7571 - recall: 0.473 - ETA: 0s - loss: 0.9787 - accuracy: 0.6424 - precision: 0.7459 - recall: 0.468 - ETA: 0s - loss: 0.9860 - accuracy: 0.6165 - precision: 0.7143 - recall: 0.454 - ETA: 0s - loss: 0.9770 - accuracy: 0.6274 - precision: 0.7300 - recall: 0.461 - 1s 2ms/sample - loss: 0.9707 - accuracy: 0.6291 - precision: 0.7333 - recall: 0.4648 - val_loss: 1.1746 - val_accuracy: 0.5634 - val_precision: 0.6437 - val_recall: 0.3944\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9752 - accuracy: 0.6250 - precision: 0.7727 - recall: 0.531 - ETA: 0s - loss: 0.8985 - accuracy: 0.6667 - precision: 0.8000 - recall: 0.541 - ETA: 0s - loss: 0.9376 - accuracy: 0.6500 - precision: 0.8085 - recall: 0.475 - ETA: 0s - loss: 0.9329 - accuracy: 0.6473 - precision: 0.7826 - recall: 0.482 - ETA: 0s - loss: 0.9449 - accuracy: 0.6389 - precision: 0.7527 - recall: 0.475 - ETA: 0s - loss: 0.9305 - accuracy: 0.6506 - precision: 0.7577 - recall: 0.488 - ETA: 0s - loss: 0.9507 - accuracy: 0.6322 - precision: 0.7396 - recall: 0.471 - 1s 1ms/sample - loss: 0.9548 - accuracy: 0.6315 - precision: 0.7390 - recall: 0.4718 - val_loss: 1.2346 - val_accuracy: 0.5141 - val_precision: 0.5814 - val_recall: 0.3521\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9327 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.8990 - accuracy: 0.6667 - precision: 0.7361 - recall: 0.552 - ETA: 0s - loss: 0.9645 - accuracy: 0.6625 - precision: 0.7143 - recall: 0.500 - ETA: 0s - loss: 0.9728 - accuracy: 0.6518 - precision: 0.7107 - recall: 0.504 - ETA: 0s - loss: 0.9445 - accuracy: 0.6562 - precision: 0.7313 - recall: 0.510 - ETA: 0s - loss: 0.9730 - accuracy: 0.6364 - precision: 0.7295 - recall: 0.505 - ETA: 0s - loss: 0.9630 - accuracy: 0.6298 - precision: 0.7213 - recall: 0.497 - 1s 1ms/sample - loss: 0.9658 - accuracy: 0.6291 - precision: 0.7133 - recall: 0.4906 - val_loss: 1.3452 - val_accuracy: 0.5423 - val_precision: 0.5543 - val_recall: 0.3592\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1155 - accuracy: 0.6250 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.9610 - accuracy: 0.6667 - precision: 0.7733 - recall: 0.604 - ETA: 0s - loss: 1.0913 - accuracy: 0.6125 - precision: 0.6750 - recall: 0.506 - ETA: 0s - loss: 1.1562 - accuracy: 0.6027 - precision: 0.6792 - recall: 0.482 - ETA: 0s - loss: 1.2055 - accuracy: 0.5729 - precision: 0.6700 - recall: 0.465 - ETA: 0s - loss: 1.1854 - accuracy: 0.5710 - precision: 0.6809 - recall: 0.454 - ETA: 0s - loss: 1.1827 - accuracy: 0.5673 - precision: 0.6703 - recall: 0.449 - 1s 1ms/sample - loss: 1.1742 - accuracy: 0.5728 - precision: 0.6749 - recall: 0.4484 - val_loss: 1.4481 - val_accuracy: 0.4225 - val_precision: 0.5062 - val_recall: 0.2887\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9562 - accuracy: 0.6250 - precision: 0.6522 - recall: 0.468 - ETA: 0s - loss: 1.1671 - accuracy: 0.5625 - precision: 0.6290 - recall: 0.406 - ETA: 0s - loss: 1.1902 - accuracy: 0.5813 - precision: 0.6139 - recall: 0.387 - ETA: 0s - loss: 1.2398 - accuracy: 0.5536 - precision: 0.5793 - recall: 0.375 - ETA: 0s - loss: 1.1834 - accuracy: 0.5660 - precision: 0.6022 - recall: 0.388 - ETA: 0s - loss: 1.1688 - accuracy: 0.5653 - precision: 0.5983 - recall: 0.397 - ETA: 0s - loss: 1.1538 - accuracy: 0.5697 - precision: 0.6084 - recall: 0.418 - 1s 1ms/sample - loss: 1.1487 - accuracy: 0.5728 - precision: 0.6136 - recall: 0.4249 - val_loss: 1.4855 - val_accuracy: 0.4366 - val_precision: 0.4608 - val_recall: 0.3310\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3996 - accuracy: 0.4688 - precision: 0.5294 - recall: 0.281 - ETA: 0s - loss: 1.1535 - accuracy: 0.5833 - precision: 0.6562 - recall: 0.437 - ETA: 0s - loss: 1.1610 - accuracy: 0.5625 - precision: 0.6355 - recall: 0.425 - ETA: 0s - loss: 1.1113 - accuracy: 0.5982 - precision: 0.6533 - recall: 0.437 - ETA: 0s - loss: 1.0923 - accuracy: 0.5764 - precision: 0.6354 - recall: 0.423 - ETA: 0s - loss: 1.0739 - accuracy: 0.5938 - precision: 0.6511 - recall: 0.434 - ETA: 0s - loss: 1.0667 - accuracy: 0.5913 - precision: 0.6464 - recall: 0.435 - 1s 2ms/sample - loss: 1.0588 - accuracy: 0.5915 - precision: 0.6481 - recall: 0.4366 - val_loss: 1.2405 - val_accuracy: 0.5282 - val_precision: 0.5567 - val_recall: 0.3803\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9303 - accuracy: 0.7188 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 1.0011 - accuracy: 0.6250 - precision: 0.7313 - recall: 0.510 - ETA: 0s - loss: 1.0263 - accuracy: 0.6250 - precision: 0.7156 - recall: 0.487 - ETA: 0s - loss: 1.0352 - accuracy: 0.6250 - precision: 0.7161 - recall: 0.495 - ETA: 0s - loss: 1.0507 - accuracy: 0.5972 - precision: 0.6915 - recall: 0.482 - ETA: 0s - loss: 1.0310 - accuracy: 0.5881 - precision: 0.6800 - recall: 0.483 - ETA: 0s - loss: 1.0250 - accuracy: 0.5938 - precision: 0.6801 - recall: 0.485 - 1s 1ms/sample - loss: 1.0267 - accuracy: 0.5915 - precision: 0.6766 - recall: 0.4812 - val_loss: 1.3105 - val_accuracy: 0.4718 - val_precision: 0.5229 - val_recall: 0.4014\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1176 - accuracy: 0.5938 - precision: 0.8000 - recall: 0.500 - ETA: 0s - loss: 1.0821 - accuracy: 0.5938 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 1.0419 - accuracy: 0.6354 - precision: 0.7692 - recall: 0.520 - ETA: 0s - loss: 1.0216 - accuracy: 0.6187 - precision: 0.7387 - recall: 0.512 - ETA: 0s - loss: 0.9975 - accuracy: 0.6473 - precision: 0.7325 - recall: 0.513 - ETA: 0s - loss: 1.0120 - accuracy: 0.6215 - precision: 0.7143 - recall: 0.503 - ETA: 0s - loss: 0.9888 - accuracy: 0.6344 - precision: 0.7205 - recall: 0.515 - ETA: 0s - loss: 0.9711 - accuracy: 0.6354 - precision: 0.7168 - recall: 0.520 - 1s 2ms/sample - loss: 0.9697 - accuracy: 0.6338 - precision: 0.7188 - recall: 0.5282 - val_loss: 1.2465 - val_accuracy: 0.5493 - val_precision: 0.6105 - val_recall: 0.4085\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.5312 - precision: 0.6522 - recall: 0.468 - ETA: 0s - loss: 0.9445 - accuracy: 0.6667 - precision: 0.7536 - recall: 0.541 - ETA: 0s - loss: 0.9549 - accuracy: 0.6328 - precision: 0.7191 - recall: 0.500 - ETA: 0s - loss: 1.0104 - accuracy: 0.6042 - precision: 0.6846 - recall: 0.463 - ETA: 0s - loss: 0.9780 - accuracy: 0.6211 - precision: 0.6941 - recall: 0.460 - ETA: 0s - loss: 0.9743 - accuracy: 0.6156 - precision: 0.7123 - recall: 0.471 - ETA: 0s - loss: 0.9713 - accuracy: 0.6250 - precision: 0.7198 - recall: 0.474 - ETA: 0s - loss: 0.9455 - accuracy: 0.6370 - precision: 0.7338 - recall: 0.490 - 1s 1ms/sample - loss: 0.9397 - accuracy: 0.6432 - precision: 0.7387 - recall: 0.4977 - val_loss: 1.2488 - val_accuracy: 0.5423 - val_precision: 0.6136 - val_recall: 0.3803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.6875 - precision: 0.8000 - recall: 0.500 - ETA: 0s - loss: 0.9337 - accuracy: 0.6771 - precision: 0.7368 - recall: 0.583 - ETA: 0s - loss: 0.9215 - accuracy: 0.6750 - precision: 0.7438 - recall: 0.562 - ETA: 0s - loss: 0.9421 - accuracy: 0.6607 - precision: 0.7484 - recall: 0.531 - ETA: 0s - loss: 0.9409 - accuracy: 0.6493 - precision: 0.7295 - recall: 0.524 - ETA: 0s - loss: 0.9326 - accuracy: 0.6562 - precision: 0.7350 - recall: 0.537 - ETA: 0s - loss: 0.9277 - accuracy: 0.6562 - precision: 0.7359 - recall: 0.544 - 1s 1ms/sample - loss: 0.9435 - accuracy: 0.6455 - precision: 0.7224 - recall: 0.5376 - val_loss: 1.3002 - val_accuracy: 0.5000 - val_precision: 0.5596 - val_recall: 0.4296\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8843 - accuracy: 0.6875 - precision: 0.7500 - recall: 0.562 - ETA: 0s - loss: 1.0944 - accuracy: 0.6250 - precision: 0.6486 - recall: 0.500 - ETA: 0s - loss: 1.1098 - accuracy: 0.6000 - precision: 0.6364 - recall: 0.481 - ETA: 0s - loss: 1.0774 - accuracy: 0.6295 - precision: 0.6786 - recall: 0.508 - ETA: 0s - loss: 1.0411 - accuracy: 0.6146 - precision: 0.6842 - recall: 0.496 - ETA: 0s - loss: 1.0257 - accuracy: 0.6136 - precision: 0.7102 - recall: 0.494 - ETA: 0s - loss: 1.0240 - accuracy: 0.6178 - precision: 0.6997 - recall: 0.492 - 1s 2ms/sample - loss: 1.0121 - accuracy: 0.6221 - precision: 0.7043 - recall: 0.4977 - val_loss: 1.2057 - val_accuracy: 0.5282 - val_precision: 0.6162 - val_recall: 0.4296\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.7188 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.7990 - accuracy: 0.7083 - precision: 0.7971 - recall: 0.572 - ETA: 0s - loss: 0.8135 - accuracy: 0.7000 - precision: 0.7899 - recall: 0.587 - ETA: 0s - loss: 0.8719 - accuracy: 0.6823 - precision: 0.7786 - recall: 0.567 - ETA: 0s - loss: 0.8628 - accuracy: 0.6836 - precision: 0.7814 - recall: 0.558 - ETA: 0s - loss: 0.8710 - accuracy: 0.6781 - precision: 0.7763 - recall: 0.553 - ETA: 0s - loss: 0.8911 - accuracy: 0.6589 - precision: 0.7675 - recall: 0.541 - 1s 2ms/sample - loss: 0.8927 - accuracy: 0.6643 - precision: 0.7664 - recall: 0.5469 - val_loss: 1.2859 - val_accuracy: 0.5211 - val_precision: 0.5859 - val_recall: 0.4085\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.7812 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.7785 - accuracy: 0.7500 - precision: 0.8451 - recall: 0.625 - ETA: 0s - loss: 0.7798 - accuracy: 0.7578 - precision: 0.8511 - recall: 0.625 - ETA: 0s - loss: 0.8137 - accuracy: 0.7292 - precision: 0.8201 - recall: 0.593 - ETA: 0s - loss: 0.8547 - accuracy: 0.6914 - precision: 0.7747 - recall: 0.550 - ETA: 0s - loss: 0.8612 - accuracy: 0.6875 - precision: 0.7725 - recall: 0.562 - ETA: 0s - loss: 0.8716 - accuracy: 0.6875 - precision: 0.7743 - recall: 0.565 - ETA: 0s - loss: 0.8811 - accuracy: 0.6755 - precision: 0.7565 - recall: 0.560 - 1s 2ms/sample - loss: 0.8849 - accuracy: 0.6737 - precision: 0.7563 - recall: 0.5610 - val_loss: 1.4173 - val_accuracy: 0.5000 - val_precision: 0.6162 - val_recall: 0.4296\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8279 - accuracy: 0.7500 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 1.0804 - accuracy: 0.6458 - precision: 0.7576 - recall: 0.520 - ETA: 0s - loss: 1.0679 - accuracy: 0.6250 - precision: 0.7207 - recall: 0.500 - ETA: 0s - loss: 1.0181 - accuracy: 0.6384 - precision: 0.7451 - recall: 0.508 - ETA: 0s - loss: 1.0150 - accuracy: 0.6319 - precision: 0.7050 - recall: 0.489 - ETA: 0s - loss: 1.0269 - accuracy: 0.6364 - precision: 0.7061 - recall: 0.491 - ETA: 0s - loss: 1.0337 - accuracy: 0.6250 - precision: 0.7038 - recall: 0.485 - 1s 1ms/sample - loss: 1.0376 - accuracy: 0.6268 - precision: 0.7027 - recall: 0.4883 - val_loss: 1.1868 - val_accuracy: 0.5423 - val_precision: 0.5918 - val_recall: 0.4085\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.7188 - precision: 0.7857 - recall: 0.687 - ETA: 0s - loss: 0.8562 - accuracy: 0.6979 - precision: 0.7568 - recall: 0.583 - ETA: 0s - loss: 0.8108 - accuracy: 0.7000 - precision: 0.7686 - recall: 0.581 - ETA: 0s - loss: 0.9262 - accuracy: 0.6518 - precision: 0.7317 - recall: 0.535 - ETA: 0s - loss: 0.9798 - accuracy: 0.6354 - precision: 0.7220 - recall: 0.513 - ETA: 0s - loss: 0.9884 - accuracy: 0.6364 - precision: 0.7097 - recall: 0.500 - ETA: 0s - loss: 0.9828 - accuracy: 0.6370 - precision: 0.7113 - recall: 0.497 - 1s 1ms/sample - loss: 0.9794 - accuracy: 0.6385 - precision: 0.7114 - recall: 0.4977 - val_loss: 1.1803 - val_accuracy: 0.5634 - val_precision: 0.5978 - val_recall: 0.3873\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9583 - accuracy: 0.6562 - precision: 0.6800 - recall: 0.531 - ETA: 0s - loss: 0.9199 - accuracy: 0.6667 - precision: 0.7432 - recall: 0.572 - ETA: 0s - loss: 0.9219 - accuracy: 0.6375 - precision: 0.7748 - recall: 0.537 - ETA: 0s - loss: 0.9565 - accuracy: 0.6205 - precision: 0.7548 - recall: 0.522 - ETA: 0s - loss: 0.9199 - accuracy: 0.6319 - precision: 0.7512 - recall: 0.545 - ETA: 0s - loss: 0.9322 - accuracy: 0.6335 - precision: 0.7375 - recall: 0.542 - ETA: 0s - loss: 0.9171 - accuracy: 0.6394 - precision: 0.7387 - recall: 0.550 - 1s 1ms/sample - loss: 0.9151 - accuracy: 0.6408 - precision: 0.7398 - recall: 0.5540 - val_loss: 1.2339 - val_accuracy: 0.5563 - val_precision: 0.5962 - val_recall: 0.4366\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.5938 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.8519 - accuracy: 0.6354 - precision: 0.7162 - recall: 0.552 - ETA: 0s - loss: 0.8312 - accuracy: 0.6687 - precision: 0.7520 - recall: 0.587 - ETA: 0s - loss: 0.8221 - accuracy: 0.6830 - precision: 0.7500 - recall: 0.589 - ETA: 0s - loss: 0.8220 - accuracy: 0.6914 - precision: 0.7586 - recall: 0.601 - ETA: 0s - loss: 0.8771 - accuracy: 0.6656 - precision: 0.7227 - recall: 0.578 - ETA: 0s - loss: 0.8543 - accuracy: 0.6797 - precision: 0.7435 - recall: 0.596 - 1s 1ms/sample - loss: 0.8790 - accuracy: 0.6737 - precision: 0.7404 - recall: 0.5892 - val_loss: 1.1781 - val_accuracy: 0.5634 - val_precision: 0.6250 - val_recall: 0.4930\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1241 - accuracy: 0.5938 - precision: 0.6429 - recall: 0.562 - ETA: 0s - loss: 0.9395 - accuracy: 0.6250 - precision: 0.6747 - recall: 0.583 - ETA: 0s - loss: 0.9367 - accuracy: 0.6125 - precision: 0.6818 - recall: 0.562 - ETA: 0s - loss: 0.9390 - accuracy: 0.6146 - precision: 0.6812 - recall: 0.567 - ETA: 0s - loss: 0.9290 - accuracy: 0.6211 - precision: 0.6967 - recall: 0.574 - ETA: 0s - loss: 0.9350 - accuracy: 0.6344 - precision: 0.6965 - recall: 0.559 - ETA: 0s - loss: 0.9287 - accuracy: 0.6406 - precision: 0.7036 - recall: 0.562 - 1s 1ms/sample - loss: 0.9033 - accuracy: 0.6549 - precision: 0.7159 - recall: 0.5798 - val_loss: 1.3301 - val_accuracy: 0.4789 - val_precision: 0.5155 - val_recall: 0.3521\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3160 - accuracy: 0.4062 - precision: 0.3846 - recall: 0.312 - ETA: 0s - loss: 1.1378 - accuracy: 0.5521 - precision: 0.5205 - recall: 0.395 - ETA: 0s - loss: 1.0819 - accuracy: 0.5750 - precision: 0.5847 - recall: 0.431 - ETA: 0s - loss: 1.0075 - accuracy: 0.6027 - precision: 0.6627 - recall: 0.491 - ETA: 0s - loss: 0.9889 - accuracy: 0.6042 - precision: 0.6714 - recall: 0.496 - ETA: 0s - loss: 0.9853 - accuracy: 0.6031 - precision: 0.6736 - recall: 0.503 - ETA: 0s - loss: 0.9540 - accuracy: 0.6224 - precision: 0.6864 - recall: 0.513 - 1s 2ms/sample - loss: 0.9553 - accuracy: 0.6244 - precision: 0.6943 - recall: 0.5117 - val_loss: 1.1715 - val_accuracy: 0.5211 - val_precision: 0.6263 - val_recall: 0.4366\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8455 - accuracy: 0.6562 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.8008 - accuracy: 0.6875 - precision: 0.8056 - recall: 0.604 - ETA: 0s - loss: 0.8450 - accuracy: 0.6750 - precision: 0.7833 - recall: 0.587 - ETA: 0s - loss: 0.8716 - accuracy: 0.6615 - precision: 0.7603 - recall: 0.578 - ETA: 0s - loss: 0.8981 - accuracy: 0.6484 - precision: 0.7385 - recall: 0.562 - ETA: 0s - loss: 0.8986 - accuracy: 0.6531 - precision: 0.7469 - recall: 0.571 - ETA: 0s - loss: 0.8850 - accuracy: 0.6648 - precision: 0.7509 - recall: 0.573 - ETA: 0s - loss: 0.8638 - accuracy: 0.6707 - precision: 0.7604 - recall: 0.572 - 1s 2ms/sample - loss: 0.8518 - accuracy: 0.6761 - precision: 0.7664 - recall: 0.5775 - val_loss: 1.2531 - val_accuracy: 0.5423 - val_precision: 0.5619 - val_recall: 0.4155\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6468 - accuracy: 0.7812 - precision: 0.7857 - recall: 0.687 - ETA: 0s - loss: 0.6975 - accuracy: 0.7708 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.7599 - accuracy: 0.7250 - precision: 0.7727 - recall: 0.637 - ETA: 0s - loss: 0.7775 - accuracy: 0.7098 - precision: 0.7778 - recall: 0.625 - ETA: 0s - loss: 0.8026 - accuracy: 0.6910 - precision: 0.7743 - recall: 0.607 - ETA: 0s - loss: 0.8111 - accuracy: 0.6844 - precision: 0.7714 - recall: 0.590 - ETA: 0s - loss: 0.8018 - accuracy: 0.6960 - precision: 0.7790 - recall: 0.610 - ETA: 0s - loss: 0.7947 - accuracy: 0.6979 - precision: 0.7759 - recall: 0.604 - 1s 2ms/sample - loss: 0.7976 - accuracy: 0.6995 - precision: 0.7748 - recall: 0.6056 - val_loss: 1.1222 - val_accuracy: 0.5775 - val_precision: 0.6087 - val_recall: 0.4930\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8849 - accuracy: 0.6562 - precision: 0.7308 - recall: 0.593 - ETA: 0s - loss: 0.7312 - accuracy: 0.7344 - precision: 0.7963 - recall: 0.671 - ETA: 0s - loss: 0.6972 - accuracy: 0.7422 - precision: 0.8269 - recall: 0.671 - ETA: 0s - loss: 0.7309 - accuracy: 0.7240 - precision: 0.7975 - recall: 0.656 - ETA: 0s - loss: 0.7776 - accuracy: 0.6992 - precision: 0.7710 - recall: 0.644 - ETA: 0s - loss: 0.7793 - accuracy: 0.6906 - precision: 0.7593 - recall: 0.640 - ETA: 0s - loss: 0.7973 - accuracy: 0.6823 - precision: 0.7469 - recall: 0.630 - 1s 1ms/sample - loss: 0.7913 - accuracy: 0.6878 - precision: 0.7542 - recall: 0.6338 - val_loss: 1.1646 - val_accuracy: 0.5563 - val_precision: 0.6034 - val_recall: 0.4930\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7699 - accuracy: 0.7188 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.8262 - accuracy: 0.6771 - precision: 0.7375 - recall: 0.614 - ETA: 0s - loss: 0.8919 - accuracy: 0.6500 - precision: 0.7132 - recall: 0.575 - ETA: 0s - loss: 0.8895 - accuracy: 0.6652 - precision: 0.7238 - recall: 0.584 - ETA: 0s - loss: 0.9069 - accuracy: 0.6632 - precision: 0.7203 - recall: 0.590 - ETA: 0s - loss: 0.8829 - accuracy: 0.6676 - precision: 0.7197 - recall: 0.590 - ETA: 0s - loss: 0.8819 - accuracy: 0.6683 - precision: 0.7235 - recall: 0.591 - 1s 1ms/sample - loss: 0.8848 - accuracy: 0.6690 - precision: 0.7229 - recall: 0.5939 - val_loss: 1.1282 - val_accuracy: 0.5775 - val_precision: 0.6132 - val_recall: 0.4577\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0005 - accuracy: 0.6562 - precision: 0.6957 - recall: 0.500 - ETA: 0s - loss: 0.8088 - accuracy: 0.7396 - precision: 0.7945 - recall: 0.604 - ETA: 0s - loss: 0.7627 - accuracy: 0.7625 - precision: 0.8168 - recall: 0.668 - ETA: 0s - loss: 0.7451 - accuracy: 0.7723 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.7402 - accuracy: 0.7535 - precision: 0.8208 - recall: 0.684 - ETA: 0s - loss: 0.7839 - accuracy: 0.7244 - precision: 0.7925 - recall: 0.661 - ETA: 0s - loss: 0.7915 - accuracy: 0.7091 - precision: 0.7918 - recall: 0.649 - 1s 1ms/sample - loss: 0.7928 - accuracy: 0.7089 - precision: 0.7914 - recall: 0.6502 - val_loss: 1.1211 - val_accuracy: 0.5915 - val_precision: 0.6325 - val_recall: 0.5211\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.8125 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.7764 - accuracy: 0.7604 - precision: 0.8228 - recall: 0.677 - ETA: 0s - loss: 0.7564 - accuracy: 0.7563 - precision: 0.8120 - recall: 0.675 - ETA: 0s - loss: 0.7749 - accuracy: 0.7277 - precision: 0.7819 - recall: 0.656 - ETA: 0s - loss: 0.7638 - accuracy: 0.7222 - precision: 0.7714 - recall: 0.656 - ETA: 0s - loss: 0.7571 - accuracy: 0.7188 - precision: 0.7682 - recall: 0.659 - ETA: 0s - loss: 0.7808 - accuracy: 0.7067 - precision: 0.7642 - recall: 0.646 - 1s 1ms/sample - loss: 0.7769 - accuracy: 0.7113 - precision: 0.7701 - recall: 0.6526 - val_loss: 1.1435 - val_accuracy: 0.5704 - val_precision: 0.6207 - val_recall: 0.5070\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.6250 - precision: 0.6333 - recall: 0.593 - ETA: 0s - loss: 0.7364 - accuracy: 0.7396 - precision: 0.7586 - recall: 0.687 - ETA: 0s - loss: 0.7124 - accuracy: 0.7500 - precision: 0.7817 - recall: 0.693 - ETA: 0s - loss: 0.7243 - accuracy: 0.7500 - precision: 0.7906 - recall: 0.674 - ETA: 0s - loss: 0.7072 - accuracy: 0.7578 - precision: 0.8037 - recall: 0.687 - ETA: 0s - loss: 0.7278 - accuracy: 0.7312 - precision: 0.7766 - recall: 0.662 - ETA: 0s - loss: 0.7148 - accuracy: 0.7448 - precision: 0.7868 - recall: 0.682 - 1s 2ms/sample - loss: 0.7216 - accuracy: 0.7418 - precision: 0.7865 - recall: 0.6831 - val_loss: 1.2320 - val_accuracy: 0.5704 - val_precision: 0.6017 - val_recall: 0.5000\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.7812 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.7557 - accuracy: 0.7604 - precision: 0.8272 - recall: 0.697 - ETA: 0s - loss: 0.7179 - accuracy: 0.7563 - precision: 0.8188 - recall: 0.706 - ETA: 0s - loss: 0.7688 - accuracy: 0.7277 - precision: 0.7989 - recall: 0.674 - ETA: 0s - loss: 0.7725 - accuracy: 0.7222 - precision: 0.7819 - recall: 0.659 - ETA: 0s - loss: 0.7730 - accuracy: 0.7188 - precision: 0.7721 - recall: 0.644 - ETA: 0s - loss: 0.7564 - accuracy: 0.7284 - precision: 0.7701 - recall: 0.644 - 1s 1ms/sample - loss: 0.7530 - accuracy: 0.7300 - precision: 0.7703 - recall: 0.6455 - val_loss: 1.2224 - val_accuracy: 0.5282 - val_precision: 0.5583 - val_recall: 0.4718\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8306 - accuracy: 0.5938 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.8175 - accuracy: 0.6875 - precision: 0.8367 - recall: 0.640 - ETA: 0s - loss: 0.7841 - accuracy: 0.6979 - precision: 0.8312 - recall: 0.666 - ETA: 0s - loss: 0.8548 - accuracy: 0.6687 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.7900 - accuracy: 0.6920 - precision: 0.7802 - recall: 0.633 - ETA: 0s - loss: 0.7591 - accuracy: 0.7049 - precision: 0.7940 - recall: 0.642 - ETA: 0s - loss: 0.7399 - accuracy: 0.7159 - precision: 0.7938 - recall: 0.656 - ETA: 0s - loss: 0.7677 - accuracy: 0.7067 - precision: 0.7768 - recall: 0.644 - 1s 2ms/sample - loss: 0.7684 - accuracy: 0.7042 - precision: 0.7712 - recall: 0.6408 - val_loss: 1.1411 - val_accuracy: 0.5775 - val_precision: 0.6372 - val_recall: 0.5070\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7188 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.7434 - accuracy: 0.7396 - precision: 0.8101 - recall: 0.666 - ETA: 0s - loss: 0.6935 - accuracy: 0.7500 - precision: 0.8074 - recall: 0.681 - ETA: 0s - loss: 0.6876 - accuracy: 0.7411 - precision: 0.7876 - recall: 0.678 - ETA: 0s - loss: 0.7034 - accuracy: 0.7361 - precision: 0.7886 - recall: 0.673 - ETA: 0s - loss: 0.6858 - accuracy: 0.7443 - precision: 0.8020 - recall: 0.679 - ETA: 0s - loss: 0.6901 - accuracy: 0.7356 - precision: 0.8029 - recall: 0.675 - 1s 2ms/sample - loss: 0.6931 - accuracy: 0.7347 - precision: 0.8034 - recall: 0.6714 - val_loss: 1.0930 - val_accuracy: 0.6268 - val_precision: 0.6460 - val_recall: 0.5141\n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.8125 - precision: 0.9286 - recall: 0.812 - ETA: 0s - loss: 0.6259 - accuracy: 0.7917 - precision: 0.8734 - recall: 0.718 - ETA: 0s - loss: 0.6953 - accuracy: 0.7625 - precision: 0.8296 - recall: 0.700 - ETA: 0s - loss: 0.6962 - accuracy: 0.7679 - precision: 0.8316 - recall: 0.705 - ETA: 0s - loss: 0.6994 - accuracy: 0.7639 - precision: 0.8211 - recall: 0.701 - ETA: 0s - loss: 0.7173 - accuracy: 0.7557 - precision: 0.8026 - recall: 0.693 - ETA: 0s - loss: 0.7322 - accuracy: 0.7404 - precision: 0.7966 - recall: 0.677 - 1s 1ms/sample - loss: 0.7296 - accuracy: 0.7418 - precision: 0.7989 - recall: 0.6808 - val_loss: 1.2627 - val_accuracy: 0.5634 - val_precision: 0.5897 - val_recall: 0.4859\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.7188 - precision: 0.7037 - recall: 0.593 - ETA: 0s - loss: 0.7472 - accuracy: 0.7396 - precision: 0.7442 - recall: 0.666 - ETA: 0s - loss: 0.7616 - accuracy: 0.7000 - precision: 0.7338 - recall: 0.637 - ETA: 0s - loss: 0.7628 - accuracy: 0.7083 - precision: 0.7410 - recall: 0.640 - ETA: 0s - loss: 0.7541 - accuracy: 0.7070 - precision: 0.7399 - recall: 0.644 - ETA: 0s - loss: 0.7456 - accuracy: 0.7125 - precision: 0.7438 - recall: 0.653 - ETA: 0s - loss: 0.7350 - accuracy: 0.7266 - precision: 0.7604 - recall: 0.669 - 1s 1ms/sample - loss: 0.7313 - accuracy: 0.7371 - precision: 0.7698 - recall: 0.6831 - val_loss: 1.2535 - val_accuracy: 0.5845 - val_precision: 0.5948 - val_recall: 0.4859\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7262 - accuracy: 0.6875 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.7983 - accuracy: 0.6979 - precision: 0.7625 - recall: 0.635 - ETA: 0s - loss: 0.8152 - accuracy: 0.7188 - precision: 0.7589 - recall: 0.668 - ETA: 0s - loss: 0.7735 - accuracy: 0.7098 - precision: 0.7577 - recall: 0.656 - ETA: 0s - loss: 0.7847 - accuracy: 0.7014 - precision: 0.7500 - recall: 0.645 - ETA: 0s - loss: 0.7893 - accuracy: 0.7045 - precision: 0.7542 - recall: 0.644 - ETA: 0s - loss: 0.7726 - accuracy: 0.7115 - precision: 0.7619 - recall: 0.653 - 1s 1ms/sample - loss: 0.7650 - accuracy: 0.7160 - precision: 0.7678 - recall: 0.6596 - val_loss: 1.1779 - val_accuracy: 0.5493 - val_precision: 0.6050 - val_recall: 0.5070\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.7500 - precision: 0.7857 - recall: 0.687 - ETA: 0s - loss: 0.6794 - accuracy: 0.7708 - precision: 0.8118 - recall: 0.718 - ETA: 0s - loss: 0.6729 - accuracy: 0.7563 - precision: 0.8028 - recall: 0.712 - ETA: 0s - loss: 0.6436 - accuracy: 0.7679 - precision: 0.8071 - recall: 0.709 - ETA: 0s - loss: 0.6595 - accuracy: 0.7639 - precision: 0.8127 - recall: 0.708 - ETA: 0s - loss: 0.6499 - accuracy: 0.7614 - precision: 0.8203 - recall: 0.713 - ETA: 0s - loss: 0.6635 - accuracy: 0.7548 - precision: 0.8151 - recall: 0.699 - 1s 1ms/sample - loss: 0.6588 - accuracy: 0.7582 - precision: 0.8169 - recall: 0.7019 - val_loss: 1.0677 - val_accuracy: 0.5986 - val_precision: 0.6148 - val_recall: 0.5282\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.9062 - precision: 0.9615 - recall: 0.781 - ETA: 0s - loss: 0.5589 - accuracy: 0.7917 - precision: 0.8718 - recall: 0.708 - ETA: 0s - loss: 0.5837 - accuracy: 0.7578 - precision: 0.8614 - recall: 0.679 - ETA: 0s - loss: 0.6399 - accuracy: 0.7656 - precision: 0.8618 - recall: 0.682 - ETA: 0s - loss: 0.6220 - accuracy: 0.7656 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.6186 - accuracy: 0.7656 - precision: 0.8441 - recall: 0.693 - ETA: 0s - loss: 0.6177 - accuracy: 0.7682 - precision: 0.8433 - recall: 0.700 - 1s 1ms/sample - loss: 0.6152 - accuracy: 0.7700 - precision: 0.8427 - recall: 0.7042 - val_loss: 1.1028 - val_accuracy: 0.6056 - val_precision: 0.6186 - val_recall: 0.5141\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.7812 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.5324 - accuracy: 0.8542 - precision: 0.8675 - recall: 0.750 - ETA: 0s - loss: 0.5724 - accuracy: 0.8250 - precision: 0.8582 - recall: 0.756 - ETA: 0s - loss: 0.5808 - accuracy: 0.8080 - precision: 0.8513 - recall: 0.741 - ETA: 0s - loss: 0.5831 - accuracy: 0.7986 - precision: 0.8520 - recall: 0.739 - ETA: 0s - loss: 0.6138 - accuracy: 0.7784 - precision: 0.8393 - recall: 0.727 - ETA: 0s - loss: 0.6386 - accuracy: 0.7644 - precision: 0.8209 - recall: 0.716 - 1s 1ms/sample - loss: 0.6451 - accuracy: 0.7629 - precision: 0.8199 - recall: 0.7160 - val_loss: 1.1714 - val_accuracy: 0.5704 - val_precision: 0.6271 - val_recall: 0.5211\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.8125 - precision: 0.7857 - recall: 0.687 - ETA: 0s - loss: 0.5055 - accuracy: 0.8229 - precision: 0.8554 - recall: 0.739 - ETA: 0s - loss: 0.6082 - accuracy: 0.8000 - precision: 0.8273 - recall: 0.718 - ETA: 0s - loss: 0.5991 - accuracy: 0.7991 - precision: 0.8250 - recall: 0.736 - ETA: 0s - loss: 0.5962 - accuracy: 0.7986 - precision: 0.8268 - recall: 0.729 - ETA: 0s - loss: 0.6039 - accuracy: 0.7926 - precision: 0.8220 - recall: 0.721 - ETA: 0s - loss: 0.6412 - accuracy: 0.7764 - precision: 0.8104 - recall: 0.709 - 1s 1ms/sample - loss: 0.6375 - accuracy: 0.7770 - precision: 0.8123 - recall: 0.7113 - val_loss: 1.1609 - val_accuracy: 0.5563 - val_precision: 0.5952 - val_recall: 0.5282\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 13063da616340510983ea73d3e9000d6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6267605423927307</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 96)                135552    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 1,079,308\n",
      "Trainable params: 1,079,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:19 - loss: 2.4790 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 22s - loss: 2.4529 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 11s - loss: 2.3498 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 6s - loss: 2.3139 - accuracy: 0.1741 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 3s - loss: 2.2810 - accuracy: 0.1736 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.2765 - accuracy: 0.1648 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2486 - accuracy: 0.1659 - precision: 0.0000e+00 - recall: 0.0000e+0 - 9s 21ms/sample - loss: 2.2508 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9700 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9362 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0196 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0073 - accuracy: 0.1625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0093 - accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9747 - accuracy: 0.1840 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9867 - accuracy: 0.1619 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9808 - accuracy: 0.1827 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9808 - accuracy: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9542 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8366 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9981 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9370 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9136 - accuracy: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8949 - accuracy: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8943 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8694 - accuracy: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8771 - accuracy: 0.2300 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8129 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8036 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8625 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8943 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8445 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8442 - accuracy: 0.2569 - precision: 0.6667 - recall: 0.0069        - ETA: 0s - loss: 1.8604 - accuracy: 0.2614 - precision: 0.5000 - recall: 0.005 - ETA: 0s - loss: 1.8749 - accuracy: 0.2596 - precision: 0.5000 - recall: 0.007 - 1s 2ms/sample - loss: 1.8774 - accuracy: 0.2606 - precision: 0.5000 - recall: 0.0070 - val_loss: 1.8027 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8988 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8257 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7884 - accuracy: 0.3250 - precision: 0.5000 - recall: 0.0125        - ETA: 0s - loss: 1.7981 - accuracy: 0.3036 - precision: 0.6000 - recall: 0.013 - ETA: 0s - loss: 1.8200 - accuracy: 0.2882 - precision: 0.6000 - recall: 0.010 - ETA: 0s - loss: 1.8143 - accuracy: 0.2983 - precision: 0.6000 - recall: 0.008 - ETA: 0s - loss: 1.8158 - accuracy: 0.2788 - precision: 0.6000 - recall: 0.007 - 1s 2ms/sample - loss: 1.8194 - accuracy: 0.2770 - precision: 0.6000 - recall: 0.0070 - val_loss: 1.8246 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6969 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8424 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8792 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9115 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8876 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8666 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8606 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8523 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7866 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7611 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7880 - accuracy: 0.2708 - precision: 1.0000 - recall: 0.041 - ETA: 0s - loss: 1.7542 - accuracy: 0.2937 - precision: 0.8333 - recall: 0.031 - ETA: 0s - loss: 1.7592 - accuracy: 0.2991 - precision: 0.5909 - recall: 0.058 - ETA: 0s - loss: 1.7606 - accuracy: 0.2986 - precision: 0.4737 - recall: 0.062 - ETA: 0s - loss: 1.7769 - accuracy: 0.3011 - precision: 0.4510 - recall: 0.065 - ETA: 0s - loss: 1.7933 - accuracy: 0.2861 - precision: 0.4528 - recall: 0.057 - 1s 1ms/sample - loss: 1.7911 - accuracy: 0.2864 - precision: 0.4630 - recall: 0.0587 - val_loss: 1.9175 - val_accuracy: 0.2606 - val_precision: 0.3333 - val_recall: 0.0141\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2106 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9335 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8740 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8888 - accuracy: 0.3080 - precision: 0.2500 - recall: 0.0045        - ETA: 0s - loss: 1.8926 - accuracy: 0.2986 - precision: 0.4286 - recall: 0.010 - ETA: 0s - loss: 1.9114 - accuracy: 0.2784 - precision: 0.5000 - recall: 0.022 - ETA: 0s - loss: 1.9373 - accuracy: 0.2620 - precision: 0.4167 - recall: 0.024 - 1s 2ms/sample - loss: 1.9354 - accuracy: 0.2653 - precision: 0.4000 - recall: 0.0235 - val_loss: 1.8803 - val_accuracy: 0.1972 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9403 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8571 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9140 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8865 - accuracy: 0.2545 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9086 - accuracy: 0.2535 - precision: 0.1667 - recall: 0.0035        - ETA: 0s - loss: 1.9019 - accuracy: 0.2472 - precision: 0.1667 - recall: 0.002 - ETA: 0s - loss: 1.8827 - accuracy: 0.2524 - precision: 0.1667 - recall: 0.002 - 1s 1ms/sample - loss: 1.8819 - accuracy: 0.2582 - precision: 0.1667 - recall: 0.0023 - val_loss: 1.8009 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7008 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6816 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7226 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.0250        - ETA: 0s - loss: 1.7648 - accuracy: 0.2589 - precision: 0.5000 - recall: 0.017 - ETA: 0s - loss: 1.7505 - accuracy: 0.2674 - precision: 0.6364 - recall: 0.024 - ETA: 0s - loss: 1.7502 - accuracy: 0.2614 - precision: 0.5833 - recall: 0.019 - ETA: 0s - loss: 1.7552 - accuracy: 0.2644 - precision: 0.6667 - recall: 0.024 - 1s 2ms/sample - loss: 1.7617 - accuracy: 0.2606 - precision: 0.6667 - recall: 0.0235 - val_loss: 1.7329 - val_accuracy: 0.2958 - val_precision: 0.5000 - val_recall: 0.0211\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9646 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8428 - accuracy: 0.2708 - precision: 0.3636 - recall: 0.0417        - ETA: 0s - loss: 1.8298 - accuracy: 0.2625 - precision: 0.3636 - recall: 0.025 - ETA: 0s - loss: 1.7719 - accuracy: 0.2991 - precision: 0.3333 - recall: 0.017 - ETA: 0s - loss: 1.7745 - accuracy: 0.2917 - precision: 0.3846 - recall: 0.017 - ETA: 0s - loss: 1.7673 - accuracy: 0.3040 - precision: 0.5000 - recall: 0.022 - ETA: 0s - loss: 1.7795 - accuracy: 0.3029 - precision: 0.4737 - recall: 0.021 - 1s 2ms/sample - loss: 1.7825 - accuracy: 0.3028 - precision: 0.4737 - recall: 0.0211 - val_loss: 1.8200 - val_accuracy: 0.2465 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8307 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6656 - accuracy: 0.3542 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.6802 - accuracy: 0.3375 - precision: 0.6667 - recall: 0.037 - ETA: 0s - loss: 1.7001 - accuracy: 0.3080 - precision: 0.6667 - recall: 0.035 - ETA: 0s - loss: 1.6850 - accuracy: 0.3160 - precision: 0.5789 - recall: 0.038 - ETA: 0s - loss: 1.6768 - accuracy: 0.3324 - precision: 0.5500 - recall: 0.031 - ETA: 0s - loss: 1.6970 - accuracy: 0.3173 - precision: 0.5385 - recall: 0.033 - 1s 2ms/sample - loss: 1.7001 - accuracy: 0.3169 - precision: 0.5385 - recall: 0.0329 - val_loss: 1.8638 - val_accuracy: 0.2465 - val_precision: 0.7000 - val_recall: 0.0493\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8124 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7559 - accuracy: 0.3438 - precision: 0.5556 - recall: 0.052 - ETA: 0s - loss: 1.6973 - accuracy: 0.3500 - precision: 0.5652 - recall: 0.081 - ETA: 0s - loss: 1.6905 - accuracy: 0.3571 - precision: 0.5526 - recall: 0.093 - ETA: 0s - loss: 1.7011 - accuracy: 0.3333 - precision: 0.5581 - recall: 0.083 - ETA: 0s - loss: 1.6960 - accuracy: 0.3352 - precision: 0.5581 - recall: 0.068 - ETA: 0s - loss: 1.7074 - accuracy: 0.3255 - precision: 0.5682 - recall: 0.065 - 1s 2ms/sample - loss: 1.7121 - accuracy: 0.3099 - precision: 0.5556 - recall: 0.0587 - val_loss: 1.6973 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7791 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8285 - accuracy: 0.2604 - precision: 0.7500 - recall: 0.031 - ETA: 0s - loss: 1.7702 - accuracy: 0.2937 - precision: 0.8571 - recall: 0.037 - ETA: 0s - loss: 1.7625 - accuracy: 0.2902 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.7534 - accuracy: 0.3021 - precision: 0.6429 - recall: 0.031 - ETA: 0s - loss: 1.7708 - accuracy: 0.2983 - precision: 0.6842 - recall: 0.036 - ETA: 0s - loss: 1.7621 - accuracy: 0.2933 - precision: 0.6842 - recall: 0.031 - 1s 1ms/sample - loss: 1.7648 - accuracy: 0.2887 - precision: 0.6842 - recall: 0.0305 - val_loss: 1.7008 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6240 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6634 - accuracy: 0.3854 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.7007 - accuracy: 0.3187 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.6789 - accuracy: 0.3348 - precision: 0.6364 - recall: 0.031 - ETA: 0s - loss: 1.6745 - accuracy: 0.3299 - precision: 0.6923 - recall: 0.031 - ETA: 0s - loss: 1.6694 - accuracy: 0.3267 - precision: 0.7647 - recall: 0.036 - ETA: 0s - loss: 1.6850 - accuracy: 0.3293 - precision: 0.7200 - recall: 0.043 - 1s 2ms/sample - loss: 1.6923 - accuracy: 0.3239 - precision: 0.7308 - recall: 0.0446 - val_loss: 1.5861 - val_accuracy: 0.3099 - val_precision: 0.8500 - val_recall: 0.1197\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7740 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.6559 - accuracy: 0.3854 - precision: 0.6667 - recall: 0.083 - ETA: 0s - loss: 1.6211 - accuracy: 0.3688 - precision: 0.6190 - recall: 0.081 - ETA: 0s - loss: 1.6479 - accuracy: 0.3705 - precision: 0.4889 - recall: 0.098 - ETA: 0s - loss: 1.6833 - accuracy: 0.3715 - precision: 0.4925 - recall: 0.114 - ETA: 0s - loss: 1.6919 - accuracy: 0.3523 - precision: 0.4750 - recall: 0.108 - ETA: 0s - loss: 1.7032 - accuracy: 0.3582 - precision: 0.4824 - recall: 0.098 - 1s 2ms/sample - loss: 1.7038 - accuracy: 0.3568 - precision: 0.4824 - recall: 0.0962 - val_loss: 1.8225 - val_accuracy: 0.3028 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8163 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7302 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6464 - accuracy: 0.3313 - precision: 1.0000 - recall: 0.0063        - ETA: 0s - loss: 1.6750 - accuracy: 0.3304 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.6654 - accuracy: 0.3333 - precision: 0.8333 - recall: 0.017 - ETA: 0s - loss: 1.7059 - accuracy: 0.3097 - precision: 0.5455 - recall: 0.017 - ETA: 0s - loss: 1.7440 - accuracy: 0.2957 - precision: 0.5455 - recall: 0.014 - 1s 2ms/sample - loss: 1.7426 - accuracy: 0.2958 - precision: 0.5455 - recall: 0.0141 - val_loss: 1.8277 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6847 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7505 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7639 - accuracy: 0.2875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7557 - accuracy: 0.2857 - precision: 1.0000 - recall: 0.0089        - ETA: 0s - loss: 1.7682 - accuracy: 0.3021 - precision: 1.0000 - recall: 0.013 - ETA: 0s - loss: 1.7468 - accuracy: 0.3097 - precision: 0.7778 - recall: 0.019 - ETA: 0s - loss: 1.7312 - accuracy: 0.3269 - precision: 0.7857 - recall: 0.026 - 1s 2ms/sample - loss: 1.7424 - accuracy: 0.3216 - precision: 0.7857 - recall: 0.0258 - val_loss: 1.6446 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0634\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6535 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.7461 - accuracy: 0.3333 - precision: 1.0000 - recall: 0.041 - ETA: 0s - loss: 1.7295 - accuracy: 0.3000 - precision: 0.6000 - recall: 0.037 - ETA: 0s - loss: 1.6781 - accuracy: 0.3170 - precision: 0.7778 - recall: 0.062 - ETA: 0s - loss: 1.6891 - accuracy: 0.3229 - precision: 0.7000 - recall: 0.072 - ETA: 0s - loss: 1.7077 - accuracy: 0.3239 - precision: 0.5625 - recall: 0.076 - ETA: 0s - loss: 1.7299 - accuracy: 0.3245 - precision: 0.5079 - recall: 0.076 - 1s 2ms/sample - loss: 1.7301 - accuracy: 0.3216 - precision: 0.4923 - recall: 0.0751 - val_loss: 1.6061 - val_accuracy: 0.3451 - val_precision: 0.6923 - val_recall: 0.1268\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0521 - accuracy: 0.2188 - precision: 0.1111 - recall: 0.031 - ETA: 0s - loss: 1.7345 - accuracy: 0.2917 - precision: 0.4545 - recall: 0.104 - ETA: 0s - loss: 1.6813 - accuracy: 0.3313 - precision: 0.5000 - recall: 0.081 - ETA: 0s - loss: 1.6689 - accuracy: 0.3259 - precision: 0.5000 - recall: 0.084 - ETA: 0s - loss: 1.6646 - accuracy: 0.3438 - precision: 0.4634 - recall: 0.066 - ETA: 0s - loss: 1.6585 - accuracy: 0.3438 - precision: 0.4783 - recall: 0.062 - ETA: 0s - loss: 1.6554 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.064 - 1s 2ms/sample - loss: 1.6542 - accuracy: 0.3427 - precision: 0.5000 - recall: 0.0634 - val_loss: 1.6362 - val_accuracy: 0.3169 - val_precision: 0.6667 - val_recall: 0.0141\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6610 - accuracy: 0.3542 - precision: 0.5000 - recall: 0.0104        - ETA: 0s - loss: 1.6287 - accuracy: 0.3562 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.6525 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.6260 - accuracy: 0.3576 - precision: 0.5789 - recall: 0.038 - ETA: 0s - loss: 1.6425 - accuracy: 0.3494 - precision: 0.5000 - recall: 0.048 - ETA: 0s - loss: 1.6656 - accuracy: 0.3341 - precision: 0.4318 - recall: 0.045 - 1s 2ms/sample - loss: 1.6663 - accuracy: 0.3310 - precision: 0.4444 - recall: 0.0469 - val_loss: 1.7529 - val_accuracy: 0.3521 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6604 - accuracy: 0.2500 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.6987 - accuracy: 0.2708 - precision: 0.2857 - recall: 0.020 - ETA: 0s - loss: 1.6637 - accuracy: 0.3375 - precision: 0.2857 - recall: 0.012 - ETA: 0s - loss: 1.6980 - accuracy: 0.3348 - precision: 0.2857 - recall: 0.008 - ETA: 0s - loss: 1.6615 - accuracy: 0.3368 - precision: 0.2857 - recall: 0.006 - ETA: 0s - loss: 1.6608 - accuracy: 0.3381 - precision: 0.2857 - recall: 0.005 - ETA: 0s - loss: 1.6622 - accuracy: 0.3486 - precision: 0.3750 - recall: 0.007 - 1s 2ms/sample - loss: 1.6636 - accuracy: 0.3474 - precision: 0.3750 - recall: 0.0070 - val_loss: 1.6158 - val_accuracy: 0.3521 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3661 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.4738 - accuracy: 0.3854 - precision: 0.6667 - recall: 0.0208        - ETA: 0s - loss: 1.5729 - accuracy: 0.3812 - precision: 0.4000 - recall: 0.050 - ETA: 0s - loss: 1.5542 - accuracy: 0.4018 - precision: 0.4054 - recall: 0.067 - ETA: 0s - loss: 1.6064 - accuracy: 0.3889 - precision: 0.4259 - recall: 0.079 - ETA: 0s - loss: 1.5959 - accuracy: 0.3949 - precision: 0.4127 - recall: 0.073 - ETA: 0s - loss: 1.6185 - accuracy: 0.3750 - precision: 0.3889 - recall: 0.067 - 1s 1ms/sample - loss: 1.6222 - accuracy: 0.3662 - precision: 0.3889 - recall: 0.0657 - val_loss: 1.7415 - val_accuracy: 0.3099 - val_precision: 0.4545 - val_recall: 0.0352\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6600 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5666 - accuracy: 0.3542 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.6463 - accuracy: 0.3375 - precision: 0.7000 - recall: 0.043 - ETA: 0s - loss: 1.5748 - accuracy: 0.3705 - precision: 0.8125 - recall: 0.058 - ETA: 0s - loss: 1.5748 - accuracy: 0.3681 - precision: 0.7826 - recall: 0.062 - ETA: 0s - loss: 1.6256 - accuracy: 0.3580 - precision: 0.6047 - recall: 0.073 - ETA: 0s - loss: 1.6480 - accuracy: 0.3438 - precision: 0.5161 - recall: 0.076 - 1s 2ms/sample - loss: 1.6575 - accuracy: 0.3404 - precision: 0.5000 - recall: 0.0751 - val_loss: 1.6289 - val_accuracy: 0.3451 - val_precision: 0.6957 - val_recall: 0.1127\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.4375 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.5829 - accuracy: 0.3542 - precision: 0.5500 - recall: 0.114 - ETA: 0s - loss: 1.6380 - accuracy: 0.3000 - precision: 0.4643 - recall: 0.081 - ETA: 0s - loss: 1.5901 - accuracy: 0.3304 - precision: 0.4667 - recall: 0.062 - ETA: 0s - loss: 1.6017 - accuracy: 0.3229 - precision: 0.4667 - recall: 0.048 - ETA: 0s - loss: 1.6292 - accuracy: 0.3295 - precision: 0.4667 - recall: 0.039 - ETA: 0s - loss: 1.6280 - accuracy: 0.3389 - precision: 0.5000 - recall: 0.038 - 1s 2ms/sample - loss: 1.6401 - accuracy: 0.3310 - precision: 0.5000 - recall: 0.0376 - val_loss: 1.6049 - val_accuracy: 0.3380 - val_precision: 0.6250 - val_recall: 0.0352\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4611 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.7667 - accuracy: 0.3021 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7882 - accuracy: 0.3063 - precision: 0.6000 - recall: 0.037 - ETA: 0s - loss: 1.7661 - accuracy: 0.3214 - precision: 0.6111 - recall: 0.049 - ETA: 0s - loss: 1.7448 - accuracy: 0.3194 - precision: 0.6190 - recall: 0.045 - ETA: 0s - loss: 1.7527 - accuracy: 0.3182 - precision: 0.6522 - recall: 0.042 - ETA: 0s - loss: 1.7480 - accuracy: 0.3101 - precision: 0.6296 - recall: 0.040 - 1s 2ms/sample - loss: 1.7500 - accuracy: 0.3075 - precision: 0.6296 - recall: 0.0399 - val_loss: 1.8829 - val_accuracy: 0.2887 - val_precision: 0.5000 - val_recall: 0.0563\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8007 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.7228 - accuracy: 0.3125 - precision: 0.5455 - recall: 0.062 - ETA: 0s - loss: 1.6842 - accuracy: 0.3063 - precision: 0.4375 - recall: 0.043 - ETA: 0s - loss: 1.6560 - accuracy: 0.3125 - precision: 0.5833 - recall: 0.062 - ETA: 0s - loss: 1.6775 - accuracy: 0.3160 - precision: 0.5806 - recall: 0.062 - ETA: 0s - loss: 1.6701 - accuracy: 0.3324 - precision: 0.5946 - recall: 0.062 - ETA: 0s - loss: 1.6580 - accuracy: 0.3341 - precision: 0.6170 - recall: 0.069 - 1s 2ms/sample - loss: 1.6574 - accuracy: 0.3310 - precision: 0.6042 - recall: 0.0681 - val_loss: 1.5887 - val_accuracy: 0.3380 - val_precision: 0.9333 - val_recall: 0.0986\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6720 - accuracy: 0.3229 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.6811 - accuracy: 0.3250 - precision: 0.6667 - recall: 0.037 - ETA: 0s - loss: 1.6755 - accuracy: 0.3214 - precision: 0.6429 - recall: 0.040 - ETA: 0s - loss: 1.7134 - accuracy: 0.3090 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.6985 - accuracy: 0.3153 - precision: 0.6296 - recall: 0.048 - ETA: 0s - loss: 1.7170 - accuracy: 0.3077 - precision: 0.6111 - recall: 0.052 - 1s 1ms/sample - loss: 1.7230 - accuracy: 0.3028 - precision: 0.6053 - recall: 0.0540 - val_loss: 1.7597 - val_accuracy: 0.2746 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7376 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8289 - accuracy: 0.3438 - precision: 0.4000 - recall: 0.020 - ETA: 0s - loss: 1.7723 - accuracy: 0.3250 - precision: 0.4000 - recall: 0.012 - ETA: 0s - loss: 1.7732 - accuracy: 0.3125 - precision: 0.4000 - recall: 0.008 - ETA: 0s - loss: 1.7164 - accuracy: 0.3090 - precision: 0.4000 - recall: 0.006 - ETA: 0s - loss: 1.6910 - accuracy: 0.3125 - precision: 0.4000 - recall: 0.005 - ETA: 0s - loss: 1.7230 - accuracy: 0.3053 - precision: 0.5000 - recall: 0.007 - 1s 2ms/sample - loss: 1.7147 - accuracy: 0.3099 - precision: 0.5000 - recall: 0.0070 - val_loss: 1.7563 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4426 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6038 - accuracy: 0.3229 - precision: 0.7500 - recall: 0.031 - ETA: 0s - loss: 1.6905 - accuracy: 0.3375 - precision: 0.5556 - recall: 0.031 - ETA: 0s - loss: 1.7103 - accuracy: 0.3281 - precision: 0.5455 - recall: 0.031 - ETA: 0s - loss: 1.7354 - accuracy: 0.3164 - precision: 0.5385 - recall: 0.027 - ETA: 0s - loss: 1.7174 - accuracy: 0.3264 - precision: 0.5714 - recall: 0.027 - ETA: 0s - loss: 1.7097 - accuracy: 0.3324 - precision: 0.5625 - recall: 0.025 - ETA: 0s - loss: 1.7150 - accuracy: 0.3317 - precision: 0.5500 - recall: 0.026 - 1s 2ms/sample - loss: 1.7230 - accuracy: 0.3286 - precision: 0.5238 - recall: 0.0258 - val_loss: 1.8879 - val_accuracy: 0.3099 - val_precision: 0.6250 - val_recall: 0.0352\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7275 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 2.2324 - accuracy: 0.2292 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 2.1841 - accuracy: 0.2313 - precision: 0.6667 - recall: 0.025 - ETA: 0s - loss: 2.1201 - accuracy: 0.2188 - precision: 0.6667 - recall: 0.017 - ETA: 0s - loss: 2.0460 - accuracy: 0.2326 - precision: 0.6250 - recall: 0.017 - ETA: 0s - loss: 1.9790 - accuracy: 0.2301 - precision: 0.5833 - recall: 0.019 - ETA: 0s - loss: 1.9263 - accuracy: 0.2404 - precision: 0.5000 - recall: 0.026 - 1s 2ms/sample - loss: 1.9212 - accuracy: 0.2394 - precision: 0.5000 - recall: 0.0258 - val_loss: 1.6992 - val_accuracy: 0.2746 - val_precision: 0.5455 - val_recall: 0.0423\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8123 - accuracy: 0.2812 - precision: 0.3750 - recall: 0.093 - ETA: 0s - loss: 1.7473 - accuracy: 0.3125 - precision: 0.4167 - recall: 0.052 - ETA: 0s - loss: 1.7259 - accuracy: 0.3375 - precision: 0.5000 - recall: 0.043 - ETA: 0s - loss: 1.6950 - accuracy: 0.3393 - precision: 0.5294 - recall: 0.040 - ETA: 0s - loss: 1.6986 - accuracy: 0.3333 - precision: 0.6190 - recall: 0.045 - ETA: 0s - loss: 1.7237 - accuracy: 0.3210 - precision: 0.6364 - recall: 0.039 - ETA: 0s - loss: 1.7357 - accuracy: 0.3125 - precision: 0.6364 - recall: 0.036 - 1s 2ms/sample - loss: 1.7319 - accuracy: 0.3099 - precision: 0.6364 - recall: 0.0329 - val_loss: 1.6539 - val_accuracy: 0.2817 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5873 - accuracy: 0.3229 - precision: 1.0000 - recall: 0.052 - ETA: 0s - loss: 1.5932 - accuracy: 0.3313 - precision: 1.0000 - recall: 0.037 - ETA: 0s - loss: 1.6178 - accuracy: 0.2991 - precision: 0.6667 - recall: 0.035 - ETA: 0s - loss: 1.6140 - accuracy: 0.3160 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.6070 - accuracy: 0.3182 - precision: 0.6897 - recall: 0.056 - ETA: 0s - loss: 1.5992 - accuracy: 0.3229 - precision: 0.6857 - recall: 0.062 - 1s 2ms/sample - loss: 1.5956 - accuracy: 0.3239 - precision: 0.7000 - recall: 0.0657 - val_loss: 1.6589 - val_accuracy: 0.3169 - val_precision: 0.7143 - val_recall: 0.1056\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5099 - accuracy: 0.3125 - precision: 0.2000 - recall: 0.031 - ETA: 0s - loss: 1.6022 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.6351 - accuracy: 0.2891 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.5694 - accuracy: 0.3313 - precision: 0.5238 - recall: 0.068 - ETA: 0s - loss: 1.5744 - accuracy: 0.3438 - precision: 0.4815 - recall: 0.058 - ETA: 0s - loss: 1.5582 - accuracy: 0.3507 - precision: 0.6000 - recall: 0.072 - ETA: 0s - loss: 1.5171 - accuracy: 0.3892 - precision: 0.6889 - recall: 0.088 - ETA: 0s - loss: 1.5339 - accuracy: 0.3942 - precision: 0.7021 - recall: 0.079 - 1s 2ms/sample - loss: 1.5437 - accuracy: 0.3897 - precision: 0.6875 - recall: 0.0775 - val_loss: 1.6262 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0915\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6414 - accuracy: 0.2812 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.7150 - accuracy: 0.3125 - precision: 0.4615 - recall: 0.062 - ETA: 0s - loss: 1.5804 - accuracy: 0.3500 - precision: 0.6316 - recall: 0.075 - ETA: 0s - loss: 1.5679 - accuracy: 0.3616 - precision: 0.7037 - recall: 0.084 - ETA: 0s - loss: 1.5211 - accuracy: 0.3889 - precision: 0.7436 - recall: 0.100 - ETA: 0s - loss: 1.5061 - accuracy: 0.4006 - precision: 0.7609 - recall: 0.099 - ETA: 0s - loss: 1.4982 - accuracy: 0.3942 - precision: 0.6970 - recall: 0.110 - 1s 2ms/sample - loss: 1.4995 - accuracy: 0.3920 - precision: 0.6866 - recall: 0.1080 - val_loss: 1.5364 - val_accuracy: 0.3873 - val_precision: 0.8571 - val_recall: 0.1268\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2990 - accuracy: 0.4062 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.4048 - accuracy: 0.4167 - precision: 0.7619 - recall: 0.166 - ETA: 0s - loss: 1.4876 - accuracy: 0.4000 - precision: 0.6923 - recall: 0.168 - ETA: 0s - loss: 1.5167 - accuracy: 0.3802 - precision: 0.6042 - recall: 0.151 - ETA: 0s - loss: 1.5329 - accuracy: 0.3711 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.5332 - accuracy: 0.3781 - precision: 0.6143 - recall: 0.134 - ETA: 0s - loss: 1.5206 - accuracy: 0.3778 - precision: 0.6111 - recall: 0.125 - ETA: 0s - loss: 1.5468 - accuracy: 0.3702 - precision: 0.6133 - recall: 0.110 - 1s 2ms/sample - loss: 1.5442 - accuracy: 0.3732 - precision: 0.6104 - recall: 0.1103 - val_loss: 1.6590 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0634\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6751 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5834 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.0312        - ETA: 0s - loss: 1.5937 - accuracy: 0.3688 - precision: 0.8000 - recall: 0.025 - ETA: 0s - loss: 1.5697 - accuracy: 0.3750 - precision: 0.8182 - recall: 0.040 - ETA: 0s - loss: 1.5424 - accuracy: 0.3681 - precision: 0.8889 - recall: 0.055 - ETA: 0s - loss: 1.5159 - accuracy: 0.3781 - precision: 0.9091 - recall: 0.062 - ETA: 0s - loss: 1.5044 - accuracy: 0.3750 - precision: 0.8462 - recall: 0.057 - ETA: 0s - loss: 1.5048 - accuracy: 0.3750 - precision: 0.8710 - recall: 0.064 - 1s 2ms/sample - loss: 1.5072 - accuracy: 0.3732 - precision: 0.8438 - recall: 0.0634 - val_loss: 1.6187 - val_accuracy: 0.3451 - val_precision: 0.8571 - val_recall: 0.1268\n",
      "Epoch 38/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1796 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.187 - ETA: 0s - loss: 1.3326 - accuracy: 0.5156 - precision: 0.9000 - recall: 0.140 - ETA: 0s - loss: 1.4072 - accuracy: 0.4479 - precision: 0.7857 - recall: 0.114 - ETA: 0s - loss: 1.4411 - accuracy: 0.4531 - precision: 0.7222 - recall: 0.101 - ETA: 0s - loss: 1.4715 - accuracy: 0.4479 - precision: 0.8000 - recall: 0.104 - ETA: 0s - loss: 1.4938 - accuracy: 0.4141 - precision: 0.7879 - recall: 0.101 - ETA: 0s - loss: 1.4939 - accuracy: 0.4097 - precision: 0.7941 - recall: 0.093 - ETA: 0s - loss: 1.4856 - accuracy: 0.4219 - precision: 0.8108 - recall: 0.093 - ETA: 0s - loss: 1.4925 - accuracy: 0.4148 - precision: 0.7857 - recall: 0.093 - ETA: 0s - loss: 1.5319 - accuracy: 0.3870 - precision: 0.7708 - recall: 0.088 - 1s 2ms/sample - loss: 1.5281 - accuracy: 0.3826 - precision: 0.7755 - recall: 0.0892 - val_loss: 1.5240 - val_accuracy: 0.3803 - val_precision: 0.8182 - val_recall: 0.1268\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2276 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.4038 - accuracy: 0.3750 - precision: 0.6316 - recall: 0.125 - ETA: 0s - loss: 1.4421 - accuracy: 0.3625 - precision: 0.6400 - recall: 0.100 - ETA: 0s - loss: 1.4604 - accuracy: 0.3594 - precision: 0.6296 - recall: 0.088 - ETA: 0s - loss: 1.4466 - accuracy: 0.3571 - precision: 0.6562 - recall: 0.093 - ETA: 0s - loss: 1.4834 - accuracy: 0.3646 - precision: 0.6571 - recall: 0.079 - ETA: 0s - loss: 1.4865 - accuracy: 0.3625 - precision: 0.6842 - recall: 0.081 - ETA: 0s - loss: 1.4911 - accuracy: 0.3698 - precision: 0.6591 - recall: 0.075 - ETA: 0s - loss: 1.4853 - accuracy: 0.3702 - precision: 0.6875 - recall: 0.079 - 1s 2ms/sample - loss: 1.4911 - accuracy: 0.3662 - precision: 0.6939 - recall: 0.0798 - val_loss: 1.5243 - val_accuracy: 0.3239 - val_precision: 0.9286 - val_recall: 0.0915\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5867 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5336 - accuracy: 0.3646 - precision: 0.7778 - recall: 0.072 - ETA: 0s - loss: 1.5272 - accuracy: 0.3750 - precision: 0.6842 - recall: 0.081 - ETA: 0s - loss: 1.5419 - accuracy: 0.3802 - precision: 0.6800 - recall: 0.088 - ETA: 0s - loss: 1.5127 - accuracy: 0.3750 - precision: 0.6857 - recall: 0.093 - ETA: 0s - loss: 1.5078 - accuracy: 0.3844 - precision: 0.7143 - recall: 0.093 - ETA: 0s - loss: 1.5185 - accuracy: 0.3776 - precision: 0.6538 - recall: 0.088 - ETA: 0s - loss: 1.5192 - accuracy: 0.3846 - precision: 0.6364 - recall: 0.084 - 1s 2ms/sample - loss: 1.5213 - accuracy: 0.3850 - precision: 0.6364 - recall: 0.0822 - val_loss: 1.6859 - val_accuracy: 0.2746 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2605 - accuracy: 0.5938 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.4323 - accuracy: 0.4896 - precision: 0.8421 - recall: 0.166 - ETA: 0s - loss: 1.4461 - accuracy: 0.4500 - precision: 0.8889 - recall: 0.150 - ETA: 0s - loss: 1.4411 - accuracy: 0.4286 - precision: 0.8000 - recall: 0.142 - ETA: 0s - loss: 1.4920 - accuracy: 0.4028 - precision: 0.6909 - recall: 0.131 - ETA: 0s - loss: 1.4787 - accuracy: 0.4000 - precision: 0.6308 - recall: 0.128 - ETA: 0s - loss: 1.4860 - accuracy: 0.3906 - precision: 0.6234 - recall: 0.125 - 1s 2ms/sample - loss: 1.4733 - accuracy: 0.3897 - precision: 0.6180 - recall: 0.1291 - val_loss: 1.6168 - val_accuracy: 0.3451 - val_precision: 0.6970 - val_recall: 0.1620\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4319 - accuracy: 0.4688 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.5576 - accuracy: 0.3906 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.4393 - accuracy: 0.4141 - precision: 0.6522 - recall: 0.117 - ETA: 0s - loss: 1.4573 - accuracy: 0.4125 - precision: 0.6897 - recall: 0.125 - ETA: 0s - loss: 1.4362 - accuracy: 0.4107 - precision: 0.6750 - recall: 0.120 - ETA: 0s - loss: 1.3993 - accuracy: 0.4444 - precision: 0.7234 - recall: 0.118 - ETA: 0s - loss: 1.4193 - accuracy: 0.4281 - precision: 0.7292 - recall: 0.109 - ETA: 0s - loss: 1.4351 - accuracy: 0.4141 - precision: 0.7037 - recall: 0.099 - 1s 2ms/sample - loss: 1.4455 - accuracy: 0.4085 - precision: 0.6897 - recall: 0.0939 - val_loss: 1.4505 - val_accuracy: 0.3592 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4023 - accuracy: 0.4062 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4361 - accuracy: 0.3958 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4493 - accuracy: 0.3688 - precision: 0.7895 - recall: 0.093 - ETA: 0s - loss: 1.4285 - accuracy: 0.3750 - precision: 0.8485 - recall: 0.125 - ETA: 0s - loss: 1.4346 - accuracy: 0.3785 - precision: 0.8158 - recall: 0.107 - ETA: 0s - loss: 1.4463 - accuracy: 0.3656 - precision: 0.7805 - recall: 0.100 - ETA: 0s - loss: 1.4259 - accuracy: 0.3854 - precision: 0.7692 - recall: 0.104 - 1s 2ms/sample - loss: 1.4322 - accuracy: 0.3779 - precision: 0.7500 - recall: 0.1056 - val_loss: 1.4527 - val_accuracy: 0.3732 - val_precision: 0.9474 - val_recall: 0.1268\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3531 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.4317 - accuracy: 0.4062 - precision: 0.8182 - recall: 0.093 - ETA: 0s - loss: 1.4084 - accuracy: 0.4437 - precision: 0.8636 - recall: 0.118 - ETA: 0s - loss: 1.4003 - accuracy: 0.4420 - precision: 0.8276 - recall: 0.107 - ETA: 0s - loss: 1.3860 - accuracy: 0.4410 - precision: 0.7727 - recall: 0.118 - ETA: 0s - loss: 1.3927 - accuracy: 0.4290 - precision: 0.7455 - recall: 0.116 - ETA: 0s - loss: 1.4041 - accuracy: 0.4303 - precision: 0.6883 - recall: 0.127 - 1s 2ms/sample - loss: 1.3968 - accuracy: 0.4296 - precision: 0.6962 - recall: 0.1291 - val_loss: 1.4822 - val_accuracy: 0.3592 - val_precision: 0.9500 - val_recall: 0.1338\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2237 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.3527 - accuracy: 0.4167 - precision: 0.6923 - recall: 0.093 - ETA: 0s - loss: 1.4277 - accuracy: 0.4062 - precision: 0.6190 - recall: 0.081 - ETA: 0s - loss: 1.4562 - accuracy: 0.3795 - precision: 0.5926 - recall: 0.071 - ETA: 0s - loss: 1.5097 - accuracy: 0.3646 - precision: 0.5641 - recall: 0.076 - ETA: 0s - loss: 1.5039 - accuracy: 0.3693 - precision: 0.6170 - recall: 0.082 - ETA: 0s - loss: 1.4901 - accuracy: 0.3774 - precision: 0.6271 - recall: 0.088 - 1s 2ms/sample - loss: 1.4900 - accuracy: 0.3756 - precision: 0.6230 - recall: 0.0892 - val_loss: 1.5125 - val_accuracy: 0.3592 - val_precision: 0.8261 - val_recall: 0.1338\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4462 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.5727 - accuracy: 0.2812 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.5799 - accuracy: 0.3313 - precision: 0.7059 - recall: 0.075 - ETA: 0s - loss: 1.5034 - accuracy: 0.3482 - precision: 0.8000 - recall: 0.089 - ETA: 0s - loss: 1.4871 - accuracy: 0.3576 - precision: 0.8276 - recall: 0.083 - ETA: 0s - loss: 1.4738 - accuracy: 0.3722 - precision: 0.8235 - recall: 0.079 - ETA: 0s - loss: 1.4660 - accuracy: 0.3894 - precision: 0.8182 - recall: 0.086 - 1s 2ms/sample - loss: 1.4691 - accuracy: 0.3920 - precision: 0.8000 - recall: 0.0845 - val_loss: 1.4635 - val_accuracy: 0.4296 - val_precision: 0.8333 - val_recall: 0.1408\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4413 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.5102 - accuracy: 0.2812 - precision: 0.4545 - recall: 0.052 - ETA: 0s - loss: 1.4234 - accuracy: 0.3750 - precision: 0.6154 - recall: 0.100 - ETA: 0s - loss: 1.4187 - accuracy: 0.3705 - precision: 0.6111 - recall: 0.098 - ETA: 0s - loss: 1.4588 - accuracy: 0.3715 - precision: 0.5686 - recall: 0.100 - ETA: 0s - loss: 1.4769 - accuracy: 0.3778 - precision: 0.6154 - recall: 0.113 - ETA: 0s - loss: 1.4961 - accuracy: 0.3558 - precision: 0.6104 - recall: 0.113 - 1s 2ms/sample - loss: 1.4985 - accuracy: 0.3592 - precision: 0.6154 - recall: 0.1127 - val_loss: 1.7500 - val_accuracy: 0.2887 - val_precision: 0.5238 - val_recall: 0.0775\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6978 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.6723 - accuracy: 0.3438 - precision: 0.5385 - recall: 0.072 - ETA: 0s - loss: 1.6597 - accuracy: 0.3500 - precision: 0.5000 - recall: 0.068 - ETA: 0s - loss: 1.6648 - accuracy: 0.3304 - precision: 0.6000 - recall: 0.080 - ETA: 0s - loss: 1.6202 - accuracy: 0.3438 - precision: 0.6286 - recall: 0.076 - ETA: 0s - loss: 1.6013 - accuracy: 0.3494 - precision: 0.6364 - recall: 0.079 - ETA: 0s - loss: 1.5782 - accuracy: 0.3582 - precision: 0.6538 - recall: 0.081 - 1s 2ms/sample - loss: 1.5818 - accuracy: 0.3592 - precision: 0.6545 - recall: 0.0845 - val_loss: 1.5846 - val_accuracy: 0.3521 - val_precision: 0.5806 - val_recall: 0.1268\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9989 - accuracy: 0.1250 - precision: 0.1667 - recall: 0.031 - ETA: 0s - loss: 1.9117 - accuracy: 0.2083 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.6753 - accuracy: 0.3250 - precision: 0.6176 - recall: 0.131 - ETA: 0s - loss: 1.6465 - accuracy: 0.3304 - precision: 0.6316 - recall: 0.107 - ETA: 0s - loss: 1.6125 - accuracy: 0.3368 - precision: 0.6863 - recall: 0.121 - ETA: 0s - loss: 1.6085 - accuracy: 0.3352 - precision: 0.6552 - recall: 0.108 - ETA: 0s - loss: 1.5911 - accuracy: 0.3365 - precision: 0.6557 - recall: 0.096 - 1s 2ms/sample - loss: 1.5953 - accuracy: 0.3333 - precision: 0.6613 - recall: 0.0962 - val_loss: 1.5575 - val_accuracy: 0.3028 - val_precision: 0.8235 - val_recall: 0.0986\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.3959 - accuracy: 0.4167 - precision: 0.8667 - recall: 0.135 - ETA: 0s - loss: 1.4508 - accuracy: 0.4187 - precision: 0.8571 - recall: 0.112 - ETA: 0s - loss: 1.4357 - accuracy: 0.4330 - precision: 0.7714 - recall: 0.120 - ETA: 0s - loss: 1.4341 - accuracy: 0.4062 - precision: 0.7551 - recall: 0.128 - ETA: 0s - loss: 1.4444 - accuracy: 0.3977 - precision: 0.7581 - recall: 0.133 - ETA: 0s - loss: 1.4533 - accuracy: 0.3918 - precision: 0.7067 - recall: 0.127 - 1s 2ms/sample - loss: 1.4561 - accuracy: 0.3920 - precision: 0.6962 - recall: 0.1291 - val_loss: 1.4799 - val_accuracy: 0.4155 - val_precision: 0.7000 - val_recall: 0.1479\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4508 - accuracy: 0.5000 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.5351 - accuracy: 0.3958 - precision: 0.6111 - recall: 0.114 - ETA: 0s - loss: 1.5375 - accuracy: 0.3938 - precision: 0.5758 - recall: 0.118 - ETA: 0s - loss: 1.5537 - accuracy: 0.3929 - precision: 0.6170 - recall: 0.129 - ETA: 0s - loss: 1.5881 - accuracy: 0.3958 - precision: 0.6538 - recall: 0.118 - ETA: 0s - loss: 1.5526 - accuracy: 0.4034 - precision: 0.6557 - recall: 0.113 - ETA: 0s - loss: 1.5761 - accuracy: 0.3966 - precision: 0.6615 - recall: 0.103 - 1s 2ms/sample - loss: 1.5751 - accuracy: 0.3944 - precision: 0.6567 - recall: 0.1033 - val_loss: 1.4734 - val_accuracy: 0.3944 - val_precision: 0.8000 - val_recall: 0.1127\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5186 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.5002 - accuracy: 0.3646 - precision: 1.0000 - recall: 0.072 - ETA: 0s - loss: 1.4759 - accuracy: 0.4125 - precision: 0.9091 - recall: 0.062 - ETA: 0s - loss: 1.4699 - accuracy: 0.4062 - precision: 0.8500 - recall: 0.075 - ETA: 0s - loss: 1.4672 - accuracy: 0.4097 - precision: 0.8000 - recall: 0.097 - ETA: 0s - loss: 1.4851 - accuracy: 0.3835 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4981 - accuracy: 0.3798 - precision: 0.7407 - recall: 0.096 - 1s 2ms/sample - loss: 1.5027 - accuracy: 0.3732 - precision: 0.7143 - recall: 0.0939 - val_loss: 1.4516 - val_accuracy: 0.3803 - val_precision: 0.9444 - val_recall: 0.1197\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 0.5312 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.3692 - accuracy: 0.4896 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.3969 - accuracy: 0.4437 - precision: 0.7273 - recall: 0.100 - ETA: 0s - loss: 1.3869 - accuracy: 0.4420 - precision: 0.7000 - recall: 0.093 - ETA: 0s - loss: 1.4051 - accuracy: 0.4306 - precision: 0.7368 - recall: 0.097 - ETA: 0s - loss: 1.4223 - accuracy: 0.4176 - precision: 0.7143 - recall: 0.099 - ETA: 0s - loss: 1.4192 - accuracy: 0.4135 - precision: 0.7302 - recall: 0.110 - 1s 2ms/sample - loss: 1.4216 - accuracy: 0.4131 - precision: 0.7302 - recall: 0.1080 - val_loss: 1.4974 - val_accuracy: 0.3803 - val_precision: 0.7436 - val_recall: 0.2042\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5008 - accuracy: 0.4062 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.4223 - accuracy: 0.4583 - precision: 0.6000 - recall: 0.125 - ETA: 0s - loss: 1.4157 - accuracy: 0.4437 - precision: 0.5833 - recall: 0.131 - ETA: 0s - loss: 1.4271 - accuracy: 0.4241 - precision: 0.5532 - recall: 0.116 - ETA: 0s - loss: 1.4102 - accuracy: 0.4375 - precision: 0.5818 - recall: 0.111 - ETA: 0s - loss: 1.4324 - accuracy: 0.4318 - precision: 0.5938 - recall: 0.108 - ETA: 0s - loss: 1.4225 - accuracy: 0.4401 - precision: 0.6176 - recall: 0.109 - 1s 2ms/sample - loss: 1.4505 - accuracy: 0.4249 - precision: 0.5897 - recall: 0.1080 - val_loss: 1.4466 - val_accuracy: 0.3732 - val_precision: 0.8750 - val_recall: 0.1479\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3869 - accuracy: 0.3438 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.4929 - accuracy: 0.3542 - precision: 0.8462 - recall: 0.114 - ETA: 0s - loss: 1.5101 - accuracy: 0.3562 - precision: 0.7727 - recall: 0.106 - ETA: 0s - loss: 1.4969 - accuracy: 0.3490 - precision: 0.7500 - recall: 0.109 - ETA: 0s - loss: 1.5000 - accuracy: 0.3672 - precision: 0.7317 - recall: 0.117 - ETA: 0s - loss: 1.4824 - accuracy: 0.3781 - precision: 0.7551 - recall: 0.115 - ETA: 0s - loss: 1.4861 - accuracy: 0.3724 - precision: 0.7544 - recall: 0.112 - 1s 2ms/sample - loss: 1.5023 - accuracy: 0.3615 - precision: 0.7544 - recall: 0.1009 - val_loss: 1.4560 - val_accuracy: 0.4014 - val_precision: 1.0000 - val_recall: 0.1197\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.4652 - accuracy: 0.3750 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.5037 - accuracy: 0.3688 - precision: 0.8333 - recall: 0.125 - ETA: 0s - loss: 1.5315 - accuracy: 0.3661 - precision: 0.7143 - recall: 0.111 - ETA: 0s - loss: 1.4980 - accuracy: 0.3819 - precision: 0.6400 - recall: 0.111 - ETA: 0s - loss: 1.4523 - accuracy: 0.4205 - precision: 0.6984 - recall: 0.125 - ETA: 0s - loss: 1.4359 - accuracy: 0.4183 - precision: 0.7000 - recall: 0.134 - 1s 2ms/sample - loss: 1.4298 - accuracy: 0.4202 - precision: 0.7024 - recall: 0.1385 - val_loss: 1.5299 - val_accuracy: 0.3873 - val_precision: 0.6522 - val_recall: 0.2113\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.3438 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.5684 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.187 - ETA: 0s - loss: 1.4304 - accuracy: 0.4187 - precision: 0.5254 - recall: 0.193 - ETA: 0s - loss: 1.4367 - accuracy: 0.4062 - precision: 0.5309 - recall: 0.192 - ETA: 0s - loss: 1.4487 - accuracy: 0.4028 - precision: 0.5556 - recall: 0.173 - ETA: 0s - loss: 1.4862 - accuracy: 0.3920 - precision: 0.5377 - recall: 0.161 - ETA: 0s - loss: 1.4652 - accuracy: 0.4014 - precision: 0.5678 - recall: 0.161 - 1s 1ms/sample - loss: 1.4710 - accuracy: 0.4038 - precision: 0.5667 - recall: 0.1596 - val_loss: 1.4947 - val_accuracy: 0.4155 - val_precision: 0.6842 - val_recall: 0.1831\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2667 - accuracy: 0.3125 - precision: 0.4000 - recall: 0.125 - ETA: 0s - loss: 1.3168 - accuracy: 0.4583 - precision: 0.5667 - recall: 0.177 - ETA: 0s - loss: 1.3881 - accuracy: 0.4250 - precision: 0.5306 - recall: 0.162 - ETA: 0s - loss: 1.3864 - accuracy: 0.4286 - precision: 0.5455 - recall: 0.160 - ETA: 0s - loss: 1.3926 - accuracy: 0.4340 - precision: 0.5604 - recall: 0.177 - ETA: 0s - loss: 1.3806 - accuracy: 0.4460 - precision: 0.5833 - recall: 0.179 - ETA: 0s - loss: 1.3770 - accuracy: 0.4447 - precision: 0.5935 - recall: 0.175 - 1s 2ms/sample - loss: 1.3741 - accuracy: 0.4437 - precision: 0.6032 - recall: 0.1784 - val_loss: 1.4243 - val_accuracy: 0.4437 - val_precision: 0.8750 - val_recall: 0.1479\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3172 - accuracy: 0.5625 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.4539 - accuracy: 0.4375 - precision: 0.6364 - recall: 0.145 - ETA: 0s - loss: 1.4067 - accuracy: 0.4437 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.3959 - accuracy: 0.4643 - precision: 0.5789 - recall: 0.147 - ETA: 0s - loss: 1.4016 - accuracy: 0.4583 - precision: 0.5942 - recall: 0.142 - ETA: 0s - loss: 1.3853 - accuracy: 0.4688 - precision: 0.6383 - recall: 0.170 - ETA: 0s - loss: 1.3631 - accuracy: 0.4784 - precision: 0.6696 - recall: 0.180 - 1s 2ms/sample - loss: 1.3662 - accuracy: 0.4718 - precision: 0.6638 - recall: 0.1808 - val_loss: 1.5631 - val_accuracy: 0.3451 - val_precision: 0.8148 - val_recall: 0.1549\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3798 - accuracy: 0.3750 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.2787 - accuracy: 0.5208 - precision: 0.7619 - recall: 0.166 - ETA: 0s - loss: 1.3434 - accuracy: 0.4625 - precision: 0.8276 - recall: 0.150 - ETA: 0s - loss: 1.3359 - accuracy: 0.4598 - precision: 0.7551 - recall: 0.165 - ETA: 0s - loss: 1.3663 - accuracy: 0.4444 - precision: 0.7049 - recall: 0.149 - ETA: 0s - loss: 1.3535 - accuracy: 0.4631 - precision: 0.6835 - recall: 0.153 - ETA: 0s - loss: 1.3516 - accuracy: 0.4760 - precision: 0.7053 - recall: 0.161 - 1s 2ms/sample - loss: 1.3582 - accuracy: 0.4671 - precision: 0.6979 - recall: 0.1573 - val_loss: 1.4596 - val_accuracy: 0.4225 - val_precision: 0.7805 - val_recall: 0.2254\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3032 - accuracy: 0.4688 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.3130 - accuracy: 0.4896 - precision: 0.5758 - recall: 0.197 - ETA: 0s - loss: 1.3344 - accuracy: 0.4625 - precision: 0.5690 - recall: 0.206 - ETA: 0s - loss: 1.3899 - accuracy: 0.4420 - precision: 0.5921 - recall: 0.200 - ETA: 0s - loss: 1.3791 - accuracy: 0.4444 - precision: 0.5773 - recall: 0.194 - ETA: 0s - loss: 1.3834 - accuracy: 0.4290 - precision: 0.6036 - recall: 0.190 - ETA: 0s - loss: 1.3822 - accuracy: 0.4303 - precision: 0.6290 - recall: 0.187 - 1s 2ms/sample - loss: 1.3871 - accuracy: 0.4272 - precision: 0.6349 - recall: 0.1878 - val_loss: 1.5076 - val_accuracy: 0.3944 - val_precision: 0.6765 - val_recall: 0.1620\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4268 - accuracy: 0.3750 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.3837 - accuracy: 0.4375 - precision: 0.5238 - recall: 0.114 - ETA: 0s - loss: 1.3526 - accuracy: 0.4437 - precision: 0.6216 - recall: 0.143 - ETA: 0s - loss: 1.3161 - accuracy: 0.4554 - precision: 0.6833 - recall: 0.183 - ETA: 0s - loss: 1.3016 - accuracy: 0.4653 - precision: 0.6951 - recall: 0.197 - ETA: 0s - loss: 1.3203 - accuracy: 0.4602 - precision: 0.6818 - recall: 0.213 - ETA: 0s - loss: 1.3296 - accuracy: 0.4615 - precision: 0.6547 - recall: 0.218 - 1s 2ms/sample - loss: 1.3317 - accuracy: 0.4601 - precision: 0.6620 - recall: 0.2207 - val_loss: 1.4629 - val_accuracy: 0.4507 - val_precision: 0.7838 - val_recall: 0.2042\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.7188 - precision: 1.0000 - recall: 0.312 - ETA: 0s - loss: 1.2355 - accuracy: 0.5938 - precision: 0.8077 - recall: 0.218 - ETA: 0s - loss: 1.2922 - accuracy: 0.5562 - precision: 0.8108 - recall: 0.187 - ETA: 0s - loss: 1.3453 - accuracy: 0.5268 - precision: 0.8039 - recall: 0.183 - ETA: 0s - loss: 1.3256 - accuracy: 0.5243 - precision: 0.7910 - recall: 0.184 - ETA: 0s - loss: 1.3320 - accuracy: 0.5085 - precision: 0.7100 - recall: 0.201 - ETA: 0s - loss: 1.3343 - accuracy: 0.4952 - precision: 0.6905 - recall: 0.209 - 1s 2ms/sample - loss: 1.3337 - accuracy: 0.4883 - precision: 0.6769 - recall: 0.2066 - val_loss: 1.4689 - val_accuracy: 0.4225 - val_precision: 0.7692 - val_recall: 0.2113\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2291 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.1891 - accuracy: 0.5521 - precision: 0.7826 - recall: 0.187 - ETA: 0s - loss: 1.2478 - accuracy: 0.5125 - precision: 0.7000 - recall: 0.175 - ETA: 0s - loss: 1.2932 - accuracy: 0.4866 - precision: 0.6949 - recall: 0.183 - ETA: 0s - loss: 1.2996 - accuracy: 0.4792 - precision: 0.6709 - recall: 0.184 - ETA: 0s - loss: 1.3248 - accuracy: 0.4659 - precision: 0.6058 - recall: 0.179 - ETA: 0s - loss: 1.3254 - accuracy: 0.4543 - precision: 0.6288 - recall: 0.199 - 1s 2ms/sample - loss: 1.3216 - accuracy: 0.4577 - precision: 0.6370 - recall: 0.2019 - val_loss: 1.4983 - val_accuracy: 0.4366 - val_precision: 0.6522 - val_recall: 0.2113\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3342 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.3170 - accuracy: 0.4375 - precision: 0.7419 - recall: 0.239 - ETA: 0s - loss: 1.3065 - accuracy: 0.4250 - precision: 0.7083 - recall: 0.212 - ETA: 0s - loss: 1.2951 - accuracy: 0.4598 - precision: 0.7231 - recall: 0.209 - ETA: 0s - loss: 1.3288 - accuracy: 0.4410 - precision: 0.6860 - recall: 0.204 - ETA: 0s - loss: 1.3292 - accuracy: 0.4460 - precision: 0.6881 - recall: 0.213 - ETA: 0s - loss: 1.2913 - accuracy: 0.4808 - precision: 0.7143 - recall: 0.228 - 1s 2ms/sample - loss: 1.2874 - accuracy: 0.4859 - precision: 0.7153 - recall: 0.2300 - val_loss: 1.4213 - val_accuracy: 0.4225 - val_precision: 0.7018 - val_recall: 0.2817\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3701 - accuracy: 0.5000 - precision: 0.6000 - recall: 0.281 - ETA: 0s - loss: 1.2187 - accuracy: 0.5625 - precision: 0.6596 - recall: 0.322 - ETA: 0s - loss: 1.2049 - accuracy: 0.5562 - precision: 0.6716 - recall: 0.281 - ETA: 0s - loss: 1.2259 - accuracy: 0.5491 - precision: 0.6977 - recall: 0.267 - ETA: 0s - loss: 1.2570 - accuracy: 0.5312 - precision: 0.6990 - recall: 0.250 - ETA: 0s - loss: 1.2635 - accuracy: 0.5284 - precision: 0.7131 - recall: 0.247 - ETA: 0s - loss: 1.2581 - accuracy: 0.5240 - precision: 0.7143 - recall: 0.252 - 1s 2ms/sample - loss: 1.2603 - accuracy: 0.5188 - precision: 0.7162 - recall: 0.2488 - val_loss: 1.4766 - val_accuracy: 0.4225 - val_precision: 0.6923 - val_recall: 0.2535\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5961 - accuracy: 0.2500 - precision: 0.4545 - recall: 0.156 - ETA: 0s - loss: 1.3763 - accuracy: 0.4375 - precision: 0.5484 - recall: 0.177 - ETA: 0s - loss: 1.3894 - accuracy: 0.4500 - precision: 0.6071 - recall: 0.212 - ETA: 0s - loss: 1.3764 - accuracy: 0.4509 - precision: 0.5904 - recall: 0.218 - ETA: 0s - loss: 1.4274 - accuracy: 0.4583 - precision: 0.5981 - recall: 0.222 - ETA: 0s - loss: 1.4527 - accuracy: 0.4574 - precision: 0.6077 - recall: 0.224 - ETA: 0s - loss: 1.4744 - accuracy: 0.4423 - precision: 0.6013 - recall: 0.221 - 1s 2ms/sample - loss: 1.4734 - accuracy: 0.4413 - precision: 0.5962 - recall: 0.2183 - val_loss: 1.5534 - val_accuracy: 0.3380 - val_precision: 0.5217 - val_recall: 0.1690\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 0.3125 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.4782 - accuracy: 0.3854 - precision: 0.7391 - recall: 0.177 - ETA: 0s - loss: 1.5256 - accuracy: 0.3750 - precision: 0.7353 - recall: 0.156 - ETA: 0s - loss: 1.4911 - accuracy: 0.3973 - precision: 0.7059 - recall: 0.160 - ETA: 0s - loss: 1.4490 - accuracy: 0.4132 - precision: 0.6806 - recall: 0.170 - ETA: 0s - loss: 1.4467 - accuracy: 0.4119 - precision: 0.6275 - recall: 0.181 - ETA: 0s - loss: 1.4119 - accuracy: 0.4351 - precision: 0.6489 - recall: 0.204 - 1s 2ms/sample - loss: 1.4039 - accuracy: 0.4366 - precision: 0.6541 - recall: 0.2042 - val_loss: 1.4660 - val_accuracy: 0.4366 - val_precision: 0.6939 - val_recall: 0.2394\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4186 - accuracy: 0.4062 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.3746 - accuracy: 0.4688 - precision: 0.6316 - recall: 0.250 - ETA: 0s - loss: 1.3067 - accuracy: 0.4938 - precision: 0.6471 - recall: 0.275 - ETA: 0s - loss: 1.3188 - accuracy: 0.4732 - precision: 0.6522 - recall: 0.267 - ETA: 0s - loss: 1.3495 - accuracy: 0.4653 - precision: 0.6577 - recall: 0.253 - ETA: 0s - loss: 1.3727 - accuracy: 0.4545 - precision: 0.6484 - recall: 0.235 - ETA: 0s - loss: 1.3402 - accuracy: 0.4712 - precision: 0.6667 - recall: 0.240 - 1s 2ms/sample - loss: 1.3515 - accuracy: 0.4671 - precision: 0.6689 - recall: 0.2371 - val_loss: 1.4619 - val_accuracy: 0.4085 - val_precision: 0.7812 - val_recall: 0.1761\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3141 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.2918 - accuracy: 0.4479 - precision: 0.8095 - recall: 0.177 - ETA: 0s - loss: 1.2839 - accuracy: 0.4437 - precision: 0.7674 - recall: 0.206 - ETA: 0s - loss: 1.3102 - accuracy: 0.4420 - precision: 0.6984 - recall: 0.196 - ETA: 0s - loss: 1.3050 - accuracy: 0.4444 - precision: 0.6962 - recall: 0.191 - ETA: 0s - loss: 1.2849 - accuracy: 0.4574 - precision: 0.6939 - recall: 0.193 - ETA: 0s - loss: 1.2796 - accuracy: 0.4736 - precision: 0.6917 - recall: 0.199 - 1s 2ms/sample - loss: 1.2839 - accuracy: 0.4695 - precision: 0.6967 - recall: 0.1995 - val_loss: 1.4729 - val_accuracy: 0.4296 - val_precision: 0.8276 - val_recall: 0.1690\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4357 - accuracy: 0.4375 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.3376 - accuracy: 0.4583 - precision: 0.7308 - recall: 0.197 - ETA: 0s - loss: 1.2482 - accuracy: 0.5188 - precision: 0.7885 - recall: 0.256 - ETA: 0s - loss: 1.2488 - accuracy: 0.5134 - precision: 0.7143 - recall: 0.267 - ETA: 0s - loss: 1.2578 - accuracy: 0.5156 - precision: 0.6915 - recall: 0.253 - ETA: 0s - loss: 1.2832 - accuracy: 0.4938 - precision: 0.6583 - recall: 0.246 - ETA: 0s - loss: 1.2536 - accuracy: 0.4974 - precision: 0.6690 - recall: 0.252 - 1s 2ms/sample - loss: 1.2518 - accuracy: 0.4977 - precision: 0.6731 - recall: 0.2465 - val_loss: 1.4144 - val_accuracy: 0.4507 - val_precision: 0.7105 - val_recall: 0.1901\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1451 - accuracy: 0.5625 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.2381 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.208 - ETA: 0s - loss: 1.2313 - accuracy: 0.5250 - precision: 0.7674 - recall: 0.206 - ETA: 0s - loss: 1.2046 - accuracy: 0.5268 - precision: 0.7846 - recall: 0.227 - ETA: 0s - loss: 1.1877 - accuracy: 0.5243 - precision: 0.7802 - recall: 0.246 - ETA: 0s - loss: 1.1965 - accuracy: 0.5284 - precision: 0.7589 - recall: 0.241 - ETA: 0s - loss: 1.1973 - accuracy: 0.5192 - precision: 0.7429 - recall: 0.250 - 1s 2ms/sample - loss: 1.1975 - accuracy: 0.5188 - precision: 0.7413 - recall: 0.2488 - val_loss: 1.3973 - val_accuracy: 0.4648 - val_precision: 0.7119 - val_recall: 0.2958\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1411 - accuracy: 0.5625 - precision: 0.8182 - recall: 0.281 - ETA: 0s - loss: 1.2759 - accuracy: 0.5312 - precision: 0.6842 - recall: 0.270 - ETA: 0s - loss: 1.1833 - accuracy: 0.5312 - precision: 0.6825 - recall: 0.268 - ETA: 0s - loss: 1.2400 - accuracy: 0.4866 - precision: 0.6588 - recall: 0.250 - ETA: 0s - loss: 1.2135 - accuracy: 0.4965 - precision: 0.6752 - recall: 0.274 - ETA: 0s - loss: 1.2142 - accuracy: 0.5085 - precision: 0.7172 - recall: 0.295 - ETA: 0s - loss: 1.2479 - accuracy: 0.4904 - precision: 0.7041 - recall: 0.286 - 1s 2ms/sample - loss: 1.2657 - accuracy: 0.4836 - precision: 0.6994 - recall: 0.2840 - val_loss: 1.5302 - val_accuracy: 0.3873 - val_precision: 0.6667 - val_recall: 0.2394\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.6875 - precision: 0.7857 - recall: 0.343 - ETA: 0s - loss: 1.1160 - accuracy: 0.6354 - precision: 0.8205 - recall: 0.333 - ETA: 0s - loss: 1.1720 - accuracy: 0.5875 - precision: 0.7241 - recall: 0.262 - ETA: 0s - loss: 1.2260 - accuracy: 0.5580 - precision: 0.7125 - recall: 0.254 - ETA: 0s - loss: 1.2204 - accuracy: 0.5799 - precision: 0.7297 - recall: 0.281 - ETA: 0s - loss: 1.2631 - accuracy: 0.5568 - precision: 0.7226 - recall: 0.281 - ETA: 0s - loss: 1.2777 - accuracy: 0.5457 - precision: 0.7019 - recall: 0.271 - 1s 2ms/sample - loss: 1.2798 - accuracy: 0.5446 - precision: 0.7091 - recall: 0.2746 - val_loss: 1.4703 - val_accuracy: 0.4014 - val_precision: 0.6170 - val_recall: 0.2042\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3082 - accuracy: 0.4375 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.2747 - accuracy: 0.5208 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.2282 - accuracy: 0.5375 - precision: 0.7213 - recall: 0.275 - ETA: 0s - loss: 1.2087 - accuracy: 0.5402 - precision: 0.6703 - recall: 0.272 - ETA: 0s - loss: 1.2290 - accuracy: 0.5312 - precision: 0.6694 - recall: 0.281 - ETA: 0s - loss: 1.2731 - accuracy: 0.4972 - precision: 0.6351 - recall: 0.267 - ETA: 0s - loss: 1.2788 - accuracy: 0.4976 - precision: 0.6379 - recall: 0.266 - 1s 2ms/sample - loss: 1.2661 - accuracy: 0.5000 - precision: 0.6389 - recall: 0.2700 - val_loss: 1.5074 - val_accuracy: 0.4155 - val_precision: 0.6327 - val_recall: 0.2183\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1107 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.312 - ETA: 0s - loss: 1.3185 - accuracy: 0.4688 - precision: 0.6410 - recall: 0.260 - ETA: 0s - loss: 1.3423 - accuracy: 0.4563 - precision: 0.6833 - recall: 0.256 - ETA: 0s - loss: 1.2739 - accuracy: 0.4911 - precision: 0.6667 - recall: 0.267 - ETA: 0s - loss: 1.2452 - accuracy: 0.5035 - precision: 0.6777 - recall: 0.284 - ETA: 0s - loss: 1.2236 - accuracy: 0.5170 - precision: 0.6993 - recall: 0.304 - ETA: 0s - loss: 1.2434 - accuracy: 0.5120 - precision: 0.6831 - recall: 0.300 - 1s 2ms/sample - loss: 1.2614 - accuracy: 0.5047 - precision: 0.6828 - recall: 0.2981 - val_loss: 1.4615 - val_accuracy: 0.4296 - val_precision: 0.5606 - val_recall: 0.2606\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.8464 - accuracy: 0.7188 - precision: 0.8333 - recall: 0.468 - ETA: 0s - loss: 1.1949 - accuracy: 0.5417 - precision: 0.6818 - recall: 0.312 - ETA: 0s - loss: 1.2666 - accuracy: 0.4938 - precision: 0.6400 - recall: 0.300 - ETA: 0s - loss: 1.2784 - accuracy: 0.5000 - precision: 0.6337 - recall: 0.285 - ETA: 0s - loss: 1.3092 - accuracy: 0.4861 - precision: 0.6552 - recall: 0.263 - ETA: 0s - loss: 1.2677 - accuracy: 0.5114 - precision: 0.6690 - recall: 0.269 - ETA: 0s - loss: 1.2313 - accuracy: 0.5264 - precision: 0.6941 - recall: 0.283 - 1s 2ms/sample - loss: 1.2234 - accuracy: 0.5258 - precision: 0.6954 - recall: 0.2840 - val_loss: 1.2973 - val_accuracy: 0.4648 - val_precision: 0.7442 - val_recall: 0.2254\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9261 - accuracy: 0.5625 - precision: 0.7059 - recall: 0.375 - ETA: 0s - loss: 1.1765 - accuracy: 0.4792 - precision: 0.7073 - recall: 0.302 - ETA: 0s - loss: 1.1764 - accuracy: 0.4750 - precision: 0.6562 - recall: 0.262 - ETA: 0s - loss: 1.1898 - accuracy: 0.4866 - precision: 0.6383 - recall: 0.267 - ETA: 0s - loss: 1.2189 - accuracy: 0.5139 - precision: 0.6475 - recall: 0.274 - ETA: 0s - loss: 1.1998 - accuracy: 0.5219 - precision: 0.6716 - recall: 0.281 - ETA: 0s - loss: 1.1868 - accuracy: 0.5339 - precision: 0.6765 - recall: 0.299 - 1s 2ms/sample - loss: 1.1673 - accuracy: 0.5376 - precision: 0.6856 - recall: 0.3122 - val_loss: 1.3638 - val_accuracy: 0.4437 - val_precision: 0.6301 - val_recall: 0.3239\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.6875 - precision: 0.8750 - recall: 0.437 - ETA: 0s - loss: 1.0960 - accuracy: 0.6146 - precision: 0.8085 - recall: 0.395 - ETA: 0s - loss: 1.1019 - accuracy: 0.6187 - precision: 0.7356 - recall: 0.400 - ETA: 0s - loss: 1.1493 - accuracy: 0.5893 - precision: 0.7165 - recall: 0.406 - ETA: 0s - loss: 1.1745 - accuracy: 0.5742 - precision: 0.7103 - recall: 0.402 - ETA: 0s - loss: 1.1539 - accuracy: 0.5750 - precision: 0.7200 - recall: 0.393 - ETA: 0s - loss: 1.1327 - accuracy: 0.5824 - precision: 0.7085 - recall: 0.400 - ETA: 0s - loss: 1.1416 - accuracy: 0.5721 - precision: 0.6897 - recall: 0.384 - 1s 2ms/sample - loss: 1.1314 - accuracy: 0.5751 - precision: 0.6917 - recall: 0.3897 - val_loss: 1.4805 - val_accuracy: 0.4437 - val_precision: 0.5341 - val_recall: 0.3310\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.5938 - precision: 0.6818 - recall: 0.468 - ETA: 0s - loss: 1.1567 - accuracy: 0.5417 - precision: 0.6557 - recall: 0.416 - ETA: 0s - loss: 1.1229 - accuracy: 0.5625 - precision: 0.6863 - recall: 0.437 - ETA: 0s - loss: 1.1860 - accuracy: 0.5357 - precision: 0.6383 - recall: 0.401 - ETA: 0s - loss: 1.1791 - accuracy: 0.5451 - precision: 0.6324 - recall: 0.406 - ETA: 0s - loss: 1.1588 - accuracy: 0.5398 - precision: 0.6227 - recall: 0.389 - ETA: 0s - loss: 1.1680 - accuracy: 0.5312 - precision: 0.6310 - recall: 0.382 - 1s 2ms/sample - loss: 1.1594 - accuracy: 0.5376 - precision: 0.6357 - recall: 0.3850 - val_loss: 1.3670 - val_accuracy: 0.4225 - val_precision: 0.6308 - val_recall: 0.2887\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.5938 - precision: 0.7500 - recall: 0.375 - ETA: 0s - loss: 1.1153 - accuracy: 0.5625 - precision: 0.7907 - recall: 0.354 - ETA: 0s - loss: 1.1360 - accuracy: 0.5375 - precision: 0.7108 - recall: 0.368 - ETA: 0s - loss: 1.1217 - accuracy: 0.5446 - precision: 0.7328 - recall: 0.379 - ETA: 0s - loss: 1.0875 - accuracy: 0.5664 - precision: 0.7444 - recall: 0.386 - ETA: 0s - loss: 1.0695 - accuracy: 0.5656 - precision: 0.7439 - recall: 0.381 - ETA: 0s - loss: 1.0570 - accuracy: 0.5807 - precision: 0.7423 - recall: 0.375 - ETA: 0s - loss: 1.0450 - accuracy: 0.5889 - precision: 0.7464 - recall: 0.375 - 1s 2ms/sample - loss: 1.0369 - accuracy: 0.5915 - precision: 0.7500 - recall: 0.3803 - val_loss: 1.2412 - val_accuracy: 0.5423 - val_precision: 0.6974 - val_recall: 0.3732\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0445 - accuracy: 0.5000 - precision: 0.6500 - recall: 0.406 - ETA: 0s - loss: 1.0831 - accuracy: 0.5417 - precision: 0.6863 - recall: 0.364 - ETA: 0s - loss: 1.0608 - accuracy: 0.5562 - precision: 0.6977 - recall: 0.375 - ETA: 0s - loss: 1.0467 - accuracy: 0.5677 - precision: 0.7115 - recall: 0.385 - ETA: 0s - loss: 1.0147 - accuracy: 0.6016 - precision: 0.7075 - recall: 0.406 - ETA: 0s - loss: 1.0318 - accuracy: 0.6094 - precision: 0.7249 - recall: 0.428 - ETA: 0s - loss: 1.0045 - accuracy: 0.6250 - precision: 0.7308 - recall: 0.431 - ETA: 0s - loss: 1.0421 - accuracy: 0.6146 - precision: 0.7105 - recall: 0.421 - ETA: 0s - loss: 1.0272 - accuracy: 0.6178 - precision: 0.7154 - recall: 0.423 - 1s 2ms/sample - loss: 1.0264 - accuracy: 0.6174 - precision: 0.7165 - recall: 0.4272 - val_loss: 1.1853 - val_accuracy: 0.5352 - val_precision: 0.7671 - val_recall: 0.3944\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0130 - accuracy: 0.5938 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.8004 - accuracy: 0.7500 - precision: 0.8182 - recall: 0.562 - ETA: 0s - loss: 0.8891 - accuracy: 0.6953 - precision: 0.7528 - recall: 0.523 - ETA: 0s - loss: 0.9444 - accuracy: 0.6750 - precision: 0.7549 - recall: 0.481 - ETA: 0s - loss: 0.9526 - accuracy: 0.6458 - precision: 0.7438 - recall: 0.468 - ETA: 0s - loss: 0.9396 - accuracy: 0.6384 - precision: 0.7397 - recall: 0.482 - ETA: 0s - loss: 0.9752 - accuracy: 0.6211 - precision: 0.7186 - recall: 0.468 - ETA: 0s - loss: 0.9802 - accuracy: 0.6187 - precision: 0.7350 - recall: 0.459 - ETA: 0s - loss: 1.0046 - accuracy: 0.6016 - precision: 0.7284 - recall: 0.440 - 1s 2ms/sample - loss: 1.0248 - accuracy: 0.5915 - precision: 0.7154 - recall: 0.4366 - val_loss: 1.2611 - val_accuracy: 0.5282 - val_precision: 0.6613 - val_recall: 0.2887\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.6250 - precision: 0.6667 - recall: 0.437 - ETA: 0s - loss: 0.9749 - accuracy: 0.6406 - precision: 0.7436 - recall: 0.453 - ETA: 0s - loss: 1.1783 - accuracy: 0.5391 - precision: 0.6098 - recall: 0.390 - ETA: 0s - loss: 1.2192 - accuracy: 0.5156 - precision: 0.6068 - recall: 0.369 - ETA: 0s - loss: 1.2090 - accuracy: 0.5195 - precision: 0.6154 - recall: 0.375 - ETA: 0s - loss: 1.1828 - accuracy: 0.5312 - precision: 0.6374 - recall: 0.378 - ETA: 0s - loss: 1.1830 - accuracy: 0.5312 - precision: 0.6398 - recall: 0.383 - ETA: 0s - loss: 1.2068 - accuracy: 0.5240 - precision: 0.6345 - recall: 0.379 - 1s 2ms/sample - loss: 1.2204 - accuracy: 0.5235 - precision: 0.6324 - recall: 0.3756 - val_loss: 1.4736 - val_accuracy: 0.4225 - val_precision: 0.5833 - val_recall: 0.2958\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.7812 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 1.0655 - accuracy: 0.6146 - precision: 0.6667 - recall: 0.416 - ETA: 0s - loss: 1.0799 - accuracy: 0.6062 - precision: 0.6804 - recall: 0.412 - ETA: 0s - loss: 1.0694 - accuracy: 0.5982 - precision: 0.6857 - recall: 0.428 - ETA: 0s - loss: 1.1070 - accuracy: 0.5833 - precision: 0.6705 - recall: 0.409 - ETA: 0s - loss: 1.0889 - accuracy: 0.5795 - precision: 0.6743 - recall: 0.417 - ETA: 0s - loss: 1.0825 - accuracy: 0.5807 - precision: 0.6780 - recall: 0.416 - 1s 2ms/sample - loss: 1.0993 - accuracy: 0.5728 - precision: 0.6641 - recall: 0.4038 - val_loss: 1.2544 - val_accuracy: 0.5000 - val_precision: 0.6136 - val_recall: 0.3803\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1514 - accuracy: 0.6562 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 1.1619 - accuracy: 0.5208 - precision: 0.6667 - recall: 0.395 - ETA: 0s - loss: 1.1513 - accuracy: 0.5375 - precision: 0.6250 - recall: 0.375 - ETA: 0s - loss: 1.1328 - accuracy: 0.5417 - precision: 0.6339 - recall: 0.369 - ETA: 0s - loss: 1.1174 - accuracy: 0.5580 - precision: 0.6489 - recall: 0.379 - ETA: 0s - loss: 1.1336 - accuracy: 0.5391 - precision: 0.6275 - recall: 0.375 - ETA: 0s - loss: 1.1133 - accuracy: 0.5406 - precision: 0.6429 - recall: 0.393 - ETA: 0s - loss: 1.1072 - accuracy: 0.5426 - precision: 0.6479 - recall: 0.392 - ETA: 0s - loss: 1.0947 - accuracy: 0.5495 - precision: 0.6594 - recall: 0.393 - ETA: 0s - loss: 1.0829 - accuracy: 0.5553 - precision: 0.6654 - recall: 0.406 - 1s 2ms/sample - loss: 1.0795 - accuracy: 0.5563 - precision: 0.6641 - recall: 0.4085 - val_loss: 1.2756 - val_accuracy: 0.4930 - val_precision: 0.6154 - val_recall: 0.3380\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.5312 - precision: 0.8125 - recall: 0.406 - ETA: 0s - loss: 0.9569 - accuracy: 0.5469 - precision: 0.7297 - recall: 0.421 - ETA: 0s - loss: 0.9566 - accuracy: 0.5781 - precision: 0.6962 - recall: 0.429 - ETA: 0s - loss: 0.9729 - accuracy: 0.5781 - precision: 0.7265 - recall: 0.442 - ETA: 0s - loss: 0.9621 - accuracy: 0.5820 - precision: 0.7134 - recall: 0.437 - ETA: 0s - loss: 0.9687 - accuracy: 0.5844 - precision: 0.7121 - recall: 0.440 - ETA: 0s - loss: 0.9859 - accuracy: 0.5833 - precision: 0.7107 - recall: 0.447 - ETA: 0s - loss: 0.9942 - accuracy: 0.5769 - precision: 0.6940 - recall: 0.447 - 1s 2ms/sample - loss: 0.9958 - accuracy: 0.5775 - precision: 0.6945 - recall: 0.4484 - val_loss: 1.2118 - val_accuracy: 0.5141 - val_precision: 0.6222 - val_recall: 0.3944\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9013 - accuracy: 0.5625 - precision: 0.6667 - recall: 0.375 - ETA: 0s - loss: 0.9292 - accuracy: 0.6250 - precision: 0.7143 - recall: 0.468 - ETA: 0s - loss: 0.8865 - accuracy: 0.6250 - precision: 0.7647 - recall: 0.507 - ETA: 0s - loss: 0.8871 - accuracy: 0.6250 - precision: 0.7476 - recall: 0.481 - ETA: 0s - loss: 0.8985 - accuracy: 0.6339 - precision: 0.7550 - recall: 0.508 - ETA: 0s - loss: 0.8989 - accuracy: 0.6328 - precision: 0.7442 - recall: 0.500 - ETA: 0s - loss: 0.9517 - accuracy: 0.6219 - precision: 0.7349 - recall: 0.493 - ETA: 0s - loss: 0.9301 - accuracy: 0.6302 - precision: 0.7385 - recall: 0.500 - 1s 2ms/sample - loss: 0.9174 - accuracy: 0.6291 - precision: 0.7361 - recall: 0.4977 - val_loss: 1.1969 - val_accuracy: 0.5493 - val_precision: 0.6484 - val_recall: 0.4155\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0473 - accuracy: 0.6562 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.9676 - accuracy: 0.6562 - precision: 0.7907 - recall: 0.531 - ETA: 0s - loss: 0.9060 - accuracy: 0.6562 - precision: 0.7692 - recall: 0.546 - ETA: 0s - loss: 0.9336 - accuracy: 0.6500 - precision: 0.7522 - recall: 0.531 - ETA: 0s - loss: 0.8704 - accuracy: 0.6696 - precision: 0.7688 - recall: 0.549 - ETA: 0s - loss: 0.8942 - accuracy: 0.6562 - precision: 0.7574 - recall: 0.531 - ETA: 0s - loss: 0.8960 - accuracy: 0.6656 - precision: 0.7568 - recall: 0.525 - ETA: 0s - loss: 0.8934 - accuracy: 0.6562 - precision: 0.7605 - recall: 0.514 - ETA: 0s - loss: 0.8932 - accuracy: 0.6536 - precision: 0.7606 - recall: 0.513 - ETA: 0s - loss: 0.8873 - accuracy: 0.6490 - precision: 0.7607 - recall: 0.512 - 1s 2ms/sample - loss: 0.8833 - accuracy: 0.6479 - precision: 0.7569 - recall: 0.5117 - val_loss: 1.2180 - val_accuracy: 0.5211 - val_precision: 0.6444 - val_recall: 0.4085\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.7500 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 0.8252 - accuracy: 0.6562 - precision: 0.8154 - recall: 0.552 - ETA: 0s - loss: 0.9920 - accuracy: 0.5938 - precision: 0.7500 - recall: 0.492 - ETA: 0s - loss: 1.0129 - accuracy: 0.5875 - precision: 0.7333 - recall: 0.481 - ETA: 0s - loss: 0.9575 - accuracy: 0.6198 - precision: 0.7500 - recall: 0.515 - ETA: 0s - loss: 0.9456 - accuracy: 0.6211 - precision: 0.7514 - recall: 0.531 - ETA: 0s - loss: 0.8954 - accuracy: 0.6500 - precision: 0.7556 - recall: 0.531 - ETA: 0s - loss: 0.9243 - accuracy: 0.6420 - precision: 0.7479 - recall: 0.514 - ETA: 0s - loss: 0.9220 - accuracy: 0.6406 - precision: 0.7443 - recall: 0.507 - 1s 2ms/sample - loss: 0.9070 - accuracy: 0.6502 - precision: 0.7561 - recall: 0.5094 - val_loss: 1.1758 - val_accuracy: 0.5282 - val_precision: 0.6364 - val_recall: 0.3944\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.7188 - precision: 0.7917 - recall: 0.593 - ETA: 0s - loss: 0.7622 - accuracy: 0.7812 - precision: 0.8667 - recall: 0.609 - ETA: 0s - loss: 0.9980 - accuracy: 0.6406 - precision: 0.7303 - recall: 0.507 - ETA: 0s - loss: 0.9728 - accuracy: 0.6562 - precision: 0.7241 - recall: 0.525 - ETA: 0s - loss: 0.9730 - accuracy: 0.6510 - precision: 0.7183 - recall: 0.531 - ETA: 0s - loss: 0.9115 - accuracy: 0.6719 - precision: 0.7579 - recall: 0.562 - ETA: 0s - loss: 0.8676 - accuracy: 0.6812 - precision: 0.7676 - recall: 0.578 - ETA: 0s - loss: 0.8615 - accuracy: 0.6847 - precision: 0.7630 - recall: 0.585 - ETA: 0s - loss: 0.8842 - accuracy: 0.6562 - precision: 0.7276 - recall: 0.564 - 1s 2ms/sample - loss: 0.8905 - accuracy: 0.6549 - precision: 0.7259 - recall: 0.5657 - val_loss: 1.1203 - val_accuracy: 0.5423 - val_precision: 0.5913 - val_recall: 0.4789\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9988 - accuracy: 0.6250 - precision: 0.6538 - recall: 0.531 - ETA: 0s - loss: 0.8678 - accuracy: 0.6771 - precision: 0.7125 - recall: 0.593 - ETA: 0s - loss: 0.9283 - accuracy: 0.6625 - precision: 0.7132 - recall: 0.575 - ETA: 0s - loss: 0.9315 - accuracy: 0.6384 - precision: 0.7294 - recall: 0.553 - ETA: 0s - loss: 0.9467 - accuracy: 0.6215 - precision: 0.7143 - recall: 0.538 - ETA: 0s - loss: 0.9376 - accuracy: 0.6250 - precision: 0.7155 - recall: 0.534 - ETA: 0s - loss: 0.9009 - accuracy: 0.6276 - precision: 0.7329 - recall: 0.528 - 1s 2ms/sample - loss: 0.8892 - accuracy: 0.6362 - precision: 0.7401 - recall: 0.5282 - val_loss: 1.0775 - val_accuracy: 0.5986 - val_precision: 0.7073 - val_recall: 0.4085\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.5938 - precision: 0.7619 - recall: 0.500 - ETA: 0s - loss: 0.8331 - accuracy: 0.6562 - precision: 0.7910 - recall: 0.552 - ETA: 0s - loss: 0.8531 - accuracy: 0.6250 - precision: 0.7522 - recall: 0.531 - ETA: 0s - loss: 0.8437 - accuracy: 0.6302 - precision: 0.7704 - recall: 0.541 - ETA: 0s - loss: 0.8236 - accuracy: 0.6518 - precision: 0.7778 - recall: 0.562 - ETA: 0s - loss: 0.8205 - accuracy: 0.6562 - precision: 0.7730 - recall: 0.558 - ETA: 0s - loss: 0.7993 - accuracy: 0.6750 - precision: 0.7835 - recall: 0.565 - ETA: 0s - loss: 0.7922 - accuracy: 0.6719 - precision: 0.7855 - recall: 0.562 - ETA: 0s - loss: 0.7864 - accuracy: 0.6731 - precision: 0.7926 - recall: 0.569 - 1s 2ms/sample - loss: 0.7926 - accuracy: 0.6690 - precision: 0.7902 - recall: 0.5657 - val_loss: 1.1931 - val_accuracy: 0.5211 - val_precision: 0.6105 - val_recall: 0.4085\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.6875 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.7707 - accuracy: 0.7188 - precision: 0.7703 - recall: 0.593 - ETA: 0s - loss: 0.8007 - accuracy: 0.7000 - precision: 0.7603 - recall: 0.575 - ETA: 0s - loss: 0.8159 - accuracy: 0.6920 - precision: 0.7544 - recall: 0.575 - ETA: 0s - loss: 0.8406 - accuracy: 0.6736 - precision: 0.7294 - recall: 0.552 - ETA: 0s - loss: 0.8448 - accuracy: 0.6733 - precision: 0.7395 - recall: 0.548 - ETA: 0s - loss: 0.8577 - accuracy: 0.6731 - precision: 0.7363 - recall: 0.550 - 1s 2ms/sample - loss: 0.8588 - accuracy: 0.6690 - precision: 0.7335 - recall: 0.5493 - val_loss: 1.0303 - val_accuracy: 0.5845 - val_precision: 0.6706 - val_recall: 0.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9024 - accuracy: 0.6250 - precision: 0.8000 - recall: 0.500 - ETA: 0s - loss: 0.8467 - accuracy: 0.6771 - precision: 0.7971 - recall: 0.572 - ETA: 0s - loss: 0.8136 - accuracy: 0.6938 - precision: 0.8214 - recall: 0.575 - ETA: 0s - loss: 0.7590 - accuracy: 0.7321 - precision: 0.8491 - recall: 0.602 - ETA: 0s - loss: 0.7515 - accuracy: 0.7222 - precision: 0.8480 - recall: 0.600 - ETA: 0s - loss: 0.7385 - accuracy: 0.7216 - precision: 0.8537 - recall: 0.596 - ETA: 0s - loss: 0.7395 - accuracy: 0.7212 - precision: 0.8516 - recall: 0.579 - 1s 2ms/sample - loss: 0.7412 - accuracy: 0.7183 - precision: 0.8512 - recall: 0.5775 - val_loss: 1.1403 - val_accuracy: 0.5845 - val_precision: 0.6667 - val_recall: 0.4366\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6875 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.7278 - accuracy: 0.6979 - precision: 0.8169 - recall: 0.604 - ETA: 0s - loss: 0.7109 - accuracy: 0.7125 - precision: 0.8235 - recall: 0.612 - ETA: 0s - loss: 0.7333 - accuracy: 0.7188 - precision: 0.7977 - recall: 0.616 - ETA: 0s - loss: 0.7083 - accuracy: 0.7257 - precision: 0.8161 - recall: 0.631 - ETA: 0s - loss: 0.7132 - accuracy: 0.7250 - precision: 0.8120 - recall: 0.634 - ETA: 0s - loss: 0.7067 - accuracy: 0.7240 - precision: 0.8046 - recall: 0.643 - 1s 2ms/sample - loss: 0.7138 - accuracy: 0.7183 - precision: 0.7912 - recall: 0.6315 - val_loss: 1.0515 - val_accuracy: 0.5845 - val_precision: 0.6087 - val_recall: 0.4930\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.8125 - precision: 0.8261 - recall: 0.593 - ETA: 0s - loss: 0.6939 - accuracy: 0.7292 - precision: 0.8194 - recall: 0.614 - ETA: 0s - loss: 0.6636 - accuracy: 0.7375 - precision: 0.8430 - recall: 0.637 - ETA: 0s - loss: 0.7465 - accuracy: 0.7054 - precision: 0.8046 - recall: 0.625 - ETA: 0s - loss: 0.7780 - accuracy: 0.6736 - precision: 0.7763 - recall: 0.590 - ETA: 0s - loss: 0.7768 - accuracy: 0.6705 - precision: 0.7753 - recall: 0.588 - ETA: 0s - loss: 0.8208 - accuracy: 0.6635 - precision: 0.7585 - recall: 0.588 - 1s 2ms/sample - loss: 0.8214 - accuracy: 0.6643 - precision: 0.7568 - recall: 0.5915 - val_loss: 1.3813 - val_accuracy: 0.4859 - val_precision: 0.5370 - val_recall: 0.4085\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.6562 - precision: 0.7407 - recall: 0.625 - ETA: 0s - loss: 0.9039 - accuracy: 0.6979 - precision: 0.7949 - recall: 0.645 - ETA: 0s - loss: 0.9707 - accuracy: 0.6562 - precision: 0.7840 - recall: 0.612 - ETA: 0s - loss: 0.9984 - accuracy: 0.6205 - precision: 0.7515 - recall: 0.567 - ETA: 0s - loss: 1.0463 - accuracy: 0.5972 - precision: 0.7196 - recall: 0.534 - ETA: 0s - loss: 1.0449 - accuracy: 0.6193 - precision: 0.7318 - recall: 0.542 - ETA: 0s - loss: 1.0391 - accuracy: 0.6202 - precision: 0.7229 - recall: 0.545 - 1s 2ms/sample - loss: 1.0507 - accuracy: 0.6150 - precision: 0.7224 - recall: 0.5376 - val_loss: 1.2809 - val_accuracy: 0.5493 - val_precision: 0.6078 - val_recall: 0.4366\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9113 - accuracy: 0.7188 - precision: 0.8571 - recall: 0.562 - ETA: 0s - loss: 0.7937 - accuracy: 0.7188 - precision: 0.8382 - recall: 0.593 - ETA: 0s - loss: 0.8444 - accuracy: 0.7125 - precision: 0.8017 - recall: 0.581 - ETA: 0s - loss: 0.8264 - accuracy: 0.6964 - precision: 0.7866 - recall: 0.575 - ETA: 0s - loss: 0.8537 - accuracy: 0.6840 - precision: 0.7523 - recall: 0.569 - ETA: 0s - loss: 0.9020 - accuracy: 0.6648 - precision: 0.7351 - recall: 0.559 - ETA: 0s - loss: 0.8742 - accuracy: 0.6707 - precision: 0.7437 - recall: 0.572 - 1s 2ms/sample - loss: 0.8802 - accuracy: 0.6714 - precision: 0.7447 - recall: 0.5751 - val_loss: 1.2631 - val_accuracy: 0.5282 - val_precision: 0.5833 - val_recall: 0.4437\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.6875 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.7980 - accuracy: 0.7292 - precision: 0.7595 - recall: 0.625 - ETA: 0s - loss: 0.8086 - accuracy: 0.6938 - precision: 0.7328 - recall: 0.600 - ETA: 0s - loss: 0.8138 - accuracy: 0.6875 - precision: 0.7278 - recall: 0.584 - ETA: 0s - loss: 0.8609 - accuracy: 0.6771 - precision: 0.7229 - recall: 0.579 - ETA: 0s - loss: 0.8531 - accuracy: 0.6781 - precision: 0.7381 - recall: 0.581 - ETA: 0s - loss: 0.8250 - accuracy: 0.6847 - precision: 0.7536 - recall: 0.590 - ETA: 0s - loss: 0.7967 - accuracy: 0.6899 - precision: 0.7645 - recall: 0.601 - 1s 2ms/sample - loss: 0.7980 - accuracy: 0.6925 - precision: 0.7672 - recall: 0.6033 - val_loss: 1.1248 - val_accuracy: 0.5915 - val_precision: 0.6970 - val_recall: 0.4859\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7511 - accuracy: 0.7500 - precision: 0.8571 - recall: 0.750 - ETA: 0s - loss: 0.6996 - accuracy: 0.7656 - precision: 0.8776 - recall: 0.671 - ETA: 0s - loss: 0.8262 - accuracy: 0.6875 - precision: 0.8105 - recall: 0.601 - ETA: 0s - loss: 0.9193 - accuracy: 0.6458 - precision: 0.7619 - recall: 0.583 - ETA: 0s - loss: 0.9676 - accuracy: 0.6339 - precision: 0.7529 - recall: 0.571 - ETA: 0s - loss: 0.9187 - accuracy: 0.6597 - precision: 0.7634 - recall: 0.593 - ETA: 0s - loss: 0.9187 - accuracy: 0.6625 - precision: 0.7570 - recall: 0.593 - ETA: 0s - loss: 0.9518 - accuracy: 0.6380 - precision: 0.7306 - recall: 0.565 - 1s 2ms/sample - loss: 0.9858 - accuracy: 0.6268 - precision: 0.7138 - recall: 0.5446 - val_loss: 1.3682 - val_accuracy: 0.4577 - val_precision: 0.5361 - val_recall: 0.3662\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9920 - accuracy: 0.5938 - precision: 0.6957 - recall: 0.500 - ETA: 0s - loss: 0.9315 - accuracy: 0.6146 - precision: 0.7385 - recall: 0.500 - ETA: 0s - loss: 0.8941 - accuracy: 0.6313 - precision: 0.7431 - recall: 0.506 - ETA: 0s - loss: 0.9130 - accuracy: 0.6339 - precision: 0.7296 - recall: 0.517 - ETA: 0s - loss: 0.9521 - accuracy: 0.6211 - precision: 0.7011 - recall: 0.503 - ETA: 0s - loss: 0.9060 - accuracy: 0.6438 - precision: 0.7234 - recall: 0.531 - ETA: 0s - loss: 0.8982 - accuracy: 0.6477 - precision: 0.7269 - recall: 0.536 - ETA: 0s - loss: 0.8982 - accuracy: 0.6442 - precision: 0.7166 - recall: 0.540 - 1s 2ms/sample - loss: 0.9067 - accuracy: 0.6455 - precision: 0.7165 - recall: 0.5399 - val_loss: 1.2566 - val_accuracy: 0.5211 - val_precision: 0.5514 - val_recall: 0.4155\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.5938 - precision: 0.6800 - recall: 0.531 - ETA: 0s - loss: 0.8982 - accuracy: 0.6667 - precision: 0.7714 - recall: 0.562 - ETA: 0s - loss: 0.8442 - accuracy: 0.6875 - precision: 0.8017 - recall: 0.581 - ETA: 0s - loss: 0.8883 - accuracy: 0.6741 - precision: 0.7848 - recall: 0.553 - ETA: 0s - loss: 0.8717 - accuracy: 0.6771 - precision: 0.7833 - recall: 0.552 - ETA: 0s - loss: 0.8298 - accuracy: 0.6903 - precision: 0.7922 - recall: 0.573 - ETA: 0s - loss: 0.8400 - accuracy: 0.6803 - precision: 0.7785 - recall: 0.557 - 1s 2ms/sample - loss: 0.8318 - accuracy: 0.6854 - precision: 0.7829 - recall: 0.5587 - val_loss: 1.0925 - val_accuracy: 0.5563 - val_precision: 0.6897 - val_recall: 0.4225\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9165 - accuracy: 0.5625 - precision: 0.7083 - recall: 0.531 - ETA: 0s - loss: 0.6747 - accuracy: 0.7500 - precision: 0.8611 - recall: 0.645 - ETA: 0s - loss: 0.6407 - accuracy: 0.7563 - precision: 0.8516 - recall: 0.681 - ETA: 0s - loss: 0.6694 - accuracy: 0.7634 - precision: 0.8531 - recall: 0.674 - ETA: 0s - loss: 0.6691 - accuracy: 0.7535 - precision: 0.8391 - recall: 0.670 - ETA: 0s - loss: 0.6613 - accuracy: 0.7557 - precision: 0.8333 - recall: 0.667 - ETA: 0s - loss: 0.6737 - accuracy: 0.7500 - precision: 0.8269 - recall: 0.665 - 1s 2ms/sample - loss: 0.6680 - accuracy: 0.7512 - precision: 0.8309 - recall: 0.6690 - val_loss: 0.9643 - val_accuracy: 0.6338 - val_precision: 0.7245 - val_recall: 0.5000\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7812 - precision: 0.8800 - recall: 0.687 - ETA: 0s - loss: 0.4898 - accuracy: 0.8229 - precision: 0.8765 - recall: 0.739 - ETA: 0s - loss: 0.6311 - accuracy: 0.7375 - precision: 0.8268 - recall: 0.656 - ETA: 0s - loss: 0.6373 - accuracy: 0.7240 - precision: 0.8146 - recall: 0.640 - ETA: 0s - loss: 0.6591 - accuracy: 0.7383 - precision: 0.8137 - recall: 0.648 - ETA: 0s - loss: 0.6832 - accuracy: 0.7292 - precision: 0.7957 - recall: 0.649 - ETA: 0s - loss: 0.7014 - accuracy: 0.7244 - precision: 0.7924 - recall: 0.650 - ETA: 0s - loss: 0.6786 - accuracy: 0.7308 - precision: 0.7965 - recall: 0.658 - 1s 2ms/sample - loss: 0.6784 - accuracy: 0.7324 - precision: 0.7977 - recall: 0.6573 - val_loss: 1.1189 - val_accuracy: 0.6056 - val_precision: 0.6549 - val_recall: 0.5211\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8848 - accuracy: 0.6562 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.8033 - accuracy: 0.6771 - precision: 0.7179 - recall: 0.583 - ETA: 0s - loss: 0.6972 - accuracy: 0.7312 - precision: 0.7923 - recall: 0.643 - ETA: 0s - loss: 0.6639 - accuracy: 0.7321 - precision: 0.8000 - recall: 0.642 - ETA: 0s - loss: 0.6627 - accuracy: 0.7188 - precision: 0.8000 - recall: 0.638 - ETA: 0s - loss: 0.6580 - accuracy: 0.7273 - precision: 0.8092 - recall: 0.650 - ETA: 0s - loss: 0.6856 - accuracy: 0.7163 - precision: 0.7988 - recall: 0.639 - 1s 2ms/sample - loss: 0.6913 - accuracy: 0.7136 - precision: 0.7977 - recall: 0.6385 - val_loss: 1.0215 - val_accuracy: 0.6197 - val_precision: 0.7374 - val_recall: 0.5141\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.7812 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6421 - accuracy: 0.7708 - precision: 0.8026 - recall: 0.635 - ETA: 0s - loss: 0.6249 - accuracy: 0.7625 - precision: 0.8145 - recall: 0.631 - ETA: 0s - loss: 0.5954 - accuracy: 0.7812 - precision: 0.8371 - recall: 0.665 - ETA: 0s - loss: 0.6274 - accuracy: 0.7639 - precision: 0.8202 - recall: 0.649 - ETA: 0s - loss: 0.6237 - accuracy: 0.7699 - precision: 0.8327 - recall: 0.650 - ETA: 0s - loss: 0.6214 - accuracy: 0.7716 - precision: 0.8298 - recall: 0.656 - 1s 2ms/sample - loss: 0.6194 - accuracy: 0.7723 - precision: 0.8309 - recall: 0.6573 - val_loss: 1.0455 - val_accuracy: 0.5845 - val_precision: 0.6863 - val_recall: 0.4930\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.7500 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.6653 - accuracy: 0.7396 - precision: 0.8250 - recall: 0.687 - ETA: 0s - loss: 0.6980 - accuracy: 0.7375 - precision: 0.8045 - recall: 0.668 - ETA: 0s - loss: 0.7344 - accuracy: 0.7321 - precision: 0.7869 - recall: 0.642 - ETA: 0s - loss: 0.7310 - accuracy: 0.7292 - precision: 0.7797 - recall: 0.638 - ETA: 0s - loss: 0.7238 - accuracy: 0.7273 - precision: 0.7735 - recall: 0.630 - ETA: 0s - loss: 0.7255 - accuracy: 0.7212 - precision: 0.7672 - recall: 0.617 - 1s 2ms/sample - loss: 0.7222 - accuracy: 0.7207 - precision: 0.7674 - recall: 0.6197 - val_loss: 1.1023 - val_accuracy: 0.6197 - val_precision: 0.6667 - val_recall: 0.4930\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7251 - accuracy: 0.7188 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 0.7168 - accuracy: 0.7083 - precision: 0.7922 - recall: 0.635 - ETA: 0s - loss: 0.6791 - accuracy: 0.7188 - precision: 0.8125 - recall: 0.650 - ETA: 0s - loss: 0.7070 - accuracy: 0.7277 - precision: 0.8090 - recall: 0.642 - ETA: 0s - loss: 0.7373 - accuracy: 0.7118 - precision: 0.7854 - recall: 0.635 - ETA: 0s - loss: 0.7539 - accuracy: 0.7031 - precision: 0.7782 - recall: 0.625 - ETA: 0s - loss: 0.7360 - accuracy: 0.7005 - precision: 0.7752 - recall: 0.619 - ETA: 0s - loss: 0.7274 - accuracy: 0.7067 - precision: 0.7778 - recall: 0.622 - 1s 2ms/sample - loss: 0.7247 - accuracy: 0.7066 - precision: 0.7749 - recall: 0.6221 - val_loss: 1.1663 - val_accuracy: 0.5563 - val_precision: 0.6061 - val_recall: 0.4225\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.8438 - precision: 0.8696 - recall: 0.625 - ETA: 0s - loss: 0.6780 - accuracy: 0.7188 - precision: 0.7941 - recall: 0.562 - ETA: 0s - loss: 0.6922 - accuracy: 0.7375 - precision: 0.8120 - recall: 0.593 - ETA: 0s - loss: 0.6716 - accuracy: 0.7396 - precision: 0.8239 - recall: 0.609 - ETA: 0s - loss: 0.6576 - accuracy: 0.7383 - precision: 0.8256 - recall: 0.628 - ETA: 0s - loss: 0.6437 - accuracy: 0.7500 - precision: 0.8251 - recall: 0.638 - ETA: 0s - loss: 0.6513 - accuracy: 0.7386 - precision: 0.8118 - recall: 0.625 - ETA: 0s - loss: 0.6486 - accuracy: 0.7380 - precision: 0.8131 - recall: 0.627 - 1s 2ms/sample - loss: 0.6521 - accuracy: 0.7394 - precision: 0.8121 - recall: 0.6291 - val_loss: 1.0020 - val_accuracy: 0.6268 - val_precision: 0.7264 - val_recall: 0.5423\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8438 - precision: 0.9167 - recall: 0.687 - ETA: 0s - loss: 0.5595 - accuracy: 0.8021 - precision: 0.8571 - recall: 0.687 - ETA: 0s - loss: 0.5712 - accuracy: 0.8062 - precision: 0.8615 - recall: 0.700 - ETA: 0s - loss: 0.5987 - accuracy: 0.7857 - precision: 0.8432 - recall: 0.696 - ETA: 0s - loss: 0.5826 - accuracy: 0.7882 - precision: 0.8410 - recall: 0.697 - ETA: 0s - loss: 0.6009 - accuracy: 0.7781 - precision: 0.8333 - recall: 0.687 - ETA: 0s - loss: 0.5956 - accuracy: 0.7841 - precision: 0.8385 - recall: 0.693 - ETA: 0s - loss: 0.5792 - accuracy: 0.7891 - precision: 0.8428 - recall: 0.697 - ETA: 0s - loss: 0.5704 - accuracy: 0.7933 - precision: 0.8439 - recall: 0.701 - 1s 2ms/sample - loss: 0.5716 - accuracy: 0.7911 - precision: 0.8399 - recall: 0.7019 - val_loss: 0.9706 - val_accuracy: 0.6620 - val_precision: 0.7525 - val_recall: 0.5352\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8125 - precision: 0.8519 - recall: 0.718 - ETA: 0s - loss: 0.5118 - accuracy: 0.7812 - precision: 0.8947 - recall: 0.708 - ETA: 0s - loss: 0.5238 - accuracy: 0.7734 - precision: 0.8762 - recall: 0.718 - ETA: 0s - loss: 0.5236 - accuracy: 0.7812 - precision: 0.8774 - recall: 0.708 - ETA: 0s - loss: 0.5709 - accuracy: 0.7656 - precision: 0.8592 - recall: 0.691 - ETA: 0s - loss: 0.5306 - accuracy: 0.7844 - precision: 0.8769 - recall: 0.712 - ETA: 0s - loss: 0.5438 - accuracy: 0.7812 - precision: 0.8711 - recall: 0.710 - ETA: 0s - loss: 0.5827 - accuracy: 0.7716 - precision: 0.8534 - recall: 0.699 - 1s 2ms/sample - loss: 0.5905 - accuracy: 0.7746 - precision: 0.8534 - recall: 0.6972 - val_loss: 1.0935 - val_accuracy: 0.5915 - val_precision: 0.6417 - val_recall: 0.5423\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.8750 - precision: 0.9310 - recall: 0.843 - ETA: 0s - loss: 0.5683 - accuracy: 0.8281 - precision: 0.9245 - recall: 0.765 - ETA: 0s - loss: 0.5714 - accuracy: 0.8229 - precision: 0.8929 - recall: 0.781 - ETA: 0s - loss: 0.5858 - accuracy: 0.8000 - precision: 0.8832 - recall: 0.756 - ETA: 0s - loss: 0.6118 - accuracy: 0.7768 - precision: 0.8557 - recall: 0.741 - ETA: 0s - loss: 0.6193 - accuracy: 0.7639 - precision: 0.8496 - recall: 0.725 - ETA: 0s - loss: 0.6177 - accuracy: 0.7699 - precision: 0.8523 - recall: 0.721 - ETA: 0s - loss: 0.6333 - accuracy: 0.7644 - precision: 0.8343 - recall: 0.701 - 1s 2ms/sample - loss: 0.6372 - accuracy: 0.7629 - precision: 0.8329 - recall: 0.7019 - val_loss: 1.0214 - val_accuracy: 0.6197 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.7188 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.6020 - accuracy: 0.7604 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.5527 - accuracy: 0.7875 - precision: 0.8540 - recall: 0.731 - ETA: 0s - loss: 0.5423 - accuracy: 0.7857 - precision: 0.8359 - recall: 0.727 - ETA: 0s - loss: 0.5611 - accuracy: 0.7708 - precision: 0.8125 - recall: 0.722 - ETA: 0s - loss: 0.5791 - accuracy: 0.7642 - precision: 0.8032 - recall: 0.718 - ETA: 0s - loss: 0.5704 - accuracy: 0.7692 - precision: 0.8076 - recall: 0.716 - 1s 2ms/sample - loss: 0.5619 - accuracy: 0.7746 - precision: 0.8127 - recall: 0.7230 - val_loss: 1.0399 - val_accuracy: 0.6549 - val_precision: 0.6489 - val_recall: 0.5986\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.6875 - precision: 0.6429 - recall: 0.562 - ETA: 0s - loss: 0.6512 - accuracy: 0.7188 - precision: 0.7294 - recall: 0.645 - ETA: 0s - loss: 0.5964 - accuracy: 0.7437 - precision: 0.7801 - recall: 0.687 - ETA: 0s - loss: 0.5648 - accuracy: 0.7500 - precision: 0.7897 - recall: 0.687 - ETA: 0s - loss: 0.5682 - accuracy: 0.7569 - precision: 0.8008 - recall: 0.697 - ETA: 0s - loss: 0.5538 - accuracy: 0.7594 - precision: 0.8043 - recall: 0.706 - ETA: 0s - loss: 0.5558 - accuracy: 0.7578 - precision: 0.8024 - recall: 0.708 - ETA: 0s - loss: 0.5626 - accuracy: 0.7548 - precision: 0.8022 - recall: 0.701 - 1s 2ms/sample - loss: 0.5606 - accuracy: 0.7559 - precision: 0.8059 - recall: 0.7019 - val_loss: 0.9692 - val_accuracy: 0.6479 - val_precision: 0.6750 - val_recall: 0.5704\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.7812 - precision: 0.7586 - recall: 0.687 - ETA: 0s - loss: 0.5502 - accuracy: 0.7604 - precision: 0.7805 - recall: 0.666 - ETA: 0s - loss: 0.6086 - accuracy: 0.7375 - precision: 0.7794 - recall: 0.662 - ETA: 0s - loss: 0.5568 - accuracy: 0.7589 - precision: 0.8053 - recall: 0.683 - ETA: 0s - loss: 0.5192 - accuracy: 0.7812 - precision: 0.8211 - recall: 0.701 - ETA: 0s - loss: 0.5627 - accuracy: 0.7812 - precision: 0.8164 - recall: 0.707 - ETA: 0s - loss: 0.5263 - accuracy: 0.8005 - precision: 0.8379 - recall: 0.733 - 1s 2ms/sample - loss: 0.5271 - accuracy: 0.8005 - precision: 0.8365 - recall: 0.7324 - val_loss: 1.0667 - val_accuracy: 0.6338 - val_precision: 0.7193 - val_recall: 0.5775\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8438 - precision: 0.9310 - recall: 0.843 - ETA: 0s - loss: 0.6410 - accuracy: 0.7292 - precision: 0.8072 - recall: 0.697 - ETA: 0s - loss: 0.6220 - accuracy: 0.7188 - precision: 0.7857 - recall: 0.687 - ETA: 0s - loss: 0.6174 - accuracy: 0.7292 - precision: 0.7831 - recall: 0.677 - ETA: 0s - loss: 0.6245 - accuracy: 0.7461 - precision: 0.7876 - recall: 0.695 - ETA: 0s - loss: 0.5880 - accuracy: 0.7674 - precision: 0.8086 - recall: 0.718 - ETA: 0s - loss: 0.5871 - accuracy: 0.7688 - precision: 0.8077 - recall: 0.721 - ETA: 0s - loss: 0.5529 - accuracy: 0.7812 - precision: 0.8246 - recall: 0.734 - ETA: 0s - loss: 0.5472 - accuracy: 0.7885 - precision: 0.8306 - recall: 0.742 - 1s 2ms/sample - loss: 0.5458 - accuracy: 0.7887 - precision: 0.8294 - recall: 0.7418 - val_loss: 1.0859 - val_accuracy: 0.6197 - val_precision: 0.6614 - val_recall: 0.5915\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.6562 - precision: 0.6897 - recall: 0.625 - ETA: 0s - loss: 0.6117 - accuracy: 0.7708 - precision: 0.8023 - recall: 0.718 - ETA: 0s - loss: 0.5550 - accuracy: 0.7812 - precision: 0.8054 - recall: 0.750 - ETA: 0s - loss: 0.5569 - accuracy: 0.7857 - precision: 0.8066 - recall: 0.763 - ETA: 0s - loss: 0.5173 - accuracy: 0.8008 - precision: 0.8197 - recall: 0.781 - ETA: 0s - loss: 0.5265 - accuracy: 0.7937 - precision: 0.8152 - recall: 0.771 - ETA: 0s - loss: 0.5181 - accuracy: 0.7917 - precision: 0.8154 - recall: 0.770 - 1s 2ms/sample - loss: 0.5329 - accuracy: 0.7911 - precision: 0.8144 - recall: 0.7723 - val_loss: 0.9688 - val_accuracy: 0.6338 - val_precision: 0.6917 - val_recall: 0.5845\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.8125 - precision: 0.8571 - recall: 0.750 - ETA: 0s - loss: 0.4815 - accuracy: 0.8229 - precision: 0.8523 - recall: 0.781 - ETA: 0s - loss: 0.4750 - accuracy: 0.8125 - precision: 0.8389 - recall: 0.781 - ETA: 0s - loss: 0.4707 - accuracy: 0.8080 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.4850 - accuracy: 0.8086 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.4990 - accuracy: 0.8031 - precision: 0.8322 - recall: 0.775 - ETA: 0s - loss: 0.4761 - accuracy: 0.8151 - precision: 0.8436 - recall: 0.786 - 1s 2ms/sample - loss: 0.4801 - accuracy: 0.8146 - precision: 0.8442 - recall: 0.7887 - val_loss: 0.9797 - val_accuracy: 0.6831 - val_precision: 0.7311 - val_recall: 0.6127\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8438 - precision: 0.9286 - recall: 0.812 - ETA: 0s - loss: 0.4747 - accuracy: 0.7812 - precision: 0.8961 - recall: 0.718 - ETA: 0s - loss: 0.5238 - accuracy: 0.7688 - precision: 0.8467 - recall: 0.725 - ETA: 0s - loss: 0.5941 - accuracy: 0.7455 - precision: 0.8187 - recall: 0.705 - ETA: 0s - loss: 0.5901 - accuracy: 0.7500 - precision: 0.8178 - recall: 0.701 - ETA: 0s - loss: 0.6191 - accuracy: 0.7344 - precision: 0.8022 - recall: 0.684 - ETA: 0s - loss: 0.6163 - accuracy: 0.7370 - precision: 0.7988 - recall: 0.682 - ETA: 0s - loss: 0.6048 - accuracy: 0.7404 - precision: 0.8034 - recall: 0.687 - 1s 2ms/sample - loss: 0.6100 - accuracy: 0.7418 - precision: 0.8027 - recall: 0.6878 - val_loss: 1.0257 - val_accuracy: 0.6408 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.7812 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.4616 - accuracy: 0.8333 - precision: 0.8539 - recall: 0.791 - ETA: 0s - loss: 0.5577 - accuracy: 0.7937 - precision: 0.8054 - recall: 0.750 - ETA: 0s - loss: 0.6019 - accuracy: 0.7812 - precision: 0.8019 - recall: 0.741 - ETA: 0s - loss: 0.5828 - accuracy: 0.7847 - precision: 0.8061 - recall: 0.736 - ETA: 0s - loss: 0.5857 - accuracy: 0.7841 - precision: 0.8037 - recall: 0.733 - ETA: 0s - loss: 0.5775 - accuracy: 0.7839 - precision: 0.8046 - recall: 0.729 - ETA: 0s - loss: 0.5750 - accuracy: 0.7837 - precision: 0.8032 - recall: 0.726 - 1s 2ms/sample - loss: 0.5823 - accuracy: 0.7817 - precision: 0.8047 - recall: 0.7254 - val_loss: 1.0609 - val_accuracy: 0.6338 - val_precision: 0.7094 - val_recall: 0.5845\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8438 - precision: 0.8966 - recall: 0.812 - ETA: 0s - loss: 0.5043 - accuracy: 0.7708 - precision: 0.8140 - recall: 0.729 - ETA: 0s - loss: 0.5128 - accuracy: 0.7734 - precision: 0.8017 - recall: 0.726 - ETA: 0s - loss: 0.5568 - accuracy: 0.7500 - precision: 0.7902 - recall: 0.706 - ETA: 0s - loss: 0.5184 - accuracy: 0.7768 - precision: 0.8182 - recall: 0.723 - ETA: 0s - loss: 0.5126 - accuracy: 0.7773 - precision: 0.8230 - recall: 0.726 - ETA: 0s - loss: 0.4952 - accuracy: 0.7882 - precision: 0.8346 - recall: 0.736 - ETA: 0s - loss: 0.4837 - accuracy: 0.7969 - precision: 0.8421 - recall: 0.750 - ETA: 0s - loss: 0.4899 - accuracy: 0.7898 - precision: 0.8286 - recall: 0.741 - ETA: 0s - loss: 0.5046 - accuracy: 0.7839 - precision: 0.8216 - recall: 0.731 - ETA: 0s - loss: 0.5185 - accuracy: 0.7740 - precision: 0.8113 - recall: 0.723 - 1s 2ms/sample - loss: 0.5160 - accuracy: 0.7746 - precision: 0.8110 - recall: 0.7254 - val_loss: 1.0547 - val_accuracy: 0.6268 - val_precision: 0.6748 - val_recall: 0.5845\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.7812 - precision: 0.8571 - recall: 0.750 - ETA: 0s - loss: 0.5200 - accuracy: 0.7500 - precision: 0.7833 - recall: 0.734 - ETA: 0s - loss: 0.5172 - accuracy: 0.7656 - precision: 0.8291 - recall: 0.757 - ETA: 0s - loss: 0.5904 - accuracy: 0.7500 - precision: 0.8095 - recall: 0.708 - ETA: 0s - loss: 0.6301 - accuracy: 0.7277 - precision: 0.7949 - recall: 0.692 - ETA: 0s - loss: 0.6395 - accuracy: 0.7305 - precision: 0.7937 - recall: 0.691 - ETA: 0s - loss: 0.6471 - accuracy: 0.7344 - precision: 0.7872 - recall: 0.693 - ETA: 0s - loss: 0.6180 - accuracy: 0.7585 - precision: 0.8065 - recall: 0.710 - ETA: 0s - loss: 0.6082 - accuracy: 0.7552 - precision: 0.8053 - recall: 0.710 - ETA: 0s - loss: 0.6187 - accuracy: 0.7500 - precision: 0.7967 - recall: 0.706 - 1s 2ms/sample - loss: 0.6177 - accuracy: 0.7512 - precision: 0.7989 - recall: 0.7089 - val_loss: 1.1814 - val_accuracy: 0.6408 - val_precision: 0.6694 - val_recall: 0.5845\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.7500 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.6175 - accuracy: 0.7188 - precision: 0.7679 - recall: 0.671 - ETA: 0s - loss: 0.5815 - accuracy: 0.7396 - precision: 0.7907 - recall: 0.708 - ETA: 0s - loss: 0.5450 - accuracy: 0.7578 - precision: 0.7949 - recall: 0.726 - ETA: 0s - loss: 0.5892 - accuracy: 0.7500 - precision: 0.7816 - recall: 0.708 - ETA: 0s - loss: 0.5697 - accuracy: 0.7634 - precision: 0.7960 - recall: 0.714 - ETA: 0s - loss: 0.5635 - accuracy: 0.7743 - precision: 0.8061 - recall: 0.736 - ETA: 0s - loss: 0.5655 - accuracy: 0.7688 - precision: 0.7973 - recall: 0.725 - ETA: 0s - loss: 0.5505 - accuracy: 0.7839 - precision: 0.8068 - recall: 0.739 - ETA: 0s - loss: 0.5398 - accuracy: 0.7837 - precision: 0.8132 - recall: 0.742 - 1s 2ms/sample - loss: 0.5403 - accuracy: 0.7840 - precision: 0.8128 - recall: 0.7441 - val_loss: 1.0608 - val_accuracy: 0.6197 - val_precision: 0.6614 - val_recall: 0.5915\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8438 - precision: 0.8929 - recall: 0.781 - ETA: 0s - loss: 0.5069 - accuracy: 0.7917 - precision: 0.8452 - recall: 0.739 - ETA: 0s - loss: 0.4938 - accuracy: 0.8062 - precision: 0.8531 - recall: 0.762 - ETA: 0s - loss: 0.4738 - accuracy: 0.8214 - precision: 0.8687 - recall: 0.767 - ETA: 0s - loss: 0.4821 - accuracy: 0.8056 - precision: 0.8471 - recall: 0.750 - ETA: 0s - loss: 0.4793 - accuracy: 0.8062 - precision: 0.8456 - recall: 0.753 - ETA: 0s - loss: 0.5009 - accuracy: 0.7969 - precision: 0.8304 - recall: 0.726 - ETA: 0s - loss: 0.4915 - accuracy: 0.7957 - precision: 0.8297 - recall: 0.726 - 1s 2ms/sample - loss: 0.4846 - accuracy: 0.8005 - precision: 0.8342 - recall: 0.7324 - val_loss: 0.9772 - val_accuracy: 0.6549 - val_precision: 0.6992 - val_recall: 0.6056\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8438 - precision: 0.8966 - recall: 0.812 - ETA: 0s - loss: 0.3799 - accuracy: 0.8438 - precision: 0.8941 - recall: 0.791 - ETA: 0s - loss: 0.3883 - accuracy: 0.8500 - precision: 0.8828 - recall: 0.800 - ETA: 0s - loss: 0.3686 - accuracy: 0.8616 - precision: 0.8960 - recall: 0.808 - ETA: 0s - loss: 0.3703 - accuracy: 0.8542 - precision: 0.8864 - recall: 0.812 - ETA: 0s - loss: 0.3893 - accuracy: 0.8523 - precision: 0.8777 - recall: 0.815 - ETA: 0s - loss: 0.4040 - accuracy: 0.8486 - precision: 0.8731 - recall: 0.810 - 1s 2ms/sample - loss: 0.4023 - accuracy: 0.8498 - precision: 0.8737 - recall: 0.8122 - val_loss: 1.1188 - val_accuracy: 0.6831 - val_precision: 0.6870 - val_recall: 0.6338\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.968 - ETA: 0s - loss: 0.3478 - accuracy: 0.8958 - precision: 0.9140 - recall: 0.885 - ETA: 0s - loss: 0.3801 - accuracy: 0.8875 - precision: 0.8974 - recall: 0.875 - ETA: 0s - loss: 0.3902 - accuracy: 0.8750 - precision: 0.8925 - recall: 0.864 - ETA: 0s - loss: 0.3692 - accuracy: 0.8828 - precision: 0.8996 - recall: 0.875 - ETA: 0s - loss: 0.3753 - accuracy: 0.8715 - precision: 0.8949 - recall: 0.857 - ETA: 0s - loss: 0.4133 - accuracy: 0.8551 - precision: 0.8769 - recall: 0.829 - ETA: 0s - loss: 0.4170 - accuracy: 0.8510 - precision: 0.8750 - recall: 0.824 - 1s 2ms/sample - loss: 0.4176 - accuracy: 0.8498 - precision: 0.8753 - recall: 0.8239 - val_loss: 1.0239 - val_accuracy: 0.6901 - val_precision: 0.7132 - val_recall: 0.6479\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.968 - ETA: 0s - loss: 0.2879 - accuracy: 0.9062 - precision: 0.9255 - recall: 0.906 - ETA: 0s - loss: 0.3259 - accuracy: 0.8875 - precision: 0.9045 - recall: 0.887 - ETA: 0s - loss: 0.3555 - accuracy: 0.8795 - precision: 0.8991 - recall: 0.875 - ETA: 0s - loss: 0.3856 - accuracy: 0.8576 - precision: 0.8750 - recall: 0.850 - ETA: 0s - loss: 0.3986 - accuracy: 0.8494 - precision: 0.8651 - recall: 0.838 - ETA: 0s - loss: 0.3772 - accuracy: 0.8630 - precision: 0.8759 - recall: 0.848 - 1s 2ms/sample - loss: 0.3826 - accuracy: 0.8568 - precision: 0.8735 - recall: 0.8427 - val_loss: 1.1011 - val_accuracy: 0.5986 - val_precision: 0.6000 - val_recall: 0.5704\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.9062 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.3923 - accuracy: 0.9167 - precision: 0.9231 - recall: 0.875 - ETA: 0s - loss: 0.5252 - accuracy: 0.8500 - precision: 0.8553 - recall: 0.812 - ETA: 0s - loss: 0.4906 - accuracy: 0.8571 - precision: 0.8660 - recall: 0.808 - ETA: 0s - loss: 0.4602 - accuracy: 0.8507 - precision: 0.8731 - recall: 0.812 - ETA: 0s - loss: 0.4744 - accuracy: 0.8381 - precision: 0.8632 - recall: 0.806 - ETA: 0s - loss: 0.5069 - accuracy: 0.8245 - precision: 0.8538 - recall: 0.786 - 1s 2ms/sample - loss: 0.5146 - accuracy: 0.8192 - precision: 0.8473 - recall: 0.7817 - val_loss: 1.3232 - val_accuracy: 0.5493 - val_precision: 0.5692 - val_recall: 0.5211\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7812 - precision: 0.7667 - recall: 0.718 - ETA: 0s - loss: 0.8010 - accuracy: 0.6979 - precision: 0.7386 - recall: 0.677 - ETA: 0s - loss: 0.7874 - accuracy: 0.7250 - precision: 0.7762 - recall: 0.693 - ETA: 0s - loss: 0.7975 - accuracy: 0.7143 - precision: 0.7727 - recall: 0.683 - ETA: 0s - loss: 0.7484 - accuracy: 0.7257 - precision: 0.7817 - recall: 0.684 - ETA: 0s - loss: 0.6846 - accuracy: 0.7500 - precision: 0.8091 - recall: 0.710 - ETA: 0s - loss: 0.6956 - accuracy: 0.7452 - precision: 0.7995 - recall: 0.709 - 1s 2ms/sample - loss: 0.6869 - accuracy: 0.7465 - precision: 0.8016 - recall: 0.7113 - val_loss: 1.1911 - val_accuracy: 0.5845 - val_precision: 0.6311 - val_recall: 0.5423\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.7812 - precision: 0.7812 - recall: 0.781 - ETA: 0s - loss: 0.7312 - accuracy: 0.6979 - precision: 0.7241 - recall: 0.656 - ETA: 0s - loss: 0.5740 - accuracy: 0.7875 - precision: 0.8056 - recall: 0.725 - ETA: 0s - loss: 0.5783 - accuracy: 0.7857 - precision: 0.8010 - recall: 0.718 - ETA: 0s - loss: 0.5561 - accuracy: 0.7951 - precision: 0.8140 - recall: 0.729 - ETA: 0s - loss: 0.5879 - accuracy: 0.7869 - precision: 0.8025 - recall: 0.727 - ETA: 0s - loss: 0.6047 - accuracy: 0.7812 - precision: 0.8032 - recall: 0.716 - 1s 2ms/sample - loss: 0.5939 - accuracy: 0.7864 - precision: 0.8084 - recall: 0.7230 - val_loss: 0.8921 - val_accuracy: 0.6972 - val_precision: 0.7581 - val_recall: 0.6620\n",
      "Epoch 132/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8750 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.4031 - accuracy: 0.8438 - precision: 0.8681 - recall: 0.822 - ETA: 0s - loss: 0.4446 - accuracy: 0.8250 - precision: 0.8446 - recall: 0.781 - ETA: 0s - loss: 0.4696 - accuracy: 0.8170 - precision: 0.8413 - recall: 0.781 - ETA: 0s - loss: 0.4737 - accuracy: 0.8125 - precision: 0.8364 - recall: 0.781 - ETA: 0s - loss: 0.4692 - accuracy: 0.8125 - precision: 0.8359 - recall: 0.781 - ETA: 0s - loss: 0.4494 - accuracy: 0.8221 - precision: 0.8436 - recall: 0.790 - 1s 2ms/sample - loss: 0.4533 - accuracy: 0.8216 - precision: 0.8425 - recall: 0.7911 - val_loss: 0.9001 - val_accuracy: 0.6761 - val_precision: 0.7031 - val_recall: 0.6338\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.8750 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.3677 - accuracy: 0.8438 - precision: 0.8864 - recall: 0.812 - ETA: 0s - loss: 0.3420 - accuracy: 0.8813 - precision: 0.9110 - recall: 0.831 - ETA: 0s - loss: 0.3628 - accuracy: 0.8795 - precision: 0.9078 - recall: 0.834 - ETA: 0s - loss: 0.3719 - accuracy: 0.8750 - precision: 0.8973 - recall: 0.819 - ETA: 0s - loss: 0.3780 - accuracy: 0.8722 - precision: 0.8947 - recall: 0.821 - ETA: 0s - loss: 0.3937 - accuracy: 0.8630 - precision: 0.8903 - recall: 0.819 - 1s 2ms/sample - loss: 0.3866 - accuracy: 0.8662 - precision: 0.8931 - recall: 0.8239 - val_loss: 0.8934 - val_accuracy: 0.6901 - val_precision: 0.7165 - val_recall: 0.6408\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9688 - precision: 0.9677 - recall: 0.937 - ETA: 0s - loss: 0.3363 - accuracy: 0.8958 - precision: 0.9213 - recall: 0.854 - ETA: 0s - loss: 0.3457 - accuracy: 0.8750 - precision: 0.8933 - recall: 0.837 - ETA: 0s - loss: 0.3296 - accuracy: 0.8839 - precision: 0.9139 - recall: 0.852 - ETA: 0s - loss: 0.3454 - accuracy: 0.8750 - precision: 0.9037 - recall: 0.847 - ETA: 0s - loss: 0.3450 - accuracy: 0.8722 - precision: 0.9085 - recall: 0.846 - ETA: 0s - loss: 0.3353 - accuracy: 0.8798 - precision: 0.9105 - recall: 0.855 - 1s 2ms/sample - loss: 0.3373 - accuracy: 0.8756 - precision: 0.9098 - recall: 0.8521 - val_loss: 0.9521 - val_accuracy: 0.6831 - val_precision: 0.7077 - val_recall: 0.6479\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.8750 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.2840 - accuracy: 0.8854 - precision: 0.9239 - recall: 0.885 - ETA: 0s - loss: 0.3163 - accuracy: 0.8875 - precision: 0.9079 - recall: 0.862 - ETA: 0s - loss: 0.3111 - accuracy: 0.8839 - precision: 0.8977 - recall: 0.861 - ETA: 0s - loss: 0.2849 - accuracy: 0.8889 - precision: 0.8996 - recall: 0.871 - ETA: 0s - loss: 0.2835 - accuracy: 0.8949 - precision: 0.9038 - recall: 0.880 - ETA: 0s - loss: 0.3043 - accuracy: 0.8880 - precision: 0.8984 - recall: 0.875 - 1s 2ms/sample - loss: 0.3035 - accuracy: 0.8873 - precision: 0.8983 - recall: 0.8709 - val_loss: 1.0554 - val_accuracy: 0.6831 - val_precision: 0.6978 - val_recall: 0.6831\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.8750 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.2673 - accuracy: 0.8854 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.2898 - accuracy: 0.8750 - precision: 0.8961 - recall: 0.862 - ETA: 0s - loss: 0.2854 - accuracy: 0.8929 - precision: 0.9159 - recall: 0.875 - ETA: 0s - loss: 0.3098 - accuracy: 0.8854 - precision: 0.9058 - recall: 0.868 - ETA: 0s - loss: 0.3279 - accuracy: 0.8722 - precision: 0.8961 - recall: 0.858 - ETA: 0s - loss: 0.3341 - accuracy: 0.8702 - precision: 0.8925 - recall: 0.858 - 1s 2ms/sample - loss: 0.3331 - accuracy: 0.8709 - precision: 0.8949 - recall: 0.8592 - val_loss: 0.8869 - val_accuracy: 0.7254 - val_precision: 0.7752 - val_recall: 0.7042\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8125 - precision: 0.8966 - recall: 0.812 - ETA: 0s - loss: 0.2159 - accuracy: 0.9062 - precision: 0.9560 - recall: 0.906 - ETA: 0s - loss: 0.2504 - accuracy: 0.9125 - precision: 0.9467 - recall: 0.887 - ETA: 0s - loss: 0.2883 - accuracy: 0.8839 - precision: 0.9234 - recall: 0.861 - ETA: 0s - loss: 0.2675 - accuracy: 0.9028 - precision: 0.9370 - recall: 0.878 - ETA: 0s - loss: 0.2637 - accuracy: 0.9091 - precision: 0.9398 - recall: 0.886 - ETA: 0s - loss: 0.2765 - accuracy: 0.8966 - precision: 0.9288 - recall: 0.877 - 1s 2ms/sample - loss: 0.2747 - accuracy: 0.8967 - precision: 0.9280 - recall: 0.8779 - val_loss: 1.0251 - val_accuracy: 0.6408 - val_precision: 0.6642 - val_recall: 0.6268\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.8750 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.3902 - accuracy: 0.8750 - precision: 0.8791 - recall: 0.833 - ETA: 0s - loss: 0.3962 - accuracy: 0.8625 - precision: 0.8627 - recall: 0.825 - ETA: 0s - loss: 0.3703 - accuracy: 0.8705 - precision: 0.8698 - recall: 0.834 - ETA: 0s - loss: 0.3633 - accuracy: 0.8715 - precision: 0.8796 - recall: 0.836 - ETA: 0s - loss: 0.3750 - accuracy: 0.8608 - precision: 0.8716 - recall: 0.829 - ETA: 0s - loss: 0.3641 - accuracy: 0.8678 - precision: 0.8810 - recall: 0.836 - 1s 2ms/sample - loss: 0.3683 - accuracy: 0.8662 - precision: 0.8790 - recall: 0.8357 - val_loss: 1.2067 - val_accuracy: 0.6549 - val_precision: 0.6800 - val_recall: 0.5986\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.7188 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.4602 - accuracy: 0.8438 - precision: 0.8681 - recall: 0.822 - ETA: 0s - loss: 0.4436 - accuracy: 0.8375 - precision: 0.8828 - recall: 0.800 - ETA: 0s - loss: 0.4161 - accuracy: 0.8542 - precision: 0.8927 - recall: 0.822 - ETA: 0s - loss: 0.4387 - accuracy: 0.8477 - precision: 0.8814 - recall: 0.812 - ETA: 0s - loss: 0.4168 - accuracy: 0.8531 - precision: 0.8829 - recall: 0.825 - ETA: 0s - loss: 0.4238 - accuracy: 0.8464 - precision: 0.8729 - recall: 0.822 - 1s 2ms/sample - loss: 0.4124 - accuracy: 0.8545 - precision: 0.8781 - recall: 0.8286 - val_loss: 1.0601 - val_accuracy: 0.6620 - val_precision: 0.7008 - val_recall: 0.6268\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9932 - accuracy: 0.6562 - precision: 0.7778 - recall: 0.656 - ETA: 0s - loss: 0.5594 - accuracy: 0.7917 - precision: 0.8488 - recall: 0.760 - ETA: 0s - loss: 0.5277 - accuracy: 0.8062 - precision: 0.8414 - recall: 0.762 - ETA: 0s - loss: 0.7819 - accuracy: 0.7545 - precision: 0.7864 - recall: 0.723 - ETA: 0s - loss: 0.7108 - accuracy: 0.7812 - precision: 0.8113 - recall: 0.746 - ETA: 0s - loss: 0.8212 - accuracy: 0.7386 - precision: 0.7631 - recall: 0.704 - ETA: 0s - loss: 0.8327 - accuracy: 0.7284 - precision: 0.7572 - recall: 0.697 - 1s 2ms/sample - loss: 0.8203 - accuracy: 0.7324 - precision: 0.7608 - recall: 0.7019 - val_loss: 1.4624 - val_accuracy: 0.5141 - val_precision: 0.5203 - val_recall: 0.4507\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.8125 - precision: 0.8571 - recall: 0.750 - ETA: 0s - loss: 0.6986 - accuracy: 0.7708 - precision: 0.8256 - recall: 0.739 - ETA: 0s - loss: 0.6708 - accuracy: 0.7688 - precision: 0.8112 - recall: 0.725 - ETA: 0s - loss: 0.6557 - accuracy: 0.7589 - precision: 0.8083 - recall: 0.696 - ETA: 0s - loss: 0.6351 - accuracy: 0.7674 - precision: 0.8040 - recall: 0.697 - ETA: 0s - loss: 0.6461 - accuracy: 0.7642 - precision: 0.8073 - recall: 0.690 - ETA: 0s - loss: 0.6186 - accuracy: 0.7668 - precision: 0.8067 - recall: 0.692 - 1s 2ms/sample - loss: 0.6136 - accuracy: 0.7700 - precision: 0.8110 - recall: 0.6948 - val_loss: 1.1041 - val_accuracy: 0.5986 - val_precision: 0.6404 - val_recall: 0.5141\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.7812 - precision: 0.8846 - recall: 0.718 - ETA: 0s - loss: 0.4761 - accuracy: 0.8542 - precision: 0.8941 - recall: 0.791 - ETA: 0s - loss: 0.4705 - accuracy: 0.8500 - precision: 0.8857 - recall: 0.775 - ETA: 0s - loss: 0.5050 - accuracy: 0.8482 - precision: 0.8744 - recall: 0.776 - ETA: 0s - loss: 0.5210 - accuracy: 0.8438 - precision: 0.8706 - recall: 0.770 - ETA: 0s - loss: 0.5086 - accuracy: 0.8466 - precision: 0.8675 - recall: 0.781 - ETA: 0s - loss: 0.5083 - accuracy: 0.8462 - precision: 0.8632 - recall: 0.788 - 1s 2ms/sample - loss: 0.5102 - accuracy: 0.8451 - precision: 0.8638 - recall: 0.7887 - val_loss: 1.1191 - val_accuracy: 0.6338 - val_precision: 0.6667 - val_recall: 0.6056\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.9062 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.5480 - accuracy: 0.7812 - precision: 0.8000 - recall: 0.750 - ETA: 0s - loss: 0.3972 - accuracy: 0.8438 - precision: 0.8689 - recall: 0.828 - ETA: 0s - loss: 0.3910 - accuracy: 0.8438 - precision: 0.8641 - recall: 0.828 - ETA: 0s - loss: 0.4027 - accuracy: 0.8438 - precision: 0.8689 - recall: 0.828 - ETA: 0s - loss: 0.4281 - accuracy: 0.8403 - precision: 0.8650 - recall: 0.822 - ETA: 0s - loss: 0.4439 - accuracy: 0.8352 - precision: 0.8610 - recall: 0.809 - ETA: 0s - loss: 0.4542 - accuracy: 0.8307 - precision: 0.8579 - recall: 0.802 - 1s 2ms/sample - loss: 0.4429 - accuracy: 0.8333 - precision: 0.8579 - recall: 0.8075 - val_loss: 0.9789 - val_accuracy: 0.6761 - val_precision: 0.7008 - val_recall: 0.6268\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.906 - ETA: 0s - loss: 0.3745 - accuracy: 0.8854 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.4977 - accuracy: 0.8125 - precision: 0.8514 - recall: 0.787 - ETA: 0s - loss: 0.6090 - accuracy: 0.7857 - precision: 0.8244 - recall: 0.754 - ETA: 0s - loss: 0.5617 - accuracy: 0.8090 - precision: 0.8377 - recall: 0.770 - ETA: 0s - loss: 0.5468 - accuracy: 0.8097 - precision: 0.8349 - recall: 0.775 - ETA: 0s - loss: 0.5431 - accuracy: 0.8053 - precision: 0.8303 - recall: 0.776 - 1s 2ms/sample - loss: 0.5496 - accuracy: 0.8028 - precision: 0.8291 - recall: 0.7746 - val_loss: 1.0697 - val_accuracy: 0.6479 - val_precision: 0.6466 - val_recall: 0.6056\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7188 - precision: 0.8800 - recall: 0.687 - ETA: 0s - loss: 0.4841 - accuracy: 0.7917 - precision: 0.8690 - recall: 0.760 - ETA: 0s - loss: 0.4782 - accuracy: 0.7812 - precision: 0.8440 - recall: 0.743 - ETA: 0s - loss: 0.4512 - accuracy: 0.8036 - precision: 0.8500 - recall: 0.758 - ETA: 0s - loss: 0.4731 - accuracy: 0.7882 - precision: 0.8366 - recall: 0.746 - ETA: 0s - loss: 0.4843 - accuracy: 0.7869 - precision: 0.8291 - recall: 0.744 - ETA: 0s - loss: 0.4965 - accuracy: 0.7909 - precision: 0.8298 - recall: 0.750 - 1s 2ms/sample - loss: 0.4909 - accuracy: 0.7958 - precision: 0.8342 - recall: 0.7559 - val_loss: 1.0895 - val_accuracy: 0.6549 - val_precision: 0.6880 - val_recall: 0.6056\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7812 - precision: 0.8000 - recall: 0.750 - ETA: 0s - loss: 0.4275 - accuracy: 0.8438 - precision: 0.8652 - recall: 0.802 - ETA: 0s - loss: 0.3938 - accuracy: 0.8500 - precision: 0.8776 - recall: 0.806 - ETA: 0s - loss: 0.4104 - accuracy: 0.8571 - precision: 0.8786 - recall: 0.808 - ETA: 0s - loss: 0.4149 - accuracy: 0.8542 - precision: 0.8694 - recall: 0.809 - ETA: 0s - loss: 0.4440 - accuracy: 0.8352 - precision: 0.8515 - recall: 0.798 - ETA: 0s - loss: 0.4342 - accuracy: 0.8389 - precision: 0.8546 - recall: 0.805 - 1s 2ms/sample - loss: 0.4357 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8028 - val_loss: 0.9554 - val_accuracy: 0.6901 - val_precision: 0.7154 - val_recall: 0.6549\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.8438 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.3580 - accuracy: 0.8438 - precision: 0.8681 - recall: 0.822 - ETA: 0s - loss: 0.4347 - accuracy: 0.8125 - precision: 0.8278 - recall: 0.781 - ETA: 0s - loss: 0.4583 - accuracy: 0.8214 - precision: 0.8310 - recall: 0.790 - ETA: 0s - loss: 0.4899 - accuracy: 0.8090 - precision: 0.8159 - recall: 0.784 - ETA: 0s - loss: 0.5035 - accuracy: 0.8040 - precision: 0.8136 - recall: 0.781 - ETA: 0s - loss: 0.5284 - accuracy: 0.7957 - precision: 0.8045 - recall: 0.771 - 1s 2ms/sample - loss: 0.5415 - accuracy: 0.7911 - precision: 0.7990 - recall: 0.7653 - val_loss: 1.4339 - val_accuracy: 0.5282 - val_precision: 0.5935 - val_recall: 0.5141\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6562 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 1.0578 - accuracy: 0.6562 - precision: 0.7342 - recall: 0.604 - ETA: 0s - loss: 0.9228 - accuracy: 0.7063 - precision: 0.7769 - recall: 0.631 - ETA: 0s - loss: 0.9558 - accuracy: 0.6875 - precision: 0.7650 - recall: 0.625 - ETA: 0s - loss: 0.8747 - accuracy: 0.7049 - precision: 0.7797 - recall: 0.638 - ETA: 0s - loss: 0.8531 - accuracy: 0.7094 - precision: 0.7868 - recall: 0.634 - ETA: 0s - loss: 0.7983 - accuracy: 0.7188 - precision: 0.7886 - recall: 0.651 - 1s 2ms/sample - loss: 0.7692 - accuracy: 0.7254 - precision: 0.7915 - recall: 0.6596 - val_loss: 1.1017 - val_accuracy: 0.5915 - val_precision: 0.6639 - val_recall: 0.5704\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.8750 - precision: 0.9286 - recall: 0.812 - ETA: 0s - loss: 0.4782 - accuracy: 0.8021 - precision: 0.8605 - recall: 0.770 - ETA: 0s - loss: 0.6205 - accuracy: 0.7625 - precision: 0.8085 - recall: 0.712 - ETA: 0s - loss: 0.5784 - accuracy: 0.7902 - precision: 0.8376 - recall: 0.736 - ETA: 0s - loss: 0.5392 - accuracy: 0.8021 - precision: 0.8452 - recall: 0.739 - ETA: 0s - loss: 0.5486 - accuracy: 0.7955 - precision: 0.8399 - recall: 0.730 - ETA: 0s - loss: 0.5435 - accuracy: 0.7981 - precision: 0.8425 - recall: 0.733 - 1s 2ms/sample - loss: 0.5534 - accuracy: 0.7934 - precision: 0.8383 - recall: 0.7300 - val_loss: 1.0346 - val_accuracy: 0.6479 - val_precision: 0.7025 - val_recall: 0.5986\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.9062 - precision: 0.9630 - recall: 0.812 - ETA: 0s - loss: 0.4522 - accuracy: 0.8750 - precision: 0.9024 - recall: 0.770 - ETA: 0s - loss: 0.4476 - accuracy: 0.8625 - precision: 0.8889 - recall: 0.750 - ETA: 0s - loss: 0.4215 - accuracy: 0.8795 - precision: 0.9062 - recall: 0.776 - ETA: 0s - loss: 0.4293 - accuracy: 0.8681 - precision: 0.8984 - recall: 0.767 - ETA: 0s - loss: 0.4307 - accuracy: 0.8523 - precision: 0.8940 - recall: 0.767 - ETA: 0s - loss: 0.4252 - accuracy: 0.8516 - precision: 0.8916 - recall: 0.770 - ETA: 0s - loss: 0.4215 - accuracy: 0.8462 - precision: 0.8867 - recall: 0.771 - 1s 2ms/sample - loss: 0.4162 - accuracy: 0.8498 - precision: 0.8898 - recall: 0.7770 - val_loss: 1.1173 - val_accuracy: 0.6479 - val_precision: 0.7049 - val_recall: 0.6056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f166411692d310016ca2dc7d04132d81</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7253521084785461</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 698,124\n",
      "Trainable params: 698,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:25 - loss: 2.4866 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 39s - loss: 2.4816 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 16s - loss: 2.4527 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 8s - loss: 2.4620 - accuracy: 0.0781 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 6s - loss: 2.4568 - accuracy: 0.0982 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 3s - loss: 2.4205 - accuracy: 0.1076 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.4229 - accuracy: 0.1136 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4114 - accuracy: 0.1094 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3902 - accuracy: 0.1178 - precision: 0.0000e+00 - recall: 0.0000e+0 - 10s 23ms/sample - loss: 2.3864 - accuracy: 0.1150 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2134 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0837 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0396 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0424 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0361 - accuracy: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0671 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0533 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0509 - accuracy: 0.2005 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0698 - accuracy: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.0790 - accuracy: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8781 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9974 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9134 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9864 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0070 - accuracy: 0.1920 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0270 - accuracy: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0117 - accuracy: 0.1733 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0183 - accuracy: 0.1659 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.0154 - accuracy: 0.1643 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9081 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8531 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8697 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8964 - accuracy: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9042 - accuracy: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9117 - accuracy: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9806 - accuracy: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9738 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9633 - accuracy: 0.2254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0378 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1280 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9827 - accuracy: 0.1771 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9109 - accuracy: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8662 - accuracy: 0.2366 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8827 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8870 - accuracy: 0.2216 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8662 - accuracy: 0.2284 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8642 - accuracy: 0.2300 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8184 - val_accuracy: 0.2535 - val_precision: 0.5000 - val_recall: 0.0211\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7971 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7828 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7946 - accuracy: 0.2750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8070 - accuracy: 0.2812 - precision: 0.5714 - recall: 0.0179        - ETA: 0s - loss: 1.8098 - accuracy: 0.2812 - precision: 0.5455 - recall: 0.020 - ETA: 0s - loss: 1.7994 - accuracy: 0.2841 - precision: 0.5294 - recall: 0.025 - ETA: 0s - loss: 1.7990 - accuracy: 0.2812 - precision: 0.5500 - recall: 0.026 - 1s 1ms/sample - loss: 1.7984 - accuracy: 0.2817 - precision: 0.5500 - recall: 0.0258 - val_loss: 1.7734 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7741 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8175 - accuracy: 0.2604 - precision: 0.6667 - recall: 0.0208        - ETA: 0s - loss: 1.7861 - accuracy: 0.2812 - precision: 0.4615 - recall: 0.037 - ETA: 0s - loss: 1.7913 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.040 - ETA: 0s - loss: 1.7726 - accuracy: 0.2639 - precision: 0.5000 - recall: 0.041 - ETA: 0s - loss: 1.7716 - accuracy: 0.2585 - precision: 0.5000 - recall: 0.036 - ETA: 0s - loss: 1.8019 - accuracy: 0.2404 - precision: 0.5000 - recall: 0.031 - 1s 1ms/sample - loss: 1.7982 - accuracy: 0.2441 - precision: 0.5000 - recall: 0.0305 - val_loss: 1.7905 - val_accuracy: 0.2606 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7218 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9067 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9033 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8262 - accuracy: 0.2946 - precision: 0.6667 - recall: 0.0089        - ETA: 0s - loss: 1.7874 - accuracy: 0.2917 - precision: 0.5714 - recall: 0.027 - ETA: 0s - loss: 1.8095 - accuracy: 0.2642 - precision: 0.4545 - recall: 0.028 - ETA: 0s - loss: 1.8309 - accuracy: 0.2716 - precision: 0.4167 - recall: 0.024 - 1s 1ms/sample - loss: 1.8295 - accuracy: 0.2723 - precision: 0.4400 - recall: 0.0258 - val_loss: 1.7672 - val_accuracy: 0.2606 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7860 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.7637 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.062 - ETA: 0s - loss: 1.7371 - accuracy: 0.2750 - precision: 0.5000 - recall: 0.037 - ETA: 0s - loss: 1.7206 - accuracy: 0.2768 - precision: 0.4583 - recall: 0.049 - ETA: 0s - loss: 1.7515 - accuracy: 0.2604 - precision: 0.3929 - recall: 0.038 - ETA: 0s - loss: 1.7945 - accuracy: 0.2330 - precision: 0.4138 - recall: 0.034 - ETA: 0s - loss: 1.7789 - accuracy: 0.2404 - precision: 0.4138 - recall: 0.028 - 1s 1ms/sample - loss: 1.7747 - accuracy: 0.2394 - precision: 0.4138 - recall: 0.0282 - val_loss: 1.8274 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6888 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7619 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7375 - accuracy: 0.2750 - precision: 0.3333 - recall: 0.0125        - ETA: 0s - loss: 1.7369 - accuracy: 0.2679 - precision: 0.2222 - recall: 0.008 - ETA: 0s - loss: 1.7632 - accuracy: 0.2569 - precision: 0.1667 - recall: 0.006 - ETA: 0s - loss: 1.7833 - accuracy: 0.2614 - precision: 0.2308 - recall: 0.008 - ETA: 0s - loss: 1.7484 - accuracy: 0.2788 - precision: 0.3529 - recall: 0.014 - 1s 1ms/sample - loss: 1.7459 - accuracy: 0.2793 - precision: 0.3529 - recall: 0.0141 - val_loss: 1.7758 - val_accuracy: 0.2465 - val_precision: 0.8000 - val_recall: 0.0282\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6562 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6938 - accuracy: 0.3229 - precision: 0.8571 - recall: 0.062 - ETA: 0s - loss: 1.6823 - accuracy: 0.3375 - precision: 0.9091 - recall: 0.062 - ETA: 0s - loss: 1.7114 - accuracy: 0.3304 - precision: 0.7333 - recall: 0.049 - ETA: 0s - loss: 1.7774 - accuracy: 0.3194 - precision: 0.6364 - recall: 0.048 - ETA: 0s - loss: 1.7744 - accuracy: 0.3153 - precision: 0.5625 - recall: 0.051 - ETA: 0s - loss: 1.7876 - accuracy: 0.3197 - precision: 0.5676 - recall: 0.050 - 1s 1ms/sample - loss: 1.7794 - accuracy: 0.3192 - precision: 0.5676 - recall: 0.0493 - val_loss: 2.0048 - val_accuracy: 0.2324 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7661 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.9761 - accuracy: 0.2344 - precision: 0.5714 - recall: 0.062 - ETA: 0s - loss: 1.9786 - accuracy: 0.2578 - precision: 0.3333 - recall: 0.039 - ETA: 0s - loss: 1.9125 - accuracy: 0.2969 - precision: 0.5000 - recall: 0.052 - ETA: 0s - loss: 1.9323 - accuracy: 0.2812 - precision: 0.5217 - recall: 0.046 - ETA: 0s - loss: 1.9582 - accuracy: 0.2594 - precision: 0.5217 - recall: 0.037 - ETA: 0s - loss: 1.9755 - accuracy: 0.2448 - precision: 0.4444 - recall: 0.041 - 1s 2ms/sample - loss: 1.9589 - accuracy: 0.2512 - precision: 0.4615 - recall: 0.0423 - val_loss: 1.7177 - val_accuracy: 0.3380 - val_precision: 0.5000 - val_recall: 0.0070\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0289 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9418 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9736 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9248 - accuracy: 0.2411 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9015 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9818 - accuracy: 0.2313 - precision: 1.0000 - recall: 0.0063        - ETA: 0s - loss: 2.0385 - accuracy: 0.2273 - precision: 1.0000 - recall: 0.005 - ETA: 0s - loss: 2.0305 - accuracy: 0.2139 - precision: 0.6667 - recall: 0.004 - 1s 2ms/sample - loss: 2.0312 - accuracy: 0.2113 - precision: 0.6667 - recall: 0.0047 - val_loss: 1.9664 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8766 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8136 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8314 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0761 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0028 - accuracy: 0.2257 - precision: 1.0000 - recall: 0.0174        - ETA: 0s - loss: 1.9987 - accuracy: 0.2074 - precision: 0.5385 - recall: 0.019 - ETA: 0s - loss: 2.0069 - accuracy: 0.1995 - precision: 0.3929 - recall: 0.026 - 1s 1ms/sample - loss: 2.0141 - accuracy: 0.1995 - precision: 0.4194 - recall: 0.0305 - val_loss: 2.0633 - val_accuracy: 0.2113 - val_precision: 1.0000 - val_recall: 0.0352\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0673 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.9267 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.010 - ETA: 0s - loss: 1.8504 - accuracy: 0.3000 - precision: 0.5000 - recall: 0.006 - ETA: 0s - loss: 1.8499 - accuracy: 0.2946 - precision: 0.5000 - recall: 0.004 - ETA: 0s - loss: 1.8507 - accuracy: 0.2951 - precision: 0.5000 - recall: 0.003 - ETA: 0s - loss: 1.8869 - accuracy: 0.2869 - precision: 0.5000 - recall: 0.002 - ETA: 0s - loss: 1.8784 - accuracy: 0.2837 - precision: 0.5000 - recall: 0.002 - 1s 1ms/sample - loss: 1.8775 - accuracy: 0.2817 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.7957 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6165 - accuracy: 0.4375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7439 - accuracy: 0.3333 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7506 - accuracy: 0.3562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7477 - accuracy: 0.3259 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7425 - accuracy: 0.3299 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7540 - accuracy: 0.3210 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7769 - accuracy: 0.3005 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7740 - accuracy: 0.3028 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7193 - val_accuracy: 0.2887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5490 - accuracy: 0.4062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6283 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7056 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6992 - accuracy: 0.2991 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7095 - accuracy: 0.2743 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7066 - accuracy: 0.2869 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7344 - accuracy: 0.2764 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7315 - accuracy: 0.2817 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7600 - val_accuracy: 0.2817 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8063 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7243 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.6994 - accuracy: 0.3187 - precision: 0.6667 - recall: 0.025 - ETA: 0s - loss: 1.7073 - accuracy: 0.3281 - precision: 0.7500 - recall: 0.031 - ETA: 0s - loss: 1.7018 - accuracy: 0.3086 - precision: 0.7273 - recall: 0.031 - ETA: 0s - loss: 1.7054 - accuracy: 0.3125 - precision: 0.7273 - recall: 0.025 - ETA: 0s - loss: 1.7040 - accuracy: 0.3047 - precision: 0.6667 - recall: 0.020 - 1s 1ms/sample - loss: 1.7049 - accuracy: 0.3075 - precision: 0.6667 - recall: 0.0188 - val_loss: 1.8671 - val_accuracy: 0.2535 - val_precision: 0.3913 - val_recall: 0.0634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6743 - accuracy: 0.3750 - precision: 0.4444 - recall: 0.125 - ETA: 0s - loss: 1.7469 - accuracy: 0.3438 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.6930 - accuracy: 0.3562 - precision: 0.4583 - recall: 0.068 - ETA: 0s - loss: 1.7231 - accuracy: 0.3214 - precision: 0.4800 - recall: 0.053 - ETA: 0s - loss: 1.7101 - accuracy: 0.3056 - precision: 0.5000 - recall: 0.048 - ETA: 0s - loss: 1.7367 - accuracy: 0.3011 - precision: 0.5172 - recall: 0.042 - ETA: 0s - loss: 1.7355 - accuracy: 0.2981 - precision: 0.5161 - recall: 0.038 - 1s 1ms/sample - loss: 1.7313 - accuracy: 0.3005 - precision: 0.5312 - recall: 0.0399 - val_loss: 1.6966 - val_accuracy: 0.2817 - val_precision: 0.8333 - val_recall: 0.0352\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8313 - accuracy: 0.1562 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7147 - accuracy: 0.3021 - precision: 0.5714 - recall: 0.041 - ETA: 0s - loss: 1.7002 - accuracy: 0.3063 - precision: 0.6000 - recall: 0.037 - ETA: 0s - loss: 1.6762 - accuracy: 0.3393 - precision: 0.5833 - recall: 0.031 - ETA: 0s - loss: 1.6598 - accuracy: 0.3438 - precision: 0.6429 - recall: 0.031 - ETA: 0s - loss: 1.6751 - accuracy: 0.3267 - precision: 0.6667 - recall: 0.034 - ETA: 0s - loss: 1.6935 - accuracy: 0.3221 - precision: 0.7000 - recall: 0.033 - 1s 1ms/sample - loss: 1.6866 - accuracy: 0.3263 - precision: 0.7000 - recall: 0.0329 - val_loss: 1.8182 - val_accuracy: 0.2676 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7466 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7548 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.7154 - accuracy: 0.3375 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.6911 - accuracy: 0.3259 - precision: 0.5000 - recall: 0.013 - ETA: 0s - loss: 1.7021 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.010 - ETA: 0s - loss: 1.7270 - accuracy: 0.2898 - precision: 0.4000 - recall: 0.011 - ETA: 0s - loss: 1.6851 - accuracy: 0.3197 - precision: 0.6250 - recall: 0.024 - 1s 1ms/sample - loss: 1.6803 - accuracy: 0.3216 - precision: 0.6250 - recall: 0.0235 - val_loss: 1.7053 - val_accuracy: 0.3028 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8598 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6257 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.0104        - ETA: 0s - loss: 1.6196 - accuracy: 0.3938 - precision: 1.0000 - recall: 0.043 - ETA: 0s - loss: 1.6203 - accuracy: 0.4018 - precision: 0.8182 - recall: 0.040 - ETA: 0s - loss: 1.6293 - accuracy: 0.3750 - precision: 0.7333 - recall: 0.038 - ETA: 0s - loss: 1.6799 - accuracy: 0.3494 - precision: 0.6000 - recall: 0.034 - ETA: 0s - loss: 1.6694 - accuracy: 0.3558 - precision: 0.6286 - recall: 0.052 - 1s 1ms/sample - loss: 1.6787 - accuracy: 0.3521 - precision: 0.6111 - recall: 0.0516 - val_loss: 1.7624 - val_accuracy: 0.2676 - val_precision: 0.5263 - val_recall: 0.0704\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8573 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.8271 - accuracy: 0.2604 - precision: 0.3571 - recall: 0.052 - ETA: 0s - loss: 1.7267 - accuracy: 0.3187 - precision: 0.4737 - recall: 0.056 - ETA: 0s - loss: 1.6526 - accuracy: 0.3482 - precision: 0.5000 - recall: 0.053 - ETA: 0s - loss: 1.6215 - accuracy: 0.3681 - precision: 0.5714 - recall: 0.055 - ETA: 0s - loss: 1.6454 - accuracy: 0.3608 - precision: 0.5333 - recall: 0.045 - ETA: 0s - loss: 1.6503 - accuracy: 0.3582 - precision: 0.5455 - recall: 0.043 - 1s 1ms/sample - loss: 1.6451 - accuracy: 0.3592 - precision: 0.5455 - recall: 0.0423 - val_loss: 1.6240 - val_accuracy: 0.3380 - val_precision: 0.7619 - val_recall: 0.1127\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3959 - accuracy: 0.4062 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.4882 - accuracy: 0.3333 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.6304 - accuracy: 0.2937 - precision: 0.6154 - recall: 0.100 - ETA: 0s - loss: 1.6475 - accuracy: 0.2991 - precision: 0.6364 - recall: 0.093 - ETA: 0s - loss: 1.6406 - accuracy: 0.3125 - precision: 0.6571 - recall: 0.079 - ETA: 0s - loss: 1.6403 - accuracy: 0.3210 - precision: 0.6667 - recall: 0.090 - ETA: 0s - loss: 1.6213 - accuracy: 0.3293 - precision: 0.6607 - recall: 0.088 - 1s 2ms/sample - loss: 1.6244 - accuracy: 0.3239 - precision: 0.6607 - recall: 0.0869 - val_loss: 1.5234 - val_accuracy: 0.3803 - val_precision: 0.9333 - val_recall: 0.0986\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6563 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.6182 - accuracy: 0.3646 - precision: 1.0000 - recall: 0.083 - ETA: 0s - loss: 1.5898 - accuracy: 0.3938 - precision: 0.8571 - recall: 0.075 - ETA: 0s - loss: 1.5613 - accuracy: 0.4018 - precision: 0.9000 - recall: 0.080 - ETA: 0s - loss: 1.5520 - accuracy: 0.3889 - precision: 0.8400 - recall: 0.072 - ETA: 0s - loss: 1.5371 - accuracy: 0.3778 - precision: 0.7941 - recall: 0.076 - ETA: 0s - loss: 1.5227 - accuracy: 0.3942 - precision: 0.7857 - recall: 0.079 - 1s 1ms/sample - loss: 1.5295 - accuracy: 0.3897 - precision: 0.7857 - recall: 0.0775 - val_loss: 1.6208 - val_accuracy: 0.3310 - val_precision: 0.9048 - val_recall: 0.1338\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.4607 - accuracy: 0.4167 - precision: 0.7778 - recall: 0.072 - ETA: 0s - loss: 1.5357 - accuracy: 0.3438 - precision: 0.7143 - recall: 0.062 - ETA: 0s - loss: 1.5511 - accuracy: 0.3348 - precision: 0.6667 - recall: 0.071 - ETA: 0s - loss: 1.5451 - accuracy: 0.3542 - precision: 0.7188 - recall: 0.079 - ETA: 0s - loss: 1.5144 - accuracy: 0.3551 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5155 - accuracy: 0.3534 - precision: 0.7593 - recall: 0.098 - 1s 2ms/sample - loss: 1.5133 - accuracy: 0.3592 - precision: 0.7679 - recall: 0.1009 - val_loss: 1.4885 - val_accuracy: 0.3944 - val_precision: 0.9091 - val_recall: 0.1408\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3883 - accuracy: 0.4688 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.3953 - accuracy: 0.4167 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.4241 - accuracy: 0.4375 - precision: 0.7308 - recall: 0.118 - ETA: 0s - loss: 1.4443 - accuracy: 0.4152 - precision: 0.7576 - recall: 0.111 - ETA: 0s - loss: 1.4955 - accuracy: 0.3819 - precision: 0.7568 - recall: 0.097 - ETA: 0s - loss: 1.4893 - accuracy: 0.3778 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4772 - accuracy: 0.3894 - precision: 0.7500 - recall: 0.101 - 1s 1ms/sample - loss: 1.4869 - accuracy: 0.3873 - precision: 0.7368 - recall: 0.0986 - val_loss: 1.4813 - val_accuracy: 0.3521 - val_precision: 0.7931 - val_recall: 0.1620\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2666 - accuracy: 0.5312 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.4609 - accuracy: 0.4167 - precision: 0.6471 - recall: 0.114 - ETA: 0s - loss: 1.3842 - accuracy: 0.4625 - precision: 0.6250 - recall: 0.125 - ETA: 0s - loss: 1.3982 - accuracy: 0.4598 - precision: 0.5909 - recall: 0.116 - ETA: 0s - loss: 1.4452 - accuracy: 0.4444 - precision: 0.6212 - recall: 0.142 - ETA: 0s - loss: 1.4500 - accuracy: 0.4375 - precision: 0.6136 - recall: 0.153 - ETA: 0s - loss: 1.4871 - accuracy: 0.4159 - precision: 0.6122 - recall: 0.144 - 1s 1ms/sample - loss: 1.5026 - accuracy: 0.4085 - precision: 0.6122 - recall: 0.1408 - val_loss: 1.5789 - val_accuracy: 0.3380 - val_precision: 0.7000 - val_recall: 0.1479\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4147 - accuracy: 0.4688 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4466 - accuracy: 0.4583 - precision: 0.7222 - recall: 0.135 - ETA: 0s - loss: 1.4427 - accuracy: 0.4250 - precision: 0.7917 - recall: 0.118 - ETA: 0s - loss: 1.4691 - accuracy: 0.4152 - precision: 0.7667 - recall: 0.102 - ETA: 0s - loss: 1.4882 - accuracy: 0.3993 - precision: 0.7949 - recall: 0.107 - ETA: 0s - loss: 1.5244 - accuracy: 0.3892 - precision: 0.7234 - recall: 0.096 - ETA: 0s - loss: 1.5070 - accuracy: 0.3918 - precision: 0.6885 - recall: 0.101 - 1s 1ms/sample - loss: 1.5008 - accuracy: 0.3944 - precision: 0.6935 - recall: 0.1009 - val_loss: 1.5106 - val_accuracy: 0.3592 - val_precision: 0.6552 - val_recall: 0.1338\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5984 - accuracy: 0.4375 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.5018 - accuracy: 0.4479 - precision: 0.4286 - recall: 0.031 - ETA: 0s - loss: 1.5215 - accuracy: 0.4187 - precision: 0.5294 - recall: 0.056 - ETA: 0s - loss: 1.4985 - accuracy: 0.4196 - precision: 0.6800 - recall: 0.075 - ETA: 0s - loss: 1.4956 - accuracy: 0.4271 - precision: 0.6364 - recall: 0.072 - ETA: 0s - loss: 1.4574 - accuracy: 0.4432 - precision: 0.6809 - recall: 0.090 - ETA: 0s - loss: 1.4347 - accuracy: 0.4375 - precision: 0.6885 - recall: 0.101 - 1s 1ms/sample - loss: 1.4337 - accuracy: 0.4390 - precision: 0.6935 - recall: 0.1009 - val_loss: 1.5134 - val_accuracy: 0.3873 - val_precision: 0.7742 - val_recall: 0.1690\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6815 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.4488 - accuracy: 0.4688 - precision: 0.6818 - recall: 0.156 - ETA: 0s - loss: 1.4915 - accuracy: 0.4250 - precision: 0.6875 - recall: 0.137 - ETA: 0s - loss: 1.4574 - accuracy: 0.4241 - precision: 0.6818 - recall: 0.133 - ETA: 0s - loss: 1.5012 - accuracy: 0.4132 - precision: 0.6852 - recall: 0.128 - ETA: 0s - loss: 1.5010 - accuracy: 0.4091 - precision: 0.7097 - recall: 0.125 - ETA: 0s - loss: 1.5317 - accuracy: 0.3990 - precision: 0.6901 - recall: 0.117 - 1s 1ms/sample - loss: 1.5327 - accuracy: 0.3991 - precision: 0.6944 - recall: 0.1174 - val_loss: 1.7504 - val_accuracy: 0.3380 - val_precision: 0.6000 - val_recall: 0.0845\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8268 - accuracy: 0.3125 - precision: 0.2500 - recall: 0.031 - ETA: 0s - loss: 1.7007 - accuracy: 0.3229 - precision: 0.3333 - recall: 0.020 - ETA: 0s - loss: 1.6790 - accuracy: 0.3438 - precision: 0.2222 - recall: 0.012 - ETA: 0s - loss: 1.6939 - accuracy: 0.3348 - precision: 0.2222 - recall: 0.008 - ETA: 0s - loss: 1.6304 - accuracy: 0.3542 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5948 - accuracy: 0.3665 - precision: 0.6207 - recall: 0.051 - ETA: 0s - loss: 1.5619 - accuracy: 0.3894 - precision: 0.7179 - recall: 0.067 - 1s 2ms/sample - loss: 1.5595 - accuracy: 0.3897 - precision: 0.7073 - recall: 0.0681 - val_loss: 1.4915 - val_accuracy: 0.4296 - val_precision: 0.6585 - val_recall: 0.1901\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4788 - accuracy: 0.4688 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.4130 - accuracy: 0.4271 - precision: 0.6818 - recall: 0.156 - ETA: 0s - loss: 1.4496 - accuracy: 0.4187 - precision: 0.6364 - recall: 0.131 - ETA: 0s - loss: 1.4472 - accuracy: 0.4196 - precision: 0.6957 - recall: 0.142 - ETA: 0s - loss: 1.4496 - accuracy: 0.3993 - precision: 0.7143 - recall: 0.138 - ETA: 0s - loss: 1.4343 - accuracy: 0.4062 - precision: 0.7465 - recall: 0.150 - ETA: 0s - loss: 1.4296 - accuracy: 0.4159 - precision: 0.7595 - recall: 0.144 - 1s 1ms/sample - loss: 1.4384 - accuracy: 0.4085 - precision: 0.7595 - recall: 0.1408 - val_loss: 1.4192 - val_accuracy: 0.4014 - val_precision: 0.8462 - val_recall: 0.1549\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3049 - accuracy: 0.5625 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4312 - accuracy: 0.4375 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.3916 - accuracy: 0.4187 - precision: 0.7200 - recall: 0.112 - ETA: 0s - loss: 1.4437 - accuracy: 0.3929 - precision: 0.6053 - recall: 0.102 - ETA: 0s - loss: 1.4231 - accuracy: 0.4028 - precision: 0.6111 - recall: 0.114 - ETA: 0s - loss: 1.4278 - accuracy: 0.3920 - precision: 0.6364 - recall: 0.119 - ETA: 0s - loss: 1.4006 - accuracy: 0.4207 - precision: 0.6579 - recall: 0.120 - 1s 1ms/sample - loss: 1.3913 - accuracy: 0.4249 - precision: 0.6709 - recall: 0.1244 - val_loss: 1.5262 - val_accuracy: 0.3803 - val_precision: 0.8125 - val_recall: 0.1831\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4084 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.3296 - accuracy: 0.4271 - precision: 0.8000 - recall: 0.166 - ETA: 0s - loss: 1.4218 - accuracy: 0.4062 - precision: 0.6857 - recall: 0.150 - ETA: 0s - loss: 1.4100 - accuracy: 0.4107 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.4038 - accuracy: 0.4236 - precision: 0.7049 - recall: 0.149 - ETA: 0s - loss: 1.4168 - accuracy: 0.4148 - precision: 0.6974 - recall: 0.150 - ETA: 0s - loss: 1.4083 - accuracy: 0.4207 - precision: 0.7097 - recall: 0.158 - 1s 1ms/sample - loss: 1.4182 - accuracy: 0.4131 - precision: 0.6875 - recall: 0.1549 - val_loss: 1.6254 - val_accuracy: 0.3380 - val_precision: 0.5882 - val_recall: 0.1408\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6705 - accuracy: 0.3125 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4952 - accuracy: 0.4375 - precision: 0.7857 - recall: 0.171 - ETA: 0s - loss: 1.4716 - accuracy: 0.4062 - precision: 0.6154 - recall: 0.125 - ETA: 0s - loss: 1.4630 - accuracy: 0.4062 - precision: 0.6250 - recall: 0.130 - ETA: 0s - loss: 1.4441 - accuracy: 0.4023 - precision: 0.6034 - recall: 0.136 - ETA: 0s - loss: 1.4440 - accuracy: 0.3906 - precision: 0.5775 - recall: 0.128 - ETA: 0s - loss: 1.4306 - accuracy: 0.4219 - precision: 0.5930 - recall: 0.132 - 1s 1ms/sample - loss: 1.4314 - accuracy: 0.4225 - precision: 0.6129 - recall: 0.1338 - val_loss: 1.4992 - val_accuracy: 0.3944 - val_precision: 0.8182 - val_recall: 0.1268\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4569 - accuracy: 0.4583 - precision: 0.8750 - recall: 0.072 - ETA: 0s - loss: 1.4212 - accuracy: 0.4812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.4299 - accuracy: 0.4643 - precision: 0.7419 - recall: 0.102 - ETA: 0s - loss: 1.3912 - accuracy: 0.4722 - precision: 0.7174 - recall: 0.114 - ETA: 0s - loss: 1.3686 - accuracy: 0.4688 - precision: 0.7000 - recall: 0.119 - ETA: 0s - loss: 1.3457 - accuracy: 0.4712 - precision: 0.7368 - recall: 0.134 - 1s 1ms/sample - loss: 1.3325 - accuracy: 0.4789 - precision: 0.7468 - recall: 0.1385 - val_loss: 1.4769 - val_accuracy: 0.4225 - val_precision: 0.7297 - val_recall: 0.1901\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3768 - accuracy: 0.3750 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.4193 - accuracy: 0.3958 - precision: 0.6071 - recall: 0.177 - ETA: 0s - loss: 1.3997 - accuracy: 0.3938 - precision: 0.6154 - recall: 0.200 - ETA: 0s - loss: 1.3474 - accuracy: 0.4464 - precision: 0.6667 - recall: 0.196 - ETA: 0s - loss: 1.3406 - accuracy: 0.4583 - precision: 0.6706 - recall: 0.197 - ETA: 0s - loss: 1.3082 - accuracy: 0.4688 - precision: 0.7255 - recall: 0.210 - ETA: 0s - loss: 1.3234 - accuracy: 0.4639 - precision: 0.7131 - recall: 0.209 - 1s 1ms/sample - loss: 1.3284 - accuracy: 0.4624 - precision: 0.7154 - recall: 0.2066 - val_loss: 1.4036 - val_accuracy: 0.4155 - val_precision: 0.7632 - val_recall: 0.2042\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.2816 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.2622 - accuracy: 0.5625 - precision: 0.8182 - recall: 0.187 - ETA: 0s - loss: 1.2695 - accuracy: 0.5125 - precision: 0.7273 - recall: 0.200 - ETA: 0s - loss: 1.2552 - accuracy: 0.5268 - precision: 0.7385 - recall: 0.214 - ETA: 0s - loss: 1.2947 - accuracy: 0.5000 - precision: 0.6556 - recall: 0.204 - ETA: 0s - loss: 1.2975 - accuracy: 0.4915 - precision: 0.6379 - recall: 0.210 - ETA: 0s - loss: 1.3181 - accuracy: 0.4928 - precision: 0.6397 - recall: 0.209 - 1s 1ms/sample - loss: 1.3102 - accuracy: 0.4953 - precision: 0.6383 - recall: 0.2113 - val_loss: 1.3843 - val_accuracy: 0.4155 - val_precision: 0.6667 - val_recall: 0.1972\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.4688 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.4688 - accuracy: 0.4688 - precision: 0.6296 - recall: 0.177 - ETA: 0s - loss: 1.4118 - accuracy: 0.4750 - precision: 0.6667 - recall: 0.225 - ETA: 0s - loss: 1.4474 - accuracy: 0.4509 - precision: 0.6543 - recall: 0.236 - ETA: 0s - loss: 1.3789 - accuracy: 0.4688 - precision: 0.7030 - recall: 0.246 - ETA: 0s - loss: 1.3839 - accuracy: 0.4574 - precision: 0.7000 - recall: 0.238 - ETA: 0s - loss: 1.3609 - accuracy: 0.4712 - precision: 0.6972 - recall: 0.238 - 1s 1ms/sample - loss: 1.3560 - accuracy: 0.4718 - precision: 0.6993 - recall: 0.2347 - val_loss: 1.4452 - val_accuracy: 0.4225 - val_precision: 0.6957 - val_recall: 0.2254\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.4688 - precision: 0.6923 - recall: 0.281 - ETA: 0s - loss: 1.4612 - accuracy: 0.3854 - precision: 0.5500 - recall: 0.229 - ETA: 0s - loss: 1.4334 - accuracy: 0.3938 - precision: 0.5741 - recall: 0.193 - ETA: 0s - loss: 1.3950 - accuracy: 0.4018 - precision: 0.6269 - recall: 0.187 - ETA: 0s - loss: 1.3957 - accuracy: 0.4201 - precision: 0.6386 - recall: 0.184 - ETA: 0s - loss: 1.3577 - accuracy: 0.4403 - precision: 0.6598 - recall: 0.181 - ETA: 0s - loss: 1.3569 - accuracy: 0.4423 - precision: 0.6916 - recall: 0.177 - 1s 1ms/sample - loss: 1.3557 - accuracy: 0.4437 - precision: 0.6881 - recall: 0.1761 - val_loss: 1.5413 - val_accuracy: 0.3944 - val_precision: 0.6744 - val_recall: 0.2042\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1990 - accuracy: 0.4688 - precision: 0.6429 - recall: 0.281 - ETA: 0s - loss: 1.2693 - accuracy: 0.5104 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.2317 - accuracy: 0.5437 - precision: 0.7547 - recall: 0.250 - ETA: 0s - loss: 1.2434 - accuracy: 0.5268 - precision: 0.7432 - recall: 0.245 - ETA: 0s - loss: 1.2772 - accuracy: 0.5139 - precision: 0.7586 - recall: 0.229 - ETA: 0s - loss: 1.3024 - accuracy: 0.4886 - precision: 0.7290 - recall: 0.221 - ETA: 0s - loss: 1.3193 - accuracy: 0.4808 - precision: 0.7154 - recall: 0.223 - 1s 2ms/sample - loss: 1.3318 - accuracy: 0.4765 - precision: 0.7121 - recall: 0.2207 - val_loss: 1.4436 - val_accuracy: 0.4366 - val_precision: 0.6889 - val_recall: 0.2183\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1135 - accuracy: 0.6250 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.1696 - accuracy: 0.5208 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.1851 - accuracy: 0.5000 - precision: 0.6774 - recall: 0.262 - ETA: 0s - loss: 1.2687 - accuracy: 0.4598 - precision: 0.6591 - recall: 0.258 - ETA: 0s - loss: 1.2656 - accuracy: 0.4653 - precision: 0.6455 - recall: 0.246 - ETA: 0s - loss: 1.2972 - accuracy: 0.4602 - precision: 0.6439 - recall: 0.241 - ETA: 0s - loss: 1.2571 - accuracy: 0.4880 - precision: 0.6688 - recall: 0.252 - 1s 1ms/sample - loss: 1.2539 - accuracy: 0.4883 - precision: 0.6750 - recall: 0.2535 - val_loss: 1.4858 - val_accuracy: 0.4085 - val_precision: 0.6111 - val_recall: 0.2324\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.4375 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.1796 - accuracy: 0.5104 - precision: 0.7353 - recall: 0.260 - ETA: 0s - loss: 1.2496 - accuracy: 0.5125 - precision: 0.7193 - recall: 0.256 - ETA: 0s - loss: 1.2015 - accuracy: 0.5357 - precision: 0.7342 - recall: 0.258 - ETA: 0s - loss: 1.1858 - accuracy: 0.5278 - precision: 0.7477 - recall: 0.277 - ETA: 0s - loss: 1.1865 - accuracy: 0.5341 - precision: 0.7153 - recall: 0.292 - ETA: 0s - loss: 1.2036 - accuracy: 0.5312 - precision: 0.7193 - recall: 0.295 - 1s 1ms/sample - loss: 1.1965 - accuracy: 0.5376 - precision: 0.7200 - recall: 0.2958 - val_loss: 1.3020 - val_accuracy: 0.4296 - val_precision: 0.7091 - val_recall: 0.2746\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0884 - accuracy: 0.5938 - precision: 0.7222 - recall: 0.406 - ETA: 0s - loss: 1.2097 - accuracy: 0.5104 - precision: 0.6818 - recall: 0.312 - ETA: 0s - loss: 1.1493 - accuracy: 0.5250 - precision: 0.7424 - recall: 0.306 - ETA: 0s - loss: 1.1834 - accuracy: 0.5357 - precision: 0.7234 - recall: 0.303 - ETA: 0s - loss: 1.1994 - accuracy: 0.5069 - precision: 0.6846 - recall: 0.309 - ETA: 0s - loss: 1.2400 - accuracy: 0.4886 - precision: 0.6625 - recall: 0.301 - ETA: 0s - loss: 1.2892 - accuracy: 0.4904 - precision: 0.6402 - recall: 0.290 - 1s 1ms/sample - loss: 1.2843 - accuracy: 0.4930 - precision: 0.6378 - recall: 0.2934 - val_loss: 1.3454 - val_accuracy: 0.4366 - val_precision: 0.6066 - val_recall: 0.2606\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3774 - accuracy: 0.5625 - precision: 0.6522 - recall: 0.468 - ETA: 0s - loss: 1.3852 - accuracy: 0.5000 - precision: 0.6531 - recall: 0.333 - ETA: 0s - loss: 1.3842 - accuracy: 0.4750 - precision: 0.6447 - recall: 0.306 - ETA: 0s - loss: 1.3416 - accuracy: 0.4911 - precision: 0.6636 - recall: 0.325 - ETA: 0s - loss: 1.2720 - accuracy: 0.5104 - precision: 0.6761 - recall: 0.333 - ETA: 0s - loss: 1.2343 - accuracy: 0.5227 - precision: 0.6854 - recall: 0.346 - ETA: 0s - loss: 1.2471 - accuracy: 0.5120 - precision: 0.6763 - recall: 0.336 - 1s 2ms/sample - loss: 1.2494 - accuracy: 0.5047 - precision: 0.6699 - recall: 0.3286 - val_loss: 1.3713 - val_accuracy: 0.4718 - val_precision: 0.6735 - val_recall: 0.2324\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0355 - accuracy: 0.5938 - precision: 0.8889 - recall: 0.250 - ETA: 0s - loss: 1.1947 - accuracy: 0.5521 - precision: 0.7568 - recall: 0.291 - ETA: 0s - loss: 1.2583 - accuracy: 0.5250 - precision: 0.6780 - recall: 0.250 - ETA: 0s - loss: 1.3081 - accuracy: 0.5000 - precision: 0.6548 - recall: 0.245 - ETA: 0s - loss: 1.2830 - accuracy: 0.4931 - precision: 0.6786 - recall: 0.263 - ETA: 0s - loss: 1.2569 - accuracy: 0.4915 - precision: 0.6822 - recall: 0.250 - ETA: 0s - loss: 1.2605 - accuracy: 0.4952 - precision: 0.6855 - recall: 0.262 - 1s 1ms/sample - loss: 1.2554 - accuracy: 0.4977 - precision: 0.6894 - recall: 0.2606 - val_loss: 1.3002 - val_accuracy: 0.4296 - val_precision: 0.7561 - val_recall: 0.2183\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2788 - accuracy: 0.5000 - precision: 0.7692 - recall: 0.312 - ETA: 0s - loss: 1.1105 - accuracy: 0.5729 - precision: 0.7632 - recall: 0.302 - ETA: 0s - loss: 1.1735 - accuracy: 0.5437 - precision: 0.7059 - recall: 0.300 - ETA: 0s - loss: 1.1630 - accuracy: 0.5312 - precision: 0.7326 - recall: 0.281 - ETA: 0s - loss: 1.1745 - accuracy: 0.5451 - precision: 0.7500 - recall: 0.291 - ETA: 0s - loss: 1.1690 - accuracy: 0.5455 - precision: 0.7536 - recall: 0.295 - ETA: 0s - loss: 1.1797 - accuracy: 0.5409 - precision: 0.7532 - recall: 0.278 - 1s 1ms/sample - loss: 1.1786 - accuracy: 0.5423 - precision: 0.7547 - recall: 0.2817 - val_loss: 1.3254 - val_accuracy: 0.4718 - val_precision: 0.6818 - val_recall: 0.2113\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0213 - accuracy: 0.5000 - precision: 0.7857 - recall: 0.343 - ETA: 0s - loss: 1.1572 - accuracy: 0.5469 - precision: 0.7917 - recall: 0.296 - ETA: 0s - loss: 1.1850 - accuracy: 0.5078 - precision: 0.7556 - recall: 0.265 - ETA: 0s - loss: 1.2109 - accuracy: 0.4792 - precision: 0.6714 - recall: 0.244 - ETA: 0s - loss: 1.1877 - accuracy: 0.5000 - precision: 0.7053 - recall: 0.261 - ETA: 0s - loss: 1.1747 - accuracy: 0.5000 - precision: 0.7107 - recall: 0.268 - ETA: 0s - loss: 1.1759 - accuracy: 0.5052 - precision: 0.7234 - recall: 0.265 - ETA: 0s - loss: 1.1742 - accuracy: 0.5072 - precision: 0.7124 - recall: 0.262 - 1s 2ms/sample - loss: 1.1782 - accuracy: 0.5070 - precision: 0.7044 - recall: 0.2629 - val_loss: 1.4178 - val_accuracy: 0.4437 - val_precision: 0.6538 - val_recall: 0.2394\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0484 - accuracy: 0.6562 - precision: 0.7222 - recall: 0.406 - ETA: 0s - loss: 1.2646 - accuracy: 0.4896 - precision: 0.5952 - recall: 0.260 - ETA: 0s - loss: 1.1815 - accuracy: 0.5500 - precision: 0.6324 - recall: 0.268 - ETA: 0s - loss: 1.1679 - accuracy: 0.5536 - precision: 0.6771 - recall: 0.290 - ETA: 0s - loss: 1.1424 - accuracy: 0.5451 - precision: 0.6693 - recall: 0.295 - ETA: 0s - loss: 1.1545 - accuracy: 0.5341 - precision: 0.6803 - recall: 0.284 - ETA: 0s - loss: 1.1468 - accuracy: 0.5457 - precision: 0.7017 - recall: 0.305 - 1s 2ms/sample - loss: 1.1406 - accuracy: 0.5469 - precision: 0.7005 - recall: 0.3075 - val_loss: 1.1610 - val_accuracy: 0.5352 - val_precision: 0.7193 - val_recall: 0.2887\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1041 - accuracy: 0.5938 - precision: 0.8333 - recall: 0.468 - ETA: 0s - loss: 0.9902 - accuracy: 0.6667 - precision: 0.8333 - recall: 0.468 - ETA: 0s - loss: 0.9800 - accuracy: 0.6438 - precision: 0.7802 - recall: 0.443 - ETA: 0s - loss: 1.0437 - accuracy: 0.5885 - precision: 0.7196 - recall: 0.401 - ETA: 0s - loss: 1.1152 - accuracy: 0.5742 - precision: 0.6879 - recall: 0.378 - ETA: 0s - loss: 1.1069 - accuracy: 0.5833 - precision: 0.7006 - recall: 0.381 - ETA: 0s - loss: 1.1097 - accuracy: 0.5938 - precision: 0.7056 - recall: 0.360 - ETA: 0s - loss: 1.1181 - accuracy: 0.5964 - precision: 0.7031 - recall: 0.351 - 1s 2ms/sample - loss: 1.1169 - accuracy: 0.5869 - precision: 0.7075 - recall: 0.3521 - val_loss: 1.1674 - val_accuracy: 0.5634 - val_precision: 0.7273 - val_recall: 0.2817\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.5938 - precision: 0.8462 - recall: 0.343 - ETA: 0s - loss: 0.9160 - accuracy: 0.6250 - precision: 0.8444 - recall: 0.395 - ETA: 0s - loss: 0.9783 - accuracy: 0.5875 - precision: 0.7692 - recall: 0.375 - ETA: 0s - loss: 1.0488 - accuracy: 0.5759 - precision: 0.7387 - recall: 0.366 - ETA: 0s - loss: 1.0762 - accuracy: 0.5586 - precision: 0.6947 - recall: 0.355 - ETA: 0s - loss: 1.0823 - accuracy: 0.5688 - precision: 0.6882 - recall: 0.365 - ETA: 0s - loss: 1.0816 - accuracy: 0.5625 - precision: 0.6845 - recall: 0.363 - ETA: 0s - loss: 1.0557 - accuracy: 0.5769 - precision: 0.6930 - recall: 0.379 - 1s 2ms/sample - loss: 1.0573 - accuracy: 0.5775 - precision: 0.6907 - recall: 0.3826 - val_loss: 1.2510 - val_accuracy: 0.5000 - val_precision: 0.6353 - val_recall: 0.3803\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0990 - accuracy: 0.6250 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 1.0991 - accuracy: 0.5833 - precision: 0.6393 - recall: 0.406 - ETA: 0s - loss: 1.0907 - accuracy: 0.6187 - precision: 0.6702 - recall: 0.393 - ETA: 0s - loss: 1.1069 - accuracy: 0.5938 - precision: 0.6870 - recall: 0.401 - ETA: 0s - loss: 1.0861 - accuracy: 0.6042 - precision: 0.7193 - recall: 0.427 - ETA: 0s - loss: 1.0905 - accuracy: 0.5852 - precision: 0.6934 - recall: 0.417 - ETA: 0s - loss: 1.1036 - accuracy: 0.5769 - precision: 0.6980 - recall: 0.411 - 1s 1ms/sample - loss: 1.0949 - accuracy: 0.5798 - precision: 0.6996 - recall: 0.4155 - val_loss: 1.2564 - val_accuracy: 0.4859 - val_precision: 0.6024 - val_recall: 0.3521\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1426 - accuracy: 0.6250 - precision: 0.5500 - recall: 0.343 - ETA: 0s - loss: 1.1612 - accuracy: 0.6042 - precision: 0.6324 - recall: 0.447 - ETA: 0s - loss: 1.2491 - accuracy: 0.5750 - precision: 0.6147 - recall: 0.418 - ETA: 0s - loss: 1.1697 - accuracy: 0.5893 - precision: 0.6454 - recall: 0.406 - ETA: 0s - loss: 1.2256 - accuracy: 0.5660 - precision: 0.6158 - recall: 0.378 - ETA: 0s - loss: 1.2583 - accuracy: 0.5455 - precision: 0.6009 - recall: 0.363 - ETA: 0s - loss: 1.3205 - accuracy: 0.5337 - precision: 0.5992 - recall: 0.348 - 1s 1ms/sample - loss: 1.3190 - accuracy: 0.5329 - precision: 0.6032 - recall: 0.3498 - val_loss: 1.4792 - val_accuracy: 0.4225 - val_precision: 0.5763 - val_recall: 0.2394\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4250 - accuracy: 0.5312 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.2599 - accuracy: 0.5104 - precision: 0.7317 - recall: 0.312 - ETA: 0s - loss: 1.2441 - accuracy: 0.5000 - precision: 0.6800 - recall: 0.318 - ETA: 0s - loss: 1.2497 - accuracy: 0.5000 - precision: 0.6442 - recall: 0.299 - ETA: 0s - loss: 1.1866 - accuracy: 0.5174 - precision: 0.6589 - recall: 0.295 - ETA: 0s - loss: 1.1930 - accuracy: 0.5227 - precision: 0.6755 - recall: 0.289 - ETA: 0s - loss: 1.1626 - accuracy: 0.5264 - precision: 0.6806 - recall: 0.312 - 1s 1ms/sample - loss: 1.1560 - accuracy: 0.5305 - precision: 0.6818 - recall: 0.3169 - val_loss: 1.2011 - val_accuracy: 0.5282 - val_precision: 0.6716 - val_recall: 0.3169\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9945 - accuracy: 0.5938 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 0.9769 - accuracy: 0.6146 - precision: 0.7600 - recall: 0.395 - ETA: 0s - loss: 1.0437 - accuracy: 0.5813 - precision: 0.7143 - recall: 0.375 - ETA: 0s - loss: 1.0835 - accuracy: 0.5848 - precision: 0.7143 - recall: 0.357 - ETA: 0s - loss: 1.0609 - accuracy: 0.5833 - precision: 0.7162 - recall: 0.368 - ETA: 0s - loss: 1.0333 - accuracy: 0.5824 - precision: 0.7348 - recall: 0.377 - ETA: 0s - loss: 1.0255 - accuracy: 0.5913 - precision: 0.7393 - recall: 0.375 - 1s 1ms/sample - loss: 1.0265 - accuracy: 0.5892 - precision: 0.7395 - recall: 0.3732 - val_loss: 1.1769 - val_accuracy: 0.4789 - val_precision: 0.6452 - val_recall: 0.2817\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0560 - accuracy: 0.6562 - precision: 0.8125 - recall: 0.406 - ETA: 0s - loss: 1.1314 - accuracy: 0.5729 - precision: 0.7551 - recall: 0.385 - ETA: 0s - loss: 1.0732 - accuracy: 0.5875 - precision: 0.7792 - recall: 0.375 - ETA: 0s - loss: 1.0623 - accuracy: 0.5982 - precision: 0.7652 - recall: 0.392 - ETA: 0s - loss: 1.0195 - accuracy: 0.5972 - precision: 0.7973 - recall: 0.409 - ETA: 0s - loss: 0.9823 - accuracy: 0.6108 - precision: 0.8152 - recall: 0.426 - ETA: 0s - loss: 0.9976 - accuracy: 0.5986 - precision: 0.7972 - recall: 0.415 - 1s 2ms/sample - loss: 0.9979 - accuracy: 0.6009 - precision: 0.7946 - recall: 0.4178 - val_loss: 1.1295 - val_accuracy: 0.5915 - val_precision: 0.6849 - val_recall: 0.3521\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9060 - accuracy: 0.6562 - precision: 0.7647 - recall: 0.406 - ETA: 0s - loss: 0.8222 - accuracy: 0.6562 - precision: 0.8113 - recall: 0.447 - ETA: 0s - loss: 0.8247 - accuracy: 0.6812 - precision: 0.8333 - recall: 0.500 - ETA: 0s - loss: 0.9397 - accuracy: 0.6384 - precision: 0.7826 - recall: 0.482 - ETA: 0s - loss: 0.9944 - accuracy: 0.6146 - precision: 0.7351 - recall: 0.472 - ETA: 0s - loss: 0.9852 - accuracy: 0.6136 - precision: 0.7523 - recall: 0.474 - ETA: 0s - loss: 0.9987 - accuracy: 0.5962 - precision: 0.7364 - recall: 0.456 - 1s 1ms/sample - loss: 1.0002 - accuracy: 0.5962 - precision: 0.7358 - recall: 0.4577 - val_loss: 1.2605 - val_accuracy: 0.4789 - val_precision: 0.6024 - val_recall: 0.3521\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1213 - accuracy: 0.5000 - precision: 0.8235 - recall: 0.437 - ETA: 0s - loss: 0.9652 - accuracy: 0.6146 - precision: 0.8113 - recall: 0.447 - ETA: 0s - loss: 0.9535 - accuracy: 0.5875 - precision: 0.7727 - recall: 0.425 - ETA: 0s - loss: 0.9537 - accuracy: 0.5848 - precision: 0.7674 - recall: 0.442 - ETA: 0s - loss: 0.9469 - accuracy: 0.6007 - precision: 0.7679 - recall: 0.447 - ETA: 0s - loss: 0.9115 - accuracy: 0.6307 - precision: 0.7751 - recall: 0.460 - ETA: 0s - loss: 0.9248 - accuracy: 0.6154 - precision: 0.7619 - recall: 0.461 - 1s 1ms/sample - loss: 0.9177 - accuracy: 0.6197 - precision: 0.7663 - recall: 0.4695 - val_loss: 1.1956 - val_accuracy: 0.5423 - val_precision: 0.6538 - val_recall: 0.3592\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.7500 - precision: 0.8400 - recall: 0.656 - ETA: 0s - loss: 0.8302 - accuracy: 0.6458 - precision: 0.7692 - recall: 0.520 - ETA: 0s - loss: 0.9034 - accuracy: 0.6250 - precision: 0.7524 - recall: 0.493 - ETA: 0s - loss: 0.8899 - accuracy: 0.6339 - precision: 0.7533 - recall: 0.504 - ETA: 0s - loss: 0.8788 - accuracy: 0.6389 - precision: 0.7602 - recall: 0.517 - ETA: 0s - loss: 0.8721 - accuracy: 0.6591 - precision: 0.7759 - recall: 0.531 - ETA: 0s - loss: 0.8821 - accuracy: 0.6659 - precision: 0.7829 - recall: 0.528 - 1s 1ms/sample - loss: 0.8892 - accuracy: 0.6573 - precision: 0.7770 - recall: 0.5235 - val_loss: 1.4185 - val_accuracy: 0.5423 - val_precision: 0.5600 - val_recall: 0.3944\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1924 - accuracy: 0.6562 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 1.2093 - accuracy: 0.6042 - precision: 0.6364 - recall: 0.437 - ETA: 0s - loss: 1.0996 - accuracy: 0.6125 - precision: 0.6832 - recall: 0.431 - ETA: 0s - loss: 1.1341 - accuracy: 0.5893 - precision: 0.7000 - recall: 0.437 - ETA: 0s - loss: 1.1443 - accuracy: 0.6007 - precision: 0.6984 - recall: 0.458 - ETA: 0s - loss: 1.1628 - accuracy: 0.5852 - precision: 0.6818 - recall: 0.426 - ETA: 0s - loss: 1.1601 - accuracy: 0.5841 - precision: 0.6795 - recall: 0.423 - 1s 1ms/sample - loss: 1.1477 - accuracy: 0.5869 - precision: 0.6844 - recall: 0.4225 - val_loss: 1.3041 - val_accuracy: 0.5282 - val_precision: 0.5930 - val_recall: 0.3592\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9058 - accuracy: 0.8125 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.9195 - accuracy: 0.7188 - precision: 0.7812 - recall: 0.520 - ETA: 0s - loss: 0.9586 - accuracy: 0.6750 - precision: 0.7264 - recall: 0.481 - ETA: 0s - loss: 1.0051 - accuracy: 0.6615 - precision: 0.7360 - recall: 0.479 - ETA: 0s - loss: 1.0400 - accuracy: 0.6289 - precision: 0.7012 - recall: 0.449 - ETA: 0s - loss: 1.0291 - accuracy: 0.6344 - precision: 0.7200 - recall: 0.450 - ETA: 0s - loss: 1.0398 - accuracy: 0.6224 - precision: 0.7210 - recall: 0.437 - 1s 1ms/sample - loss: 1.0224 - accuracy: 0.6291 - precision: 0.7326 - recall: 0.4437 - val_loss: 1.3825 - val_accuracy: 0.4718 - val_precision: 0.5875 - val_recall: 0.3310\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.5312 - precision: 0.6500 - recall: 0.406 - ETA: 0s - loss: 0.9432 - accuracy: 0.6146 - precision: 0.7377 - recall: 0.468 - ETA: 0s - loss: 0.9776 - accuracy: 0.6062 - precision: 0.7391 - recall: 0.425 - ETA: 0s - loss: 0.9561 - accuracy: 0.6116 - precision: 0.7778 - recall: 0.437 - ETA: 0s - loss: 0.9560 - accuracy: 0.6111 - precision: 0.7665 - recall: 0.444 - ETA: 0s - loss: 0.9815 - accuracy: 0.6051 - precision: 0.7358 - recall: 0.443 - ETA: 0s - loss: 0.9651 - accuracy: 0.6226 - precision: 0.7500 - recall: 0.461 - 1s 1ms/sample - loss: 0.9624 - accuracy: 0.6244 - precision: 0.7500 - recall: 0.4648 - val_loss: 1.2306 - val_accuracy: 0.5563 - val_precision: 0.6000 - val_recall: 0.4014\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7297 - accuracy: 0.7812 - precision: 0.8095 - recall: 0.531 - ETA: 0s - loss: 0.8341 - accuracy: 0.7292 - precision: 0.8413 - recall: 0.552 - ETA: 0s - loss: 0.8786 - accuracy: 0.6812 - precision: 0.7885 - recall: 0.512 - ETA: 0s - loss: 0.9017 - accuracy: 0.6652 - precision: 0.7755 - recall: 0.508 - ETA: 0s - loss: 0.9008 - accuracy: 0.6528 - precision: 0.7749 - recall: 0.513 - ETA: 0s - loss: 0.9189 - accuracy: 0.6392 - precision: 0.7521 - recall: 0.500 - ETA: 0s - loss: 0.9306 - accuracy: 0.6322 - precision: 0.7527 - recall: 0.504 - 1s 1ms/sample - loss: 0.9233 - accuracy: 0.6362 - precision: 0.7579 - recall: 0.5070 - val_loss: 1.2044 - val_accuracy: 0.5493 - val_precision: 0.5962 - val_recall: 0.4366\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.7188 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.7243 - accuracy: 0.7083 - precision: 0.7671 - recall: 0.583 - ETA: 0s - loss: 0.7842 - accuracy: 0.7000 - precision: 0.7500 - recall: 0.581 - ETA: 0s - loss: 0.8563 - accuracy: 0.6786 - precision: 0.7310 - recall: 0.558 - ETA: 0s - loss: 0.8441 - accuracy: 0.6840 - precision: 0.7373 - recall: 0.555 - ETA: 0s - loss: 0.8543 - accuracy: 0.6676 - precision: 0.7490 - recall: 0.542 - ETA: 0s - loss: 0.8605 - accuracy: 0.6683 - precision: 0.7559 - recall: 0.543 - 1s 1ms/sample - loss: 0.8500 - accuracy: 0.6761 - precision: 0.7614 - recall: 0.5469 - val_loss: 1.2026 - val_accuracy: 0.5704 - val_precision: 0.6277 - val_recall: 0.4155\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7500 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.7946 - accuracy: 0.7188 - precision: 0.7432 - recall: 0.572 - ETA: 0s - loss: 0.7780 - accuracy: 0.7188 - precision: 0.7712 - recall: 0.568 - ETA: 0s - loss: 0.7457 - accuracy: 0.7188 - precision: 0.7765 - recall: 0.589 - ETA: 0s - loss: 0.7942 - accuracy: 0.6910 - precision: 0.7593 - recall: 0.569 - ETA: 0s - loss: 0.7851 - accuracy: 0.7017 - precision: 0.7724 - recall: 0.588 - ETA: 0s - loss: 0.7642 - accuracy: 0.7115 - precision: 0.7747 - recall: 0.603 - 1s 1ms/sample - loss: 0.7666 - accuracy: 0.7136 - precision: 0.7778 - recall: 0.6080 - val_loss: 1.3240 - val_accuracy: 0.5423 - val_precision: 0.5750 - val_recall: 0.4859\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.7812 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.8475 - accuracy: 0.6771 - precision: 0.7368 - recall: 0.583 - ETA: 0s - loss: 0.8076 - accuracy: 0.6750 - precision: 0.7308 - recall: 0.593 - ETA: 0s - loss: 0.8187 - accuracy: 0.6607 - precision: 0.7213 - recall: 0.589 - ETA: 0s - loss: 0.7852 - accuracy: 0.6736 - precision: 0.7331 - recall: 0.600 - ETA: 0s - loss: 0.8158 - accuracy: 0.6761 - precision: 0.7340 - recall: 0.588 - ETA: 0s - loss: 0.8130 - accuracy: 0.6803 - precision: 0.7335 - recall: 0.588 - 1s 1ms/sample - loss: 0.8215 - accuracy: 0.6784 - precision: 0.7339 - recall: 0.5892 - val_loss: 1.2373 - val_accuracy: 0.5563 - val_precision: 0.6262 - val_recall: 0.4718\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.5938 - precision: 0.7391 - recall: 0.531 - ETA: 0s - loss: 0.7891 - accuracy: 0.6771 - precision: 0.7595 - recall: 0.625 - ETA: 0s - loss: 0.8224 - accuracy: 0.6750 - precision: 0.7368 - recall: 0.612 - ETA: 0s - loss: 0.8940 - accuracy: 0.6250 - precision: 0.6957 - recall: 0.571 - ETA: 0s - loss: 0.9124 - accuracy: 0.6319 - precision: 0.6923 - recall: 0.562 - ETA: 0s - loss: 0.8760 - accuracy: 0.6562 - precision: 0.7254 - recall: 0.585 - ETA: 0s - loss: 0.8778 - accuracy: 0.6659 - precision: 0.7303 - recall: 0.579 - 1s 1ms/sample - loss: 0.8927 - accuracy: 0.6573 - precision: 0.7240 - recall: 0.5728 - val_loss: 1.2126 - val_accuracy: 0.5352 - val_precision: 0.6300 - val_recall: 0.4437\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7765 - accuracy: 0.6875 - precision: 0.8400 - recall: 0.656 - ETA: 0s - loss: 0.7955 - accuracy: 0.7083 - precision: 0.8133 - recall: 0.635 - ETA: 0s - loss: 0.8186 - accuracy: 0.7000 - precision: 0.7787 - recall: 0.593 - ETA: 0s - loss: 0.8552 - accuracy: 0.6875 - precision: 0.7651 - recall: 0.567 - ETA: 0s - loss: 0.9182 - accuracy: 0.6667 - precision: 0.7488 - recall: 0.538 - ETA: 0s - loss: 0.9128 - accuracy: 0.6676 - precision: 0.7642 - recall: 0.534 - ETA: 0s - loss: 0.9163 - accuracy: 0.6635 - precision: 0.7578 - recall: 0.526 - 1s 1ms/sample - loss: 0.9122 - accuracy: 0.6667 - precision: 0.7627 - recall: 0.5282 - val_loss: 1.4986 - val_accuracy: 0.5282 - val_precision: 0.5524 - val_recall: 0.4085\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0756 - accuracy: 0.6250 - precision: 0.6667 - recall: 0.500 - ETA: 0s - loss: 0.8606 - accuracy: 0.6771 - precision: 0.7606 - recall: 0.562 - ETA: 0s - loss: 0.8566 - accuracy: 0.6687 - precision: 0.7946 - recall: 0.556 - ETA: 0s - loss: 0.9329 - accuracy: 0.6518 - precision: 0.7647 - recall: 0.522 - ETA: 0s - loss: 0.9330 - accuracy: 0.6493 - precision: 0.7487 - recall: 0.517 - ETA: 0s - loss: 0.9234 - accuracy: 0.6477 - precision: 0.7400 - recall: 0.525 - ETA: 0s - loss: 0.9135 - accuracy: 0.6538 - precision: 0.7338 - recall: 0.516 - 1s 1ms/sample - loss: 0.9141 - accuracy: 0.6526 - precision: 0.7333 - recall: 0.5164 - val_loss: 1.2845 - val_accuracy: 0.5352 - val_precision: 0.6180 - val_recall: 0.3873\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.8125 - precision: 0.9200 - recall: 0.718 - ETA: 0s - loss: 0.8197 - accuracy: 0.7083 - precision: 0.8082 - recall: 0.614 - ETA: 0s - loss: 0.8332 - accuracy: 0.6938 - precision: 0.7934 - recall: 0.600 - ETA: 0s - loss: 0.8594 - accuracy: 0.6652 - precision: 0.7558 - recall: 0.580 - ETA: 0s - loss: 0.8768 - accuracy: 0.6806 - precision: 0.7634 - recall: 0.593 - ETA: 0s - loss: 0.8874 - accuracy: 0.6676 - precision: 0.7593 - recall: 0.582 - ETA: 0s - loss: 0.8729 - accuracy: 0.6683 - precision: 0.7531 - recall: 0.579 - 1s 2ms/sample - loss: 0.8731 - accuracy: 0.6667 - precision: 0.7462 - recall: 0.5728 - val_loss: 1.1314 - val_accuracy: 0.5986 - val_precision: 0.6735 - val_recall: 0.4648\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9280 - accuracy: 0.6562 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.8652 - accuracy: 0.6771 - precision: 0.7887 - recall: 0.583 - ETA: 0s - loss: 0.8375 - accuracy: 0.6750 - precision: 0.7731 - recall: 0.575 - ETA: 0s - loss: 0.8292 - accuracy: 0.6786 - precision: 0.7633 - recall: 0.575 - ETA: 0s - loss: 0.8142 - accuracy: 0.7014 - precision: 0.7731 - recall: 0.579 - ETA: 0s - loss: 0.8200 - accuracy: 0.6903 - precision: 0.7603 - recall: 0.576 - ETA: 0s - loss: 0.8601 - accuracy: 0.6755 - precision: 0.7390 - recall: 0.564 - 1s 2ms/sample - loss: 0.8502 - accuracy: 0.6784 - precision: 0.7431 - recall: 0.5704 - val_loss: 1.1402 - val_accuracy: 0.6127 - val_precision: 0.6476 - val_recall: 0.4789\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9060 - accuracy: 0.6875 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 1.0210 - accuracy: 0.6354 - precision: 0.6892 - recall: 0.531 - ETA: 0s - loss: 0.8685 - accuracy: 0.6750 - precision: 0.7417 - recall: 0.556 - ETA: 0s - loss: 0.8289 - accuracy: 0.6652 - precision: 0.7560 - recall: 0.567 - ETA: 0s - loss: 0.7989 - accuracy: 0.6806 - precision: 0.7808 - recall: 0.593 - ETA: 0s - loss: 0.8263 - accuracy: 0.6676 - precision: 0.7769 - recall: 0.573 - ETA: 0s - loss: 0.8578 - accuracy: 0.6611 - precision: 0.7697 - recall: 0.562 - 1s 1ms/sample - loss: 0.8577 - accuracy: 0.6643 - precision: 0.7724 - recall: 0.5657 - val_loss: 1.2838 - val_accuracy: 0.5141 - val_precision: 0.6200 - val_recall: 0.4366\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.6250 - precision: 0.6522 - recall: 0.468 - ETA: 0s - loss: 0.9364 - accuracy: 0.6354 - precision: 0.6447 - recall: 0.510 - ETA: 0s - loss: 0.8825 - accuracy: 0.6812 - precision: 0.7258 - recall: 0.562 - ETA: 0s - loss: 0.9092 - accuracy: 0.6562 - precision: 0.6989 - recall: 0.549 - ETA: 0s - loss: 0.8630 - accuracy: 0.6736 - precision: 0.7289 - recall: 0.569 - ETA: 0s - loss: 0.8466 - accuracy: 0.6705 - precision: 0.7333 - recall: 0.562 - ETA: 0s - loss: 0.8261 - accuracy: 0.6827 - precision: 0.7484 - recall: 0.572 - 1s 1ms/sample - loss: 0.8202 - accuracy: 0.6854 - precision: 0.7500 - recall: 0.5775 - val_loss: 1.0972 - val_accuracy: 0.5775 - val_precision: 0.6636 - val_recall: 0.5000\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.6875 - precision: 0.7826 - recall: 0.562 - ETA: 0s - loss: 0.7456 - accuracy: 0.7708 - precision: 0.8378 - recall: 0.645 - ETA: 0s - loss: 0.7276 - accuracy: 0.7312 - precision: 0.8254 - recall: 0.650 - ETA: 0s - loss: 0.6995 - accuracy: 0.7411 - precision: 0.8436 - recall: 0.674 - ETA: 0s - loss: 0.7110 - accuracy: 0.7361 - precision: 0.8283 - recall: 0.670 - ETA: 0s - loss: 0.7472 - accuracy: 0.7188 - precision: 0.8149 - recall: 0.650 - ETA: 0s - loss: 0.7333 - accuracy: 0.7212 - precision: 0.8262 - recall: 0.651 - 1s 2ms/sample - loss: 0.7332 - accuracy: 0.7254 - precision: 0.8274 - recall: 0.6526 - val_loss: 1.1050 - val_accuracy: 0.6338 - val_precision: 0.7117 - val_recall: 0.5563\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8438 - precision: 0.9286 - recall: 0.812 - ETA: 0s - loss: 0.5356 - accuracy: 0.8333 - precision: 0.9125 - recall: 0.760 - ETA: 0s - loss: 0.5464 - accuracy: 0.8062 - precision: 0.8667 - recall: 0.731 - ETA: 0s - loss: 0.6536 - accuracy: 0.7545 - precision: 0.8063 - recall: 0.687 - ETA: 0s - loss: 0.6497 - accuracy: 0.7674 - precision: 0.8216 - recall: 0.687 - ETA: 0s - loss: 0.6375 - accuracy: 0.7642 - precision: 0.8182 - recall: 0.690 - ETA: 0s - loss: 0.6921 - accuracy: 0.7380 - precision: 0.7920 - recall: 0.668 - 1s 1ms/sample - loss: 0.6856 - accuracy: 0.7418 - precision: 0.7950 - recall: 0.6737 - val_loss: 1.1765 - val_accuracy: 0.6197 - val_precision: 0.6480 - val_recall: 0.5704\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7812 - precision: 0.9231 - recall: 0.750 - ETA: 0s - loss: 0.9226 - accuracy: 0.6667 - precision: 0.7467 - recall: 0.583 - ETA: 0s - loss: 0.9411 - accuracy: 0.6625 - precision: 0.7197 - recall: 0.593 - ETA: 0s - loss: 0.9164 - accuracy: 0.6652 - precision: 0.7097 - recall: 0.589 - ETA: 0s - loss: 0.8444 - accuracy: 0.6910 - precision: 0.7384 - recall: 0.607 - ETA: 0s - loss: 0.8148 - accuracy: 0.6903 - precision: 0.7439 - recall: 0.610 - ETA: 0s - loss: 0.8028 - accuracy: 0.6995 - precision: 0.7485 - recall: 0.615 - 1s 1ms/sample - loss: 0.8045 - accuracy: 0.6995 - precision: 0.7493 - recall: 0.6174 - val_loss: 1.2160 - val_accuracy: 0.5423 - val_precision: 0.6346 - val_recall: 0.4648\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7500 - precision: 0.8000 - recall: 0.625 - ETA: 0s - loss: 0.8136 - accuracy: 0.6979 - precision: 0.7778 - recall: 0.583 - ETA: 0s - loss: 0.7757 - accuracy: 0.7188 - precision: 0.7795 - recall: 0.618 - ETA: 0s - loss: 0.8116 - accuracy: 0.7054 - precision: 0.7586 - recall: 0.589 - ETA: 0s - loss: 0.7863 - accuracy: 0.7118 - precision: 0.7758 - recall: 0.600 - ETA: 0s - loss: 0.7511 - accuracy: 0.7188 - precision: 0.7970 - recall: 0.613 - ETA: 0s - loss: 0.7399 - accuracy: 0.7356 - precision: 0.8019 - recall: 0.622 - 1s 1ms/sample - loss: 0.7404 - accuracy: 0.7347 - precision: 0.8030 - recall: 0.6221 - val_loss: 1.3369 - val_accuracy: 0.4859 - val_precision: 0.5556 - val_recall: 0.4577\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.8493 - accuracy: 0.6875 - precision: 0.8077 - recall: 0.656 - ETA: 0s - loss: 0.8728 - accuracy: 0.6667 - precision: 0.7568 - recall: 0.583 - ETA: 0s - loss: 0.8914 - accuracy: 0.6750 - precision: 0.7520 - recall: 0.587 - ETA: 0s - loss: 0.8784 - accuracy: 0.6741 - precision: 0.7389 - recall: 0.593 - ETA: 0s - loss: 0.8390 - accuracy: 0.6806 - precision: 0.7511 - recall: 0.607 - ETA: 0s - loss: 0.7972 - accuracy: 0.6960 - precision: 0.7641 - recall: 0.616 - ETA: 0s - loss: 0.7708 - accuracy: 0.7067 - precision: 0.7742 - recall: 0.634 - 1s 1ms/sample - loss: 0.7741 - accuracy: 0.7066 - precision: 0.7721 - recall: 0.6362 - val_loss: 1.2710 - val_accuracy: 0.5211 - val_precision: 0.6018 - val_recall: 0.4789\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.6562 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.6974 - accuracy: 0.7083 - precision: 0.8312 - recall: 0.666 - ETA: 0s - loss: 0.6785 - accuracy: 0.7188 - precision: 0.8148 - recall: 0.687 - ETA: 0s - loss: 0.6608 - accuracy: 0.7321 - precision: 0.8042 - recall: 0.678 - ETA: 0s - loss: 0.6411 - accuracy: 0.7396 - precision: 0.8115 - recall: 0.687 - ETA: 0s - loss: 0.6318 - accuracy: 0.7443 - precision: 0.8225 - recall: 0.684 - ETA: 0s - loss: 0.6499 - accuracy: 0.7404 - precision: 0.8260 - recall: 0.673 - 1s 1ms/sample - loss: 0.6546 - accuracy: 0.7371 - precision: 0.8195 - recall: 0.6714 - val_loss: 1.1624 - val_accuracy: 0.6056 - val_precision: 0.6446 - val_recall: 0.5493\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7500 - precision: 0.8750 - recall: 0.656 - ETA: 0s - loss: 0.7191 - accuracy: 0.7500 - precision: 0.8553 - recall: 0.677 - ETA: 0s - loss: 0.7494 - accuracy: 0.7188 - precision: 0.7955 - recall: 0.656 - ETA: 0s - loss: 0.7328 - accuracy: 0.7188 - precision: 0.7903 - recall: 0.656 - ETA: 0s - loss: 0.6816 - accuracy: 0.7465 - precision: 0.8091 - recall: 0.677 - ETA: 0s - loss: 0.6762 - accuracy: 0.7443 - precision: 0.8027 - recall: 0.670 - ETA: 0s - loss: 0.6929 - accuracy: 0.7356 - precision: 0.7955 - recall: 0.673 - 1s 1ms/sample - loss: 0.6938 - accuracy: 0.7347 - precision: 0.7922 - recall: 0.6714 - val_loss: 1.1786 - val_accuracy: 0.5986 - val_precision: 0.6160 - val_recall: 0.5423\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7054 - accuracy: 0.7500 - precision: 0.7586 - recall: 0.687 - ETA: 0s - loss: 0.8930 - accuracy: 0.6979 - precision: 0.7176 - recall: 0.635 - ETA: 0s - loss: 0.9139 - accuracy: 0.7063 - precision: 0.7183 - recall: 0.637 - ETA: 0s - loss: 0.8576 - accuracy: 0.7188 - precision: 0.7413 - recall: 0.665 - ETA: 0s - loss: 0.8511 - accuracy: 0.7118 - precision: 0.7308 - recall: 0.659 - ETA: 0s - loss: 0.8061 - accuracy: 0.7244 - precision: 0.7508 - recall: 0.676 - ETA: 0s - loss: 0.7961 - accuracy: 0.7188 - precision: 0.7433 - recall: 0.668 - 1s 2ms/sample - loss: 0.8007 - accuracy: 0.7183 - precision: 0.7415 - recall: 0.6667 - val_loss: 1.0755 - val_accuracy: 0.6620 - val_precision: 0.6875 - val_recall: 0.6197\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.7500 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.6766 - accuracy: 0.7396 - precision: 0.7727 - recall: 0.708 - ETA: 0s - loss: 0.7196 - accuracy: 0.7375 - precision: 0.7687 - recall: 0.706 - ETA: 0s - loss: 0.7542 - accuracy: 0.7232 - precision: 0.7500 - recall: 0.696 - ETA: 0s - loss: 0.7110 - accuracy: 0.7465 - precision: 0.7724 - recall: 0.718 - ETA: 0s - loss: 0.7221 - accuracy: 0.7330 - precision: 0.7623 - recall: 0.701 - ETA: 0s - loss: 0.7656 - accuracy: 0.7260 - precision: 0.7579 - recall: 0.692 - 1s 1ms/sample - loss: 0.7737 - accuracy: 0.7230 - precision: 0.7538 - recall: 0.6901 - val_loss: 1.2527 - val_accuracy: 0.5704 - val_precision: 0.6000 - val_recall: 0.5282\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8125 - precision: 0.8125 - recall: 0.812 - ETA: 0s - loss: 0.7018 - accuracy: 0.7188 - precision: 0.7473 - recall: 0.708 - ETA: 0s - loss: 0.7369 - accuracy: 0.7063 - precision: 0.7552 - recall: 0.675 - ETA: 0s - loss: 0.7476 - accuracy: 0.7098 - precision: 0.7538 - recall: 0.669 - ETA: 0s - loss: 0.7072 - accuracy: 0.7257 - precision: 0.7665 - recall: 0.684 - ETA: 0s - loss: 0.7195 - accuracy: 0.7244 - precision: 0.7645 - recall: 0.673 - ETA: 0s - loss: 0.7173 - accuracy: 0.7308 - precision: 0.7750 - recall: 0.670 - 1s 1ms/sample - loss: 0.7092 - accuracy: 0.7347 - precision: 0.7793 - recall: 0.6714 - val_loss: 1.2430 - val_accuracy: 0.5845 - val_precision: 0.6754 - val_recall: 0.5423\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8750 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.7031 - accuracy: 0.7812 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.6820 - accuracy: 0.7625 - precision: 0.7755 - recall: 0.712 - ETA: 0s - loss: 0.7071 - accuracy: 0.7500 - precision: 0.7861 - recall: 0.705 - ETA: 0s - loss: 0.7050 - accuracy: 0.7431 - precision: 0.7778 - recall: 0.704 - ETA: 0s - loss: 0.7164 - accuracy: 0.7472 - precision: 0.7746 - recall: 0.693 - ETA: 0s - loss: 0.7236 - accuracy: 0.7332 - precision: 0.7641 - recall: 0.685 - 1s 1ms/sample - loss: 0.7311 - accuracy: 0.7300 - precision: 0.7592 - recall: 0.6808 - val_loss: 1.2250 - val_accuracy: 0.6127 - val_precision: 0.6371 - val_recall: 0.5563\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9912 - accuracy: 0.6250 - precision: 0.6786 - recall: 0.593 - ETA: 0s - loss: 1.0530 - accuracy: 0.6771 - precision: 0.7262 - recall: 0.635 - ETA: 0s - loss: 1.2861 - accuracy: 0.6562 - precision: 0.6966 - recall: 0.631 - ETA: 0s - loss: 1.4271 - accuracy: 0.6161 - precision: 0.6616 - recall: 0.584 - ETA: 0s - loss: 1.5207 - accuracy: 0.5799 - precision: 0.6356 - recall: 0.545 - ETA: 0s - loss: 1.4785 - accuracy: 0.5852 - precision: 0.6339 - recall: 0.531 - ETA: 0s - loss: 1.4210 - accuracy: 0.5889 - precision: 0.6495 - recall: 0.516 - 1s 1ms/sample - loss: 1.4231 - accuracy: 0.5869 - precision: 0.6499 - recall: 0.5141 - val_loss: 1.4926 - val_accuracy: 0.4577 - val_precision: 0.4865 - val_recall: 0.3803\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1541 - accuracy: 0.4375 - precision: 0.5294 - recall: 0.281 - ETA: 0s - loss: 1.1183 - accuracy: 0.5521 - precision: 0.6508 - recall: 0.427 - ETA: 0s - loss: 1.0388 - accuracy: 0.5750 - precision: 0.6887 - recall: 0.456 - ETA: 0s - loss: 1.0053 - accuracy: 0.6071 - precision: 0.7152 - recall: 0.482 - ETA: 0s - loss: 1.0059 - accuracy: 0.6250 - precision: 0.7368 - recall: 0.486 - ETA: 0s - loss: 0.9955 - accuracy: 0.6278 - precision: 0.7586 - recall: 0.500 - ETA: 0s - loss: 0.9924 - accuracy: 0.6322 - precision: 0.7645 - recall: 0.507 - 1s 1ms/sample - loss: 0.9897 - accuracy: 0.6315 - precision: 0.7616 - recall: 0.5023 - val_loss: 1.6166 - val_accuracy: 0.4718 - val_precision: 0.5842 - val_recall: 0.4155\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0300 - accuracy: 0.6875 - precision: 0.7273 - recall: 0.500 - ETA: 0s - loss: 1.0911 - accuracy: 0.6719 - precision: 0.7442 - recall: 0.500 - ETA: 0s - loss: 1.1668 - accuracy: 0.6328 - precision: 0.7143 - recall: 0.507 - ETA: 0s - loss: 1.1407 - accuracy: 0.6250 - precision: 0.7168 - recall: 0.506 - ETA: 0s - loss: 1.1075 - accuracy: 0.6116 - precision: 0.7089 - recall: 0.500 - ETA: 0s - loss: 1.1047 - accuracy: 0.6016 - precision: 0.6740 - recall: 0.476 - ETA: 0s - loss: 1.0632 - accuracy: 0.6094 - precision: 0.6923 - recall: 0.478 - ETA: 0s - loss: 1.0710 - accuracy: 0.5911 - precision: 0.6988 - recall: 0.471 - 1s 2ms/sample - loss: 1.0505 - accuracy: 0.6033 - precision: 0.7133 - recall: 0.4789 - val_loss: 1.1915 - val_accuracy: 0.6197 - val_precision: 0.7079 - val_recall: 0.4437\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8259 - accuracy: 0.7188 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 0.7615 - accuracy: 0.7500 - precision: 0.8852 - recall: 0.562 - ETA: 0s - loss: 0.8384 - accuracy: 0.7250 - precision: 0.8350 - recall: 0.537 - ETA: 0s - loss: 0.8132 - accuracy: 0.7188 - precision: 0.7925 - recall: 0.562 - ETA: 0s - loss: 0.8282 - accuracy: 0.6944 - precision: 0.7619 - recall: 0.555 - ETA: 0s - loss: 0.8236 - accuracy: 0.6960 - precision: 0.7636 - recall: 0.559 - ETA: 0s - loss: 0.8125 - accuracy: 0.7005 - precision: 0.7714 - recall: 0.562 - 1s 1ms/sample - loss: 0.8434 - accuracy: 0.6878 - precision: 0.7645 - recall: 0.5563 - val_loss: 1.1420 - val_accuracy: 0.6620 - val_precision: 0.7333 - val_recall: 0.5423\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9157 - accuracy: 0.7188 - precision: 0.7500 - recall: 0.468 - ETA: 0s - loss: 0.7091 - accuracy: 0.7604 - precision: 0.8361 - recall: 0.531 - ETA: 0s - loss: 0.7538 - accuracy: 0.7750 - precision: 0.8396 - recall: 0.556 - ETA: 0s - loss: 0.7702 - accuracy: 0.7411 - precision: 0.8224 - recall: 0.558 - ETA: 0s - loss: 0.7653 - accuracy: 0.7292 - precision: 0.8218 - recall: 0.576 - ETA: 0s - loss: 0.7542 - accuracy: 0.7312 - precision: 0.8297 - recall: 0.593 - ETA: 0s - loss: 0.7488 - accuracy: 0.7370 - precision: 0.8250 - recall: 0.601 - ETA: 0s - loss: 0.7459 - accuracy: 0.7284 - precision: 0.8224 - recall: 0.601 - 1s 2ms/sample - loss: 0.7443 - accuracy: 0.7300 - precision: 0.8264 - recall: 0.6033 - val_loss: 1.0539 - val_accuracy: 0.6761 - val_precision: 0.7387 - val_recall: 0.5775\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7568 - accuracy: 0.6875 - precision: 0.7692 - recall: 0.625 - ETA: 0s - loss: 0.7276 - accuracy: 0.7083 - precision: 0.7529 - recall: 0.666 - ETA: 0s - loss: 0.8021 - accuracy: 0.7250 - precision: 0.7660 - recall: 0.675 - ETA: 0s - loss: 0.8232 - accuracy: 0.7054 - precision: 0.7766 - recall: 0.651 - ETA: 0s - loss: 0.7881 - accuracy: 0.7153 - precision: 0.7792 - recall: 0.649 - ETA: 0s - loss: 0.7764 - accuracy: 0.7074 - precision: 0.7867 - recall: 0.639 - ETA: 0s - loss: 0.7763 - accuracy: 0.7091 - precision: 0.7899 - recall: 0.641 - 1s 1ms/sample - loss: 0.7660 - accuracy: 0.7136 - precision: 0.7948 - recall: 0.6455 - val_loss: 1.1483 - val_accuracy: 0.6197 - val_precision: 0.6581 - val_recall: 0.5423\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.7500 - precision: 0.7600 - recall: 0.593 - ETA: 0s - loss: 0.6489 - accuracy: 0.7188 - precision: 0.7564 - recall: 0.614 - ETA: 0s - loss: 0.6420 - accuracy: 0.7500 - precision: 0.8110 - recall: 0.643 - ETA: 0s - loss: 0.6685 - accuracy: 0.7545 - precision: 0.8056 - recall: 0.647 - ETA: 0s - loss: 0.6530 - accuracy: 0.7639 - precision: 0.8083 - recall: 0.673 - ETA: 0s - loss: 0.6507 - accuracy: 0.7614 - precision: 0.8055 - recall: 0.670 - ETA: 0s - loss: 0.6652 - accuracy: 0.7548 - precision: 0.8029 - recall: 0.665 - 1s 1ms/sample - loss: 0.6680 - accuracy: 0.7559 - precision: 0.8028 - recall: 0.6690 - val_loss: 1.1924 - val_accuracy: 0.5986 - val_precision: 0.6471 - val_recall: 0.5423\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.7500 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.6661 - accuracy: 0.7292 - precision: 0.7976 - recall: 0.697 - ETA: 0s - loss: 0.6984 - accuracy: 0.7063 - precision: 0.7941 - recall: 0.675 - ETA: 0s - loss: 0.6491 - accuracy: 0.7321 - precision: 0.8031 - recall: 0.692 - ETA: 0s - loss: 0.6239 - accuracy: 0.7396 - precision: 0.8138 - recall: 0.697 - ETA: 0s - loss: 0.6173 - accuracy: 0.7472 - precision: 0.8086 - recall: 0.696 - ETA: 0s - loss: 0.6458 - accuracy: 0.7308 - precision: 0.7867 - recall: 0.682 - 1s 1ms/sample - loss: 0.6400 - accuracy: 0.7324 - precision: 0.7892 - recall: 0.6854 - val_loss: 1.1496 - val_accuracy: 0.6197 - val_precision: 0.6562 - val_recall: 0.5915\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.8438 - precision: 0.9630 - recall: 0.812 - ETA: 0s - loss: 0.4646 - accuracy: 0.8333 - precision: 0.9125 - recall: 0.760 - ETA: 0s - loss: 0.5883 - accuracy: 0.7750 - precision: 0.8309 - recall: 0.706 - ETA: 0s - loss: 0.5983 - accuracy: 0.7634 - precision: 0.8298 - recall: 0.696 - ETA: 0s - loss: 0.6042 - accuracy: 0.7708 - precision: 0.8266 - recall: 0.711 - ETA: 0s - loss: 0.5833 - accuracy: 0.7727 - precision: 0.8257 - recall: 0.713 - ETA: 0s - loss: 0.5891 - accuracy: 0.7740 - precision: 0.8247 - recall: 0.723 - 1s 1ms/sample - loss: 0.5965 - accuracy: 0.7629 - precision: 0.8150 - recall: 0.7136 - val_loss: 1.1557 - val_accuracy: 0.6408 - val_precision: 0.6613 - val_recall: 0.5775\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.8125 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.6300 - accuracy: 0.7812 - precision: 0.8090 - recall: 0.750 - ETA: 0s - loss: 0.5834 - accuracy: 0.7812 - precision: 0.8079 - recall: 0.762 - ETA: 0s - loss: 0.5334 - accuracy: 0.8036 - precision: 0.8286 - recall: 0.776 - ETA: 0s - loss: 0.5382 - accuracy: 0.7951 - precision: 0.8222 - recall: 0.770 - ETA: 0s - loss: 0.5356 - accuracy: 0.8011 - precision: 0.8253 - recall: 0.778 - ETA: 0s - loss: 0.5731 - accuracy: 0.7812 - precision: 0.8119 - recall: 0.757 - 1s 1ms/sample - loss: 0.5678 - accuracy: 0.7840 - precision: 0.8141 - recall: 0.7606 - val_loss: 1.1055 - val_accuracy: 0.6620 - val_precision: 0.6953 - val_recall: 0.6268\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.8125 - precision: 0.8065 - recall: 0.781 - ETA: 0s - loss: 0.4177 - accuracy: 0.8542 - precision: 0.8681 - recall: 0.822 - ETA: 0s - loss: 0.4825 - accuracy: 0.8313 - precision: 0.8411 - recall: 0.793 - ETA: 0s - loss: 0.4958 - accuracy: 0.8125 - precision: 0.8301 - recall: 0.763 - ETA: 0s - loss: 0.4813 - accuracy: 0.8160 - precision: 0.8327 - recall: 0.777 - ETA: 0s - loss: 0.5229 - accuracy: 0.8011 - precision: 0.8237 - recall: 0.769 - ETA: 0s - loss: 0.5174 - accuracy: 0.7995 - precision: 0.8217 - recall: 0.768 - 1s 1ms/sample - loss: 0.5234 - accuracy: 0.8028 - precision: 0.8253 - recall: 0.7653 - val_loss: 1.1680 - val_accuracy: 0.6408 - val_precision: 0.6591 - val_recall: 0.6127\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7812 - precision: 0.7812 - recall: 0.781 - ETA: 0s - loss: 0.5637 - accuracy: 0.7917 - precision: 0.8043 - recall: 0.770 - ETA: 0s - loss: 0.6274 - accuracy: 0.7937 - precision: 0.8151 - recall: 0.743 - ETA: 0s - loss: 0.7058 - accuracy: 0.7589 - precision: 0.7756 - recall: 0.709 - ETA: 0s - loss: 0.6680 - accuracy: 0.7604 - precision: 0.7786 - recall: 0.708 - ETA: 0s - loss: 0.6524 - accuracy: 0.7727 - precision: 0.7841 - recall: 0.701 - ETA: 0s - loss: 0.6856 - accuracy: 0.7596 - precision: 0.7748 - recall: 0.694 - 1s 1ms/sample - loss: 0.6842 - accuracy: 0.7606 - precision: 0.7749 - recall: 0.6948 - val_loss: 1.1992 - val_accuracy: 0.6549 - val_precision: 0.6617 - val_recall: 0.6197\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.8125 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.6297 - accuracy: 0.8021 - precision: 0.7935 - recall: 0.760 - ETA: 0s - loss: 0.7074 - accuracy: 0.7563 - precision: 0.7733 - recall: 0.725 - ETA: 0s - loss: 0.6619 - accuracy: 0.7679 - precision: 0.7877 - recall: 0.745 - ETA: 0s - loss: 0.6510 - accuracy: 0.7708 - precision: 0.7963 - recall: 0.746 - ETA: 0s - loss: 0.6220 - accuracy: 0.7756 - precision: 0.8067 - recall: 0.747 - ETA: 0s - loss: 0.5952 - accuracy: 0.7909 - precision: 0.8196 - recall: 0.764 - 1s 1ms/sample - loss: 0.5936 - accuracy: 0.7911 - precision: 0.8186 - recall: 0.7629 - val_loss: 1.1823 - val_accuracy: 0.6268 - val_precision: 0.6614 - val_recall: 0.5915\n",
      "Epoch 99/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8750 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.5009 - accuracy: 0.7812 - precision: 0.8161 - recall: 0.739 - ETA: 0s - loss: 0.4525 - accuracy: 0.8062 - precision: 0.8425 - recall: 0.768 - ETA: 0s - loss: 0.4884 - accuracy: 0.8080 - precision: 0.8450 - recall: 0.754 - ETA: 0s - loss: 0.5308 - accuracy: 0.7986 - precision: 0.8352 - recall: 0.756 - ETA: 0s - loss: 0.5495 - accuracy: 0.7898 - precision: 0.8219 - recall: 0.747 - ETA: 0s - loss: 0.5571 - accuracy: 0.7788 - precision: 0.8127 - recall: 0.740 - 1s 1ms/sample - loss: 0.5586 - accuracy: 0.7746 - precision: 0.8067 - recall: 0.7347 - val_loss: 1.1227 - val_accuracy: 0.6690 - val_precision: 0.6846 - val_recall: 0.6268\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.7188 - precision: 0.8800 - recall: 0.687 - ETA: 0s - loss: 0.4926 - accuracy: 0.7708 - precision: 0.8471 - recall: 0.750 - ETA: 0s - loss: 0.5001 - accuracy: 0.7937 - precision: 0.8493 - recall: 0.775 - ETA: 0s - loss: 0.5019 - accuracy: 0.7991 - precision: 0.8421 - recall: 0.785 - ETA: 0s - loss: 0.4800 - accuracy: 0.8090 - precision: 0.8425 - recall: 0.798 - ETA: 0s - loss: 0.4905 - accuracy: 0.8011 - precision: 0.8304 - recall: 0.792 - ETA: 0s - loss: 0.4813 - accuracy: 0.8029 - precision: 0.8325 - recall: 0.788 - 1s 1ms/sample - loss: 0.4803 - accuracy: 0.8028 - precision: 0.8317 - recall: 0.7887 - val_loss: 1.0590 - val_accuracy: 0.6761 - val_precision: 0.7068 - val_recall: 0.6620\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7500 - precision: 0.7667 - recall: 0.718 - ETA: 0s - loss: 0.4870 - accuracy: 0.7812 - precision: 0.8111 - recall: 0.760 - ETA: 0s - loss: 0.4513 - accuracy: 0.8062 - precision: 0.8278 - recall: 0.781 - ETA: 0s - loss: 0.4273 - accuracy: 0.8214 - precision: 0.8357 - recall: 0.794 - ETA: 0s - loss: 0.4387 - accuracy: 0.8160 - precision: 0.8364 - recall: 0.781 - ETA: 0s - loss: 0.4393 - accuracy: 0.8210 - precision: 0.8389 - recall: 0.784 - ETA: 0s - loss: 0.4456 - accuracy: 0.8221 - precision: 0.8372 - recall: 0.778 - 1s 1ms/sample - loss: 0.4422 - accuracy: 0.8216 - precision: 0.8363 - recall: 0.7793 - val_loss: 1.2351 - val_accuracy: 0.6690 - val_precision: 0.6940 - val_recall: 0.6549\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.7812 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.4311 - accuracy: 0.8333 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.4112 - accuracy: 0.8375 - precision: 0.8784 - recall: 0.812 - ETA: 0s - loss: 0.4109 - accuracy: 0.8393 - precision: 0.8835 - recall: 0.812 - ETA: 0s - loss: 0.4064 - accuracy: 0.8438 - precision: 0.8806 - recall: 0.819 - ETA: 0s - loss: 0.4347 - accuracy: 0.8466 - precision: 0.8773 - recall: 0.812 - ETA: 0s - loss: 0.4366 - accuracy: 0.8510 - precision: 0.8763 - recall: 0.817 - 1s 1ms/sample - loss: 0.4385 - accuracy: 0.8521 - precision: 0.8769 - recall: 0.8192 - val_loss: 1.1445 - val_accuracy: 0.6690 - val_precision: 0.6765 - val_recall: 0.6479\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.8125 - precision: 0.8276 - recall: 0.750 - ETA: 0s - loss: 0.6352 - accuracy: 0.8125 - precision: 0.8471 - recall: 0.750 - ETA: 0s - loss: 0.7818 - accuracy: 0.7875 - precision: 0.8027 - recall: 0.737 - ETA: 0s - loss: 0.8721 - accuracy: 0.7723 - precision: 0.7941 - recall: 0.723 - ETA: 0s - loss: 0.7826 - accuracy: 0.7812 - precision: 0.8046 - recall: 0.729 - ETA: 0s - loss: 0.7166 - accuracy: 0.7983 - precision: 0.8168 - recall: 0.747 - ETA: 0s - loss: 0.6968 - accuracy: 0.7933 - precision: 0.8125 - recall: 0.750 - 1s 1ms/sample - loss: 0.6885 - accuracy: 0.7958 - precision: 0.8147 - recall: 0.7535 - val_loss: 1.2338 - val_accuracy: 0.6408 - val_precision: 0.6522 - val_recall: 0.6338\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.8750 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.4474 - accuracy: 0.8750 - precision: 0.8901 - recall: 0.843 - ETA: 0s - loss: 0.5487 - accuracy: 0.8250 - precision: 0.8366 - recall: 0.800 - ETA: 0s - loss: 0.5890 - accuracy: 0.8036 - precision: 0.8278 - recall: 0.772 - ETA: 0s - loss: 0.5748 - accuracy: 0.8021 - precision: 0.8209 - recall: 0.763 - ETA: 0s - loss: 0.6064 - accuracy: 0.7812 - precision: 0.8062 - recall: 0.744 - ETA: 0s - loss: 0.5988 - accuracy: 0.7885 - precision: 0.8125 - recall: 0.750 - 1s 1ms/sample - loss: 0.5903 - accuracy: 0.7911 - precision: 0.8147 - recall: 0.7535 - val_loss: 1.3118 - val_accuracy: 0.6408 - val_precision: 0.6418 - val_recall: 0.6056\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.7812 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.5552 - accuracy: 0.7500 - precision: 0.7765 - recall: 0.687 - ETA: 0s - loss: 0.5467 - accuracy: 0.7750 - precision: 0.8069 - recall: 0.731 - ETA: 0s - loss: 0.5095 - accuracy: 0.7946 - precision: 0.8333 - recall: 0.758 - ETA: 0s - loss: 0.5021 - accuracy: 0.7917 - precision: 0.8359 - recall: 0.760 - ETA: 0s - loss: 0.4918 - accuracy: 0.8011 - precision: 0.8395 - recall: 0.772 - ETA: 0s - loss: 0.5082 - accuracy: 0.7957 - precision: 0.8373 - recall: 0.766 - 1s 1ms/sample - loss: 0.5108 - accuracy: 0.7981 - precision: 0.8389 - recall: 0.7700 - val_loss: 1.4410 - val_accuracy: 0.5563 - val_precision: 0.5746 - val_recall: 0.5423\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0200 - accuracy: 0.6875 - precision: 0.7333 - recall: 0.687 - ETA: 0s - loss: 0.6723 - accuracy: 0.8021 - precision: 0.8261 - recall: 0.791 - ETA: 0s - loss: 0.6459 - accuracy: 0.8000 - precision: 0.8235 - recall: 0.787 - ETA: 0s - loss: 0.5868 - accuracy: 0.8214 - precision: 0.8404 - recall: 0.799 - ETA: 0s - loss: 0.5727 - accuracy: 0.8194 - precision: 0.8496 - recall: 0.784 - ETA: 0s - loss: 0.5837 - accuracy: 0.7955 - precision: 0.8349 - recall: 0.761 - ETA: 0s - loss: 0.5636 - accuracy: 0.8005 - precision: 0.8342 - recall: 0.762 - 1s 1ms/sample - loss: 0.5771 - accuracy: 0.7981 - precision: 0.8308 - recall: 0.7606 - val_loss: 1.1934 - val_accuracy: 0.6549 - val_precision: 0.6739 - val_recall: 0.6549\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.7812 - precision: 0.8065 - recall: 0.781 - ETA: 0s - loss: 0.4761 - accuracy: 0.8333 - precision: 0.8511 - recall: 0.833 - ETA: 0s - loss: 0.4278 - accuracy: 0.8500 - precision: 0.8590 - recall: 0.837 - ETA: 0s - loss: 0.4700 - accuracy: 0.8259 - precision: 0.8349 - recall: 0.812 - ETA: 0s - loss: 0.4987 - accuracy: 0.8160 - precision: 0.8375 - recall: 0.805 - ETA: 0s - loss: 0.5002 - accuracy: 0.8182 - precision: 0.8378 - recall: 0.806 - ETA: 0s - loss: 0.5148 - accuracy: 0.8125 - precision: 0.8333 - recall: 0.793 - 1s 2ms/sample - loss: 0.5126 - accuracy: 0.8122 - precision: 0.8321 - recall: 0.7911 - val_loss: 1.2192 - val_accuracy: 0.6479 - val_precision: 0.6496 - val_recall: 0.6268\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8125 - precision: 0.8667 - recall: 0.812 - ETA: 0s - loss: 0.4467 - accuracy: 0.8333 - precision: 0.8778 - recall: 0.822 - ETA: 0s - loss: 0.5081 - accuracy: 0.7937 - precision: 0.8170 - recall: 0.781 - ETA: 0s - loss: 0.5252 - accuracy: 0.7857 - precision: 0.8113 - recall: 0.767 - ETA: 0s - loss: 0.5414 - accuracy: 0.7778 - precision: 0.8044 - recall: 0.756 - ETA: 0s - loss: 0.5477 - accuracy: 0.7727 - precision: 0.8000 - recall: 0.750 - ETA: 0s - loss: 0.5941 - accuracy: 0.7620 - precision: 0.7923 - recall: 0.742 - 1s 1ms/sample - loss: 0.5937 - accuracy: 0.7629 - precision: 0.7945 - recall: 0.7441 - val_loss: 1.6888 - val_accuracy: 0.5352 - val_precision: 0.5564 - val_recall: 0.5211\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1864 - accuracy: 0.7188 - precision: 0.7097 - recall: 0.687 - ETA: 0s - loss: 0.7063 - accuracy: 0.8021 - precision: 0.7935 - recall: 0.760 - ETA: 0s - loss: 0.6952 - accuracy: 0.7625 - precision: 0.7800 - recall: 0.731 - ETA: 0s - loss: 0.6350 - accuracy: 0.7812 - precision: 0.8077 - recall: 0.750 - ETA: 0s - loss: 0.6295 - accuracy: 0.7812 - precision: 0.8067 - recall: 0.753 - ETA: 0s - loss: 0.6000 - accuracy: 0.7955 - precision: 0.8201 - recall: 0.764 - ETA: 0s - loss: 0.6256 - accuracy: 0.7837 - precision: 0.8067 - recall: 0.752 - 1s 1ms/sample - loss: 0.6270 - accuracy: 0.7817 - precision: 0.8040 - recall: 0.7512 - val_loss: 1.3578 - val_accuracy: 0.5986 - val_precision: 0.6308 - val_recall: 0.5775\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7722 - accuracy: 0.7188 - precision: 0.7931 - recall: 0.718 - ETA: 0s - loss: 0.5675 - accuracy: 0.7812 - precision: 0.8202 - recall: 0.760 - ETA: 0s - loss: 0.5702 - accuracy: 0.7625 - precision: 0.7959 - recall: 0.731 - ETA: 0s - loss: 0.5727 - accuracy: 0.7760 - precision: 0.8079 - recall: 0.744 - ETA: 0s - loss: 0.5515 - accuracy: 0.7852 - precision: 0.8178 - recall: 0.753 - ETA: 0s - loss: 0.5663 - accuracy: 0.7719 - precision: 0.8000 - recall: 0.737 - ETA: 0s - loss: 0.5674 - accuracy: 0.7734 - precision: 0.8000 - recall: 0.739 - ETA: 0s - loss: 0.6032 - accuracy: 0.7644 - precision: 0.7937 - recall: 0.730 - 1s 2ms/sample - loss: 0.6004 - accuracy: 0.7629 - precision: 0.7928 - recall: 0.7277 - val_loss: 1.2029 - val_accuracy: 0.6056 - val_precision: 0.6457 - val_recall: 0.5775\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.7812 - precision: 0.7586 - recall: 0.687 - ETA: 0s - loss: 0.6526 - accuracy: 0.7812 - precision: 0.7802 - recall: 0.739 - ETA: 0s - loss: 0.6099 - accuracy: 0.8000 - precision: 0.8054 - recall: 0.750 - ETA: 0s - loss: 0.5618 - accuracy: 0.8125 - precision: 0.8204 - recall: 0.754 - ETA: 0s - loss: 0.5745 - accuracy: 0.8125 - precision: 0.8248 - recall: 0.753 - ETA: 0s - loss: 0.5505 - accuracy: 0.8188 - precision: 0.8277 - recall: 0.765 - ETA: 0s - loss: 0.5680 - accuracy: 0.8047 - precision: 0.8225 - recall: 0.760 - 1s 2ms/sample - loss: 0.5712 - accuracy: 0.8028 - precision: 0.8240 - recall: 0.7582 - val_loss: 1.2207 - val_accuracy: 0.5915 - val_precision: 0.6328 - val_recall: 0.5704\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8750 - precision: 0.9310 - recall: 0.843 - ETA: 0s - loss: 0.5514 - accuracy: 0.8125 - precision: 0.8539 - recall: 0.791 - ETA: 0s - loss: 0.6113 - accuracy: 0.7734 - precision: 0.8151 - recall: 0.757 - ETA: 0s - loss: 0.5713 - accuracy: 0.8021 - precision: 0.8315 - recall: 0.770 - ETA: 0s - loss: 0.5369 - accuracy: 0.8008 - precision: 0.8340 - recall: 0.765 - ETA: 0s - loss: 0.5041 - accuracy: 0.8219 - precision: 0.8475 - recall: 0.781 - ETA: 0s - loss: 0.5074 - accuracy: 0.8153 - precision: 0.8379 - recall: 0.778 - ETA: 0s - loss: 0.5289 - accuracy: 0.8077 - precision: 0.8338 - recall: 0.771 - 1s 2ms/sample - loss: 0.5387 - accuracy: 0.8052 - precision: 0.8304 - recall: 0.7700 - val_loss: 1.5083 - val_accuracy: 0.5634 - val_precision: 0.5769 - val_recall: 0.5282\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.7500 - precision: 0.7742 - recall: 0.750 - ETA: 0s - loss: 0.6545 - accuracy: 0.7708 - precision: 0.7935 - recall: 0.760 - ETA: 0s - loss: 0.6009 - accuracy: 0.7563 - precision: 0.7933 - recall: 0.743 - ETA: 0s - loss: 0.5661 - accuracy: 0.7656 - precision: 0.8011 - recall: 0.755 - ETA: 0s - loss: 0.5738 - accuracy: 0.7656 - precision: 0.7975 - recall: 0.753 - ETA: 0s - loss: 0.6304 - accuracy: 0.7563 - precision: 0.7781 - recall: 0.734 - ETA: 0s - loss: 0.7139 - accuracy: 0.7422 - precision: 0.7603 - recall: 0.718 - 1s 2ms/sample - loss: 0.7001 - accuracy: 0.7441 - precision: 0.7656 - recall: 0.7207 - val_loss: 1.2046 - val_accuracy: 0.6197 - val_precision: 0.6418 - val_recall: 0.6056\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8438 - precision: 0.8621 - recall: 0.781 - ETA: 0s - loss: 0.4962 - accuracy: 0.7708 - precision: 0.8256 - recall: 0.739 - ETA: 0s - loss: 0.5411 - accuracy: 0.7750 - precision: 0.8138 - recall: 0.737 - ETA: 0s - loss: 0.6690 - accuracy: 0.7589 - precision: 0.7837 - recall: 0.727 - ETA: 0s - loss: 0.7080 - accuracy: 0.7396 - precision: 0.7727 - recall: 0.708 - ETA: 0s - loss: 0.7485 - accuracy: 0.7250 - precision: 0.7577 - recall: 0.693 - ETA: 0s - loss: 0.7025 - accuracy: 0.7386 - precision: 0.7709 - recall: 0.707 - ETA: 0s - loss: 0.7128 - accuracy: 0.7284 - precision: 0.7686 - recall: 0.694 - 1s 2ms/sample - loss: 0.7075 - accuracy: 0.7300 - precision: 0.7694 - recall: 0.6972 - val_loss: 1.1782 - val_accuracy: 0.6338 - val_precision: 0.6748 - val_recall: 0.5845\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.7500 - precision: 0.8462 - recall: 0.687 - ETA: 0s - loss: 0.5724 - accuracy: 0.7708 - precision: 0.8333 - recall: 0.729 - ETA: 0s - loss: 0.6137 - accuracy: 0.7578 - precision: 0.8108 - recall: 0.703 - ETA: 0s - loss: 0.5865 - accuracy: 0.7688 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.5862 - accuracy: 0.7768 - precision: 0.8177 - recall: 0.741 - ETA: 0s - loss: 0.5800 - accuracy: 0.7812 - precision: 0.8197 - recall: 0.746 - ETA: 0s - loss: 0.5667 - accuracy: 0.7812 - precision: 0.8244 - recall: 0.750 - ETA: 0s - loss: 0.5648 - accuracy: 0.7898 - precision: 0.8261 - recall: 0.755 - ETA: 0s - loss: 0.5679 - accuracy: 0.7837 - precision: 0.8153 - recall: 0.742 - 1s 2ms/sample - loss: 0.5618 - accuracy: 0.7887 - precision: 0.8191 - recall: 0.7441 - val_loss: 1.0304 - val_accuracy: 0.6549 - val_precision: 0.6815 - val_recall: 0.6479\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.7500 - precision: 0.7333 - recall: 0.687 - ETA: 0s - loss: 0.4669 - accuracy: 0.8021 - precision: 0.8043 - recall: 0.770 - ETA: 0s - loss: 0.4456 - accuracy: 0.8313 - precision: 0.8355 - recall: 0.793 - ETA: 0s - loss: 0.4495 - accuracy: 0.8333 - precision: 0.8361 - recall: 0.796 - ETA: 0s - loss: 0.4813 - accuracy: 0.8170 - precision: 0.8255 - recall: 0.781 - ETA: 0s - loss: 0.5041 - accuracy: 0.7986 - precision: 0.8202 - recall: 0.760 - ETA: 0s - loss: 0.4934 - accuracy: 0.7983 - precision: 0.8157 - recall: 0.767 - ETA: 0s - loss: 0.5029 - accuracy: 0.7943 - precision: 0.8122 - recall: 0.765 - ETA: 0s - loss: 0.5080 - accuracy: 0.7933 - precision: 0.8117 - recall: 0.766 - 1s 2ms/sample - loss: 0.5021 - accuracy: 0.7981 - precision: 0.8164 - recall: 0.7723 - val_loss: 0.9793 - val_accuracy: 0.6761 - val_precision: 0.7077 - val_recall: 0.6479\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.7188 - precision: 0.7097 - recall: 0.687 - ETA: 0s - loss: 0.4737 - accuracy: 0.8229 - precision: 0.8202 - recall: 0.760 - ETA: 0s - loss: 0.4810 - accuracy: 0.8250 - precision: 0.8311 - recall: 0.768 - ETA: 0s - loss: 0.4821 - accuracy: 0.8259 - precision: 0.8325 - recall: 0.776 - ETA: 0s - loss: 0.4826 - accuracy: 0.8242 - precision: 0.8333 - recall: 0.781 - ETA: 0s - loss: 0.4722 - accuracy: 0.8219 - precision: 0.8389 - recall: 0.781 - ETA: 0s - loss: 0.5052 - accuracy: 0.8125 - precision: 0.8395 - recall: 0.763 - ETA: 0s - loss: 0.5128 - accuracy: 0.8077 - precision: 0.8338 - recall: 0.759 - 1s 2ms/sample - loss: 0.5227 - accuracy: 0.8028 - precision: 0.8278 - recall: 0.7559 - val_loss: 1.1338 - val_accuracy: 0.6197 - val_precision: 0.6471 - val_recall: 0.6197\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8750 - precision: 0.9000 - recall: 0.843 - ETA: 0s - loss: 0.4146 - accuracy: 0.8542 - precision: 0.8791 - recall: 0.833 - ETA: 0s - loss: 0.4325 - accuracy: 0.8438 - precision: 0.8627 - recall: 0.825 - ETA: 0s - loss: 0.4661 - accuracy: 0.8259 - precision: 0.8498 - recall: 0.808 - ETA: 0s - loss: 0.4624 - accuracy: 0.8333 - precision: 0.8514 - recall: 0.816 - ETA: 0s - loss: 0.4725 - accuracy: 0.8313 - precision: 0.8469 - recall: 0.812 - ETA: 0s - loss: 0.4844 - accuracy: 0.8229 - precision: 0.8370 - recall: 0.802 - 1s 1ms/sample - loss: 0.4838 - accuracy: 0.8239 - precision: 0.8444 - recall: 0.8028 - val_loss: 1.1839 - val_accuracy: 0.6479 - val_precision: 0.6741 - val_recall: 0.6408\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.812 - ETA: 0s - loss: 0.4283 - accuracy: 0.8958 - precision: 0.8837 - recall: 0.791 - ETA: 0s - loss: 0.4719 - accuracy: 0.8750 - precision: 0.8707 - recall: 0.800 - ETA: 0s - loss: 0.5076 - accuracy: 0.8304 - precision: 0.8465 - recall: 0.763 - ETA: 0s - loss: 0.4573 - accuracy: 0.8472 - precision: 0.8609 - recall: 0.795 - ETA: 0s - loss: 0.4400 - accuracy: 0.8551 - precision: 0.8681 - recall: 0.804 - ETA: 0s - loss: 0.4386 - accuracy: 0.8594 - precision: 0.8739 - recall: 0.812 - 1s 2ms/sample - loss: 0.4443 - accuracy: 0.8545 - precision: 0.8690 - recall: 0.8099 - val_loss: 1.1388 - val_accuracy: 0.7042 - val_precision: 0.7090 - val_recall: 0.6690\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.8750 - precision: 0.8750 - recall: 0.875 - ETA: 0s - loss: 0.2896 - accuracy: 0.8750 - precision: 0.8925 - recall: 0.864 - ETA: 0s - loss: 0.2928 - accuracy: 0.8813 - precision: 0.8910 - recall: 0.868 - ETA: 0s - loss: 0.2835 - accuracy: 0.8839 - precision: 0.9070 - recall: 0.870 - ETA: 0s - loss: 0.2896 - accuracy: 0.8785 - precision: 0.8957 - recall: 0.864 - ETA: 0s - loss: 0.3316 - accuracy: 0.8636 - precision: 0.8820 - recall: 0.849 - ETA: 0s - loss: 0.3433 - accuracy: 0.8582 - precision: 0.8756 - recall: 0.846 - 1s 1ms/sample - loss: 0.3419 - accuracy: 0.8615 - precision: 0.8783 - recall: 0.8474 - val_loss: 1.2090 - val_accuracy: 0.6690 - val_precision: 0.6715 - val_recall: 0.6479\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9375 - precision: 0.9677 - recall: 0.937 - ETA: 0s - loss: 0.3270 - accuracy: 0.8906 - precision: 0.9048 - recall: 0.890 - ETA: 0s - loss: 0.3332 - accuracy: 0.8984 - precision: 0.9194 - recall: 0.890 - ETA: 0s - loss: 0.3323 - accuracy: 0.8854 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.3263 - accuracy: 0.8945 - precision: 0.9076 - recall: 0.882 - ETA: 0s - loss: 0.3171 - accuracy: 0.8906 - precision: 0.9068 - recall: 0.881 - ETA: 0s - loss: 0.3243 - accuracy: 0.8854 - precision: 0.9011 - recall: 0.877 - 1s 2ms/sample - loss: 0.3257 - accuracy: 0.8850 - precision: 0.9012 - recall: 0.8779 - val_loss: 1.1039 - val_accuracy: 0.7113 - val_precision: 0.7353 - val_recall: 0.7042\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.906 - ETA: 0s - loss: 0.3011 - accuracy: 0.9167 - precision: 0.9263 - recall: 0.916 - ETA: 0s - loss: 0.3117 - accuracy: 0.9125 - precision: 0.9231 - recall: 0.900 - ETA: 0s - loss: 0.3095 - accuracy: 0.9062 - precision: 0.9171 - recall: 0.888 - ETA: 0s - loss: 0.2854 - accuracy: 0.9167 - precision: 0.9253 - recall: 0.902 - ETA: 0s - loss: 0.2873 - accuracy: 0.9119 - precision: 0.9213 - recall: 0.897 - ETA: 0s - loss: 0.3092 - accuracy: 0.8990 - precision: 0.9129 - recall: 0.882 - 1s 1ms/sample - loss: 0.3073 - accuracy: 0.8991 - precision: 0.9126 - recall: 0.8826 - val_loss: 1.1909 - val_accuracy: 0.6549 - val_precision: 0.6741 - val_recall: 0.6408\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.937 - ETA: 0s - loss: 0.2309 - accuracy: 0.9271 - precision: 0.9271 - recall: 0.927 - ETA: 0s - loss: 0.2971 - accuracy: 0.8938 - precision: 0.8924 - recall: 0.881 - ETA: 0s - loss: 0.2827 - accuracy: 0.8973 - precision: 0.8959 - recall: 0.883 - ETA: 0s - loss: 0.2913 - accuracy: 0.8924 - precision: 0.8975 - recall: 0.881 - ETA: 0s - loss: 0.2981 - accuracy: 0.8949 - precision: 0.9014 - recall: 0.883 - ETA: 0s - loss: 0.3289 - accuracy: 0.8822 - precision: 0.8958 - recall: 0.867 - 1s 1ms/sample - loss: 0.3244 - accuracy: 0.8850 - precision: 0.8983 - recall: 0.8709 - val_loss: 1.1240 - val_accuracy: 0.7042 - val_precision: 0.7226 - val_recall: 0.6972\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.906 - ETA: 0s - loss: 0.2703 - accuracy: 0.9062 - precision: 0.9149 - recall: 0.895 - ETA: 0s - loss: 0.2375 - accuracy: 0.9125 - precision: 0.9236 - recall: 0.906 - ETA: 0s - loss: 0.2343 - accuracy: 0.9107 - precision: 0.9182 - recall: 0.901 - ETA: 0s - loss: 0.2445 - accuracy: 0.9132 - precision: 0.9250 - recall: 0.899 - ETA: 0s - loss: 0.2695 - accuracy: 0.9006 - precision: 0.9120 - recall: 0.883 - ETA: 0s - loss: 0.2826 - accuracy: 0.8918 - precision: 0.9035 - recall: 0.877 - 1s 2ms/sample - loss: 0.2932 - accuracy: 0.8873 - precision: 0.9007 - recall: 0.8732 - val_loss: 1.1369 - val_accuracy: 0.7183 - val_precision: 0.7266 - val_recall: 0.7113\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9062 - precision: 0.9355 - recall: 0.906 - ETA: 0s - loss: 0.2237 - accuracy: 0.9271 - precision: 0.9362 - recall: 0.916 - ETA: 0s - loss: 0.2293 - accuracy: 0.9062 - precision: 0.9114 - recall: 0.900 - ETA: 0s - loss: 0.2616 - accuracy: 0.8929 - precision: 0.8964 - recall: 0.888 - ETA: 0s - loss: 0.2726 - accuracy: 0.8924 - precision: 0.8940 - recall: 0.878 - ETA: 0s - loss: 0.2640 - accuracy: 0.8977 - precision: 0.8991 - recall: 0.886 - ETA: 0s - loss: 0.2651 - accuracy: 0.9014 - precision: 0.9027 - recall: 0.891 - 1s 1ms/sample - loss: 0.2661 - accuracy: 0.9014 - precision: 0.9026 - recall: 0.8920 - val_loss: 1.2390 - val_accuracy: 0.6690 - val_precision: 0.6835 - val_recall: 0.6690\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.8750 - precision: 0.8750 - recall: 0.875 - ETA: 0s - loss: 0.2906 - accuracy: 0.9062 - precision: 0.9053 - recall: 0.895 - ETA: 0s - loss: 0.2599 - accuracy: 0.9125 - precision: 0.9177 - recall: 0.906 - ETA: 0s - loss: 0.2621 - accuracy: 0.9107 - precision: 0.9182 - recall: 0.901 - ETA: 0s - loss: 0.2573 - accuracy: 0.9132 - precision: 0.9184 - recall: 0.899 - ETA: 0s - loss: 0.2733 - accuracy: 0.9034 - precision: 0.9099 - recall: 0.889 - ETA: 0s - loss: 0.2918 - accuracy: 0.8966 - precision: 0.9064 - recall: 0.884 - 1s 1ms/sample - loss: 0.2872 - accuracy: 0.8991 - precision: 0.9087 - recall: 0.8873 - val_loss: 1.2196 - val_accuracy: 0.6972 - val_precision: 0.7122 - val_recall: 0.6972\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.968 - ETA: 0s - loss: 0.2973 - accuracy: 0.9062 - precision: 0.9158 - recall: 0.906 - ETA: 0s - loss: 0.3332 - accuracy: 0.8875 - precision: 0.8917 - recall: 0.875 - ETA: 0s - loss: 0.3161 - accuracy: 0.8929 - precision: 0.9041 - recall: 0.883 - ETA: 0s - loss: 0.2984 - accuracy: 0.8958 - precision: 0.9071 - recall: 0.881 - ETA: 0s - loss: 0.2742 - accuracy: 0.9062 - precision: 0.9157 - recall: 0.894 - ETA: 0s - loss: 0.2893 - accuracy: 0.9014 - precision: 0.9093 - recall: 0.891 - 1s 1ms/sample - loss: 0.2838 - accuracy: 0.9038 - precision: 0.9115 - recall: 0.8944 - val_loss: 1.1693 - val_accuracy: 0.7042 - val_precision: 0.7279 - val_recall: 0.6972\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.968 - ETA: 0s - loss: 0.1826 - accuracy: 0.9375 - precision: 0.9570 - recall: 0.927 - ETA: 0s - loss: 0.1995 - accuracy: 0.9312 - precision: 0.9484 - recall: 0.918 - ETA: 0s - loss: 0.1908 - accuracy: 0.9330 - precision: 0.9452 - recall: 0.924 - ETA: 0s - loss: 0.1823 - accuracy: 0.9410 - precision: 0.9504 - recall: 0.930 - ETA: 0s - loss: 0.1918 - accuracy: 0.9347 - precision: 0.9446 - recall: 0.920 - ETA: 0s - loss: 0.2154 - accuracy: 0.9279 - precision: 0.9406 - recall: 0.913 - 1s 1ms/sample - loss: 0.2202 - accuracy: 0.9272 - precision: 0.9396 - recall: 0.9131 - val_loss: 1.2929 - val_accuracy: 0.6549 - val_precision: 0.6571 - val_recall: 0.6479\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9062 - precision: 0.9355 - recall: 0.906 - ETA: 0s - loss: 0.2358 - accuracy: 0.9062 - precision: 0.9158 - recall: 0.906 - ETA: 0s - loss: 0.2402 - accuracy: 0.9062 - precision: 0.9172 - recall: 0.900 - ETA: 0s - loss: 0.2313 - accuracy: 0.9196 - precision: 0.9273 - recall: 0.910 - ETA: 0s - loss: 0.2104 - accuracy: 0.9306 - precision: 0.9366 - recall: 0.923 - ETA: 0s - loss: 0.2336 - accuracy: 0.9205 - precision: 0.9253 - recall: 0.914 - ETA: 0s - loss: 0.2435 - accuracy: 0.9183 - precision: 0.9223 - recall: 0.913 - 1s 1ms/sample - loss: 0.2424 - accuracy: 0.9178 - precision: 0.9218 - recall: 0.9131 - val_loss: 1.1869 - val_accuracy: 0.6972 - val_precision: 0.7174 - val_recall: 0.6972\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.937 - ETA: 0s - loss: 0.1821 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.937 - ETA: 0s - loss: 0.1970 - accuracy: 0.9438 - precision: 0.9434 - recall: 0.937 - ETA: 0s - loss: 0.2124 - accuracy: 0.9375 - precision: 0.9418 - recall: 0.927 - ETA: 0s - loss: 0.2083 - accuracy: 0.9375 - precision: 0.9405 - recall: 0.925 - ETA: 0s - loss: 0.1930 - accuracy: 0.9444 - precision: 0.9472 - recall: 0.934 - ETA: 0s - loss: 0.2142 - accuracy: 0.9318 - precision: 0.9393 - recall: 0.923 - ETA: 0s - loss: 0.2025 - accuracy: 0.9351 - precision: 0.9415 - recall: 0.927 - 1s 2ms/sample - loss: 0.2072 - accuracy: 0.9319 - precision: 0.9379 - recall: 0.9225 - val_loss: 1.2891 - val_accuracy: 0.7042 - val_precision: 0.7143 - val_recall: 0.7042\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.000 - ETA: 0s - loss: 0.2445 - accuracy: 0.9271 - precision: 0.9271 - recall: 0.927 - ETA: 0s - loss: 0.2527 - accuracy: 0.9250 - precision: 0.9250 - recall: 0.925 - ETA: 0s - loss: 0.2904 - accuracy: 0.9018 - precision: 0.9058 - recall: 0.901 - ETA: 0s - loss: 0.2979 - accuracy: 0.8958 - precision: 0.9049 - recall: 0.892 - ETA: 0s - loss: 0.2952 - accuracy: 0.8977 - precision: 0.9052 - recall: 0.894 - ETA: 0s - loss: 0.2808 - accuracy: 0.9014 - precision: 0.9100 - recall: 0.899 - 1s 1ms/sample - loss: 0.2784 - accuracy: 0.9014 - precision: 0.9097 - recall: 0.8991 - val_loss: 1.2423 - val_accuracy: 0.6831 - val_precision: 0.7029 - val_recall: 0.6831\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9375 - precision: 0.9355 - recall: 0.906 - ETA: 0s - loss: 0.2549 - accuracy: 0.9271 - precision: 0.9255 - recall: 0.906 - ETA: 0s - loss: 0.2659 - accuracy: 0.9187 - precision: 0.9172 - recall: 0.900 - ETA: 0s - loss: 0.2582 - accuracy: 0.9241 - precision: 0.9266 - recall: 0.901 - ETA: 0s - loss: 0.2668 - accuracy: 0.9236 - precision: 0.9288 - recall: 0.906 - ETA: 0s - loss: 0.2623 - accuracy: 0.9261 - precision: 0.9300 - recall: 0.906 - ETA: 0s - loss: 0.2386 - accuracy: 0.9351 - precision: 0.9407 - recall: 0.915 - 1s 1ms/sample - loss: 0.2377 - accuracy: 0.9343 - precision: 0.9398 - recall: 0.9155 - val_loss: 1.1852 - val_accuracy: 0.7113 - val_precision: 0.7214 - val_recall: 0.7113\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.968 - ETA: 0s - loss: 0.2941 - accuracy: 0.9167 - precision: 0.9158 - recall: 0.906 - ETA: 0s - loss: 0.2181 - accuracy: 0.9375 - precision: 0.9371 - recall: 0.931 - ETA: 0s - loss: 0.1954 - accuracy: 0.9420 - precision: 0.9414 - recall: 0.933 - ETA: 0s - loss: 0.2132 - accuracy: 0.9236 - precision: 0.9231 - recall: 0.916 - ETA: 0s - loss: 0.2284 - accuracy: 0.9176 - precision: 0.9195 - recall: 0.909 - ETA: 0s - loss: 0.2412 - accuracy: 0.9135 - precision: 0.9195 - recall: 0.906 - 1s 1ms/sample - loss: 0.2529 - accuracy: 0.9108 - precision: 0.9189 - recall: 0.9038 - val_loss: 1.2144 - val_accuracy: 0.7042 - val_precision: 0.7174 - val_recall: 0.6972\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9062 - precision: 1.0000 - recall: 0.906 - ETA: 0s - loss: 0.2326 - accuracy: 0.8958 - precision: 0.9545 - recall: 0.875 - ETA: 0s - loss: 0.2973 - accuracy: 0.8938 - precision: 0.9338 - recall: 0.881 - ETA: 0s - loss: 0.3073 - accuracy: 0.8929 - precision: 0.9206 - recall: 0.879 - ETA: 0s - loss: 0.3005 - accuracy: 0.8924 - precision: 0.9170 - recall: 0.881 - ETA: 0s - loss: 0.3269 - accuracy: 0.8807 - precision: 0.9053 - recall: 0.869 - ETA: 0s - loss: 0.3945 - accuracy: 0.8654 - precision: 0.8878 - recall: 0.855 - 1s 1ms/sample - loss: 0.4051 - accuracy: 0.8592 - precision: 0.8808 - recall: 0.8498 - val_loss: 1.2550 - val_accuracy: 0.6408 - val_precision: 0.6567 - val_recall: 0.6197\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.8438 - precision: 0.8438 - recall: 0.843 - ETA: 0s - loss: 0.4147 - accuracy: 0.8646 - precision: 0.8791 - recall: 0.833 - ETA: 0s - loss: 0.3995 - accuracy: 0.8687 - precision: 0.8808 - recall: 0.831 - ETA: 0s - loss: 0.3825 - accuracy: 0.8661 - precision: 0.8868 - recall: 0.839 - ETA: 0s - loss: 0.3718 - accuracy: 0.8681 - precision: 0.8901 - recall: 0.843 - ETA: 0s - loss: 0.3447 - accuracy: 0.8807 - precision: 0.9009 - recall: 0.852 - ETA: 0s - loss: 0.3400 - accuracy: 0.8798 - precision: 0.8987 - recall: 0.853 - 1s 1ms/sample - loss: 0.3410 - accuracy: 0.8803 - precision: 0.8985 - recall: 0.8521 - val_loss: 1.2314 - val_accuracy: 0.6761 - val_precision: 0.7037 - val_recall: 0.6690\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.8750 - precision: 0.9333 - recall: 0.875 - ETA: 0s - loss: 0.2440 - accuracy: 0.8958 - precision: 0.9348 - recall: 0.895 - ETA: 0s - loss: 0.2760 - accuracy: 0.9062 - precision: 0.9295 - recall: 0.906 - ETA: 0s - loss: 0.2910 - accuracy: 0.9018 - precision: 0.9182 - recall: 0.901 - ETA: 0s - loss: 0.2760 - accuracy: 0.9028 - precision: 0.9187 - recall: 0.902 - ETA: 0s - loss: 0.2583 - accuracy: 0.9119 - precision: 0.9300 - recall: 0.906 - ETA: 0s - loss: 0.2659 - accuracy: 0.9014 - precision: 0.9210 - recall: 0.896 - 1s 1ms/sample - loss: 0.2613 - accuracy: 0.9038 - precision: 0.9229 - recall: 0.8991 - val_loss: 1.3549 - val_accuracy: 0.6338 - val_precision: 0.6544 - val_recall: 0.6268\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.937 - ETA: 0s - loss: 0.2851 - accuracy: 0.8958 - precision: 0.9043 - recall: 0.885 - ETA: 0s - loss: 0.2655 - accuracy: 0.9000 - precision: 0.9108 - recall: 0.893 - ETA: 0s - loss: 0.2471 - accuracy: 0.9152 - precision: 0.9231 - recall: 0.910 - ETA: 0s - loss: 0.2523 - accuracy: 0.9097 - precision: 0.9286 - recall: 0.902 - ETA: 0s - loss: 0.2511 - accuracy: 0.9148 - precision: 0.9329 - recall: 0.909 - ETA: 0s - loss: 0.2496 - accuracy: 0.9111 - precision: 0.9332 - recall: 0.906 - 1s 1ms/sample - loss: 0.2589 - accuracy: 0.9061 - precision: 0.9298 - recall: 0.9014 - val_loss: 1.3077 - val_accuracy: 0.6831 - val_precision: 0.6879 - val_recall: 0.6831\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.8438 - precision: 0.8387 - recall: 0.812 - ETA: 0s - loss: 0.2685 - accuracy: 0.9062 - precision: 0.9149 - recall: 0.895 - ETA: 0s - loss: 0.2594 - accuracy: 0.9125 - precision: 0.9177 - recall: 0.906 - ETA: 0s - loss: 0.2979 - accuracy: 0.8750 - precision: 0.8784 - recall: 0.870 - ETA: 0s - loss: 0.3507 - accuracy: 0.8507 - precision: 0.8526 - recall: 0.843 - ETA: 0s - loss: 0.4112 - accuracy: 0.8295 - precision: 0.8353 - recall: 0.821 - ETA: 0s - loss: 0.4164 - accuracy: 0.8365 - precision: 0.8424 - recall: 0.822 - 1s 1ms/sample - loss: 0.4114 - accuracy: 0.8404 - precision: 0.8458 - recall: 0.8239 - val_loss: 1.3408 - val_accuracy: 0.6479 - val_precision: 0.6716 - val_recall: 0.6338\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.9062 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.5716 - accuracy: 0.7917 - precision: 0.8022 - recall: 0.760 - ETA: 0s - loss: 0.5422 - accuracy: 0.8188 - precision: 0.8312 - recall: 0.800 - ETA: 0s - loss: 0.5230 - accuracy: 0.8482 - precision: 0.8611 - recall: 0.830 - ETA: 0s - loss: 0.4997 - accuracy: 0.8438 - precision: 0.8536 - recall: 0.829 - ETA: 0s - loss: 0.4693 - accuracy: 0.8523 - precision: 0.8614 - recall: 0.829 - ETA: 0s - loss: 0.4598 - accuracy: 0.8534 - precision: 0.8625 - recall: 0.829 - 1s 1ms/sample - loss: 0.4584 - accuracy: 0.8521 - precision: 0.8610 - recall: 0.8286 - val_loss: 1.1287 - val_accuracy: 0.7042 - val_precision: 0.7226 - val_recall: 0.6972\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9375 - precision: 0.9355 - recall: 0.906 - ETA: 0s - loss: 0.3255 - accuracy: 0.8750 - precision: 0.8830 - recall: 0.864 - ETA: 0s - loss: 0.3687 - accuracy: 0.8562 - precision: 0.8654 - recall: 0.843 - ETA: 0s - loss: 0.4131 - accuracy: 0.8438 - precision: 0.8618 - recall: 0.834 - ETA: 0s - loss: 0.4158 - accuracy: 0.8472 - precision: 0.8696 - recall: 0.833 - ETA: 0s - loss: 0.4111 - accuracy: 0.8494 - precision: 0.8698 - recall: 0.835 - ETA: 0s - loss: 0.3908 - accuracy: 0.8558 - precision: 0.8747 - recall: 0.838 - 1s 1ms/sample - loss: 0.4014 - accuracy: 0.8521 - precision: 0.8701 - recall: 0.8333 - val_loss: 1.1786 - val_accuracy: 0.6761 - val_precision: 0.7045 - val_recall: 0.6549\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.906 - ETA: 0s - loss: 0.4767 - accuracy: 0.8542 - precision: 0.8632 - recall: 0.854 - ETA: 0s - loss: 0.4652 - accuracy: 0.8625 - precision: 0.8790 - recall: 0.862 - ETA: 0s - loss: 0.6362 - accuracy: 0.8259 - precision: 0.8426 - recall: 0.812 - ETA: 0s - loss: 0.7761 - accuracy: 0.8056 - precision: 0.8195 - recall: 0.788 - ETA: 0s - loss: 0.8035 - accuracy: 0.7727 - precision: 0.7870 - recall: 0.755 - ETA: 0s - loss: 0.8277 - accuracy: 0.7572 - precision: 0.7725 - recall: 0.742 - 1s 1ms/sample - loss: 0.8178 - accuracy: 0.7559 - precision: 0.7721 - recall: 0.7394 - val_loss: 1.4510 - val_accuracy: 0.5845 - val_precision: 0.6260 - val_recall: 0.5775\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7500 - precision: 0.8214 - recall: 0.718 - ETA: 0s - loss: 0.6234 - accuracy: 0.7604 - precision: 0.8256 - recall: 0.739 - ETA: 0s - loss: 0.6168 - accuracy: 0.7688 - precision: 0.8207 - recall: 0.743 - ETA: 0s - loss: 0.6972 - accuracy: 0.7366 - precision: 0.7772 - recall: 0.700 - ETA: 0s - loss: 0.6658 - accuracy: 0.7396 - precision: 0.7816 - recall: 0.708 - ETA: 0s - loss: 0.6432 - accuracy: 0.7528 - precision: 0.7919 - recall: 0.724 - ETA: 0s - loss: 0.6364 - accuracy: 0.7596 - precision: 0.7953 - recall: 0.728 - 1s 1ms/sample - loss: 0.6299 - accuracy: 0.7629 - precision: 0.7980 - recall: 0.7324 - val_loss: 1.4441 - val_accuracy: 0.5986 - val_precision: 0.6129 - val_recall: 0.5352\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.8750 - precision: 0.8966 - recall: 0.812 - ETA: 0s - loss: 0.5246 - accuracy: 0.8333 - precision: 0.8588 - recall: 0.760 - ETA: 0s - loss: 0.5356 - accuracy: 0.8313 - precision: 0.8521 - recall: 0.756 - ETA: 0s - loss: 0.5504 - accuracy: 0.8304 - precision: 0.8529 - recall: 0.776 - ETA: 0s - loss: 0.5795 - accuracy: 0.8056 - precision: 0.8359 - recall: 0.760 - ETA: 0s - loss: 0.5636 - accuracy: 0.8097 - precision: 0.8375 - recall: 0.761 - ETA: 0s - loss: 0.5767 - accuracy: 0.7981 - precision: 0.8259 - recall: 0.752 - 1s 1ms/sample - loss: 0.5755 - accuracy: 0.7958 - precision: 0.8226 - recall: 0.7512 - val_loss: 1.4495 - val_accuracy: 0.5845 - val_precision: 0.6061 - val_recall: 0.5634\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6679 - accuracy: 0.7500 - precision: 0.7667 - recall: 0.718 - ETA: 0s - loss: 0.6047 - accuracy: 0.8125 - precision: 0.8132 - recall: 0.770 - ETA: 0s - loss: 0.5356 - accuracy: 0.8375 - precision: 0.8355 - recall: 0.793 - ETA: 0s - loss: 0.5155 - accuracy: 0.8259 - precision: 0.8271 - recall: 0.790 - ETA: 0s - loss: 0.4517 - accuracy: 0.8507 - precision: 0.8551 - recall: 0.819 - ETA: 0s - loss: 0.4549 - accuracy: 0.8438 - precision: 0.8537 - recall: 0.812 - ETA: 0s - loss: 0.4439 - accuracy: 0.8510 - precision: 0.8593 - recall: 0.822 - 1s 1ms/sample - loss: 0.4397 - accuracy: 0.8521 - precision: 0.8603 - recall: 0.8239 - val_loss: 1.1349 - val_accuracy: 0.6690 - val_precision: 0.6742 - val_recall: 0.6268\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.8438 - precision: 0.8710 - recall: 0.843 - ETA: 0s - loss: 0.4007 - accuracy: 0.8854 - precision: 0.8925 - recall: 0.864 - ETA: 0s - loss: 0.3707 - accuracy: 0.8875 - precision: 0.8910 - recall: 0.868 - ETA: 0s - loss: 0.3676 - accuracy: 0.8750 - precision: 0.8894 - recall: 0.861 - ETA: 0s - loss: 0.3595 - accuracy: 0.8854 - precision: 0.8996 - recall: 0.871 - ETA: 0s - loss: 0.3237 - accuracy: 0.9006 - precision: 0.9125 - recall: 0.889 - ETA: 0s - loss: 0.3297 - accuracy: 0.8918 - precision: 0.9057 - recall: 0.877 - 1s 1ms/sample - loss: 0.3323 - accuracy: 0.8873 - precision: 0.9007 - recall: 0.8732 - val_loss: 1.1052 - val_accuracy: 0.6972 - val_precision: 0.7132 - val_recall: 0.6831\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8750 - precision: 0.8750 - recall: 0.875 - ETA: 0s - loss: 0.2912 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.895 - ETA: 0s - loss: 0.2931 - accuracy: 0.9000 - precision: 0.9057 - recall: 0.900 - ETA: 0s - loss: 0.2723 - accuracy: 0.9196 - precision: 0.9276 - recall: 0.915 - ETA: 0s - loss: 0.2969 - accuracy: 0.8993 - precision: 0.9053 - recall: 0.895 - ETA: 0s - loss: 0.2837 - accuracy: 0.9091 - precision: 0.9167 - recall: 0.906 - ETA: 0s - loss: 0.2736 - accuracy: 0.9111 - precision: 0.9214 - recall: 0.901 - 1s 1ms/sample - loss: 0.2703 - accuracy: 0.9108 - precision: 0.9231 - recall: 0.9014 - val_loss: 1.1658 - val_accuracy: 0.6761 - val_precision: 0.6857 - val_recall: 0.6761\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8750 - precision: 0.8750 - recall: 0.875 - ETA: 0s - loss: 0.2839 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.895 - ETA: 0s - loss: 0.2853 - accuracy: 0.9000 - precision: 0.9057 - recall: 0.900 - ETA: 0s - loss: 0.2739 - accuracy: 0.9018 - precision: 0.9058 - recall: 0.901 - ETA: 0s - loss: 0.2497 - accuracy: 0.9132 - precision: 0.9228 - recall: 0.913 - ETA: 0s - loss: 0.2362 - accuracy: 0.9176 - precision: 0.9255 - recall: 0.917 - ETA: 0s - loss: 0.2426 - accuracy: 0.9159 - precision: 0.9246 - recall: 0.913 - 1s 1ms/sample - loss: 0.2473 - accuracy: 0.9131 - precision: 0.9216 - recall: 0.9108 - val_loss: 1.1460 - val_accuracy: 0.6972 - val_precision: 0.7021 - val_recall: 0.6972\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9688 - precision: 0.9677 - recall: 0.937 - ETA: 0s - loss: 0.2891 - accuracy: 0.9271 - precision: 0.9355 - recall: 0.906 - ETA: 0s - loss: 0.3167 - accuracy: 0.9000 - precision: 0.9161 - recall: 0.887 - ETA: 0s - loss: 0.4557 - accuracy: 0.8616 - precision: 0.8721 - recall: 0.852 - ETA: 0s - loss: 0.4887 - accuracy: 0.8542 - precision: 0.8622 - recall: 0.847 - ETA: 0s - loss: 0.5000 - accuracy: 0.8494 - precision: 0.8580 - recall: 0.840 - ETA: 0s - loss: 0.5217 - accuracy: 0.8293 - precision: 0.8382 - recall: 0.822 - 1s 1ms/sample - loss: 0.5201 - accuracy: 0.8310 - precision: 0.8397 - recall: 0.8239 - val_loss: 1.4005 - val_accuracy: 0.6056 - val_precision: 0.6466 - val_recall: 0.6056\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3025 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.906 - ETA: 0s - loss: 0.4209 - accuracy: 0.8542 - precision: 0.8542 - recall: 0.854 - ETA: 0s - loss: 0.4359 - accuracy: 0.8438 - precision: 0.8544 - recall: 0.843 - ETA: 0s - loss: 0.4739 - accuracy: 0.8214 - precision: 0.8326 - recall: 0.821 - ETA: 0s - loss: 0.4854 - accuracy: 0.8160 - precision: 0.8262 - recall: 0.809 - ETA: 0s - loss: 0.5361 - accuracy: 0.8068 - precision: 0.8169 - recall: 0.798 - ETA: 0s - loss: 0.5104 - accuracy: 0.8149 - precision: 0.8251 - recall: 0.805 - 1s 1ms/sample - loss: 0.5306 - accuracy: 0.8075 - precision: 0.8213 - recall: 0.7981 - val_loss: 1.2259 - val_accuracy: 0.6338 - val_precision: 0.6541 - val_recall: 0.6127\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8750 - precision: 0.9032 - recall: 0.875 - ETA: 0s - loss: 0.3578 - accuracy: 0.8750 - precision: 0.8925 - recall: 0.864 - ETA: 0s - loss: 0.4823 - accuracy: 0.8125 - precision: 0.8467 - recall: 0.793 - ETA: 0s - loss: 0.4843 - accuracy: 0.8080 - precision: 0.8421 - recall: 0.785 - ETA: 0s - loss: 0.5215 - accuracy: 0.8125 - precision: 0.8407 - recall: 0.788 - ETA: 0s - loss: 0.5097 - accuracy: 0.8210 - precision: 0.8476 - recall: 0.789 - ETA: 0s - loss: 0.5296 - accuracy: 0.8029 - precision: 0.8364 - recall: 0.774 - 1s 1ms/sample - loss: 0.5304 - accuracy: 0.8028 - precision: 0.8376 - recall: 0.7746 - val_loss: 1.1153 - val_accuracy: 0.6831 - val_precision: 0.7068 - val_recall: 0.6620\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 11611c6ee5c789b015705d90f5cbf9ac</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7183098793029785</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                65792     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 861,452\n",
      "Trainable params: 861,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:14 - loss: 2.4962 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 21s - loss: 2.4720 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 10s - loss: 2.4492 - accuracy: 0.1375 - precision: 0.0000e+00 - recall: 0.0000e+ - ETA: 5s - loss: 2.4338 - accuracy: 0.1473 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 3s - loss: 2.3806 - accuracy: 0.1597 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.3447 - accuracy: 0.1648 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3089 - accuracy: 0.1755 - precision: 0.0000e+00 - recall: 0.0000e+0 - 8s 20ms/sample - loss: 2.3088 - accuracy: 0.1784 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0597 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8317 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9606 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0334 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0379 - accuracy: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0295 - accuracy: 0.2222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0428 - accuracy: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0181 - accuracy: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.0152 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8823 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7190 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7964 - accuracy: 0.2708 - precision: 0.6000 - recall: 0.0312        - ETA: 0s - loss: 1.8212 - accuracy: 0.2500 - precision: 0.4167 - recall: 0.031 - ETA: 0s - loss: 1.8840 - accuracy: 0.2232 - precision: 0.2381 - recall: 0.022 - ETA: 0s - loss: 1.9139 - accuracy: 0.2118 - precision: 0.2381 - recall: 0.017 - ETA: 0s - loss: 1.9088 - accuracy: 0.2017 - precision: 0.2381 - recall: 0.014 - ETA: 0s - loss: 1.9098 - accuracy: 0.1995 - precision: 0.2381 - recall: 0.012 - 1s 2ms/sample - loss: 1.9107 - accuracy: 0.1972 - precision: 0.2381 - recall: 0.0117 - val_loss: 2.4188 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1409 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4616 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5442 - accuracy: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6331 - accuracy: 0.1719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6086 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6235 - accuracy: 0.1375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5878 - accuracy: 0.1432 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.5854 - accuracy: 0.1315 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4507 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4918 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4255 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4331 - accuracy: 0.1063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4286 - accuracy: 0.1205 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4266 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4383 - accuracy: 0.1051 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4396 - accuracy: 0.1010 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4412 - accuracy: 0.1009 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4287 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4478 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4129 - accuracy: 0.0729 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4165 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4158 - accuracy: 0.0804 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4159 - accuracy: 0.0868 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4156 - accuracy: 0.0852 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4131 - accuracy: 0.0889 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4149 - accuracy: 0.0869 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4122 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3910 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4056 - accuracy: 0.0417 - precision: 0.0000e+00 - recall: 0.0000e+00    - ETA: 0s - loss: 2.4061 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4063 - accuracy: 0.0580 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4090 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4086 - accuracy: 0.0767 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4095 - accuracy: 0.0769 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4084 - accuracy: 0.0775 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4233 - val_accuracy: 0.0704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3280 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3825 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4016 - accuracy: 0.1063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4054 - accuracy: 0.1205 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4019 - accuracy: 0.1181 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3997 - accuracy: 0.1108 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3993 - accuracy: 0.1010 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3995 - accuracy: 0.1009 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4190 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4034 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3908 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3897 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3888 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3934 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3945 - accuracy: 0.1108 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3983 - accuracy: 0.1034 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3993 - accuracy: 0.1033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4201 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3644 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3748 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3832 - accuracy: 0.0812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3811 - accuracy: 0.0848 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3882 - accuracy: 0.0799 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3993 - accuracy: 0.0795 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3987 - accuracy: 0.0793 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3999 - accuracy: 0.0775 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4177 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3939 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3899 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3871 - accuracy: 0.1063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3964 - accuracy: 0.0893 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3969 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3977 - accuracy: 0.0994 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4010 - accuracy: 0.0962 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4018 - accuracy: 0.0939 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4077 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4415 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4079 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4047 - accuracy: 0.1000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4007 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4007 - accuracy: 0.1007 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3969 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4000 - accuracy: 0.1106 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4005 - accuracy: 0.1103 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4124 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4224 - accuracy: 0.0312 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3905 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3934 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3847 - accuracy: 0.1295 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3937 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3977 - accuracy: 0.1051 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3985 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3975 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4217 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4314 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4187 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4103 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4043 - accuracy: 0.1071 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3995 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3981 - accuracy: 0.1136 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3990 - accuracy: 0.1010 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3989 - accuracy: 0.0986 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4195 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3891 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4114 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4040 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4015 - accuracy: 0.1027 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3957 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3964 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3958 - accuracy: 0.1034 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3968 - accuracy: 0.1033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4167 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3905 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3793 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3916 - accuracy: 0.1063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3986 - accuracy: 0.1116 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4007 - accuracy: 0.1007 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4009 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3985 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3968 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4167 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4191 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3999 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3901 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3925 - accuracy: 0.1161 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3887 - accuracy: 0.1181 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3929 - accuracy: 0.1136 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3985 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3971 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4211 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 2.4212 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4057 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4094 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4054 - accuracy: 0.0848 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3964 - accuracy: 0.0868 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3921 - accuracy: 0.0824 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3942 - accuracy: 0.0817 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3952 - accuracy: 0.0822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4126 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3485 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3793 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3842 - accuracy: 0.1125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3876 - accuracy: 0.1116 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3920 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3934 - accuracy: 0.1108 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3966 - accuracy: 0.1034 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3987 - accuracy: 0.1009 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4052 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4349 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3936 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3912 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3930 - accuracy: 0.0804 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3984 - accuracy: 0.0729 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3965 - accuracy: 0.0739 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3990 - accuracy: 0.0769 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3992 - accuracy: 0.0751 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4084 - val_accuracy: 0.0986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3854 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3828 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3985 - accuracy: 0.0812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3953 - accuracy: 0.0804 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3966 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3957 - accuracy: 0.0966 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3964 - accuracy: 0.1010 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3963 - accuracy: 0.1009 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4148 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3896 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3943 - accuracy: 0.0729 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3904 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3948 - accuracy: 0.1071 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3919 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3920 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3944 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3952 - accuracy: 0.0939 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4167 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3585 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3790 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3948 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3892 - accuracy: 0.0848 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3844 - accuracy: 0.0868 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3877 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3988 - accuracy: 0.0807 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3968 - accuracy: 0.0892 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4171 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3901 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4021 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4055 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3970 - accuracy: 0.1116 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3947 - accuracy: 0.1076 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3935 - accuracy: 0.1165 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3931 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3915 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4098 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4366 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4202 - accuracy: 0.0729 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4156 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3983 - accuracy: 0.1027 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3963 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3903 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3893 - accuracy: 0.0962 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3891 - accuracy: 0.0939 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4055 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3330 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3485 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3796 - accuracy: 0.0750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3776 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3698 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3674 - accuracy: 0.1335 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3517 - accuracy: 0.1490 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3509 - accuracy: 0.1479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2980 - val_accuracy: 0.1338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3365 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2612 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2599 - accuracy: 0.1813 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2219 - accuracy: 0.1920 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2191 - accuracy: 0.1736 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2587 - accuracy: 0.1591 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2289 - accuracy: 0.1611 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2265 - accuracy: 0.1573 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0730 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0602 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1086 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0716 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0834 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0477 - accuracy: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0349 - accuracy: 0.1818 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0266 - accuracy: 0.1827 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.0313 - accuracy: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9756 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8627 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9419 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9271 - accuracy: 0.1500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9097 - accuracy: 0.1741 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9030 - accuracy: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9148 - accuracy: 0.1733 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9374 - accuracy: 0.1755 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9520 - accuracy: 0.1714 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8830 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0762 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9710 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9420 - accuracy: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9379 - accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9502 - accuracy: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9493 - accuracy: 0.2216 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9223 - accuracy: 0.2139 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9181 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8999 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8183 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9043 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8930 - accuracy: 0.2250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9121 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8913 - accuracy: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8937 - accuracy: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9094 - accuracy: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.9157 - accuracy: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8262 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7546 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8276 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8922 - accuracy: 0.2250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9215 - accuracy: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8992 - accuracy: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9066 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8920 - accuracy: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8875 - accuracy: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8408 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8816 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8285 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8215 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8065 - accuracy: 0.2455 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8022 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8096 - accuracy: 0.2528 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8116 - accuracy: 0.2524 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8137 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7662 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9891 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0668 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9741 - accuracy: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9087 - accuracy: 0.2455 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8726 - accuracy: 0.2569 - precision: 1.0000 - recall: 0.0035        - ETA: 0s - loss: 1.8503 - accuracy: 0.2656 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.8302 - accuracy: 0.2604 - precision: 0.6316 - recall: 0.031 - 1s 1ms/sample - loss: 1.8171 - accuracy: 0.2559 - precision: 0.6000 - recall: 0.0352 - val_loss: 1.7662 - val_accuracy: 0.2324 - val_precision: 0.6667 - val_recall: 0.0423\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8000 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.7709 - accuracy: 0.2396 - precision: 0.5000 - recall: 0.020 - ETA: 0s - loss: 1.7899 - accuracy: 0.2500 - precision: 0.5714 - recall: 0.025 - ETA: 0s - loss: 1.8127 - accuracy: 0.2545 - precision: 0.6667 - recall: 0.026 - ETA: 0s - loss: 1.8269 - accuracy: 0.2465 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.7997 - accuracy: 0.2614 - precision: 0.6667 - recall: 0.017 - ETA: 0s - loss: 1.8176 - accuracy: 0.2596 - precision: 0.6667 - recall: 0.014 - 1s 2ms/sample - loss: 1.8190 - accuracy: 0.2582 - precision: 0.6667 - recall: 0.0141 - val_loss: 1.7583 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.7610 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7563 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7948 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7947 - accuracy: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7874 - accuracy: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7786 - accuracy: 0.1969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8102 - accuracy: 0.2057 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8058 - accuracy: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8440 - val_accuracy: 0.2183 - val_precision: 0.7000 - val_recall: 0.0493\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7972 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8909 - accuracy: 0.2292 - precision: 0.7273 - recall: 0.083 - ETA: 0s - loss: 1.8722 - accuracy: 0.2438 - precision: 0.4583 - recall: 0.068 - ETA: 0s - loss: 1.9248 - accuracy: 0.2232 - precision: 0.3590 - recall: 0.062 - ETA: 0s - loss: 1.9229 - accuracy: 0.2188 - precision: 0.3438 - recall: 0.076 - ETA: 0s - loss: 1.8985 - accuracy: 0.2188 - precision: 0.3108 - recall: 0.065 - ETA: 0s - loss: 1.8984 - accuracy: 0.2163 - precision: 0.3108 - recall: 0.055 - 1s 1ms/sample - loss: 1.9009 - accuracy: 0.2136 - precision: 0.3108 - recall: 0.0540 - val_loss: 1.7677 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8649 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7470 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7778 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7808 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8003 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8188 - accuracy: 0.2216 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8156 - accuracy: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8162 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7520 - val_accuracy: 0.2887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7903 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7765 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7570 - accuracy: 0.3063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7669 - accuracy: 0.2902 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7932 - accuracy: 0.2778 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7948 - accuracy: 0.2670 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7962 - accuracy: 0.2620 - precision: 1.0000 - recall: 0.0024        - 1s 1ms/sample - loss: 1.7943 - accuracy: 0.2606 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.7526 - val_accuracy: 0.2113 - val_precision: 0.5200 - val_recall: 0.0915\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8066 - accuracy: 0.1562 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.8176 - accuracy: 0.2292 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.8676 - accuracy: 0.2000 - precision: 0.3824 - recall: 0.081 - ETA: 0s - loss: 1.8545 - accuracy: 0.2277 - precision: 0.4474 - recall: 0.075 - ETA: 0s - loss: 1.8306 - accuracy: 0.2257 - precision: 0.4474 - recall: 0.059 - ETA: 0s - loss: 1.8403 - accuracy: 0.2244 - precision: 0.4474 - recall: 0.048 - ETA: 0s - loss: 1.8432 - accuracy: 0.2260 - precision: 0.4474 - recall: 0.040 - 1s 1ms/sample - loss: 1.8419 - accuracy: 0.2254 - precision: 0.4474 - recall: 0.0399 - val_loss: 1.7677 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7696 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7646 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7731 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7393 - accuracy: 0.2991 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7526 - accuracy: 0.2847 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7807 - accuracy: 0.2614 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8025 - accuracy: 0.2620 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7983 - accuracy: 0.2629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7534 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7361 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7731 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7654 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8132 - accuracy: 0.2366 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7762 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7692 - accuracy: 0.2585 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7949 - accuracy: 0.2452 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7938 - accuracy: 0.2441 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7983 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7195 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8902 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8983 - accuracy: 0.2625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8454 - accuracy: 0.2589 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8190 - accuracy: 0.2465 - precision: 0.4286 - recall: 0.0104        - ETA: 0s - loss: 1.8101 - accuracy: 0.2330 - precision: 0.4167 - recall: 0.014 - ETA: 0s - loss: 1.8029 - accuracy: 0.2284 - precision: 0.5000 - recall: 0.016 - 1s 1ms/sample - loss: 1.8004 - accuracy: 0.2300 - precision: 0.5000 - recall: 0.0164 - val_loss: 1.7143 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8031 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7959 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7216 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7674 - accuracy: 0.2545 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7806 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8011 - accuracy: 0.2670 - precision: 0.3333 - recall: 0.0028        - ETA: 0s - loss: 1.8015 - accuracy: 0.2452 - precision: 0.5000 - recall: 0.012 - 1s 1ms/sample - loss: 1.8041 - accuracy: 0.2418 - precision: 0.4545 - recall: 0.0117 - val_loss: 1.7367 - val_accuracy: 0.2817 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8793 - accuracy: 0.1562 - precision: 0.2000 - recall: 0.031 - ETA: 0s - loss: 1.7778 - accuracy: 0.2292 - precision: 0.3889 - recall: 0.072 - ETA: 0s - loss: 1.7783 - accuracy: 0.2500 - precision: 0.3889 - recall: 0.043 - ETA: 0s - loss: 1.7770 - accuracy: 0.2455 - precision: 0.3889 - recall: 0.031 - ETA: 0s - loss: 1.7820 - accuracy: 0.2465 - precision: 0.3889 - recall: 0.024 - ETA: 0s - loss: 1.7767 - accuracy: 0.2415 - precision: 0.3889 - recall: 0.019 - ETA: 0s - loss: 1.7737 - accuracy: 0.2356 - precision: 0.3889 - recall: 0.016 - 1s 1ms/sample - loss: 1.7682 - accuracy: 0.2394 - precision: 0.3889 - recall: 0.0164 - val_loss: 1.7417 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6536 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6852 - accuracy: 0.3021 - precision: 0.4545 - recall: 0.0521        - ETA: 0s - loss: 1.7393 - accuracy: 0.2875 - precision: 0.4167 - recall: 0.031 - ETA: 0s - loss: 1.7595 - accuracy: 0.2857 - precision: 0.4167 - recall: 0.022 - ETA: 0s - loss: 1.7591 - accuracy: 0.2743 - precision: 0.4167 - recall: 0.017 - ETA: 0s - loss: 1.7647 - accuracy: 0.2557 - precision: 0.4167 - recall: 0.014 - ETA: 0s - loss: 1.7641 - accuracy: 0.2620 - precision: 0.4167 - recall: 0.012 - 1s 1ms/sample - loss: 1.7672 - accuracy: 0.2629 - precision: 0.4167 - recall: 0.0117 - val_loss: 1.7835 - val_accuracy: 0.2394 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7477 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7176 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.0417        - ETA: 0s - loss: 1.7306 - accuracy: 0.2875 - precision: 0.5385 - recall: 0.043 - ETA: 0s - loss: 1.7453 - accuracy: 0.2679 - precision: 0.4483 - recall: 0.058 - ETA: 0s - loss: 1.7721 - accuracy: 0.2604 - precision: 0.4595 - recall: 0.059 - ETA: 0s - loss: 1.8028 - accuracy: 0.2415 - precision: 0.4082 - recall: 0.056 - ETA: 0s - loss: 1.7804 - accuracy: 0.2500 - precision: 0.4603 - recall: 0.069 - 1s 1ms/sample - loss: 1.7863 - accuracy: 0.2512 - precision: 0.4603 - recall: 0.0681 - val_loss: 1.7441 - val_accuracy: 0.2606 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8371 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.8641 - accuracy: 0.2292 - precision: 1.0000 - recall: 0.020 - ETA: 0s - loss: 1.8156 - accuracy: 0.2562 - precision: 1.0000 - recall: 0.012 - ETA: 0s - loss: 1.7796 - accuracy: 0.2768 - precision: 1.0000 - recall: 0.008 - ETA: 0s - loss: 1.7717 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.011 - ETA: 0s - loss: 1.7758 - accuracy: 0.2674 - precision: 0.8000 - recall: 0.013 - ETA: 0s - loss: 1.7929 - accuracy: 0.2531 - precision: 0.5556 - recall: 0.015 - ETA: 0s - loss: 1.7905 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.019 - ETA: 0s - loss: 1.7820 - accuracy: 0.2500 - precision: 0.4815 - recall: 0.031 - 1s 3ms/sample - loss: 1.7833 - accuracy: 0.2488 - precision: 0.4333 - recall: 0.0305 - val_loss: 1.7094 - val_accuracy: 0.2817 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6588 - accuracy: 0.1562 - precision: 0.2857 - recall: 0.062 - ETA: 0s - loss: 1.6748 - accuracy: 0.2604 - precision: 0.4444 - recall: 0.041 - ETA: 0s - loss: 1.7462 - accuracy: 0.2688 - precision: 0.4444 - recall: 0.025 - ETA: 0s - loss: 1.7436 - accuracy: 0.2656 - precision: 0.4444 - recall: 0.020 - ETA: 0s - loss: 1.7606 - accuracy: 0.2539 - precision: 0.4444 - recall: 0.015 - ETA: 0s - loss: 1.7431 - accuracy: 0.2465 - precision: 0.4444 - recall: 0.013 - ETA: 0s - loss: 1.7607 - accuracy: 0.2415 - precision: 0.4444 - recall: 0.011 - ETA: 0s - loss: 1.7592 - accuracy: 0.2380 - precision: 0.4444 - recall: 0.009 - 1s 2ms/sample - loss: 1.7663 - accuracy: 0.2371 - precision: 0.4444 - recall: 0.0094 - val_loss: 1.7444 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7164 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7865 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7577 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8189 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7654 - accuracy: 0.2882 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7634 - accuracy: 0.2955 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7730 - accuracy: 0.2740 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7699 - accuracy: 0.2746 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7221 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7654 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6768 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6969 - accuracy: 0.2891 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7539 - accuracy: 0.2865 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7517 - accuracy: 0.2695 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7541 - accuracy: 0.2719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7488 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7552 - accuracy: 0.2676 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7204 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7791 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7000 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7098 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7179 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7321 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7383 - accuracy: 0.2585 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7407 - accuracy: 0.2644 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7444 - accuracy: 0.2653 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7156 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7138 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6995 - accuracy: 0.3906 - precision: 1.0000 - recall: 0.0156        - ETA: 0s - loss: 1.7802 - accuracy: 0.2969 - precision: 0.3333 - recall: 0.015 - ETA: 0s - loss: 1.7571 - accuracy: 0.3073 - precision: 0.4545 - recall: 0.026 - ETA: 0s - loss: 1.7280 - accuracy: 0.3036 - precision: 0.5333 - recall: 0.035 - ETA: 0s - loss: 1.7283 - accuracy: 0.2847 - precision: 0.5417 - recall: 0.045 - ETA: 0s - loss: 1.7355 - accuracy: 0.2812 - precision: 0.5278 - recall: 0.054 - ETA: 0s - loss: 1.7440 - accuracy: 0.2668 - precision: 0.4419 - recall: 0.045 - 1s 2ms/sample - loss: 1.7502 - accuracy: 0.2629 - precision: 0.4318 - recall: 0.0446 - val_loss: 1.7346 - val_accuracy: 0.2324 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7048 - accuracy: 0.1875 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.6362 - accuracy: 0.3021 - precision: 0.6316 - recall: 0.125 - ETA: 0s - loss: 1.6831 - accuracy: 0.3125 - precision: 0.6400 - recall: 0.100 - ETA: 0s - loss: 1.6586 - accuracy: 0.3125 - precision: 0.6250 - recall: 0.089 - ETA: 0s - loss: 1.6860 - accuracy: 0.2986 - precision: 0.5778 - recall: 0.090 - ETA: 0s - loss: 1.7344 - accuracy: 0.2642 - precision: 0.5385 - recall: 0.079 - ETA: 0s - loss: 1.7526 - accuracy: 0.2596 - precision: 0.4839 - recall: 0.072 - 1s 1ms/sample - loss: 1.7475 - accuracy: 0.2606 - precision: 0.4923 - recall: 0.0751 - val_loss: 1.7032 - val_accuracy: 0.2606 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6395 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.7054 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.083 - ETA: 0s - loss: 1.7558 - accuracy: 0.2313 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.7645 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.052 - ETA: 0s - loss: 1.7493 - accuracy: 0.2578 - precision: 0.5000 - recall: 0.039 - ETA: 0s - loss: 1.7511 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.034 - ETA: 0s - loss: 1.7698 - accuracy: 0.2472 - precision: 0.5000 - recall: 0.028 - ETA: 0s - loss: 1.7677 - accuracy: 0.2448 - precision: 0.5000 - recall: 0.026 - 1s 2ms/sample - loss: 1.7774 - accuracy: 0.2465 - precision: 0.5000 - recall: 0.0235 - val_loss: 1.7281 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8109 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7378 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7971 - accuracy: 0.2375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8284 - accuracy: 0.2455 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8255 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8265 - accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8234 - accuracy: 0.2356 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8222 - accuracy: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7901 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6521 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6821 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7319 - accuracy: 0.2625 - precision: 0.5000 - recall: 0.0312        - ETA: 0s - loss: 1.7319 - accuracy: 0.2768 - precision: 0.5600 - recall: 0.062 - ETA: 0s - loss: 1.7477 - accuracy: 0.2500 - precision: 0.4857 - recall: 0.059 - ETA: 0s - loss: 1.8001 - accuracy: 0.2216 - precision: 0.4390 - recall: 0.051 - ETA: 0s - loss: 1.7993 - accuracy: 0.2091 - precision: 0.4390 - recall: 0.043 - 1s 1ms/sample - loss: 1.8095 - accuracy: 0.2066 - precision: 0.4390 - recall: 0.0423 - val_loss: 1.7050 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8024 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7646 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7883 - accuracy: 0.2875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7628 - accuracy: 0.2768 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7700 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7731 - accuracy: 0.2642 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7495 - accuracy: 0.2644 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7542 - accuracy: 0.2629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7206 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7973 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7747 - accuracy: 0.2396 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.7566 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.025 - ETA: 0s - loss: 1.7466 - accuracy: 0.2902 - precision: 0.6364 - recall: 0.031 - ETA: 0s - loss: 1.7516 - accuracy: 0.2778 - precision: 0.6250 - recall: 0.034 - ETA: 0s - loss: 1.7414 - accuracy: 0.2784 - precision: 0.6250 - recall: 0.042 - ETA: 0s - loss: 1.7377 - accuracy: 0.2740 - precision: 0.5455 - recall: 0.043 - 1s 1ms/sample - loss: 1.7360 - accuracy: 0.2770 - precision: 0.5455 - recall: 0.0423 - val_loss: 1.7097 - val_accuracy: 0.2535 - val_precision: 0.5000 - val_recall: 0.0704\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8255 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.8232 - accuracy: 0.2917 - precision: 0.5000 - recall: 0.072 - ETA: 0s - loss: 1.7354 - accuracy: 0.3375 - precision: 0.5556 - recall: 0.062 - ETA: 0s - loss: 1.7218 - accuracy: 0.3214 - precision: 0.5926 - recall: 0.071 - ETA: 0s - loss: 1.7177 - accuracy: 0.3090 - precision: 0.6176 - recall: 0.072 - ETA: 0s - loss: 1.7165 - accuracy: 0.2926 - precision: 0.6098 - recall: 0.071 - ETA: 0s - loss: 1.7296 - accuracy: 0.2764 - precision: 0.5870 - recall: 0.064 - 1s 1ms/sample - loss: 1.7331 - accuracy: 0.2746 - precision: 0.5870 - recall: 0.0634 - val_loss: 1.6918 - val_accuracy: 0.2535 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6251 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6526 - accuracy: 0.3333 - precision: 0.5455 - recall: 0.0625        - ETA: 0s - loss: 1.6792 - accuracy: 0.3063 - precision: 0.5882 - recall: 0.062 - ETA: 0s - loss: 1.6895 - accuracy: 0.2991 - precision: 0.5833 - recall: 0.062 - ETA: 0s - loss: 1.7301 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.062 - ETA: 0s - loss: 1.7213 - accuracy: 0.2784 - precision: 0.5676 - recall: 0.059 - ETA: 0s - loss: 1.7323 - accuracy: 0.2788 - precision: 0.5455 - recall: 0.057 - 1s 1ms/sample - loss: 1.7255 - accuracy: 0.2817 - precision: 0.5532 - recall: 0.0610 - val_loss: 1.7173 - val_accuracy: 0.2606 - val_precision: 0.5600 - val_recall: 0.0986\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8012 - accuracy: 0.1562 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.8259 - accuracy: 0.2083 - precision: 0.2857 - recall: 0.041 - ETA: 0s - loss: 1.7361 - accuracy: 0.2812 - precision: 0.4815 - recall: 0.081 - ETA: 0s - loss: 1.7241 - accuracy: 0.2902 - precision: 0.5312 - recall: 0.075 - ETA: 0s - loss: 1.7074 - accuracy: 0.2882 - precision: 0.5500 - recall: 0.076 - ETA: 0s - loss: 1.7104 - accuracy: 0.2898 - precision: 0.5476 - recall: 0.065 - ETA: 0s - loss: 1.7281 - accuracy: 0.2812 - precision: 0.5833 - recall: 0.067 - 1s 1ms/sample - loss: 1.7291 - accuracy: 0.2793 - precision: 0.5800 - recall: 0.0681 - val_loss: 1.6823 - val_accuracy: 0.2606 - val_precision: 0.5556 - val_recall: 0.0704\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6013 - accuracy: 0.3438 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6714 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.104 - ETA: 0s - loss: 1.6948 - accuracy: 0.2812 - precision: 0.6471 - recall: 0.068 - ETA: 0s - loss: 1.7090 - accuracy: 0.2857 - precision: 0.6316 - recall: 0.053 - ETA: 0s - loss: 1.7259 - accuracy: 0.2639 - precision: 0.5909 - recall: 0.045 - ETA: 0s - loss: 1.7044 - accuracy: 0.2727 - precision: 0.6667 - recall: 0.051 - ETA: 0s - loss: 1.7150 - accuracy: 0.2716 - precision: 0.6250 - recall: 0.048 - 1s 1ms/sample - loss: 1.7158 - accuracy: 0.2746 - precision: 0.5882 - recall: 0.0469 - val_loss: 1.7050 - val_accuracy: 0.2606 - val_precision: 0.5652 - val_recall: 0.0915\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7693 - accuracy: 0.1875 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7905 - accuracy: 0.2292 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.7833 - accuracy: 0.2313 - precision: 0.5217 - recall: 0.075 - ETA: 0s - loss: 1.7416 - accuracy: 0.2277 - precision: 0.5357 - recall: 0.067 - ETA: 0s - loss: 1.7282 - accuracy: 0.2535 - precision: 0.5312 - recall: 0.059 - ETA: 0s - loss: 1.7388 - accuracy: 0.2557 - precision: 0.5405 - recall: 0.056 - ETA: 0s - loss: 1.7492 - accuracy: 0.2404 - precision: 0.5405 - recall: 0.048 - 1s 1ms/sample - loss: 1.7438 - accuracy: 0.2418 - precision: 0.5526 - recall: 0.0493 - val_loss: 1.7086 - val_accuracy: 0.2254 - val_precision: 0.8333 - val_recall: 0.0352\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6225 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7304 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.041 - ETA: 0s - loss: 1.7028 - accuracy: 0.2875 - precision: 0.5000 - recall: 0.037 - ETA: 0s - loss: 1.7072 - accuracy: 0.2812 - precision: 0.5556 - recall: 0.044 - ETA: 0s - loss: 1.7131 - accuracy: 0.2674 - precision: 0.5417 - recall: 0.045 - ETA: 0s - loss: 1.7075 - accuracy: 0.2699 - precision: 0.6176 - recall: 0.059 - ETA: 0s - loss: 1.7244 - accuracy: 0.2740 - precision: 0.6585 - recall: 0.064 - 1s 1ms/sample - loss: 1.7221 - accuracy: 0.2770 - precision: 0.6279 - recall: 0.0634 - val_loss: 1.6737 - val_accuracy: 0.2394 - val_precision: 0.7857 - val_recall: 0.0775\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7527 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.7144 - accuracy: 0.2812 - precision: 0.7778 - recall: 0.072 - ETA: 0s - loss: 1.7462 - accuracy: 0.2562 - precision: 0.6154 - recall: 0.050 - ETA: 0s - loss: 1.7169 - accuracy: 0.2455 - precision: 0.6316 - recall: 0.053 - ETA: 0s - loss: 1.7340 - accuracy: 0.2257 - precision: 0.6400 - recall: 0.055 - ETA: 0s - loss: 1.6941 - accuracy: 0.2500 - precision: 0.6389 - recall: 0.065 - ETA: 0s - loss: 1.7217 - accuracy: 0.2452 - precision: 0.6000 - recall: 0.064 - 1s 1ms/sample - loss: 1.7273 - accuracy: 0.2394 - precision: 0.5745 - recall: 0.0634 - val_loss: 1.6925 - val_accuracy: 0.2324 - val_precision: 0.8000 - val_recall: 0.0563\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8421 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7694 - accuracy: 0.2708 - precision: 0.7500 - recall: 0.062 - ETA: 0s - loss: 1.7392 - accuracy: 0.2562 - precision: 0.6667 - recall: 0.050 - ETA: 0s - loss: 1.7024 - accuracy: 0.2500 - precision: 0.7333 - recall: 0.049 - ETA: 0s - loss: 1.7061 - accuracy: 0.2535 - precision: 0.7500 - recall: 0.052 - ETA: 0s - loss: 1.7068 - accuracy: 0.2585 - precision: 0.6429 - recall: 0.051 - ETA: 0s - loss: 1.7185 - accuracy: 0.2692 - precision: 0.6176 - recall: 0.050 - 1s 1ms/sample - loss: 1.7203 - accuracy: 0.2653 - precision: 0.5676 - recall: 0.0493 - val_loss: 1.6763 - val_accuracy: 0.2817 - val_precision: 0.8000 - val_recall: 0.0845\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6592 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.6555 - accuracy: 0.3229 - precision: 0.4444 - recall: 0.041 - ETA: 0s - loss: 1.6813 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.043 - ETA: 0s - loss: 1.7207 - accuracy: 0.2857 - precision: 0.5789 - recall: 0.049 - ETA: 0s - loss: 1.6913 - accuracy: 0.3021 - precision: 0.6190 - recall: 0.045 - ETA: 0s - loss: 1.6865 - accuracy: 0.3125 - precision: 0.6522 - recall: 0.042 - ETA: 0s - loss: 1.6929 - accuracy: 0.2957 - precision: 0.7037 - recall: 0.045 - 1s 1ms/sample - loss: 1.7025 - accuracy: 0.2911 - precision: 0.7037 - recall: 0.0446 - val_loss: 1.6681 - val_accuracy: 0.2746 - val_precision: 0.7500 - val_recall: 0.0634\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6211 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.6775 - accuracy: 0.2917 - precision: 0.7143 - recall: 0.052 - ETA: 0s - loss: 1.7344 - accuracy: 0.2500 - precision: 0.5455 - recall: 0.037 - ETA: 0s - loss: 1.6942 - accuracy: 0.2768 - precision: 0.6000 - recall: 0.053 - ETA: 0s - loss: 1.6895 - accuracy: 0.2917 - precision: 0.6250 - recall: 0.052 - ETA: 0s - loss: 1.6921 - accuracy: 0.2841 - precision: 0.5758 - recall: 0.054 - ETA: 0s - loss: 1.7187 - accuracy: 0.2764 - precision: 0.5641 - recall: 0.052 - 1s 1ms/sample - loss: 1.7180 - accuracy: 0.2746 - precision: 0.5750 - recall: 0.0540 - val_loss: 1.6844 - val_accuracy: 0.2394 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7715 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.8411 - accuracy: 0.2396 - precision: 0.3750 - recall: 0.031 - ETA: 0s - loss: 1.8676 - accuracy: 0.2500 - precision: 0.5294 - recall: 0.056 - ETA: 0s - loss: 1.7794 - accuracy: 0.2634 - precision: 0.5556 - recall: 0.067 - ETA: 0s - loss: 1.7670 - accuracy: 0.2500 - precision: 0.5405 - recall: 0.069 - ETA: 0s - loss: 1.7685 - accuracy: 0.2528 - precision: 0.5778 - recall: 0.073 - ETA: 0s - loss: 1.7521 - accuracy: 0.2692 - precision: 0.5577 - recall: 0.069 - 1s 1ms/sample - loss: 1.7438 - accuracy: 0.2723 - precision: 0.5660 - recall: 0.0704 - val_loss: 1.7279 - val_accuracy: 0.2535 - val_precision: 0.7000 - val_recall: 0.0493\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5925 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6967 - accuracy: 0.2604 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.7263 - accuracy: 0.2375 - precision: 0.5833 - recall: 0.043 - ETA: 0s - loss: 1.7147 - accuracy: 0.2455 - precision: 0.5789 - recall: 0.049 - ETA: 0s - loss: 1.7232 - accuracy: 0.2396 - precision: 0.6000 - recall: 0.052 - ETA: 0s - loss: 1.6829 - accuracy: 0.2670 - precision: 0.6842 - recall: 0.073 - ETA: 0s - loss: 1.7274 - accuracy: 0.2596 - precision: 0.6512 - recall: 0.067 - 1s 1ms/sample - loss: 1.7226 - accuracy: 0.2629 - precision: 0.6304 - recall: 0.0681 - val_loss: 1.6987 - val_accuracy: 0.2887 - val_precision: 0.5652 - val_recall: 0.0915\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6771 - accuracy: 0.3750 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.7473 - accuracy: 0.3229 - precision: 0.6923 - recall: 0.093 - ETA: 0s - loss: 1.7048 - accuracy: 0.3125 - precision: 0.7083 - recall: 0.106 - ETA: 0s - loss: 1.7044 - accuracy: 0.3036 - precision: 0.6970 - recall: 0.102 - ETA: 0s - loss: 1.7075 - accuracy: 0.2847 - precision: 0.6667 - recall: 0.097 - ETA: 0s - loss: 1.7151 - accuracy: 0.2812 - precision: 0.6327 - recall: 0.088 - ETA: 0s - loss: 1.7109 - accuracy: 0.2788 - precision: 0.5965 - recall: 0.081 - 1s 1ms/sample - loss: 1.7080 - accuracy: 0.2793 - precision: 0.5763 - recall: 0.0798 - val_loss: 1.6952 - val_accuracy: 0.2817 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5577 - accuracy: 0.4375 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.6499 - accuracy: 0.3229 - precision: 0.5625 - recall: 0.093 - ETA: 0s - loss: 1.6560 - accuracy: 0.3187 - precision: 0.5926 - recall: 0.100 - ETA: 0s - loss: 1.7258 - accuracy: 0.2946 - precision: 0.6250 - recall: 0.089 - ETA: 0s - loss: 1.7208 - accuracy: 0.2951 - precision: 0.6216 - recall: 0.079 - ETA: 0s - loss: 1.7268 - accuracy: 0.2812 - precision: 0.6222 - recall: 0.079 - ETA: 0s - loss: 1.7117 - accuracy: 0.2740 - precision: 0.6122 - recall: 0.072 - 1s 1ms/sample - loss: 1.7154 - accuracy: 0.2770 - precision: 0.6122 - recall: 0.0704 - val_loss: 1.6953 - val_accuracy: 0.2394 - val_precision: 0.6923 - val_recall: 0.0634\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8220 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6932 - accuracy: 0.3229 - precision: 0.7500 - recall: 0.0625        - ETA: 0s - loss: 1.7264 - accuracy: 0.2937 - precision: 0.6667 - recall: 0.050 - ETA: 0s - loss: 1.7357 - accuracy: 0.2768 - precision: 0.7500 - recall: 0.053 - ETA: 0s - loss: 1.7127 - accuracy: 0.2847 - precision: 0.6800 - recall: 0.059 - ETA: 0s - loss: 1.7176 - accuracy: 0.2841 - precision: 0.6333 - recall: 0.054 - ETA: 0s - loss: 1.7035 - accuracy: 0.2812 - precision: 0.6136 - recall: 0.064 - 1s 1ms/sample - loss: 1.7070 - accuracy: 0.2817 - precision: 0.6000 - recall: 0.0634 - val_loss: 1.6714 - val_accuracy: 0.2887 - val_precision: 0.5652 - val_recall: 0.0915\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8187 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.7877 - accuracy: 0.2917 - precision: 0.5385 - recall: 0.072 - ETA: 0s - loss: 1.7542 - accuracy: 0.3125 - precision: 0.6087 - recall: 0.087 - ETA: 0s - loss: 1.7350 - accuracy: 0.3036 - precision: 0.5938 - recall: 0.084 - ETA: 0s - loss: 1.7246 - accuracy: 0.2882 - precision: 0.5641 - recall: 0.076 - ETA: 0s - loss: 1.7256 - accuracy: 0.2869 - precision: 0.5745 - recall: 0.076 - ETA: 0s - loss: 1.7271 - accuracy: 0.2812 - precision: 0.5965 - recall: 0.081 - 1s 2ms/sample - loss: 1.7234 - accuracy: 0.2840 - precision: 0.6000 - recall: 0.0845 - val_loss: 1.7013 - val_accuracy: 0.2606 - val_precision: 0.6000 - val_recall: 0.0634\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 0.3125 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.6720 - accuracy: 0.3438 - precision: 0.7857 - recall: 0.114 - ETA: 0s - loss: 1.6650 - accuracy: 0.3359 - precision: 0.8125 - recall: 0.101 - ETA: 0s - loss: 1.6714 - accuracy: 0.3229 - precision: 0.6923 - recall: 0.093 - ETA: 0s - loss: 1.6880 - accuracy: 0.3281 - precision: 0.7059 - recall: 0.093 - ETA: 0s - loss: 1.6933 - accuracy: 0.3250 - precision: 0.6923 - recall: 0.112 - ETA: 0s - loss: 1.7345 - accuracy: 0.3099 - precision: 0.6143 - recall: 0.112 - 1s 2ms/sample - loss: 1.7485 - accuracy: 0.2958 - precision: 0.5897 - recall: 0.1080 - val_loss: 1.8123 - val_accuracy: 0.2606 - val_precision: 0.5385 - val_recall: 0.0986\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8348 - accuracy: 0.2500 - precision: 0.1667 - recall: 0.031 - ETA: 0s - loss: 1.8962 - accuracy: 0.2396 - precision: 0.3333 - recall: 0.052 - ETA: 0s - loss: 1.8311 - accuracy: 0.2375 - precision: 0.4348 - recall: 0.062 - ETA: 0s - loss: 1.8154 - accuracy: 0.2366 - precision: 0.4400 - recall: 0.049 - ETA: 0s - loss: 1.7836 - accuracy: 0.2604 - precision: 0.4643 - recall: 0.045 - ETA: 0s - loss: 1.7690 - accuracy: 0.2719 - precision: 0.4483 - recall: 0.040 - ETA: 0s - loss: 1.7636 - accuracy: 0.2708 - precision: 0.4324 - recall: 0.041 - 1s 2ms/sample - loss: 1.7754 - accuracy: 0.2676 - precision: 0.4524 - recall: 0.0446 - val_loss: 1.6850 - val_accuracy: 0.3169 - val_precision: 0.5385 - val_recall: 0.0986\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7150 - accuracy: 0.2188 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.7427 - accuracy: 0.2604 - precision: 0.5500 - recall: 0.114 - ETA: 0s - loss: 1.7152 - accuracy: 0.2250 - precision: 0.5000 - recall: 0.106 - ETA: 0s - loss: 1.7179 - accuracy: 0.2545 - precision: 0.5417 - recall: 0.116 - ETA: 0s - loss: 1.7089 - accuracy: 0.2569 - precision: 0.5231 - recall: 0.118 - ETA: 0s - loss: 1.7410 - accuracy: 0.2500 - precision: 0.4933 - recall: 0.105 - ETA: 0s - loss: 1.7323 - accuracy: 0.2620 - precision: 0.5114 - recall: 0.108 - 1s 2ms/sample - loss: 1.7327 - accuracy: 0.2653 - precision: 0.5056 - recall: 0.1056 - val_loss: 1.7024 - val_accuracy: 0.2606 - val_precision: 0.5000 - val_recall: 0.0634\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7648 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.6467 - accuracy: 0.3594 - precision: 0.3333 - recall: 0.015 - ETA: 0s - loss: 1.6959 - accuracy: 0.3125 - precision: 0.3333 - recall: 0.007 - ETA: 0s - loss: 1.6738 - accuracy: 0.3073 - precision: 0.4000 - recall: 0.010 - ETA: 0s - loss: 1.6641 - accuracy: 0.3203 - precision: 0.3333 - recall: 0.007 - ETA: 0s - loss: 1.6743 - accuracy: 0.3281 - precision: 0.5294 - recall: 0.028 - ETA: 0s - loss: 1.6943 - accuracy: 0.3151 - precision: 0.4800 - recall: 0.031 - 1s 2ms/sample - loss: 1.6914 - accuracy: 0.3239 - precision: 0.5152 - recall: 0.0399 - val_loss: 1.6874 - val_accuracy: 0.2535 - val_precision: 0.5600 - val_recall: 0.0986\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6740 - accuracy: 0.3125 - precision: 0.2500 - recall: 0.031 - ETA: 0s - loss: 1.6842 - accuracy: 0.2917 - precision: 0.4286 - recall: 0.062 - ETA: 0s - loss: 1.7200 - accuracy: 0.2875 - precision: 0.4483 - recall: 0.081 - ETA: 0s - loss: 1.7093 - accuracy: 0.3073 - precision: 0.4615 - recall: 0.093 - ETA: 0s - loss: 1.6761 - accuracy: 0.3203 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.6714 - accuracy: 0.3250 - precision: 0.5690 - recall: 0.103 - ETA: 0s - loss: 1.6735 - accuracy: 0.3229 - precision: 0.5588 - recall: 0.099 - ETA: 0s - loss: 1.6819 - accuracy: 0.3197 - precision: 0.5600 - recall: 0.101 - 1s 1ms/sample - loss: 1.6871 - accuracy: 0.3169 - precision: 0.5526 - recall: 0.0986 - val_loss: 1.6894 - val_accuracy: 0.2676 - val_precision: 0.5517 - val_recall: 0.1127\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7711 - accuracy: 0.2188 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6797 - accuracy: 0.2604 - precision: 0.5789 - recall: 0.114 - ETA: 0s - loss: 1.6832 - accuracy: 0.2625 - precision: 0.5556 - recall: 0.125 - ETA: 0s - loss: 1.6947 - accuracy: 0.2679 - precision: 0.6000 - recall: 0.120 - ETA: 0s - loss: 1.6756 - accuracy: 0.2882 - precision: 0.6250 - recall: 0.121 - ETA: 0s - loss: 1.6766 - accuracy: 0.2926 - precision: 0.6056 - recall: 0.122 - ETA: 0s - loss: 1.6799 - accuracy: 0.3053 - precision: 0.5875 - recall: 0.113 - 1s 1ms/sample - loss: 1.6855 - accuracy: 0.3005 - precision: 0.5854 - recall: 0.1127 - val_loss: 1.6765 - val_accuracy: 0.2676 - val_precision: 0.6667 - val_recall: 0.0986\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4270 - accuracy: 0.4375 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.5864 - accuracy: 0.3646 - precision: 0.8421 - recall: 0.166 - ETA: 0s - loss: 1.6915 - accuracy: 0.3125 - precision: 0.7097 - recall: 0.137 - ETA: 0s - loss: 1.6682 - accuracy: 0.3214 - precision: 0.7021 - recall: 0.147 - ETA: 0s - loss: 1.6570 - accuracy: 0.3194 - precision: 0.6667 - recall: 0.131 - ETA: 0s - loss: 1.6767 - accuracy: 0.3011 - precision: 0.6232 - recall: 0.122 - ETA: 0s - loss: 1.6669 - accuracy: 0.3101 - precision: 0.6190 - recall: 0.125 - 1s 1ms/sample - loss: 1.6683 - accuracy: 0.3122 - precision: 0.6118 - recall: 0.1221 - val_loss: 1.6937 - val_accuracy: 0.2324 - val_precision: 0.4667 - val_recall: 0.0986\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8056 - accuracy: 0.3125 - precision: 0.2000 - recall: 0.031 - ETA: 0s - loss: 1.7139 - accuracy: 0.3333 - precision: 0.4667 - recall: 0.072 - ETA: 0s - loss: 1.7002 - accuracy: 0.3187 - precision: 0.4000 - recall: 0.075 - ETA: 0s - loss: 1.7033 - accuracy: 0.3036 - precision: 0.4167 - recall: 0.067 - ETA: 0s - loss: 1.6986 - accuracy: 0.2986 - precision: 0.4359 - recall: 0.059 - ETA: 0s - loss: 1.7002 - accuracy: 0.3153 - precision: 0.4651 - recall: 0.056 - ETA: 0s - loss: 1.7011 - accuracy: 0.3101 - precision: 0.4600 - recall: 0.055 - 1s 2ms/sample - loss: 1.7014 - accuracy: 0.3075 - precision: 0.4706 - recall: 0.0563 - val_loss: 1.6473 - val_accuracy: 0.2958 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.6559 - accuracy: 0.3542 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.6636 - accuracy: 0.3250 - precision: 0.5625 - recall: 0.112 - ETA: 0s - loss: 1.6558 - accuracy: 0.3259 - precision: 0.6279 - recall: 0.120 - ETA: 0s - loss: 1.6469 - accuracy: 0.3264 - precision: 0.6667 - recall: 0.131 - ETA: 0s - loss: 1.6270 - accuracy: 0.3409 - precision: 0.6528 - recall: 0.133 - ETA: 0s - loss: 1.6517 - accuracy: 0.3341 - precision: 0.6207 - recall: 0.129 - 1s 1ms/sample - loss: 1.6604 - accuracy: 0.3310 - precision: 0.6180 - recall: 0.1291 - val_loss: 1.6846 - val_accuracy: 0.2676 - val_precision: 0.5484 - val_recall: 0.1197\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5426 - accuracy: 0.3125 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.6013 - accuracy: 0.3854 - precision: 0.6500 - recall: 0.135 - ETA: 0s - loss: 1.5925 - accuracy: 0.3688 - precision: 0.6585 - recall: 0.168 - ETA: 0s - loss: 1.6135 - accuracy: 0.3661 - precision: 0.6909 - recall: 0.169 - ETA: 0s - loss: 1.6183 - accuracy: 0.3472 - precision: 0.6667 - recall: 0.173 - ETA: 0s - loss: 1.6175 - accuracy: 0.3523 - precision: 0.6526 - recall: 0.176 - ETA: 0s - loss: 1.6591 - accuracy: 0.3413 - precision: 0.6018 - recall: 0.163 - 1s 1ms/sample - loss: 1.6604 - accuracy: 0.3427 - precision: 0.6053 - recall: 0.1620 - val_loss: 1.6747 - val_accuracy: 0.2817 - val_precision: 0.5806 - val_recall: 0.1268\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6023 - accuracy: 0.3750 - precision: 0.4545 - recall: 0.156 - ETA: 0s - loss: 1.7631 - accuracy: 0.2812 - precision: 0.4118 - recall: 0.072 - ETA: 0s - loss: 1.8129 - accuracy: 0.2937 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.7651 - accuracy: 0.2902 - precision: 0.3947 - recall: 0.067 - ETA: 0s - loss: 1.7458 - accuracy: 0.2951 - precision: 0.4255 - recall: 0.069 - ETA: 0s - loss: 1.7412 - accuracy: 0.2955 - precision: 0.4561 - recall: 0.073 - ETA: 0s - loss: 1.7225 - accuracy: 0.2981 - precision: 0.5000 - recall: 0.079 - 1s 1ms/sample - loss: 1.7246 - accuracy: 0.2958 - precision: 0.4925 - recall: 0.0775 - val_loss: 1.6652 - val_accuracy: 0.2817 - val_precision: 0.5217 - val_recall: 0.0845\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6051 - accuracy: 0.3438 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.7340 - accuracy: 0.2500 - precision: 0.6429 - recall: 0.093 - ETA: 0s - loss: 1.6883 - accuracy: 0.2875 - precision: 0.6207 - recall: 0.112 - ETA: 0s - loss: 1.6954 - accuracy: 0.2768 - precision: 0.6486 - recall: 0.107 - ETA: 0s - loss: 1.6945 - accuracy: 0.2852 - precision: 0.6429 - recall: 0.105 - ETA: 0s - loss: 1.6782 - accuracy: 0.3000 - precision: 0.6364 - recall: 0.109 - ETA: 0s - loss: 1.6653 - accuracy: 0.3068 - precision: 0.6557 - recall: 0.113 - ETA: 0s - loss: 1.6714 - accuracy: 0.3053 - precision: 0.6562 - recall: 0.101 - 1s 2ms/sample - loss: 1.6716 - accuracy: 0.3075 - precision: 0.6562 - recall: 0.0986 - val_loss: 1.6565 - val_accuracy: 0.2958 - val_precision: 0.6250 - val_recall: 0.1056\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7678 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5755 - accuracy: 0.3646 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.6540 - accuracy: 0.3375 - precision: 0.6667 - recall: 0.112 - ETA: 0s - loss: 1.6258 - accuracy: 0.3259 - precision: 0.6275 - recall: 0.142 - ETA: 0s - loss: 1.6116 - accuracy: 0.3477 - precision: 0.6094 - recall: 0.152 - ETA: 0s - loss: 1.6194 - accuracy: 0.3469 - precision: 0.5632 - recall: 0.153 - ETA: 0s - loss: 1.6453 - accuracy: 0.3295 - precision: 0.5591 - recall: 0.147 - ETA: 0s - loss: 1.6419 - accuracy: 0.3365 - precision: 0.5575 - recall: 0.151 - 1s 2ms/sample - loss: 1.6497 - accuracy: 0.3310 - precision: 0.5565 - recall: 0.1502 - val_loss: 1.6711 - val_accuracy: 0.2817 - val_precision: 0.5556 - val_recall: 0.1761\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6752 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.7123 - accuracy: 0.3021 - precision: 0.4643 - recall: 0.135 - ETA: 0s - loss: 1.7023 - accuracy: 0.3063 - precision: 0.5000 - recall: 0.137 - ETA: 0s - loss: 1.6587 - accuracy: 0.3214 - precision: 0.5072 - recall: 0.156 - ETA: 0s - loss: 1.6654 - accuracy: 0.3160 - precision: 0.5488 - recall: 0.156 - ETA: 0s - loss: 1.6520 - accuracy: 0.3295 - precision: 0.5769 - recall: 0.170 - ETA: 0s - loss: 1.6618 - accuracy: 0.3293 - precision: 0.5847 - recall: 0.165 - 1s 1ms/sample - loss: 1.6584 - accuracy: 0.3333 - precision: 0.5820 - recall: 0.1667 - val_loss: 1.6881 - val_accuracy: 0.2606 - val_precision: 0.5000 - val_recall: 0.1408\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 0.4688 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.6402 - accuracy: 0.3646 - precision: 0.5161 - recall: 0.166 - ETA: 0s - loss: 1.6449 - accuracy: 0.3438 - precision: 0.5510 - recall: 0.168 - ETA: 0s - loss: 1.6550 - accuracy: 0.3170 - precision: 0.5417 - recall: 0.174 - ETA: 0s - loss: 1.6601 - accuracy: 0.3090 - precision: 0.5258 - recall: 0.177 - ETA: 0s - loss: 1.6598 - accuracy: 0.3153 - precision: 0.5470 - recall: 0.181 - ETA: 0s - loss: 1.6654 - accuracy: 0.3125 - precision: 0.5692 - recall: 0.177 - 1s 1ms/sample - loss: 1.6680 - accuracy: 0.3169 - precision: 0.5682 - recall: 0.1761 - val_loss: 1.6844 - val_accuracy: 0.3028 - val_precision: 0.6111 - val_recall: 0.1549\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.5709 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.208 - ETA: 0s - loss: 1.5349 - accuracy: 0.3984 - precision: 0.6444 - recall: 0.226 - ETA: 0s - loss: 1.6391 - accuracy: 0.3385 - precision: 0.5833 - recall: 0.182 - ETA: 0s - loss: 1.6777 - accuracy: 0.3477 - precision: 0.5714 - recall: 0.171 - ETA: 0s - loss: 1.6590 - accuracy: 0.3542 - precision: 0.6000 - recall: 0.177 - ETA: 0s - loss: 1.6410 - accuracy: 0.3693 - precision: 0.6038 - recall: 0.181 - ETA: 0s - loss: 1.6516 - accuracy: 0.3678 - precision: 0.5891 - recall: 0.182 - 1s 2ms/sample - loss: 1.6595 - accuracy: 0.3615 - precision: 0.5802 - recall: 0.1784 - val_loss: 1.6566 - val_accuracy: 0.3099 - val_precision: 0.5870 - val_recall: 0.1901\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4442 - accuracy: 0.3750 - precision: 0.7143 - recall: 0.312 - ETA: 0s - loss: 1.5741 - accuracy: 0.3854 - precision: 0.6486 - recall: 0.250 - ETA: 0s - loss: 1.6150 - accuracy: 0.3500 - precision: 0.6078 - recall: 0.193 - ETA: 0s - loss: 1.6470 - accuracy: 0.3438 - precision: 0.5821 - recall: 0.174 - ETA: 0s - loss: 1.6505 - accuracy: 0.3507 - precision: 0.6000 - recall: 0.177 - ETA: 0s - loss: 1.6179 - accuracy: 0.3580 - precision: 0.6355 - recall: 0.193 - ETA: 0s - loss: 1.6345 - accuracy: 0.3558 - precision: 0.6160 - recall: 0.185 - 1s 1ms/sample - loss: 1.6244 - accuracy: 0.3615 - precision: 0.6308 - recall: 0.1925 - val_loss: 1.6659 - val_accuracy: 0.2887 - val_precision: 0.5250 - val_recall: 0.1479\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7710 - accuracy: 0.2500 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.5948 - accuracy: 0.3229 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.5901 - accuracy: 0.3500 - precision: 0.7143 - recall: 0.218 - ETA: 0s - loss: 1.6062 - accuracy: 0.3571 - precision: 0.6479 - recall: 0.205 - ETA: 0s - loss: 1.6018 - accuracy: 0.3403 - precision: 0.6444 - recall: 0.201 - ETA: 0s - loss: 1.6146 - accuracy: 0.3352 - precision: 0.6481 - recall: 0.198 - ETA: 0s - loss: 1.6208 - accuracy: 0.3307 - precision: 0.6387 - recall: 0.197 - 1s 1ms/sample - loss: 1.6342 - accuracy: 0.3263 - precision: 0.6107 - recall: 0.1878 - val_loss: 1.6537 - val_accuracy: 0.2746 - val_precision: 0.5778 - val_recall: 0.1831\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4771 - accuracy: 0.4062 - precision: 0.6923 - recall: 0.281 - ETA: 0s - loss: 1.5318 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.270 - ETA: 0s - loss: 1.6086 - accuracy: 0.3562 - precision: 0.6250 - recall: 0.218 - ETA: 0s - loss: 1.6177 - accuracy: 0.3750 - precision: 0.6250 - recall: 0.200 - ETA: 0s - loss: 1.6092 - accuracy: 0.3785 - precision: 0.6392 - recall: 0.215 - ETA: 0s - loss: 1.6216 - accuracy: 0.3523 - precision: 0.6071 - recall: 0.193 - ETA: 0s - loss: 1.6395 - accuracy: 0.3486 - precision: 0.5772 - recall: 0.170 - 1s 1ms/sample - loss: 1.6409 - accuracy: 0.3498 - precision: 0.5726 - recall: 0.1667 - val_loss: 1.7388 - val_accuracy: 0.3169 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7811 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7696 - accuracy: 0.2812 - precision: 0.6471 - recall: 0.114 - ETA: 0s - loss: 1.7689 - accuracy: 0.2625 - precision: 0.6154 - recall: 0.100 - ETA: 0s - loss: 1.7555 - accuracy: 0.2723 - precision: 0.5882 - recall: 0.089 - ETA: 0s - loss: 1.7323 - accuracy: 0.2847 - precision: 0.6136 - recall: 0.093 - ETA: 0s - loss: 1.7362 - accuracy: 0.2955 - precision: 0.5918 - recall: 0.082 - ETA: 0s - loss: 1.7431 - accuracy: 0.3005 - precision: 0.5818 - recall: 0.076 - 1s 1ms/sample - loss: 1.7401 - accuracy: 0.3005 - precision: 0.5690 - recall: 0.0775 - val_loss: 1.7190 - val_accuracy: 0.2746 - val_precision: 0.6250 - val_recall: 0.1056\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8852 - accuracy: 0.1875 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.7731 - accuracy: 0.2396 - precision: 0.4167 - recall: 0.052 - ETA: 0s - loss: 1.7760 - accuracy: 0.2688 - precision: 0.5200 - recall: 0.081 - ETA: 0s - loss: 1.7475 - accuracy: 0.2812 - precision: 0.5405 - recall: 0.089 - ETA: 0s - loss: 1.7432 - accuracy: 0.2917 - precision: 0.5714 - recall: 0.097 - ETA: 0s - loss: 1.7652 - accuracy: 0.2756 - precision: 0.5185 - recall: 0.079 - ETA: 0s - loss: 1.7497 - accuracy: 0.2764 - precision: 0.5079 - recall: 0.076 - 1s 1ms/sample - loss: 1.7506 - accuracy: 0.2770 - precision: 0.5079 - recall: 0.0751 - val_loss: 1.7352 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7698 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8030 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7157 - accuracy: 0.3063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6825 - accuracy: 0.3393 - precision: 0.6667 - recall: 0.0268        - ETA: 0s - loss: 1.7340 - accuracy: 0.3160 - precision: 0.5455 - recall: 0.041 - ETA: 0s - loss: 1.7271 - accuracy: 0.3097 - precision: 0.4474 - recall: 0.048 - ETA: 0s - loss: 1.7438 - accuracy: 0.2861 - precision: 0.4444 - recall: 0.048 - 1s 1ms/sample - loss: 1.7457 - accuracy: 0.2840 - precision: 0.4444 - recall: 0.0469 - val_loss: 1.6650 - val_accuracy: 0.2746 - val_precision: 0.5500 - val_recall: 0.0775\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6035 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5967 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.6158 - accuracy: 0.3375 - precision: 0.6667 - recall: 0.012 - ETA: 0s - loss: 1.6796 - accuracy: 0.3036 - precision: 0.6667 - recall: 0.008 - ETA: 0s - loss: 1.7054 - accuracy: 0.2917 - precision: 0.6667 - recall: 0.006 - ETA: 0s - loss: 1.6974 - accuracy: 0.2869 - precision: 0.8000 - recall: 0.011 - ETA: 0s - loss: 1.7013 - accuracy: 0.2764 - precision: 0.8000 - recall: 0.019 - 1s 1ms/sample - loss: 1.6986 - accuracy: 0.2817 - precision: 0.8000 - recall: 0.0188 - val_loss: 1.6940 - val_accuracy: 0.2958 - val_precision: 0.6087 - val_recall: 0.0986\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4911 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.6737 - accuracy: 0.2917 - precision: 0.5789 - recall: 0.114 - ETA: 0s - loss: 1.7073 - accuracy: 0.3000 - precision: 0.6129 - recall: 0.118 - ETA: 0s - loss: 1.7190 - accuracy: 0.2812 - precision: 0.6136 - recall: 0.120 - ETA: 0s - loss: 1.7124 - accuracy: 0.3021 - precision: 0.6600 - recall: 0.114 - ETA: 0s - loss: 1.7274 - accuracy: 0.2898 - precision: 0.6610 - recall: 0.110 - ETA: 0s - loss: 1.7358 - accuracy: 0.2837 - precision: 0.6438 - recall: 0.113 - 1s 1ms/sample - loss: 1.7423 - accuracy: 0.2770 - precision: 0.6351 - recall: 0.1103 - val_loss: 1.7373 - val_accuracy: 0.2606 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7347 - accuracy: 0.3125 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.7266 - accuracy: 0.3125 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.7093 - accuracy: 0.3063 - precision: 0.6875 - recall: 0.137 - ETA: 0s - loss: 1.6733 - accuracy: 0.3438 - precision: 0.6889 - recall: 0.138 - ETA: 0s - loss: 1.6692 - accuracy: 0.3507 - precision: 0.6333 - recall: 0.131 - ETA: 0s - loss: 1.6786 - accuracy: 0.3267 - precision: 0.6027 - recall: 0.125 - ETA: 0s - loss: 1.6977 - accuracy: 0.3173 - precision: 0.6098 - recall: 0.120 - 1s 1ms/sample - loss: 1.7002 - accuracy: 0.3122 - precision: 0.6071 - recall: 0.1197 - val_loss: 1.6721 - val_accuracy: 0.2676 - val_precision: 0.5200 - val_recall: 0.0915\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6052 - accuracy: 0.3125 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.6654 - accuracy: 0.2604 - precision: 0.4706 - recall: 0.083 - ETA: 0s - loss: 1.6360 - accuracy: 0.2812 - precision: 0.4848 - recall: 0.100 - ETA: 0s - loss: 1.6717 - accuracy: 0.2946 - precision: 0.5000 - recall: 0.084 - ETA: 0s - loss: 1.7039 - accuracy: 0.2847 - precision: 0.5400 - recall: 0.093 - ETA: 0s - loss: 1.6962 - accuracy: 0.2841 - precision: 0.5789 - recall: 0.093 - ETA: 0s - loss: 1.7090 - accuracy: 0.2837 - precision: 0.5522 - recall: 0.088 - 1s 1ms/sample - loss: 1.7055 - accuracy: 0.2817 - precision: 0.5507 - recall: 0.0892 - val_loss: 1.7089 - val_accuracy: 0.2535 - val_precision: 0.6667 - val_recall: 0.0986\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9236 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7665 - accuracy: 0.3229 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.7044 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.7369 - accuracy: 0.2991 - precision: 0.5333 - recall: 0.107 - ETA: 0s - loss: 1.6783 - accuracy: 0.3194 - precision: 0.5909 - recall: 0.135 - ETA: 0s - loss: 1.6721 - accuracy: 0.3267 - precision: 0.5976 - recall: 0.139 - ETA: 0s - loss: 1.6786 - accuracy: 0.3245 - precision: 0.5922 - recall: 0.146 - 1s 1ms/sample - loss: 1.6786 - accuracy: 0.3239 - precision: 0.5888 - recall: 0.1479 - val_loss: 1.6854 - val_accuracy: 0.2746 - val_precision: 0.4848 - val_recall: 0.1127\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4809 - accuracy: 0.3750 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.5969 - accuracy: 0.3646 - precision: 0.6296 - recall: 0.177 - ETA: 0s - loss: 1.5912 - accuracy: 0.3500 - precision: 0.6170 - recall: 0.181 - ETA: 0s - loss: 1.6663 - accuracy: 0.3170 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.6609 - accuracy: 0.3229 - precision: 0.6125 - recall: 0.170 - ETA: 0s - loss: 1.6663 - accuracy: 0.3182 - precision: 0.6250 - recall: 0.170 - ETA: 0s - loss: 1.6785 - accuracy: 0.3149 - precision: 0.5678 - recall: 0.161 - 1s 1ms/sample - loss: 1.6761 - accuracy: 0.3146 - precision: 0.5620 - recall: 0.1596 - val_loss: 1.6638 - val_accuracy: 0.3028 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3854 - accuracy: 0.5312 - precision: 0.9000 - recall: 0.281 - ETA: 0s - loss: 1.5873 - accuracy: 0.3646 - precision: 0.6538 - recall: 0.177 - ETA: 0s - loss: 1.5826 - accuracy: 0.3750 - precision: 0.6410 - recall: 0.156 - ETA: 0s - loss: 1.5996 - accuracy: 0.3527 - precision: 0.6066 - recall: 0.165 - ETA: 0s - loss: 1.6524 - accuracy: 0.3229 - precision: 0.5694 - recall: 0.142 - ETA: 0s - loss: 1.6643 - accuracy: 0.3125 - precision: 0.5882 - recall: 0.142 - ETA: 0s - loss: 1.6637 - accuracy: 0.3149 - precision: 0.5882 - recall: 0.144 - 1s 1ms/sample - loss: 1.6617 - accuracy: 0.3146 - precision: 0.5922 - recall: 0.1432 - val_loss: 1.6668 - val_accuracy: 0.2887 - val_precision: 0.5862 - val_recall: 0.1197\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5684 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.156 - ETA: 0s - loss: 1.6152 - accuracy: 0.3333 - precision: 0.7308 - recall: 0.197 - ETA: 0s - loss: 1.6092 - accuracy: 0.3313 - precision: 0.6458 - recall: 0.193 - ETA: 0s - loss: 1.6295 - accuracy: 0.3125 - precision: 0.6232 - recall: 0.192 - ETA: 0s - loss: 1.6476 - accuracy: 0.3160 - precision: 0.6310 - recall: 0.184 - ETA: 0s - loss: 1.6361 - accuracy: 0.3153 - precision: 0.6436 - recall: 0.184 - ETA: 0s - loss: 1.6439 - accuracy: 0.3077 - precision: 0.6167 - recall: 0.177 - 1s 1ms/sample - loss: 1.6478 - accuracy: 0.3028 - precision: 0.6098 - recall: 0.1761 - val_loss: 1.6693 - val_accuracy: 0.2958 - val_precision: 0.5250 - val_recall: 0.1479\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.4062 - precision: 0.6471 - recall: 0.343 - ETA: 0s - loss: 1.6580 - accuracy: 0.3125 - precision: 0.5806 - recall: 0.187 - ETA: 0s - loss: 1.6731 - accuracy: 0.3375 - precision: 0.5641 - recall: 0.137 - ETA: 0s - loss: 1.6441 - accuracy: 0.3527 - precision: 0.5686 - recall: 0.129 - ETA: 0s - loss: 1.6727 - accuracy: 0.3403 - precision: 0.5522 - recall: 0.128 - ETA: 0s - loss: 1.6532 - accuracy: 0.3438 - precision: 0.5843 - recall: 0.147 - ETA: 0s - loss: 1.6910 - accuracy: 0.3221 - precision: 0.5686 - recall: 0.139 - 1s 1ms/sample - loss: 1.6932 - accuracy: 0.3192 - precision: 0.5577 - recall: 0.1362 - val_loss: 1.6739 - val_accuracy: 0.2887 - val_precision: 0.5714 - val_recall: 0.1690\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5090 - accuracy: 0.3750 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.6028 - accuracy: 0.3333 - precision: 0.6296 - recall: 0.177 - ETA: 0s - loss: 1.6223 - accuracy: 0.3500 - precision: 0.6667 - recall: 0.175 - ETA: 0s - loss: 1.6067 - accuracy: 0.3750 - precision: 0.6792 - recall: 0.160 - ETA: 0s - loss: 1.6513 - accuracy: 0.3368 - precision: 0.6552 - recall: 0.131 - ETA: 0s - loss: 1.6593 - accuracy: 0.3267 - precision: 0.6620 - recall: 0.133 - ETA: 0s - loss: 1.6819 - accuracy: 0.3173 - precision: 0.6310 - recall: 0.127 - 1s 1ms/sample - loss: 1.6783 - accuracy: 0.3192 - precision: 0.6279 - recall: 0.1268 - val_loss: 1.6768 - val_accuracy: 0.2817 - val_precision: 0.6154 - val_recall: 0.1127\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5275 - accuracy: 0.4062 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.6206 - accuracy: 0.3854 - precision: 0.5833 - recall: 0.145 - ETA: 0s - loss: 1.6609 - accuracy: 0.3438 - precision: 0.5938 - recall: 0.118 - ETA: 0s - loss: 1.6605 - accuracy: 0.3259 - precision: 0.5686 - recall: 0.129 - ETA: 0s - loss: 1.6386 - accuracy: 0.3299 - precision: 0.5909 - recall: 0.135 - ETA: 0s - loss: 1.6369 - accuracy: 0.3381 - precision: 0.5897 - recall: 0.130 - ETA: 0s - loss: 1.6325 - accuracy: 0.3438 - precision: 0.6067 - recall: 0.129 - 1s 1ms/sample - loss: 1.6380 - accuracy: 0.3404 - precision: 0.6067 - recall: 0.1268 - val_loss: 1.6948 - val_accuracy: 0.2746 - val_precision: 0.5676 - val_recall: 0.1479\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6400 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.6379 - accuracy: 0.3438 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.5733 - accuracy: 0.3828 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.5849 - accuracy: 0.3802 - precision: 0.7447 - recall: 0.182 - ETA: 0s - loss: 1.6025 - accuracy: 0.3828 - precision: 0.6885 - recall: 0.164 - ETA: 0s - loss: 1.6058 - accuracy: 0.3750 - precision: 0.6800 - recall: 0.159 - ETA: 0s - loss: 1.6154 - accuracy: 0.3594 - precision: 0.6813 - recall: 0.161 - 1s 1ms/sample - loss: 1.6102 - accuracy: 0.3615 - precision: 0.6636 - recall: 0.1714 - val_loss: 1.6979 - val_accuracy: 0.2676 - val_precision: 0.5610 - val_recall: 0.1620\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6843 - accuracy: 0.2188 - precision: 0.5000 - recall: 0.187 - ETA: 0s - loss: 1.6498 - accuracy: 0.2812 - precision: 0.6207 - recall: 0.187 - ETA: 0s - loss: 1.6551 - accuracy: 0.3250 - precision: 0.6190 - recall: 0.162 - ETA: 0s - loss: 1.6263 - accuracy: 0.3348 - precision: 0.6140 - recall: 0.156 - ETA: 0s - loss: 1.6290 - accuracy: 0.3299 - precision: 0.6316 - recall: 0.166 - ETA: 0s - loss: 1.6292 - accuracy: 0.3352 - precision: 0.6176 - recall: 0.179 - ETA: 0s - loss: 1.6253 - accuracy: 0.3341 - precision: 0.6142 - recall: 0.187 - 1s 1ms/sample - loss: 1.6288 - accuracy: 0.3310 - precision: 0.6107 - recall: 0.1878 - val_loss: 1.6966 - val_accuracy: 0.2887 - val_precision: 0.5778 - val_recall: 0.1831\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6740 - accuracy: 0.3438 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.5930 - accuracy: 0.3750 - precision: 0.6410 - recall: 0.260 - ETA: 0s - loss: 1.6196 - accuracy: 0.3125 - precision: 0.6182 - recall: 0.212 - ETA: 0s - loss: 1.6554 - accuracy: 0.3125 - precision: 0.5278 - recall: 0.169 - ETA: 0s - loss: 1.6549 - accuracy: 0.3229 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.6586 - accuracy: 0.3153 - precision: 0.5618 - recall: 0.142 - ETA: 0s - loss: 1.6195 - accuracy: 0.3413 - precision: 0.5941 - recall: 0.144 - 1s 1ms/sample - loss: 1.6206 - accuracy: 0.3451 - precision: 0.5941 - recall: 0.1408 - val_loss: 1.6774 - val_accuracy: 0.2746 - val_precision: 0.6316 - val_recall: 0.0845\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6515 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.5547 - accuracy: 0.4479 - precision: 0.8462 - recall: 0.114 - ETA: 0s - loss: 1.5961 - accuracy: 0.3938 - precision: 0.6667 - recall: 0.100 - ETA: 0s - loss: 1.6381 - accuracy: 0.3705 - precision: 0.6471 - recall: 0.098 - ETA: 0s - loss: 1.6466 - accuracy: 0.3611 - precision: 0.6596 - recall: 0.107 - ETA: 0s - loss: 1.6676 - accuracy: 0.3438 - precision: 0.6316 - recall: 0.102 - ETA: 0s - loss: 1.6284 - accuracy: 0.3606 - precision: 0.6986 - recall: 0.122 - 1s 2ms/sample - loss: 1.6284 - accuracy: 0.3615 - precision: 0.7067 - recall: 0.1244 - val_loss: 1.6441 - val_accuracy: 0.3451 - val_precision: 0.5349 - val_recall: 0.1620\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7693 - accuracy: 0.3125 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.6933 - accuracy: 0.3333 - precision: 0.5769 - recall: 0.156 - ETA: 0s - loss: 1.6359 - accuracy: 0.3438 - precision: 0.6429 - recall: 0.168 - ETA: 0s - loss: 1.6428 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.178 - ETA: 0s - loss: 1.6296 - accuracy: 0.3403 - precision: 0.6410 - recall: 0.173 - ETA: 0s - loss: 1.6005 - accuracy: 0.3494 - precision: 0.6979 - recall: 0.190 - ETA: 0s - loss: 1.6114 - accuracy: 0.3462 - precision: 0.6838 - recall: 0.192 - 1s 1ms/sample - loss: 1.5992 - accuracy: 0.3545 - precision: 0.6911 - recall: 0.1995 - val_loss: 1.6550 - val_accuracy: 0.2887 - val_precision: 0.5319 - val_recall: 0.1761\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4345 - accuracy: 0.4375 - precision: 0.7143 - recall: 0.312 - ETA: 0s - loss: 1.4865 - accuracy: 0.3906 - precision: 0.7083 - recall: 0.265 - ETA: 0s - loss: 1.5529 - accuracy: 0.3984 - precision: 0.7105 - recall: 0.210 - ETA: 0s - loss: 1.5407 - accuracy: 0.3906 - precision: 0.6418 - recall: 0.224 - ETA: 0s - loss: 1.5337 - accuracy: 0.3945 - precision: 0.6703 - recall: 0.238 - ETA: 0s - loss: 1.5521 - accuracy: 0.3844 - precision: 0.6637 - recall: 0.234 - ETA: 0s - loss: 1.6042 - accuracy: 0.3672 - precision: 0.6148 - recall: 0.216 - 1s 2ms/sample - loss: 1.6096 - accuracy: 0.3568 - precision: 0.6067 - recall: 0.2136 - val_loss: 1.6203 - val_accuracy: 0.3239 - val_precision: 0.5814 - val_recall: 0.1761\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5358 - accuracy: 0.3438 - precision: 0.7273 - recall: 0.250 - ETA: 0s - loss: 1.5272 - accuracy: 0.3542 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.5673 - accuracy: 0.3562 - precision: 0.6981 - recall: 0.231 - ETA: 0s - loss: 1.5715 - accuracy: 0.3705 - precision: 0.6712 - recall: 0.218 - ETA: 0s - loss: 1.5716 - accuracy: 0.3611 - precision: 0.6162 - recall: 0.211 - ETA: 0s - loss: 1.5915 - accuracy: 0.3466 - precision: 0.6068 - recall: 0.201 - ETA: 0s - loss: 1.5824 - accuracy: 0.3486 - precision: 0.6423 - recall: 0.211 - 1s 1ms/sample - loss: 1.5834 - accuracy: 0.3451 - precision: 0.6357 - recall: 0.2089 - val_loss: 1.5993 - val_accuracy: 0.3028 - val_precision: 0.6757 - val_recall: 0.1761\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6612 - accuracy: 0.3750 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.5272 - accuracy: 0.3854 - precision: 0.6667 - recall: 0.166 - ETA: 0s - loss: 1.5507 - accuracy: 0.3812 - precision: 0.7027 - recall: 0.162 - ETA: 0s - loss: 1.5578 - accuracy: 0.3795 - precision: 0.6786 - recall: 0.169 - ETA: 0s - loss: 1.5915 - accuracy: 0.3715 - precision: 0.6667 - recall: 0.173 - ETA: 0s - loss: 1.5522 - accuracy: 0.3920 - precision: 0.6634 - recall: 0.190 - ETA: 0s - loss: 1.5691 - accuracy: 0.3846 - precision: 0.6610 - recall: 0.187 - 1s 1ms/sample - loss: 1.5662 - accuracy: 0.3850 - precision: 0.6639 - recall: 0.1854 - val_loss: 1.6015 - val_accuracy: 0.3380 - val_precision: 0.6154 - val_recall: 0.1690\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2923 - accuracy: 0.5312 - precision: 0.7500 - recall: 0.281 - ETA: 0s - loss: 1.4877 - accuracy: 0.4271 - precision: 0.6571 - recall: 0.239 - ETA: 0s - loss: 1.5119 - accuracy: 0.4187 - precision: 0.6667 - recall: 0.225 - ETA: 0s - loss: 1.5466 - accuracy: 0.3929 - precision: 0.6761 - recall: 0.214 - ETA: 0s - loss: 1.5477 - accuracy: 0.3993 - precision: 0.7143 - recall: 0.208 - ETA: 0s - loss: 1.5521 - accuracy: 0.3864 - precision: 0.7157 - recall: 0.207 - ETA: 0s - loss: 1.5613 - accuracy: 0.3726 - precision: 0.6975 - recall: 0.199 - 1s 1ms/sample - loss: 1.5621 - accuracy: 0.3732 - precision: 0.7049 - recall: 0.2019 - val_loss: 1.6289 - val_accuracy: 0.2676 - val_precision: 0.6098 - val_recall: 0.1761\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5509 - accuracy: 0.4062 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.5899 - accuracy: 0.3750 - precision: 0.6818 - recall: 0.156 - ETA: 0s - loss: 1.5409 - accuracy: 0.3938 - precision: 0.7561 - recall: 0.193 - ETA: 0s - loss: 1.5579 - accuracy: 0.3929 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.5643 - accuracy: 0.3993 - precision: 0.6747 - recall: 0.194 - ETA: 0s - loss: 1.5485 - accuracy: 0.3920 - precision: 0.6606 - recall: 0.204 - ETA: 0s - loss: 1.5539 - accuracy: 0.3966 - precision: 0.6842 - recall: 0.218 - 1s 1ms/sample - loss: 1.5694 - accuracy: 0.3897 - precision: 0.6715 - recall: 0.2160 - val_loss: 1.7057 - val_accuracy: 0.2887 - val_precision: 0.5952 - val_recall: 0.1761\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7179 - accuracy: 0.3438 - precision: 0.5455 - recall: 0.187 - ETA: 0s - loss: 1.5903 - accuracy: 0.3854 - precision: 0.5938 - recall: 0.197 - ETA: 0s - loss: 1.6298 - accuracy: 0.3438 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.6213 - accuracy: 0.3542 - precision: 0.5660 - recall: 0.156 - ETA: 0s - loss: 1.6162 - accuracy: 0.3527 - precision: 0.5833 - recall: 0.156 - ETA: 0s - loss: 1.6582 - accuracy: 0.3403 - precision: 0.5797 - recall: 0.138 - ETA: 0s - loss: 1.6723 - accuracy: 0.3281 - precision: 0.5946 - recall: 0.137 - ETA: 0s - loss: 1.6198 - accuracy: 0.3516 - precision: 0.6289 - recall: 0.158 - ETA: 0s - loss: 1.6246 - accuracy: 0.3486 - precision: 0.6111 - recall: 0.158 - 1s 2ms/sample - loss: 1.6250 - accuracy: 0.3498 - precision: 0.6091 - recall: 0.1573 - val_loss: 1.7046 - val_accuracy: 0.2746 - val_precision: 0.6250 - val_recall: 0.1408\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6361 - accuracy: 0.3438 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.6030 - accuracy: 0.3229 - precision: 0.5926 - recall: 0.166 - ETA: 0s - loss: 1.6049 - accuracy: 0.3063 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.5918 - accuracy: 0.3348 - precision: 0.6727 - recall: 0.165 - ETA: 0s - loss: 1.5973 - accuracy: 0.3333 - precision: 0.7101 - recall: 0.170 - ETA: 0s - loss: 1.5899 - accuracy: 0.3352 - precision: 0.6744 - recall: 0.164 - ETA: 0s - loss: 1.5862 - accuracy: 0.3510 - precision: 0.6907 - recall: 0.161 - 1s 1ms/sample - loss: 1.5886 - accuracy: 0.3498 - precision: 0.6832 - recall: 0.1620 - val_loss: 1.5867 - val_accuracy: 0.3239 - val_precision: 0.6875 - val_recall: 0.1549\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4199 - accuracy: 0.5000 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.5094 - accuracy: 0.3854 - precision: 0.6400 - recall: 0.166 - ETA: 0s - loss: 1.5557 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.187 - ETA: 0s - loss: 1.5415 - accuracy: 0.4018 - precision: 0.6716 - recall: 0.200 - ETA: 0s - loss: 1.5494 - accuracy: 0.3750 - precision: 0.6404 - recall: 0.197 - ETA: 0s - loss: 1.5836 - accuracy: 0.3636 - precision: 0.6321 - recall: 0.190 - ETA: 0s - loss: 1.5776 - accuracy: 0.3702 - precision: 0.6484 - recall: 0.199 - 1s 1ms/sample - loss: 1.5770 - accuracy: 0.3732 - precision: 0.6462 - recall: 0.1972 - val_loss: 1.6017 - val_accuracy: 0.3099 - val_precision: 0.5455 - val_recall: 0.1690\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5420 - accuracy: 0.4062 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.4965 - accuracy: 0.4062 - precision: 0.8276 - recall: 0.250 - ETA: 0s - loss: 1.5252 - accuracy: 0.3812 - precision: 0.7308 - recall: 0.237 - ETA: 0s - loss: 1.5339 - accuracy: 0.3929 - precision: 0.6456 - recall: 0.227 - ETA: 0s - loss: 1.5289 - accuracy: 0.3924 - precision: 0.6667 - recall: 0.222 - ETA: 0s - loss: 1.5529 - accuracy: 0.3892 - precision: 0.6316 - recall: 0.204 - ETA: 0s - loss: 1.5547 - accuracy: 0.3918 - precision: 0.6439 - recall: 0.204 - 1s 2ms/sample - loss: 1.5531 - accuracy: 0.3873 - precision: 0.6444 - recall: 0.2042 - val_loss: 1.5920 - val_accuracy: 0.3521 - val_precision: 0.6279 - val_recall: 0.1901\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6813 - accuracy: 0.3438 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.5326 - accuracy: 0.3854 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.5834 - accuracy: 0.3688 - precision: 0.6500 - recall: 0.162 - ETA: 0s - loss: 1.6098 - accuracy: 0.3482 - precision: 0.6429 - recall: 0.160 - ETA: 0s - loss: 1.5801 - accuracy: 0.3681 - precision: 0.6883 - recall: 0.184 - ETA: 0s - loss: 1.5813 - accuracy: 0.3722 - precision: 0.6932 - recall: 0.173 - ETA: 0s - loss: 1.5643 - accuracy: 0.3966 - precision: 0.7059 - recall: 0.173 - 1s 1ms/sample - loss: 1.5679 - accuracy: 0.3920 - precision: 0.7019 - recall: 0.1714 - val_loss: 1.6303 - val_accuracy: 0.3239 - val_precision: 0.6774 - val_recall: 0.1479\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5957 - accuracy: 0.3750 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.4604 - accuracy: 0.4583 - precision: 0.8621 - recall: 0.260 - ETA: 0s - loss: 1.4609 - accuracy: 0.4938 - precision: 0.8261 - recall: 0.237 - ETA: 0s - loss: 1.4601 - accuracy: 0.5045 - precision: 0.7612 - recall: 0.227 - ETA: 0s - loss: 1.4756 - accuracy: 0.4826 - precision: 0.7294 - recall: 0.215 - ETA: 0s - loss: 1.4808 - accuracy: 0.4744 - precision: 0.7075 - recall: 0.213 - ETA: 0s - loss: 1.4764 - accuracy: 0.4663 - precision: 0.7054 - recall: 0.218 - 1s 2ms/sample - loss: 1.4790 - accuracy: 0.4695 - precision: 0.6992 - recall: 0.2183 - val_loss: 1.5415 - val_accuracy: 0.3944 - val_precision: 0.6383 - val_recall: 0.2113\n",
      "Epoch 125/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6175 - accuracy: 0.4688 - precision: 0.5000 - recall: 0.187 - ETA: 0s - loss: 1.5898 - accuracy: 0.4062 - precision: 0.5758 - recall: 0.197 - ETA: 0s - loss: 1.4934 - accuracy: 0.4313 - precision: 0.6667 - recall: 0.212 - ETA: 0s - loss: 1.4527 - accuracy: 0.4464 - precision: 0.6447 - recall: 0.218 - ETA: 0s - loss: 1.4385 - accuracy: 0.4583 - precision: 0.6837 - recall: 0.232 - ETA: 0s - loss: 1.4822 - accuracy: 0.4375 - precision: 0.6452 - recall: 0.227 - ETA: 0s - loss: 1.4653 - accuracy: 0.4471 - precision: 0.6623 - recall: 0.240 - 1s 1ms/sample - loss: 1.4671 - accuracy: 0.4460 - precision: 0.6581 - recall: 0.2394 - val_loss: 1.6333 - val_accuracy: 0.3592 - val_precision: 0.5909 - val_recall: 0.1831\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.4795 - accuracy: 0.4167 - precision: 0.6562 - recall: 0.218 - ETA: 0s - loss: 1.5131 - accuracy: 0.4375 - precision: 0.6735 - recall: 0.206 - ETA: 0s - loss: 1.4884 - accuracy: 0.4330 - precision: 0.7424 - recall: 0.218 - ETA: 0s - loss: 1.5038 - accuracy: 0.4132 - precision: 0.7262 - recall: 0.211 - ETA: 0s - loss: 1.4850 - accuracy: 0.4261 - precision: 0.7212 - recall: 0.213 - ETA: 0s - loss: 1.5004 - accuracy: 0.4183 - precision: 0.7265 - recall: 0.204 - 1s 1ms/sample - loss: 1.5052 - accuracy: 0.4131 - precision: 0.7073 - recall: 0.2042 - val_loss: 1.5862 - val_accuracy: 0.3169 - val_precision: 0.6000 - val_recall: 0.1901\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.5000 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.3514 - accuracy: 0.4479 - precision: 0.7500 - recall: 0.250 - ETA: 0s - loss: 1.4006 - accuracy: 0.4563 - precision: 0.6786 - recall: 0.237 - ETA: 0s - loss: 1.4196 - accuracy: 0.4464 - precision: 0.7123 - recall: 0.232 - ETA: 0s - loss: 1.4566 - accuracy: 0.4306 - precision: 0.7222 - recall: 0.225 - ETA: 0s - loss: 1.4998 - accuracy: 0.4261 - precision: 0.6822 - recall: 0.207 - ETA: 0s - loss: 1.4811 - accuracy: 0.4351 - precision: 0.6797 - recall: 0.209 - 1s 2ms/sample - loss: 1.4905 - accuracy: 0.4272 - precision: 0.6744 - recall: 0.2042 - val_loss: 1.5340 - val_accuracy: 0.4014 - val_precision: 0.6579 - val_recall: 0.1761\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5242 - accuracy: 0.4688 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.4520 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.3950 - accuracy: 0.5125 - precision: 0.8261 - recall: 0.237 - ETA: 0s - loss: 1.4050 - accuracy: 0.5000 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.4323 - accuracy: 0.4688 - precision: 0.7342 - recall: 0.201 - ETA: 0s - loss: 1.4132 - accuracy: 0.4659 - precision: 0.7600 - recall: 0.215 - ETA: 0s - loss: 1.4155 - accuracy: 0.4567 - precision: 0.7667 - recall: 0.221 - 1s 1ms/sample - loss: 1.4180 - accuracy: 0.4554 - precision: 0.7581 - recall: 0.2207 - val_loss: 1.5268 - val_accuracy: 0.3873 - val_precision: 0.6042 - val_recall: 0.2042\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2867 - accuracy: 0.5000 - precision: 0.6250 - recall: 0.312 - ETA: 0s - loss: 1.3599 - accuracy: 0.4583 - precision: 0.7222 - recall: 0.270 - ETA: 0s - loss: 1.4378 - accuracy: 0.4250 - precision: 0.7241 - recall: 0.262 - ETA: 0s - loss: 1.4209 - accuracy: 0.4375 - precision: 0.7059 - recall: 0.267 - ETA: 0s - loss: 1.4182 - accuracy: 0.4306 - precision: 0.6930 - recall: 0.274 - ETA: 0s - loss: 1.4313 - accuracy: 0.4261 - precision: 0.6818 - recall: 0.255 - ETA: 0s - loss: 1.4235 - accuracy: 0.4351 - precision: 0.6928 - recall: 0.254 - 1s 2ms/sample - loss: 1.4201 - accuracy: 0.4390 - precision: 0.6923 - recall: 0.2535 - val_loss: 1.4438 - val_accuracy: 0.4437 - val_precision: 0.6500 - val_recall: 0.1831\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5568 - accuracy: 0.4062 - precision: 0.6364 - recall: 0.218 - ETA: 0s - loss: 1.3880 - accuracy: 0.4583 - precision: 0.7333 - recall: 0.229 - ETA: 0s - loss: 1.4204 - accuracy: 0.4625 - precision: 0.6818 - recall: 0.187 - ETA: 0s - loss: 1.4041 - accuracy: 0.4821 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.4011 - accuracy: 0.4722 - precision: 0.7093 - recall: 0.211 - ETA: 0s - loss: 1.3753 - accuracy: 0.4886 - precision: 0.6964 - recall: 0.221 - ETA: 0s - loss: 1.3666 - accuracy: 0.4760 - precision: 0.7101 - recall: 0.235 - 1s 1ms/sample - loss: 1.3631 - accuracy: 0.4765 - precision: 0.7050 - recall: 0.2300 - val_loss: 1.4870 - val_accuracy: 0.3662 - val_precision: 0.6596 - val_recall: 0.2183\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.4688 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.4742 - accuracy: 0.4479 - precision: 0.6571 - recall: 0.239 - ETA: 0s - loss: 1.4077 - accuracy: 0.4750 - precision: 0.6567 - recall: 0.275 - ETA: 0s - loss: 1.3684 - accuracy: 0.5045 - precision: 0.6514 - recall: 0.317 - ETA: 0s - loss: 1.3474 - accuracy: 0.4861 - precision: 0.6643 - recall: 0.329 - ETA: 0s - loss: 1.3637 - accuracy: 0.4716 - precision: 0.6509 - recall: 0.312 - ETA: 0s - loss: 1.3746 - accuracy: 0.4808 - precision: 0.6531 - recall: 0.307 - 1s 1ms/sample - loss: 1.3652 - accuracy: 0.4859 - precision: 0.6600 - recall: 0.3099 - val_loss: 1.4772 - val_accuracy: 0.4014 - val_precision: 0.6538 - val_recall: 0.2394\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2596 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.3341 - accuracy: 0.4375 - precision: 0.7812 - recall: 0.260 - ETA: 0s - loss: 1.4067 - accuracy: 0.4250 - precision: 0.6852 - recall: 0.231 - ETA: 0s - loss: 1.3765 - accuracy: 0.4464 - precision: 0.7051 - recall: 0.245 - ETA: 0s - loss: 1.3828 - accuracy: 0.4375 - precision: 0.6952 - recall: 0.253 - ETA: 0s - loss: 1.3823 - accuracy: 0.4460 - precision: 0.7045 - recall: 0.264 - ETA: 0s - loss: 1.3784 - accuracy: 0.4471 - precision: 0.6962 - recall: 0.264 - 1s 1ms/sample - loss: 1.3685 - accuracy: 0.4531 - precision: 0.7055 - recall: 0.2700 - val_loss: 1.4665 - val_accuracy: 0.4014 - val_precision: 0.7451 - val_recall: 0.2676\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3237 - accuracy: 0.4688 - precision: 0.8462 - recall: 0.343 - ETA: 0s - loss: 1.2105 - accuracy: 0.5312 - precision: 0.8837 - recall: 0.395 - ETA: 0s - loss: 1.2402 - accuracy: 0.5312 - precision: 0.8382 - recall: 0.356 - ETA: 0s - loss: 1.2507 - accuracy: 0.5223 - precision: 0.7835 - recall: 0.339 - ETA: 0s - loss: 1.2638 - accuracy: 0.5104 - precision: 0.7419 - recall: 0.319 - ETA: 0s - loss: 1.2666 - accuracy: 0.5028 - precision: 0.7417 - recall: 0.318 - ETA: 0s - loss: 1.3025 - accuracy: 0.4832 - precision: 0.7384 - recall: 0.305 - 1s 1ms/sample - loss: 1.3001 - accuracy: 0.4883 - precision: 0.7386 - recall: 0.3052 - val_loss: 1.4073 - val_accuracy: 0.4085 - val_precision: 0.6250 - val_recall: 0.2465\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1796 - accuracy: 0.5625 - precision: 0.6842 - recall: 0.406 - ETA: 0s - loss: 1.3196 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.291 - ETA: 0s - loss: 1.3537 - accuracy: 0.4437 - precision: 0.6462 - recall: 0.262 - ETA: 0s - loss: 1.3258 - accuracy: 0.4732 - precision: 0.6703 - recall: 0.272 - ETA: 0s - loss: 1.3009 - accuracy: 0.5069 - precision: 0.6942 - recall: 0.291 - ETA: 0s - loss: 1.3010 - accuracy: 0.5028 - precision: 0.6821 - recall: 0.292 - ETA: 0s - loss: 1.3125 - accuracy: 0.4928 - precision: 0.7006 - recall: 0.298 - 1s 1ms/sample - loss: 1.3108 - accuracy: 0.4883 - precision: 0.6902 - recall: 0.2981 - val_loss: 1.4676 - val_accuracy: 0.4437 - val_precision: 0.6545 - val_recall: 0.2535\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3250 - accuracy: 0.4688 - precision: 0.7500 - recall: 0.375 - ETA: 0s - loss: 1.2428 - accuracy: 0.5417 - precision: 0.7959 - recall: 0.406 - ETA: 0s - loss: 1.3801 - accuracy: 0.4812 - precision: 0.6757 - recall: 0.312 - ETA: 0s - loss: 1.4127 - accuracy: 0.4598 - precision: 0.6593 - recall: 0.267 - ETA: 0s - loss: 1.3959 - accuracy: 0.4653 - precision: 0.6441 - recall: 0.263 - ETA: 0s - loss: 1.3728 - accuracy: 0.4716 - precision: 0.6408 - recall: 0.258 - ETA: 0s - loss: 1.3455 - accuracy: 0.4712 - precision: 0.6627 - recall: 0.264 - 1s 1ms/sample - loss: 1.3404 - accuracy: 0.4718 - precision: 0.6628 - recall: 0.2676 - val_loss: 1.4679 - val_accuracy: 0.4437 - val_precision: 0.6667 - val_recall: 0.2394\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4776 - accuracy: 0.4375 - precision: 0.5000 - recall: 0.250 - ETA: 0s - loss: 1.3365 - accuracy: 0.5000 - precision: 0.5714 - recall: 0.250 - ETA: 0s - loss: 1.3343 - accuracy: 0.4875 - precision: 0.5915 - recall: 0.262 - ETA: 0s - loss: 1.3374 - accuracy: 0.4955 - precision: 0.5938 - recall: 0.254 - ETA: 0s - loss: 1.3159 - accuracy: 0.4965 - precision: 0.6529 - recall: 0.274 - ETA: 0s - loss: 1.2725 - accuracy: 0.5085 - precision: 0.6824 - recall: 0.286 - ETA: 0s - loss: 1.2653 - accuracy: 0.5168 - precision: 0.6879 - recall: 0.286 - 1s 2ms/sample - loss: 1.2667 - accuracy: 0.5117 - precision: 0.6854 - recall: 0.2864 - val_loss: 1.4273 - val_accuracy: 0.4859 - val_precision: 0.7273 - val_recall: 0.2254\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2824 - accuracy: 0.5312 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.3318 - accuracy: 0.4688 - precision: 0.6071 - recall: 0.177 - ETA: 0s - loss: 1.3029 - accuracy: 0.4812 - precision: 0.6818 - recall: 0.187 - ETA: 0s - loss: 1.2961 - accuracy: 0.4866 - precision: 0.6866 - recall: 0.205 - ETA: 0s - loss: 1.2772 - accuracy: 0.4931 - precision: 0.7143 - recall: 0.225 - ETA: 0s - loss: 1.2851 - accuracy: 0.5000 - precision: 0.7117 - recall: 0.224 - ETA: 0s - loss: 1.2806 - accuracy: 0.5024 - precision: 0.7021 - recall: 0.238 - 1s 1ms/sample - loss: 1.2756 - accuracy: 0.5047 - precision: 0.7047 - recall: 0.2465 - val_loss: 1.6096 - val_accuracy: 0.3380 - val_precision: 0.5556 - val_recall: 0.2465\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3141 - accuracy: 0.5312 - precision: 0.7674 - recall: 0.343 - ETA: 0s - loss: 1.3842 - accuracy: 0.5000 - precision: 0.7042 - recall: 0.312 - ETA: 0s - loss: 1.3907 - accuracy: 0.4911 - precision: 0.7158 - recall: 0.303 - ETA: 0s - loss: 1.4224 - accuracy: 0.4618 - precision: 0.7281 - recall: 0.288 - ETA: 0s - loss: 1.4044 - accuracy: 0.4545 - precision: 0.7174 - recall: 0.281 - ETA: 0s - loss: 1.3932 - accuracy: 0.4591 - precision: 0.7143 - recall: 0.276 - 1s 1ms/sample - loss: 1.3961 - accuracy: 0.4577 - precision: 0.7048 - recall: 0.2746 - val_loss: 1.4032 - val_accuracy: 0.4366 - val_precision: 0.6905 - val_recall: 0.2042\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2882 - accuracy: 0.4688 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.1607 - accuracy: 0.5417 - precision: 0.8780 - recall: 0.375 - ETA: 0s - loss: 1.2303 - accuracy: 0.5125 - precision: 0.8167 - recall: 0.306 - ETA: 0s - loss: 1.2879 - accuracy: 0.4777 - precision: 0.7738 - recall: 0.290 - ETA: 0s - loss: 1.2686 - accuracy: 0.4931 - precision: 0.7818 - recall: 0.298 - ETA: 0s - loss: 1.2652 - accuracy: 0.4886 - precision: 0.7681 - recall: 0.301 - ETA: 0s - loss: 1.2580 - accuracy: 0.5024 - precision: 0.7862 - recall: 0.300 - 1s 1ms/sample - loss: 1.2512 - accuracy: 0.5047 - precision: 0.7914 - recall: 0.3028 - val_loss: 1.3826 - val_accuracy: 0.4437 - val_precision: 0.6607 - val_recall: 0.2606\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3869 - accuracy: 0.4375 - precision: 0.7500 - recall: 0.281 - ETA: 0s - loss: 1.3929 - accuracy: 0.4792 - precision: 0.7222 - recall: 0.270 - ETA: 0s - loss: 1.3376 - accuracy: 0.5000 - precision: 0.7500 - recall: 0.262 - ETA: 0s - loss: 1.3141 - accuracy: 0.5045 - precision: 0.7386 - recall: 0.290 - ETA: 0s - loss: 1.2650 - accuracy: 0.5278 - precision: 0.7652 - recall: 0.305 - ETA: 0s - loss: 1.2525 - accuracy: 0.5284 - precision: 0.7635 - recall: 0.321 - ETA: 0s - loss: 1.2185 - accuracy: 0.5553 - precision: 0.7809 - recall: 0.334 - 1s 1ms/sample - loss: 1.2196 - accuracy: 0.5516 - precision: 0.7760 - recall: 0.3333 - val_loss: 1.4287 - val_accuracy: 0.4648 - val_precision: 0.6923 - val_recall: 0.3169\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4052 - accuracy: 0.4375 - precision: 0.8462 - recall: 0.343 - ETA: 0s - loss: 1.3370 - accuracy: 0.4688 - precision: 0.8000 - recall: 0.333 - ETA: 0s - loss: 1.2806 - accuracy: 0.5125 - precision: 0.7571 - recall: 0.331 - ETA: 0s - loss: 1.2581 - accuracy: 0.5402 - precision: 0.7547 - recall: 0.357 - ETA: 0s - loss: 1.2352 - accuracy: 0.5382 - precision: 0.7361 - recall: 0.368 - ETA: 0s - loss: 1.2196 - accuracy: 0.5398 - precision: 0.7374 - recall: 0.375 - ETA: 0s - loss: 1.2283 - accuracy: 0.5337 - precision: 0.7136 - recall: 0.365 - 1s 1ms/sample - loss: 1.2351 - accuracy: 0.5305 - precision: 0.7097 - recall: 0.3615 - val_loss: 1.3696 - val_accuracy: 0.4718 - val_precision: 0.7241 - val_recall: 0.2958\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0876 - accuracy: 0.6250 - precision: 0.7143 - recall: 0.312 - ETA: 0s - loss: 1.1038 - accuracy: 0.5729 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 1.1181 - accuracy: 0.5813 - precision: 0.7308 - recall: 0.356 - ETA: 0s - loss: 1.1661 - accuracy: 0.5536 - precision: 0.7143 - recall: 0.357 - ETA: 0s - loss: 1.1950 - accuracy: 0.5417 - precision: 0.7080 - recall: 0.336 - ETA: 0s - loss: 1.2001 - accuracy: 0.5398 - precision: 0.7160 - recall: 0.343 - ETA: 0s - loss: 1.2005 - accuracy: 0.5409 - precision: 0.7277 - recall: 0.334 - 1s 1ms/sample - loss: 1.1982 - accuracy: 0.5446 - precision: 0.7282 - recall: 0.3333 - val_loss: 1.2897 - val_accuracy: 0.4577 - val_precision: 0.6897 - val_recall: 0.2817\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0664 - accuracy: 0.5938 - precision: 0.8000 - recall: 0.375 - ETA: 0s - loss: 1.0982 - accuracy: 0.5938 - precision: 0.7609 - recall: 0.364 - ETA: 0s - loss: 1.1585 - accuracy: 0.5437 - precision: 0.7385 - recall: 0.300 - ETA: 0s - loss: 1.1409 - accuracy: 0.5402 - precision: 0.7826 - recall: 0.321 - ETA: 0s - loss: 1.1284 - accuracy: 0.5590 - precision: 0.7652 - recall: 0.350 - ETA: 0s - loss: 1.1571 - accuracy: 0.5483 - precision: 0.7531 - recall: 0.346 - ETA: 0s - loss: 1.1583 - accuracy: 0.5577 - precision: 0.7553 - recall: 0.341 - 1s 2ms/sample - loss: 1.1609 - accuracy: 0.5587 - precision: 0.7577 - recall: 0.3451 - val_loss: 1.3352 - val_accuracy: 0.4930 - val_precision: 0.6500 - val_recall: 0.2746\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0631 - accuracy: 0.5625 - precision: 0.7647 - recall: 0.406 - ETA: 0s - loss: 1.1113 - accuracy: 0.5312 - precision: 0.6957 - recall: 0.333 - ETA: 0s - loss: 1.1463 - accuracy: 0.5437 - precision: 0.6757 - recall: 0.312 - ETA: 0s - loss: 1.1343 - accuracy: 0.5580 - precision: 0.7340 - recall: 0.308 - ETA: 0s - loss: 1.1048 - accuracy: 0.5660 - precision: 0.7581 - recall: 0.326 - ETA: 0s - loss: 1.0989 - accuracy: 0.5739 - precision: 0.7563 - recall: 0.343 - ETA: 0s - loss: 1.1060 - accuracy: 0.5673 - precision: 0.7435 - recall: 0.341 - 1s 1ms/sample - loss: 1.1181 - accuracy: 0.5610 - precision: 0.7398 - recall: 0.3404 - val_loss: 1.5435 - val_accuracy: 0.4577 - val_precision: 0.6957 - val_recall: 0.3380\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.2397 - accuracy: 0.5625 - precision: 0.8000 - recall: 0.375 - ETA: 0s - loss: 1.1628 - accuracy: 0.5729 - precision: 0.8333 - recall: 0.364 - ETA: 0s - loss: 1.1492 - accuracy: 0.5750 - precision: 0.8052 - recall: 0.387 - ETA: 0s - loss: 1.1888 - accuracy: 0.5580 - precision: 0.7619 - recall: 0.357 - ETA: 0s - loss: 1.2116 - accuracy: 0.5486 - precision: 0.7234 - recall: 0.354 - ETA: 0s - loss: 1.1813 - accuracy: 0.5568 - precision: 0.7471 - recall: 0.360 - ETA: 0s - loss: 1.1551 - accuracy: 0.5697 - precision: 0.7612 - recall: 0.367 - 1s 1ms/sample - loss: 1.1553 - accuracy: 0.5728 - precision: 0.7633 - recall: 0.3709 - val_loss: 1.3954 - val_accuracy: 0.4577 - val_precision: 0.6441 - val_recall: 0.2676\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4481 - accuracy: 0.5312 - precision: 0.5333 - recall: 0.250 - ETA: 0s - loss: 1.2489 - accuracy: 0.5729 - precision: 0.6829 - recall: 0.291 - ETA: 0s - loss: 1.1675 - accuracy: 0.5813 - precision: 0.7571 - recall: 0.331 - ETA: 0s - loss: 1.1579 - accuracy: 0.5670 - precision: 0.7766 - recall: 0.325 - ETA: 0s - loss: 1.1049 - accuracy: 0.5833 - precision: 0.8095 - recall: 0.354 - ETA: 0s - loss: 1.0916 - accuracy: 0.5881 - precision: 0.8025 - recall: 0.358 - ETA: 0s - loss: 1.0870 - accuracy: 0.6010 - precision: 0.7906 - recall: 0.363 - 1s 1ms/sample - loss: 1.0885 - accuracy: 0.6009 - precision: 0.7927 - recall: 0.3592 - val_loss: 1.4122 - val_accuracy: 0.4577 - val_precision: 0.6094 - val_recall: 0.2746\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.8125 - precision: 0.8824 - recall: 0.468 - ETA: 0s - loss: 0.9401 - accuracy: 0.6354 - precision: 0.7857 - recall: 0.458 - ETA: 0s - loss: 1.0784 - accuracy: 0.5750 - precision: 0.7283 - recall: 0.418 - ETA: 0s - loss: 1.0646 - accuracy: 0.5714 - precision: 0.7559 - recall: 0.428 - ETA: 0s - loss: 1.0943 - accuracy: 0.5556 - precision: 0.7342 - recall: 0.402 - ETA: 0s - loss: 1.0729 - accuracy: 0.5682 - precision: 0.7500 - recall: 0.409 - ETA: 0s - loss: 1.1433 - accuracy: 0.5505 - precision: 0.7432 - recall: 0.396 - 1s 1ms/sample - loss: 1.1435 - accuracy: 0.5516 - precision: 0.7467 - recall: 0.3944 - val_loss: 1.6068 - val_accuracy: 0.3662 - val_precision: 0.6290 - val_recall: 0.2746\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6855 - accuracy: 0.4688 - precision: 0.8000 - recall: 0.375 - ETA: 0s - loss: 1.4483 - accuracy: 0.5208 - precision: 0.7333 - recall: 0.343 - ETA: 0s - loss: 1.3812 - accuracy: 0.5125 - precision: 0.7500 - recall: 0.337 - ETA: 0s - loss: 1.4789 - accuracy: 0.4777 - precision: 0.6915 - recall: 0.290 - ETA: 0s - loss: 1.4358 - accuracy: 0.4861 - precision: 0.6880 - recall: 0.298 - ETA: 0s - loss: 1.4072 - accuracy: 0.4943 - precision: 0.7059 - recall: 0.306 - ETA: 0s - loss: 1.3743 - accuracy: 0.4952 - precision: 0.7111 - recall: 0.307 - 1s 1ms/sample - loss: 1.3648 - accuracy: 0.4977 - precision: 0.7204 - recall: 0.3146 - val_loss: 1.3783 - val_accuracy: 0.4577 - val_precision: 0.6207 - val_recall: 0.2535\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.218 - ETA: 0s - loss: 1.2108 - accuracy: 0.5521 - precision: 0.7805 - recall: 0.333 - ETA: 0s - loss: 1.1930 - accuracy: 0.5688 - precision: 0.7467 - recall: 0.350 - ETA: 0s - loss: 1.1342 - accuracy: 0.6027 - precision: 0.7568 - recall: 0.375 - ETA: 0s - loss: 1.1794 - accuracy: 0.5868 - precision: 0.7211 - recall: 0.368 - ETA: 0s - loss: 1.1619 - accuracy: 0.5824 - precision: 0.7391 - recall: 0.386 - ETA: 0s - loss: 1.1618 - accuracy: 0.5721 - precision: 0.7309 - recall: 0.391 - 1s 2ms/sample - loss: 1.1579 - accuracy: 0.5728 - precision: 0.7336 - recall: 0.3944 - val_loss: 1.3262 - val_accuracy: 0.5000 - val_precision: 0.6351 - val_recall: 0.3310\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8839 - accuracy: 0.7812 - precision: 0.8500 - recall: 0.531 - ETA: 0s - loss: 1.0175 - accuracy: 0.6562 - precision: 0.8000 - recall: 0.375 - ETA: 0s - loss: 1.0515 - accuracy: 0.6187 - precision: 0.7439 - recall: 0.381 - ETA: 0s - loss: 1.1118 - accuracy: 0.5938 - precision: 0.7387 - recall: 0.366 - ETA: 0s - loss: 1.1451 - accuracy: 0.5764 - precision: 0.7518 - recall: 0.357 - ETA: 0s - loss: 1.0951 - accuracy: 0.6023 - precision: 0.7719 - recall: 0.375 - ETA: 0s - loss: 1.0653 - accuracy: 0.6130 - precision: 0.7941 - recall: 0.389 - 1s 1ms/sample - loss: 1.0578 - accuracy: 0.6174 - precision: 0.7971 - recall: 0.3873 - val_loss: 1.3994 - val_accuracy: 0.4366 - val_precision: 0.6500 - val_recall: 0.2746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 693a43ede8156822951db1567950c154</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          344832    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 96)                86400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 947,980\n",
      "Trainable params: 947,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:10 - loss: 2.4856 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 19s - loss: 2.4517 - accuracy: 0.1042 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 9s - loss: 2.4577 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+00 - ETA: 5s - loss: 2.4172 - accuracy: 0.1027 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 2s - loss: 2.3937 - accuracy: 0.1215 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 1s - loss: 2.3759 - accuracy: 0.1222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3353 - accuracy: 0.1298 - precision: 0.0000e+00 - recall: 0.0000e+0 - 8s 19ms/sample - loss: 2.3301 - accuracy: 0.1315 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0846 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0412 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9806 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1038 - accuracy: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2641 - accuracy: 0.1652 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2699 - accuracy: 0.1493 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2976 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3675 - accuracy: 0.1490 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3821 - accuracy: 0.1479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.7962 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.8204 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.7100 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6732 - accuracy: 0.1719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6640 - accuracy: 0.1458 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.6383 - accuracy: 0.1384 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5860 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5767 - accuracy: 0.1222 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.5732 - accuracy: 0.1202 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.5727 - accuracy: 0.1174 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4804 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4202 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4497 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4455 - accuracy: 0.0750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4376 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4470 - accuracy: 0.0859 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4525 - accuracy: 0.0906 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4453 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.4427 - accuracy: 0.0822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4188 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4070 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4171 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4140 - accuracy: 0.0812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4125 - accuracy: 0.0804 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4094 - accuracy: 0.0694 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4096 - accuracy: 0.0682 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4112 - accuracy: 0.0697 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4108 - accuracy: 0.0704 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4209 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4195 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4064 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4130 - accuracy: 0.1000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4078 - accuracy: 0.0982 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4061 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4045 - accuracy: 0.0972 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4018 - accuracy: 0.1023 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4032 - accuracy: 0.1016 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.4010 - accuracy: 0.1174 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4238 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4009 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3700 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3750 - accuracy: 0.1406 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3837 - accuracy: 0.1302 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3812 - accuracy: 0.1328 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3918 - accuracy: 0.1187 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4041 - accuracy: 0.1120 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4079 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.4072 - accuracy: 0.1080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4225 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4176 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4138 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4089 - accuracy: 0.0812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4108 - accuracy: 0.0714 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4032 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4009 - accuracy: 0.0852 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4031 - accuracy: 0.0817 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.4030 - accuracy: 0.0798 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4210 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4145 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3962 - accuracy: 0.0417 - precision: 0.0000e+00 - recall: 0.0000e+00    - ETA: 0s - loss: 2.3932 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3893 - accuracy: 0.0893 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3883 - accuracy: 0.0903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3900 - accuracy: 0.0875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3995 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3994 - accuracy: 0.0915 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4193 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4310 - accuracy: 0.0625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4167 - accuracy: 0.0833 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4041 - accuracy: 0.0781 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4057 - accuracy: 0.0688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.4072 - accuracy: 0.0670 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3993 - accuracy: 0.0903 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3985 - accuracy: 0.0906 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3993 - accuracy: 0.0964 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3987 - accuracy: 0.0892 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4118 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4332 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3897 - accuracy: 0.1719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3863 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3938 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3917 - accuracy: 0.1328 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3868 - accuracy: 0.1285 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3847 - accuracy: 0.1307 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3920 - accuracy: 0.1154 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.3933 - accuracy: 0.1174 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4077 - val_accuracy: 0.1056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4017 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3876 - accuracy: 0.0938 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3737 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3788 - accuracy: 0.1339 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3807 - accuracy: 0.1146 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3826 - accuracy: 0.0994 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3803 - accuracy: 0.1058 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.3826 - accuracy: 0.1056 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3527 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3341 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3400 - accuracy: 0.1354 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3347 - accuracy: 0.1500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3163 - accuracy: 0.1518 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.3076 - accuracy: 0.1493 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2972 - accuracy: 0.1534 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2757 - accuracy: 0.1707 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 2.2736 - accuracy: 0.1690 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1482 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2308 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1337 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1038 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1549 - accuracy: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2744 - accuracy: 0.1632 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2698 - accuracy: 0.1676 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.2408 - accuracy: 0.1683 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 2.2427 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0941 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9923 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0025 - accuracy: 0.1667 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0303 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0073 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.0076 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9857 - accuracy: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9962 - accuracy: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9954 - accuracy: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9159 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9796 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9946 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9986 - accuracy: 0.2375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9772 - accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9648 - accuracy: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9520 - accuracy: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9315 - accuracy: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.9319 - accuracy: 0.1972 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8133 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8304 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8109 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8484 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8523 - accuracy: 0.2366 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8841 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8889 - accuracy: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8698 - accuracy: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8635 - accuracy: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8063 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8874 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8686 - accuracy: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8388 - accuracy: 0.2313 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8357 - accuracy: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8279 - accuracy: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8279 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8521 - accuracy: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8531 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7957 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8032 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7762 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7731 - accuracy: 0.2937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7587 - accuracy: 0.2857 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8078 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7923 - accuracy: 0.2594 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8319 - accuracy: 0.2526 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8272 - accuracy: 0.2572 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8298 - accuracy: 0.2535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7836 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8609 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7848 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7794 - accuracy: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8046 - accuracy: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8068 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8005 - accuracy: 0.2386 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8100 - accuracy: 0.2380 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8124 - accuracy: 0.2347 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7640 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 0.4062 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6984 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7122 - accuracy: 0.3063 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7140 - accuracy: 0.2917 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7388 - accuracy: 0.3047 - precision: 0.5000 - recall: 0.0078        - ETA: 0s - loss: 1.7552 - accuracy: 0.2986 - precision: 0.4286 - recall: 0.010 - ETA: 0s - loss: 1.8092 - accuracy: 0.2756 - precision: 0.4444 - recall: 0.011 - ETA: 0s - loss: 1.8081 - accuracy: 0.2630 - precision: 0.3636 - recall: 0.010 - 1s 2ms/sample - loss: 1.8127 - accuracy: 0.2653 - precision: 0.4667 - recall: 0.0164 - val_loss: 1.8295 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9989 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8066 - accuracy: 0.2656 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7982 - accuracy: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7681 - accuracy: 0.2552 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7937 - accuracy: 0.2656 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7863 - accuracy: 0.2719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7841 - accuracy: 0.2656 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7803 - accuracy: 0.2668 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.7819 - accuracy: 0.2653 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7255 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7178 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7963 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7900 - accuracy: 0.2875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7579 - accuracy: 0.2679 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7643 - accuracy: 0.2578 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7811 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7961 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8164 - accuracy: 0.2370 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8185 - accuracy: 0.2356 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.8115 - accuracy: 0.2394 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7758 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7115 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6861 - accuracy: 0.2969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6767 - accuracy: 0.3333 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7048 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7131 - accuracy: 0.3125 - precision: 0.5714 - recall: 0.0208        - ETA: 0s - loss: 1.7138 - accuracy: 0.3080 - precision: 0.5714 - recall: 0.035 - ETA: 0s - loss: 1.7442 - accuracy: 0.2812 - precision: 0.5294 - recall: 0.035 - ETA: 0s - loss: 1.7423 - accuracy: 0.2875 - precision: 0.5500 - recall: 0.034 - ETA: 0s - loss: 1.7393 - accuracy: 0.2943 - precision: 0.5417 - recall: 0.033 - 1s 2ms/sample - loss: 1.7276 - accuracy: 0.2981 - precision: 0.5600 - recall: 0.0329 - val_loss: 1.6645 - val_accuracy: 0.2817 - val_precision: 0.5385 - val_recall: 0.0493\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7067 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6262 - accuracy: 0.3438 - precision: 0.8750 - recall: 0.109 - ETA: 0s - loss: 1.6967 - accuracy: 0.3542 - precision: 0.6429 - recall: 0.093 - ETA: 0s - loss: 1.7785 - accuracy: 0.3125 - precision: 0.4286 - recall: 0.075 - ETA: 0s - loss: 1.7438 - accuracy: 0.3080 - precision: 0.4516 - recall: 0.062 - ETA: 0s - loss: 1.7596 - accuracy: 0.2917 - precision: 0.4516 - recall: 0.048 - ETA: 0s - loss: 1.7364 - accuracy: 0.2875 - precision: 0.4516 - recall: 0.043 - ETA: 0s - loss: 1.7336 - accuracy: 0.2812 - precision: 0.4516 - recall: 0.036 - ETA: 0s - loss: 1.7535 - accuracy: 0.2716 - precision: 0.4516 - recall: 0.033 - 1s 2ms/sample - loss: 1.7475 - accuracy: 0.2723 - precision: 0.4516 - recall: 0.0329 - val_loss: 1.7439 - val_accuracy: 0.3028 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6919 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6722 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6770 - accuracy: 0.2969 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6498 - accuracy: 0.3021 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6424 - accuracy: 0.3086 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6481 - accuracy: 0.3056 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6520 - accuracy: 0.3239 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6581 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6670 - accuracy: 0.3101 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 2ms/sample - loss: 1.6661 - accuracy: 0.3075 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6989 - val_accuracy: 0.3169 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4450 - accuracy: 0.3750 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5995 - accuracy: 0.2917 - precision: 1.0000 - recall: 0.041 - ETA: 0s - loss: 1.6037 - accuracy: 0.2969 - precision: 1.0000 - recall: 0.046 - ETA: 0s - loss: 1.5476 - accuracy: 0.3385 - precision: 0.7647 - recall: 0.067 - ETA: 0s - loss: 1.5777 - accuracy: 0.3304 - precision: 0.7000 - recall: 0.062 - ETA: 0s - loss: 1.6031 - accuracy: 0.3229 - precision: 0.7143 - recall: 0.069 - ETA: 0s - loss: 1.6083 - accuracy: 0.3182 - precision: 0.7333 - recall: 0.062 - ETA: 0s - loss: 1.6150 - accuracy: 0.3221 - precision: 0.7188 - recall: 0.055 - 1s 2ms/sample - loss: 1.6138 - accuracy: 0.3192 - precision: 0.7188 - recall: 0.0540 - val_loss: 1.5942 - val_accuracy: 0.3239 - val_precision: 0.8571 - val_recall: 0.0845\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4572 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.4753 - accuracy: 0.3646 - precision: 0.8182 - recall: 0.093 - ETA: 0s - loss: 1.5454 - accuracy: 0.3438 - precision: 0.6500 - recall: 0.081 - ETA: 0s - loss: 1.5837 - accuracy: 0.3438 - precision: 0.6061 - recall: 0.089 - ETA: 0s - loss: 1.5673 - accuracy: 0.3403 - precision: 0.5526 - recall: 0.072 - ETA: 0s - loss: 1.5668 - accuracy: 0.3295 - precision: 0.6000 - recall: 0.076 - ETA: 0s - loss: 1.5622 - accuracy: 0.3359 - precision: 0.6087 - recall: 0.072 - 1s 2ms/sample - loss: 1.5697 - accuracy: 0.3286 - precision: 0.6170 - recall: 0.0681 - val_loss: 1.6360 - val_accuracy: 0.3239 - val_precision: 1.0000 - val_recall: 0.0563\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4956 - accuracy: 0.4062 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.5367 - accuracy: 0.3542 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.5596 - accuracy: 0.3625 - precision: 0.7778 - recall: 0.043 - ETA: 0s - loss: 1.5629 - accuracy: 0.3571 - precision: 0.8000 - recall: 0.035 - ETA: 0s - loss: 1.5604 - accuracy: 0.3542 - precision: 0.7222 - recall: 0.045 - ETA: 0s - loss: 1.6123 - accuracy: 0.3381 - precision: 0.6818 - recall: 0.042 - ETA: 0s - loss: 1.5845 - accuracy: 0.3317 - precision: 0.6923 - recall: 0.043 - 1s 2ms/sample - loss: 1.5781 - accuracy: 0.3333 - precision: 0.7143 - recall: 0.0469 - val_loss: 1.5170 - val_accuracy: 0.4296 - val_precision: 0.8333 - val_recall: 0.1056\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4603 - accuracy: 0.4062 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.4904 - accuracy: 0.3646 - precision: 0.6364 - recall: 0.072 - ETA: 0s - loss: 1.4267 - accuracy: 0.4125 - precision: 0.7333 - recall: 0.068 - ETA: 0s - loss: 1.4495 - accuracy: 0.3705 - precision: 0.7222 - recall: 0.058 - ETA: 0s - loss: 1.4421 - accuracy: 0.3785 - precision: 0.7600 - recall: 0.066 - ETA: 0s - loss: 1.4758 - accuracy: 0.3656 - precision: 0.7407 - recall: 0.062 - ETA: 0s - loss: 1.4709 - accuracy: 0.3646 - precision: 0.7647 - recall: 0.067 - 1s 2ms/sample - loss: 1.4937 - accuracy: 0.3615 - precision: 0.7895 - recall: 0.0704 - val_loss: 1.4991 - val_accuracy: 0.3380 - val_precision: 0.8571 - val_recall: 0.1268\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5566 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.5944 - accuracy: 0.3333 - precision: 0.5833 - recall: 0.072 - ETA: 0s - loss: 1.6471 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.070 - ETA: 0s - loss: 1.6826 - accuracy: 0.2865 - precision: 0.5926 - recall: 0.083 - ETA: 0s - loss: 1.6555 - accuracy: 0.3125 - precision: 0.6207 - recall: 0.080 - ETA: 0s - loss: 1.6038 - accuracy: 0.3403 - precision: 0.6765 - recall: 0.079 - ETA: 0s - loss: 1.5695 - accuracy: 0.3636 - precision: 0.7073 - recall: 0.082 - ETA: 0s - loss: 1.5670 - accuracy: 0.3542 - precision: 0.7143 - recall: 0.078 - 1s 2ms/sample - loss: 1.5701 - accuracy: 0.3545 - precision: 0.7000 - recall: 0.0822 - val_loss: 1.5306 - val_accuracy: 0.3732 - val_precision: 0.6176 - val_recall: 0.1479\n",
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7057 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.5584 - accuracy: 0.3542 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.5731 - accuracy: 0.3438 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6313 - accuracy: 0.3438 - precision: 0.6429 - recall: 0.093 - ETA: 0s - loss: 1.6340 - accuracy: 0.3482 - precision: 0.6667 - recall: 0.098 - ETA: 0s - loss: 1.6506 - accuracy: 0.3333 - precision: 0.6750 - recall: 0.093 - ETA: 0s - loss: 1.6432 - accuracy: 0.3466 - precision: 0.7174 - recall: 0.093 - ETA: 0s - loss: 1.6295 - accuracy: 0.3464 - precision: 0.7143 - recall: 0.091 - 1s 2ms/sample - loss: 1.6334 - accuracy: 0.3404 - precision: 0.6923 - recall: 0.0845 - val_loss: 1.5737 - val_accuracy: 0.3803 - val_precision: 0.5897 - val_recall: 0.1620\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4799 - accuracy: 0.4062 - precision: 0.6250 - recall: 0.156 - ETA: 0s - loss: 1.4991 - accuracy: 0.4375 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.5329 - accuracy: 0.3984 - precision: 0.6000 - recall: 0.117 - ETA: 0s - loss: 1.5970 - accuracy: 0.3594 - precision: 0.5938 - recall: 0.099 - ETA: 0s - loss: 1.5948 - accuracy: 0.3594 - precision: 0.6000 - recall: 0.082 - ETA: 0s - loss: 1.6015 - accuracy: 0.3542 - precision: 0.6216 - recall: 0.079 - ETA: 0s - loss: 1.5911 - accuracy: 0.3466 - precision: 0.6744 - recall: 0.082 - ETA: 0s - loss: 1.5760 - accuracy: 0.3462 - precision: 0.6604 - recall: 0.084 - 1s 2ms/sample - loss: 1.5729 - accuracy: 0.3498 - precision: 0.6429 - recall: 0.0845 - val_loss: 1.5178 - val_accuracy: 0.3380 - val_precision: 0.6471 - val_recall: 0.1549\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 0.3438 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.4787 - accuracy: 0.3438 - precision: 0.5385 - recall: 0.109 - ETA: 0s - loss: 1.4999 - accuracy: 0.3281 - precision: 0.5000 - recall: 0.109 - ETA: 0s - loss: 1.4608 - accuracy: 0.3562 - precision: 0.5556 - recall: 0.125 - ETA: 0s - loss: 1.4959 - accuracy: 0.3527 - precision: 0.5417 - recall: 0.116 - ETA: 0s - loss: 1.4740 - accuracy: 0.3681 - precision: 0.5818 - recall: 0.111 - ETA: 0s - loss: 1.4645 - accuracy: 0.3688 - precision: 0.5932 - recall: 0.109 - ETA: 0s - loss: 1.4706 - accuracy: 0.3776 - precision: 0.6364 - recall: 0.109 - 1s 2ms/sample - loss: 1.4767 - accuracy: 0.3732 - precision: 0.6197 - recall: 0.1033 - val_loss: 1.5296 - val_accuracy: 0.3662 - val_precision: 0.8571 - val_recall: 0.1268\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4269 - accuracy: 0.5000 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.4979 - accuracy: 0.4271 - precision: 0.8182 - recall: 0.093 - ETA: 0s - loss: 1.4436 - accuracy: 0.4437 - precision: 0.8235 - recall: 0.087 - ETA: 0s - loss: 1.4712 - accuracy: 0.4062 - precision: 0.7727 - recall: 0.088 - ETA: 0s - loss: 1.4258 - accuracy: 0.4219 - precision: 0.8333 - recall: 0.097 - ETA: 0s - loss: 1.4133 - accuracy: 0.4236 - precision: 0.8611 - recall: 0.107 - ETA: 0s - loss: 1.4052 - accuracy: 0.4318 - precision: 0.8723 - recall: 0.116 - ETA: 0s - loss: 1.4420 - accuracy: 0.4207 - precision: 0.7538 - recall: 0.117 - 1s 2ms/sample - loss: 1.4485 - accuracy: 0.4155 - precision: 0.7463 - recall: 0.1174 - val_loss: 1.5148 - val_accuracy: 0.3592 - val_precision: 0.7045 - val_recall: 0.2183\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6301 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.5877 - accuracy: 0.3229 - precision: 0.4545 - recall: 0.104 - ETA: 0s - loss: 1.5727 - accuracy: 0.3250 - precision: 0.4359 - recall: 0.106 - ETA: 0s - loss: 1.5183 - accuracy: 0.3482 - precision: 0.5577 - recall: 0.129 - ETA: 0s - loss: 1.5177 - accuracy: 0.3368 - precision: 0.5690 - recall: 0.114 - ETA: 0s - loss: 1.4934 - accuracy: 0.3551 - precision: 0.6212 - recall: 0.116 - ETA: 0s - loss: 1.4963 - accuracy: 0.3558 - precision: 0.6296 - recall: 0.122 - 1s 1ms/sample - loss: 1.4929 - accuracy: 0.3545 - precision: 0.6341 - recall: 0.1221 - val_loss: 1.4997 - val_accuracy: 0.4014 - val_precision: 0.6486 - val_recall: 0.1690\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7349 - accuracy: 0.2500 - precision: 0.3636 - recall: 0.125 - ETA: 0s - loss: 1.5340 - accuracy: 0.3333 - precision: 0.5000 - recall: 0.125 - ETA: 0s - loss: 1.5283 - accuracy: 0.3500 - precision: 0.4524 - recall: 0.118 - ETA: 0s - loss: 1.5190 - accuracy: 0.3348 - precision: 0.5094 - recall: 0.120 - ETA: 0s - loss: 1.4920 - accuracy: 0.3368 - precision: 0.5312 - recall: 0.118 - ETA: 0s - loss: 1.4615 - accuracy: 0.3466 - precision: 0.5733 - recall: 0.122 - ETA: 0s - loss: 1.4676 - accuracy: 0.3606 - precision: 0.5783 - recall: 0.115 - 1s 1ms/sample - loss: 1.4713 - accuracy: 0.3592 - precision: 0.5783 - recall: 0.1127 - val_loss: 1.6307 - val_accuracy: 0.3239 - val_precision: 0.6111 - val_recall: 0.1549\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5580 - accuracy: 0.3438 - precision: 0.3000 - recall: 0.093 - ETA: 0s - loss: 1.5410 - accuracy: 0.3542 - precision: 0.3600 - recall: 0.093 - ETA: 0s - loss: 1.5214 - accuracy: 0.3938 - precision: 0.4615 - recall: 0.112 - ETA: 0s - loss: 1.5623 - accuracy: 0.3884 - precision: 0.4490 - recall: 0.098 - ETA: 0s - loss: 1.5670 - accuracy: 0.3681 - precision: 0.4667 - recall: 0.097 - ETA: 0s - loss: 1.5888 - accuracy: 0.3551 - precision: 0.4638 - recall: 0.090 - ETA: 0s - loss: 1.5750 - accuracy: 0.3672 - precision: 0.4667 - recall: 0.091 - 1s 2ms/sample - loss: 1.5617 - accuracy: 0.3662 - precision: 0.4940 - recall: 0.0962 - val_loss: 1.6769 - val_accuracy: 0.2958 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.5113 - accuracy: 0.2656 - precision: 0.5000 - recall: 0.0156        - ETA: 0s - loss: 1.4534 - accuracy: 0.3438 - precision: 0.8571 - recall: 0.046 - ETA: 0s - loss: 1.4786 - accuracy: 0.3490 - precision: 0.9000 - recall: 0.046 - ETA: 0s - loss: 1.4455 - accuracy: 0.3828 - precision: 0.9048 - recall: 0.074 - ETA: 0s - loss: 1.4574 - accuracy: 0.3750 - precision: 0.9200 - recall: 0.079 - ETA: 0s - loss: 1.4240 - accuracy: 0.3807 - precision: 0.8889 - recall: 0.090 - ETA: 0s - loss: 1.4418 - accuracy: 0.3774 - precision: 0.8571 - recall: 0.086 - 1s 2ms/sample - loss: 1.4443 - accuracy: 0.3756 - precision: 0.8571 - recall: 0.0845 - val_loss: 1.5032 - val_accuracy: 0.3451 - val_precision: 0.9412 - val_recall: 0.1127\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3395 - accuracy: 0.5000 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.2856 - accuracy: 0.5000 - precision: 0.8462 - recall: 0.114 - ETA: 0s - loss: 1.3986 - accuracy: 0.4187 - precision: 0.8000 - recall: 0.100 - ETA: 0s - loss: 1.3889 - accuracy: 0.4375 - precision: 0.7059 - recall: 0.107 - ETA: 0s - loss: 1.3783 - accuracy: 0.4375 - precision: 0.7209 - recall: 0.107 - ETA: 0s - loss: 1.4069 - accuracy: 0.4290 - precision: 0.7551 - recall: 0.105 - ETA: 0s - loss: 1.4043 - accuracy: 0.4207 - precision: 0.7458 - recall: 0.105 - 1s 1ms/sample - loss: 1.3991 - accuracy: 0.4225 - precision: 0.7581 - recall: 0.1103 - val_loss: 1.5637 - val_accuracy: 0.3944 - val_precision: 0.7692 - val_recall: 0.1408\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2825 - accuracy: 0.5625 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.2521 - accuracy: 0.5104 - precision: 0.9000 - recall: 0.187 - ETA: 0s - loss: 1.3292 - accuracy: 0.4375 - precision: 0.6970 - recall: 0.143 - ETA: 0s - loss: 1.3759 - accuracy: 0.4286 - precision: 0.7021 - recall: 0.147 - ETA: 0s - loss: 1.3876 - accuracy: 0.4236 - precision: 0.7167 - recall: 0.149 - ETA: 0s - loss: 1.4165 - accuracy: 0.4062 - precision: 0.7000 - recall: 0.139 - ETA: 0s - loss: 1.3926 - accuracy: 0.4135 - precision: 0.7160 - recall: 0.139 - 1s 2ms/sample - loss: 1.3926 - accuracy: 0.4085 - precision: 0.7073 - recall: 0.1362 - val_loss: 1.3768 - val_accuracy: 0.4507 - val_precision: 0.8000 - val_recall: 0.1408\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2931 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.2670 - accuracy: 0.5417 - precision: 0.8500 - recall: 0.177 - ETA: 0s - loss: 1.3260 - accuracy: 0.4875 - precision: 0.7188 - recall: 0.143 - ETA: 0s - loss: 1.3339 - accuracy: 0.4688 - precision: 0.6538 - recall: 0.151 - ETA: 0s - loss: 1.3874 - accuracy: 0.4722 - precision: 0.6143 - recall: 0.149 - ETA: 0s - loss: 1.4096 - accuracy: 0.4688 - precision: 0.6000 - recall: 0.144 - ETA: 0s - loss: 1.4321 - accuracy: 0.4519 - precision: 0.5800 - recall: 0.139 - 1s 1ms/sample - loss: 1.4259 - accuracy: 0.4554 - precision: 0.5905 - recall: 0.1455 - val_loss: 1.5908 - val_accuracy: 0.3521 - val_precision: 0.6800 - val_recall: 0.1197\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3165 - accuracy: 0.5000 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.5416 - accuracy: 0.3750 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.4712 - accuracy: 0.4250 - precision: 0.6316 - recall: 0.075 - ETA: 0s - loss: 1.4575 - accuracy: 0.4152 - precision: 0.6667 - recall: 0.080 - ETA: 0s - loss: 1.4692 - accuracy: 0.4097 - precision: 0.6316 - recall: 0.083 - ETA: 0s - loss: 1.4559 - accuracy: 0.4148 - precision: 0.6071 - recall: 0.096 - ETA: 0s - loss: 1.4496 - accuracy: 0.4183 - precision: 0.6164 - recall: 0.108 - 1s 1ms/sample - loss: 1.4494 - accuracy: 0.4202 - precision: 0.6267 - recall: 0.1103 - val_loss: 1.5745 - val_accuracy: 0.3662 - val_precision: 0.6970 - val_recall: 0.1620\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3689 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.125 - ETA: 0s - loss: 1.4222 - accuracy: 0.4062 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.3768 - accuracy: 0.4125 - precision: 0.7222 - recall: 0.162 - ETA: 0s - loss: 1.3837 - accuracy: 0.3929 - precision: 0.6667 - recall: 0.151 - ETA: 0s - loss: 1.3590 - accuracy: 0.4132 - precision: 0.6620 - recall: 0.163 - ETA: 0s - loss: 1.3689 - accuracy: 0.4091 - precision: 0.6707 - recall: 0.156 - ETA: 0s - loss: 1.3902 - accuracy: 0.3846 - precision: 0.6629 - recall: 0.141 - 1s 1ms/sample - loss: 1.3869 - accuracy: 0.3920 - precision: 0.6667 - recall: 0.1408 - val_loss: 1.4984 - val_accuracy: 0.4014 - val_precision: 0.8519 - val_recall: 0.1620\n",
      "Epoch 45/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.0698 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.250 - ETA: 0s - loss: 1.1766 - accuracy: 0.5104 - precision: 0.8824 - recall: 0.156 - ETA: 0s - loss: 1.2405 - accuracy: 0.4750 - precision: 0.8387 - recall: 0.162 - ETA: 0s - loss: 1.3012 - accuracy: 0.4509 - precision: 0.7500 - recall: 0.147 - ETA: 0s - loss: 1.3140 - accuracy: 0.4583 - precision: 0.7143 - recall: 0.138 - ETA: 0s - loss: 1.3116 - accuracy: 0.4631 - precision: 0.7121 - recall: 0.133 - ETA: 0s - loss: 1.3373 - accuracy: 0.4688 - precision: 0.6951 - recall: 0.137 - 1s 2ms/sample - loss: 1.3399 - accuracy: 0.4718 - precision: 0.6824 - recall: 0.1362 - val_loss: 1.3790 - val_accuracy: 0.4577 - val_precision: 0.7692 - val_recall: 0.1408\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.4688 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.2562 - accuracy: 0.5312 - precision: 0.6500 - recall: 0.135 - ETA: 0s - loss: 1.2650 - accuracy: 0.4875 - precision: 0.6667 - recall: 0.162 - ETA: 0s - loss: 1.2823 - accuracy: 0.4911 - precision: 0.6667 - recall: 0.169 - ETA: 0s - loss: 1.2609 - accuracy: 0.5104 - precision: 0.7067 - recall: 0.184 - ETA: 0s - loss: 1.2492 - accuracy: 0.5094 - precision: 0.7412 - recall: 0.196 - ETA: 0s - loss: 1.3048 - accuracy: 0.4844 - precision: 0.6847 - recall: 0.197 - 1s 1ms/sample - loss: 1.3106 - accuracy: 0.4859 - precision: 0.6850 - recall: 0.2042 - val_loss: 1.4147 - val_accuracy: 0.4366 - val_precision: 0.6154 - val_recall: 0.1690\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1270 - accuracy: 0.5938 - precision: 0.9167 - recall: 0.343 - ETA: 0s - loss: 1.2958 - accuracy: 0.4583 - precision: 0.6970 - recall: 0.239 - ETA: 0s - loss: 1.4728 - accuracy: 0.4062 - precision: 0.5185 - recall: 0.175 - ETA: 0s - loss: 1.5107 - accuracy: 0.3616 - precision: 0.4776 - recall: 0.142 - ETA: 0s - loss: 1.4708 - accuracy: 0.3854 - precision: 0.5181 - recall: 0.149 - ETA: 0s - loss: 1.4830 - accuracy: 0.3864 - precision: 0.5435 - recall: 0.142 - ETA: 0s - loss: 1.4799 - accuracy: 0.3846 - precision: 0.5800 - recall: 0.139 - 1s 1ms/sample - loss: 1.4900 - accuracy: 0.3803 - precision: 0.5800 - recall: 0.1362 - val_loss: 1.5366 - val_accuracy: 0.4085 - val_precision: 0.6667 - val_recall: 0.1268\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2814 - accuracy: 0.5625 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.3004 - accuracy: 0.5104 - precision: 0.8095 - recall: 0.177 - ETA: 0s - loss: 1.3669 - accuracy: 0.4688 - precision: 0.6944 - recall: 0.156 - ETA: 0s - loss: 1.4286 - accuracy: 0.4330 - precision: 0.6531 - recall: 0.142 - ETA: 0s - loss: 1.4102 - accuracy: 0.4340 - precision: 0.6418 - recall: 0.149 - ETA: 0s - loss: 1.4083 - accuracy: 0.4233 - precision: 0.6220 - recall: 0.144 - ETA: 0s - loss: 1.3784 - accuracy: 0.4399 - precision: 0.6569 - recall: 0.161 - 1s 1ms/sample - loss: 1.3778 - accuracy: 0.4390 - precision: 0.6509 - recall: 0.1620 - val_loss: 1.4927 - val_accuracy: 0.4437 - val_precision: 0.6486 - val_recall: 0.1690\n",
      "Epoch 49/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4235 - accuracy: 0.4375 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.3717 - accuracy: 0.4688 - precision: 0.6786 - recall: 0.197 - ETA: 0s - loss: 1.3646 - accuracy: 0.4563 - precision: 0.6591 - recall: 0.181 - ETA: 0s - loss: 1.3839 - accuracy: 0.4509 - precision: 0.6333 - recall: 0.169 - ETA: 0s - loss: 1.3572 - accuracy: 0.4792 - precision: 0.5952 - recall: 0.173 - ETA: 0s - loss: 1.3566 - accuracy: 0.4545 - precision: 0.5743 - recall: 0.164 - ETA: 0s - loss: 1.3303 - accuracy: 0.4760 - precision: 0.6033 - recall: 0.175 - 1s 1ms/sample - loss: 1.3318 - accuracy: 0.4742 - precision: 0.5968 - recall: 0.1737 - val_loss: 1.5457 - val_accuracy: 0.3944 - val_precision: 0.5789 - val_recall: 0.1549\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5026 - accuracy: 0.3438 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.3136 - accuracy: 0.4792 - precision: 0.5946 - recall: 0.229 - ETA: 0s - loss: 1.2841 - accuracy: 0.5000 - precision: 0.6296 - recall: 0.212 - ETA: 0s - loss: 1.2493 - accuracy: 0.5045 - precision: 0.6575 - recall: 0.214 - ETA: 0s - loss: 1.2568 - accuracy: 0.5104 - precision: 0.6042 - recall: 0.201 - ETA: 0s - loss: 1.2380 - accuracy: 0.5170 - precision: 0.6290 - recall: 0.221 - ETA: 0s - loss: 1.2453 - accuracy: 0.5240 - precision: 0.6423 - recall: 0.211 - 1s 1ms/sample - loss: 1.2487 - accuracy: 0.5258 - precision: 0.6357 - recall: 0.2089 - val_loss: 1.4952 - val_accuracy: 0.4014 - val_precision: 0.6444 - val_recall: 0.2042\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2483 - accuracy: 0.5312 - precision: 0.6667 - recall: 0.312 - ETA: 0s - loss: 1.2968 - accuracy: 0.4583 - precision: 0.6216 - recall: 0.239 - ETA: 0s - loss: 1.3121 - accuracy: 0.4688 - precision: 0.6379 - recall: 0.231 - ETA: 0s - loss: 1.3366 - accuracy: 0.4598 - precision: 0.6463 - recall: 0.236 - ETA: 0s - loss: 1.3465 - accuracy: 0.4618 - precision: 0.6571 - recall: 0.239 - ETA: 0s - loss: 1.3756 - accuracy: 0.4375 - precision: 0.6378 - recall: 0.230 - ETA: 0s - loss: 1.3408 - accuracy: 0.4591 - precision: 0.6536 - recall: 0.240 - 1s 2ms/sample - loss: 1.3388 - accuracy: 0.4601 - precision: 0.6541 - recall: 0.2441 - val_loss: 1.4733 - val_accuracy: 0.4718 - val_precision: 0.6081 - val_recall: 0.3169\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2351 - accuracy: 0.5625 - precision: 0.5882 - recall: 0.312 - ETA: 0s - loss: 1.4166 - accuracy: 0.4375 - precision: 0.5000 - recall: 0.229 - ETA: 0s - loss: 1.3123 - accuracy: 0.4750 - precision: 0.5882 - recall: 0.250 - ETA: 0s - loss: 1.2824 - accuracy: 0.4866 - precision: 0.6222 - recall: 0.250 - ETA: 0s - loss: 1.2684 - accuracy: 0.5035 - precision: 0.6250 - recall: 0.243 - ETA: 0s - loss: 1.2533 - accuracy: 0.5028 - precision: 0.6489 - recall: 0.241 - ETA: 0s - loss: 1.2677 - accuracy: 0.4952 - precision: 0.6447 - recall: 0.235 - 1s 2ms/sample - loss: 1.2704 - accuracy: 0.4930 - precision: 0.6452 - recall: 0.2347 - val_loss: 1.2841 - val_accuracy: 0.5211 - val_precision: 0.6667 - val_recall: 0.2254\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.6250 - precision: 0.9231 - recall: 0.375 - ETA: 0s - loss: 1.0919 - accuracy: 0.6250 - precision: 0.8421 - recall: 0.333 - ETA: 0s - loss: 1.2114 - accuracy: 0.5250 - precision: 0.7031 - recall: 0.281 - ETA: 0s - loss: 1.2367 - accuracy: 0.5357 - precision: 0.6739 - recall: 0.276 - ETA: 0s - loss: 1.2225 - accuracy: 0.5243 - precision: 0.6774 - recall: 0.291 - ETA: 0s - loss: 1.2167 - accuracy: 0.5256 - precision: 0.6903 - recall: 0.304 - ETA: 0s - loss: 1.1940 - accuracy: 0.5505 - precision: 0.6966 - recall: 0.298 - 1s 1ms/sample - loss: 1.1911 - accuracy: 0.5493 - precision: 0.7000 - recall: 0.2958 - val_loss: 1.2825 - val_accuracy: 0.5000 - val_precision: 0.6230 - val_recall: 0.2676\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0486 - accuracy: 0.6562 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.0498 - accuracy: 0.6042 - precision: 0.7179 - recall: 0.291 - ETA: 0s - loss: 1.0284 - accuracy: 0.6250 - precision: 0.7037 - recall: 0.356 - ETA: 0s - loss: 1.1009 - accuracy: 0.5759 - precision: 0.6581 - recall: 0.343 - ETA: 0s - loss: 1.1473 - accuracy: 0.5590 - precision: 0.6433 - recall: 0.350 - ETA: 0s - loss: 1.1931 - accuracy: 0.5256 - precision: 0.6198 - recall: 0.338 - ETA: 0s - loss: 1.1908 - accuracy: 0.5312 - precision: 0.6272 - recall: 0.343 - 1s 2ms/sample - loss: 1.1820 - accuracy: 0.5305 - precision: 0.6293 - recall: 0.3427 - val_loss: 1.2283 - val_accuracy: 0.5775 - val_precision: 0.6579 - val_recall: 0.3521\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9290 - accuracy: 0.7188 - precision: 0.7895 - recall: 0.468 - ETA: 0s - loss: 1.0298 - accuracy: 0.6354 - precision: 0.7442 - recall: 0.333 - ETA: 0s - loss: 1.1123 - accuracy: 0.5562 - precision: 0.6486 - recall: 0.300 - ETA: 0s - loss: 1.1076 - accuracy: 0.5670 - precision: 0.6635 - recall: 0.308 - ETA: 0s - loss: 1.1814 - accuracy: 0.5208 - precision: 0.6615 - recall: 0.298 - ETA: 0s - loss: 1.2130 - accuracy: 0.5114 - precision: 0.6220 - recall: 0.289 - ETA: 0s - loss: 1.2401 - accuracy: 0.5052 - precision: 0.6171 - recall: 0.281 - 1s 1ms/sample - loss: 1.2127 - accuracy: 0.5188 - precision: 0.6308 - recall: 0.2887 - val_loss: 1.3937 - val_accuracy: 0.4577 - val_precision: 0.6500 - val_recall: 0.2746\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1394 - accuracy: 0.4688 - precision: 0.6875 - recall: 0.343 - ETA: 0s - loss: 1.1122 - accuracy: 0.4896 - precision: 0.6739 - recall: 0.322 - ETA: 0s - loss: 1.2455 - accuracy: 0.4688 - precision: 0.6377 - recall: 0.275 - ETA: 0s - loss: 1.3235 - accuracy: 0.4464 - precision: 0.5728 - recall: 0.263 - ETA: 0s - loss: 1.2929 - accuracy: 0.4583 - precision: 0.6032 - recall: 0.263 - ETA: 0s - loss: 1.2966 - accuracy: 0.4744 - precision: 0.6216 - recall: 0.261 - ETA: 0s - loss: 1.3222 - accuracy: 0.4591 - precision: 0.6303 - recall: 0.250 - 1s 1ms/sample - loss: 1.3237 - accuracy: 0.4531 - precision: 0.6325 - recall: 0.2465 - val_loss: 1.5095 - val_accuracy: 0.4014 - val_precision: 0.5714 - val_recall: 0.2535\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4201 - accuracy: 0.4062 - precision: 0.5333 - recall: 0.250 - ETA: 0s - loss: 1.4208 - accuracy: 0.4271 - precision: 0.5000 - recall: 0.260 - ETA: 0s - loss: 1.5045 - accuracy: 0.3875 - precision: 0.4545 - recall: 0.218 - ETA: 0s - loss: 1.5181 - accuracy: 0.4107 - precision: 0.4688 - recall: 0.200 - ETA: 0s - loss: 1.4943 - accuracy: 0.4167 - precision: 0.4870 - recall: 0.194 - ETA: 0s - loss: 1.5003 - accuracy: 0.4062 - precision: 0.4844 - recall: 0.176 - ETA: 0s - loss: 1.4870 - accuracy: 0.4111 - precision: 0.5235 - recall: 0.187 - 1s 1ms/sample - loss: 1.4834 - accuracy: 0.4202 - precision: 0.5232 - recall: 0.1854 - val_loss: 1.7211 - val_accuracy: 0.3873 - val_precision: 0.4762 - val_recall: 0.1408\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6535 - accuracy: 0.4375 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.4769 - accuracy: 0.5104 - precision: 0.6486 - recall: 0.250 - ETA: 0s - loss: 1.4672 - accuracy: 0.4812 - precision: 0.6327 - recall: 0.193 - ETA: 0s - loss: 1.4496 - accuracy: 0.4821 - precision: 0.6094 - recall: 0.174 - ETA: 0s - loss: 1.3922 - accuracy: 0.4826 - precision: 0.6437 - recall: 0.194 - ETA: 0s - loss: 1.4049 - accuracy: 0.4574 - precision: 0.6226 - recall: 0.187 - ETA: 0s - loss: 1.3982 - accuracy: 0.4543 - precision: 0.6080 - recall: 0.182 - 1s 1ms/sample - loss: 1.3948 - accuracy: 0.4577 - precision: 0.6142 - recall: 0.1831 - val_loss: 1.4458 - val_accuracy: 0.4296 - val_precision: 0.6176 - val_recall: 0.1479\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3589 - accuracy: 0.5312 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.2698 - accuracy: 0.5000 - precision: 0.6000 - recall: 0.140 - ETA: 0s - loss: 1.2670 - accuracy: 0.4375 - precision: 0.6296 - recall: 0.132 - ETA: 0s - loss: 1.2700 - accuracy: 0.4271 - precision: 0.6053 - recall: 0.119 - ETA: 0s - loss: 1.3050 - accuracy: 0.4336 - precision: 0.6071 - recall: 0.132 - ETA: 0s - loss: 1.3033 - accuracy: 0.4313 - precision: 0.6400 - recall: 0.150 - ETA: 0s - loss: 1.3207 - accuracy: 0.4219 - precision: 0.6263 - recall: 0.161 - 1s 1ms/sample - loss: 1.3096 - accuracy: 0.4343 - precision: 0.6581 - recall: 0.1808 - val_loss: 1.6012 - val_accuracy: 0.4225 - val_precision: 0.6829 - val_recall: 0.1972\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4570 - accuracy: 0.4375 - precision: 0.7778 - recall: 0.218 - ETA: 0s - loss: 1.4136 - accuracy: 0.4792 - precision: 0.7000 - recall: 0.218 - ETA: 0s - loss: 1.6679 - accuracy: 0.3938 - precision: 0.5517 - recall: 0.200 - ETA: 0s - loss: 2.1115 - accuracy: 0.3170 - precision: 0.3486 - recall: 0.169 - ETA: 0s - loss: 2.1910 - accuracy: 0.2951 - precision: 0.2875 - recall: 0.159 - ETA: 0s - loss: 2.2077 - accuracy: 0.2812 - precision: 0.2857 - recall: 0.142 - ETA: 0s - loss: 2.3223 - accuracy: 0.2668 - precision: 0.2881 - recall: 0.122 - 1s 1ms/sample - loss: 2.3235 - accuracy: 0.2629 - precision: 0.2881 - recall: 0.1197 - val_loss: 2.3295 - val_accuracy: 0.1549 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0699 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 2.1495 - accuracy: 0.1667 - precision: 0.3333 - recall: 0.0104        - ETA: 0s - loss: 2.1155 - accuracy: 0.1750 - precision: 0.3750 - recall: 0.018 - ETA: 0s - loss: 2.0759 - accuracy: 0.1786 - precision: 0.2143 - recall: 0.013 - ETA: 0s - loss: 2.0618 - accuracy: 0.1875 - precision: 0.3478 - recall: 0.027 - ETA: 0s - loss: 2.0244 - accuracy: 0.1989 - precision: 0.3611 - recall: 0.036 - ETA: 0s - loss: 2.0252 - accuracy: 0.2019 - precision: 0.3958 - recall: 0.045 - 1s 1ms/sample - loss: 2.0209 - accuracy: 0.2019 - precision: 0.3958 - recall: 0.0446 - val_loss: 1.8337 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0945 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9521 - accuracy: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9172 - accuracy: 0.2250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8856 - accuracy: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8801 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8841 - accuracy: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8749 - accuracy: 0.2332 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8767 - accuracy: 0.2371 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7883 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8843 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8708 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8722 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8386 - accuracy: 0.2545 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8377 - accuracy: 0.2431 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8182 - accuracy: 0.2443 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8280 - accuracy: 0.2404 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8253 - accuracy: 0.2394 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7620 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7264 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8016 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7871 - accuracy: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7973 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7804 - accuracy: 0.2431 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7763 - accuracy: 0.2358 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7822 - accuracy: 0.2332 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.7980 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7878 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.7316 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7621 - accuracy: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7582 - accuracy: 0.2438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7690 - accuracy: 0.2366 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8070 - accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7987 - accuracy: 0.2330 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8195 - accuracy: 0.2212 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8135 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7227 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7390 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7006 - accuracy: 0.3229 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7392 - accuracy: 0.3000 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7772 - accuracy: 0.2589 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7873 - accuracy: 0.2639 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7882 - accuracy: 0.2528 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7849 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.0024        - 1s 1ms/sample - loss: 1.7840 - accuracy: 0.2512 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.7130 - val_accuracy: 0.2606 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7280 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7316 - accuracy: 0.3125 - precision: 0.8000 - recall: 0.041 - ETA: 0s - loss: 1.7723 - accuracy: 0.2688 - precision: 0.6429 - recall: 0.056 - ETA: 0s - loss: 1.7713 - accuracy: 0.2411 - precision: 0.6087 - recall: 0.062 - ETA: 0s - loss: 1.7591 - accuracy: 0.2535 - precision: 0.6154 - recall: 0.055 - ETA: 0s - loss: 1.7885 - accuracy: 0.2443 - precision: 0.5714 - recall: 0.045 - ETA: 0s - loss: 1.8005 - accuracy: 0.2428 - precision: 0.5714 - recall: 0.038 - 1s 1ms/sample - loss: 1.8029 - accuracy: 0.2394 - precision: 0.5714 - recall: 0.0376 - val_loss: 1.8225 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0298 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9166 - accuracy: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8546 - accuracy: 0.2250 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8466 - accuracy: 0.2366 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8079 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.0035        - ETA: 0s - loss: 1.8164 - accuracy: 0.2244 - precision: 1.0000 - recall: 0.002 - ETA: 0s - loss: 1.8187 - accuracy: 0.2332 - precision: 1.0000 - recall: 0.004 - 1s 1ms/sample - loss: 1.8158 - accuracy: 0.2300 - precision: 0.5000 - recall: 0.0047 - val_loss: 1.7655 - val_accuracy: 0.2535 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9710 - accuracy: 0.1562 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.7998 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8515 - accuracy: 0.2250 - precision: 1.0000 - recall: 0.018 - ETA: 0s - loss: 1.8378 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.013 - ETA: 0s - loss: 1.8532 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.8376 - accuracy: 0.2102 - precision: 1.0000 - recall: 0.011 - ETA: 0s - loss: 1.8595 - accuracy: 0.2163 - precision: 1.0000 - recall: 0.009 - 1s 1ms/sample - loss: 1.8573 - accuracy: 0.2136 - precision: 1.0000 - recall: 0.0094 - val_loss: 1.7436 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6055 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7777 - accuracy: 0.2812 - precision: 0.8000 - recall: 0.0417        - ETA: 0s - loss: 1.8029 - accuracy: 0.2750 - precision: 0.5500 - recall: 0.068 - ETA: 0s - loss: 1.9164 - accuracy: 0.2589 - precision: 0.4800 - recall: 0.053 - ETA: 0s - loss: 1.9108 - accuracy: 0.2465 - precision: 0.4800 - recall: 0.041 - ETA: 0s - loss: 1.9313 - accuracy: 0.2216 - precision: 0.4800 - recall: 0.034 - ETA: 0s - loss: 1.9027 - accuracy: 0.2212 - precision: 0.4800 - recall: 0.028 - 1s 1ms/sample - loss: 1.9014 - accuracy: 0.2160 - precision: 0.4800 - recall: 0.0282 - val_loss: 1.7756 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8939 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8356 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8399 - accuracy: 0.2375 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8641 - accuracy: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8792 - accuracy: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8594 - accuracy: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8402 - accuracy: 0.2260 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8351 - accuracy: 0.2230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7419 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9667 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8620 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8251 - accuracy: 0.2625 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8053 - accuracy: 0.2455 - precision: 0.2500 - recall: 0.0045        - ETA: 0s - loss: 1.8014 - accuracy: 0.2431 - precision: 0.5714 - recall: 0.013 - ETA: 0s - loss: 1.7800 - accuracy: 0.2301 - precision: 0.5714 - recall: 0.011 - ETA: 0s - loss: 1.7957 - accuracy: 0.2163 - precision: 0.5714 - recall: 0.009 - 1s 1ms/sample - loss: 1.8088 - accuracy: 0.2113 - precision: 0.5714 - recall: 0.0094 - val_loss: 1.8034 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7268 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7953 - accuracy: 0.2708 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8484 - accuracy: 0.2937 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8490 - accuracy: 0.2589 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8515 - accuracy: 0.2639 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8554 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8655 - accuracy: 0.2356 - precision: 0.0000e+00 - recall: 0.0000e+0 - 1s 1ms/sample - loss: 1.8549 - accuracy: 0.2441 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7554 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7477 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7680 - accuracy: 0.3438 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.8164 - accuracy: 0.2937 - precision: 0.6667 - recall: 0.0250        - ETA: 0s - loss: 1.8539 - accuracy: 0.2723 - precision: 0.5000 - recall: 0.022 - ETA: 0s - loss: 1.8822 - accuracy: 0.2465 - precision: 0.6000 - recall: 0.031 - ETA: 0s - loss: 1.9438 - accuracy: 0.2330 - precision: 0.5000 - recall: 0.025 - ETA: 0s - loss: 2.0032 - accuracy: 0.2139 - precision: 0.5238 - recall: 0.026 - 1s 2ms/sample - loss: 2.0140 - accuracy: 0.2113 - precision: 0.5238 - recall: 0.0258 - val_loss: 1.7965 - val_accuracy: 0.1901 - val_precision: 0.5833 - val_recall: 0.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9932 - accuracy: 0.1562 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9999 - accuracy: 0.1719 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.9042 - accuracy: 0.1797 - precision: 0.3333 - recall: 0.0391        - ETA: 0s - loss: 1.9097 - accuracy: 0.1927 - precision: 0.3462 - recall: 0.046 - ETA: 0s - loss: 1.8815 - accuracy: 0.2054 - precision: 0.4000 - recall: 0.053 - ETA: 0s - loss: 1.8701 - accuracy: 0.2014 - precision: 0.4615 - recall: 0.062 - ETA: 0s - loss: 1.8671 - accuracy: 0.2045 - precision: 0.5116 - recall: 0.062 - ETA: 0s - loss: 1.8501 - accuracy: 0.2214 - precision: 0.5116 - recall: 0.057 - 1s 2ms/sample - loss: 1.8609 - accuracy: 0.2277 - precision: 0.5116 - recall: 0.0516 - val_loss: 1.7722 - val_accuracy: 0.2394 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8487 - accuracy: 0.1875 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.8725 - accuracy: 0.2708 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 1.8213 - accuracy: 0.2438 - precision: 1.0000 - recall: 0.006 - ETA: 0s - loss: 1.8214 - accuracy: 0.2455 - precision: 0.6667 - recall: 0.008 - ETA: 0s - loss: 1.8101 - accuracy: 0.2535 - precision: 0.6667 - recall: 0.006 - ETA: 0s - loss: 1.8124 - accuracy: 0.2301 - precision: 0.7500 - recall: 0.008 - ETA: 0s - loss: 1.8209 - accuracy: 0.2266 - precision: 0.6250 - recall: 0.013 - 1s 2ms/sample - loss: 1.7991 - accuracy: 0.2347 - precision: 0.7143 - recall: 0.0235 - val_loss: 1.7495 - val_accuracy: 0.2042 - val_precision: 0.5333 - val_recall: 0.0563\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5381 - accuracy: 0.4375 - precision: 1.0000 - recall: 0.187 - ETA: 0s - loss: 1.7026 - accuracy: 0.3229 - precision: 0.7857 - recall: 0.114 - ETA: 0s - loss: 1.7176 - accuracy: 0.2875 - precision: 0.7778 - recall: 0.087 - ETA: 0s - loss: 1.7128 - accuracy: 0.2857 - precision: 0.7143 - recall: 0.089 - ETA: 0s - loss: 1.7155 - accuracy: 0.2778 - precision: 0.6571 - recall: 0.079 - ETA: 0s - loss: 1.7540 - accuracy: 0.2557 - precision: 0.6154 - recall: 0.068 - ETA: 0s - loss: 1.7602 - accuracy: 0.2572 - precision: 0.6136 - recall: 0.064 - 1s 1ms/sample - loss: 1.7694 - accuracy: 0.2535 - precision: 0.6000 - recall: 0.0634 - val_loss: 1.7685 - val_accuracy: 0.2183 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8359 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8319 - accuracy: 0.2500 - precision: 0.5000 - recall: 0.010 - ETA: 0s - loss: 1.8472 - accuracy: 0.2000 - precision: 0.5000 - recall: 0.006 - ETA: 0s - loss: 1.8233 - accuracy: 0.2366 - precision: 0.7500 - recall: 0.013 - ETA: 0s - loss: 1.8016 - accuracy: 0.2465 - precision: 0.7143 - recall: 0.017 - ETA: 0s - loss: 1.7944 - accuracy: 0.2472 - precision: 0.7273 - recall: 0.022 - ETA: 0s - loss: 1.7923 - accuracy: 0.2356 - precision: 0.6364 - recall: 0.033 - 1s 1ms/sample - loss: 1.8004 - accuracy: 0.2371 - precision: 0.6087 - recall: 0.0329 - val_loss: 1.7531 - val_accuracy: 0.2676 - val_precision: 0.5200 - val_recall: 0.0915\n",
      "Epoch 79/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8175 - accuracy: 0.2500 - precision: 0.4444 - recall: 0.125 - ETA: 0s - loss: 1.8001 - accuracy: 0.2708 - precision: 0.3529 - recall: 0.062 - ETA: 0s - loss: 1.8188 - accuracy: 0.2438 - precision: 0.3529 - recall: 0.037 - ETA: 0s - loss: 1.7863 - accuracy: 0.2589 - precision: 0.3529 - recall: 0.026 - ETA: 0s - loss: 1.8097 - accuracy: 0.2431 - precision: 0.3529 - recall: 0.020 - ETA: 0s - loss: 1.8105 - accuracy: 0.2273 - precision: 0.3529 - recall: 0.017 - ETA: 0s - loss: 1.8125 - accuracy: 0.2332 - precision: 0.3529 - recall: 0.014 - 1s 1ms/sample - loss: 1.8071 - accuracy: 0.2371 - precision: 0.3529 - recall: 0.0141 - val_loss: 1.7665 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7006 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7381 - accuracy: 0.2604 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7935 - accuracy: 0.2688 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7835 - accuracy: 0.2500 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7950 - accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7801 - accuracy: 0.2415 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7721 - accuracy: 0.2452 - precision: 0.7143 - recall: 0.0120        - 1s 1ms/sample - loss: 1.7699 - accuracy: 0.2418 - precision: 0.7500 - recall: 0.0141 - val_loss: 1.7203 - val_accuracy: 0.2535 - val_precision: 0.5238 - val_recall: 0.0775\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7107 - accuracy: 0.3125 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.7676 - accuracy: 0.2500 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.7630 - accuracy: 0.2188 - precision: 0.3750 - recall: 0.056 - ETA: 0s - loss: 1.7505 - accuracy: 0.2455 - precision: 0.4286 - recall: 0.067 - ETA: 0s - loss: 1.7622 - accuracy: 0.2431 - precision: 0.4750 - recall: 0.066 - ETA: 0s - loss: 1.7726 - accuracy: 0.2386 - precision: 0.5417 - recall: 0.073 - ETA: 0s - loss: 1.7754 - accuracy: 0.2236 - precision: 0.5385 - recall: 0.067 - 1s 1ms/sample - loss: 1.7677 - accuracy: 0.2277 - precision: 0.5472 - recall: 0.0681 - val_loss: 1.7183 - val_accuracy: 0.2042 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8532 - accuracy: 0.2812 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7663 - accuracy: 0.3125 - precision: 0.7000 - recall: 0.0729        - ETA: 0s - loss: 1.7895 - accuracy: 0.2875 - precision: 0.6471 - recall: 0.068 - ETA: 0s - loss: 1.7515 - accuracy: 0.2812 - precision: 0.6364 - recall: 0.062 - ETA: 0s - loss: 1.7735 - accuracy: 0.2569 - precision: 0.6129 - recall: 0.066 - ETA: 0s - loss: 1.7756 - accuracy: 0.2415 - precision: 0.5882 - recall: 0.056 - ETA: 0s - loss: 1.7733 - accuracy: 0.2380 - precision: 0.5676 - recall: 0.050 - 1s 1ms/sample - loss: 1.7707 - accuracy: 0.2418 - precision: 0.5897 - recall: 0.0540 - val_loss: 1.7296 - val_accuracy: 0.2394 - val_precision: 0.8333 - val_recall: 0.0352\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7560 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7519 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.031 - ETA: 0s - loss: 1.7440 - accuracy: 0.3125 - precision: 0.7692 - recall: 0.062 - ETA: 0s - loss: 1.7354 - accuracy: 0.3036 - precision: 0.7000 - recall: 0.062 - ETA: 0s - loss: 1.7639 - accuracy: 0.2812 - precision: 0.6207 - recall: 0.062 - ETA: 0s - loss: 1.7519 - accuracy: 0.2955 - precision: 0.6053 - recall: 0.065 - ETA: 0s - loss: 1.7495 - accuracy: 0.2909 - precision: 0.6279 - recall: 0.064 - 1s 1ms/sample - loss: 1.7582 - accuracy: 0.2840 - precision: 0.6279 - recall: 0.0634 - val_loss: 1.7170 - val_accuracy: 0.2676 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7209 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.7604 - accuracy: 0.2188 - precision: 0.5714 - recall: 0.041 - ETA: 0s - loss: 1.7850 - accuracy: 0.2562 - precision: 0.5833 - recall: 0.043 - ETA: 0s - loss: 1.7786 - accuracy: 0.2589 - precision: 0.5625 - recall: 0.040 - ETA: 0s - loss: 1.7662 - accuracy: 0.2569 - precision: 0.6000 - recall: 0.052 - ETA: 0s - loss: 1.7667 - accuracy: 0.2614 - precision: 0.5833 - recall: 0.059 - ETA: 0s - loss: 1.7856 - accuracy: 0.2596 - precision: 0.5435 - recall: 0.060 - 1s 1ms/sample - loss: 1.7870 - accuracy: 0.2559 - precision: 0.5417 - recall: 0.0610 - val_loss: 1.7379 - val_accuracy: 0.2324 - val_precision: 0.5385 - val_recall: 0.0986\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7663 - accuracy: 0.2500 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.7428 - accuracy: 0.2917 - precision: 0.5385 - recall: 0.072 - ETA: 0s - loss: 1.7230 - accuracy: 0.3000 - precision: 0.5882 - recall: 0.062 - ETA: 0s - loss: 1.7156 - accuracy: 0.2946 - precision: 0.5238 - recall: 0.049 - ETA: 0s - loss: 1.7428 - accuracy: 0.2882 - precision: 0.5217 - recall: 0.041 - ETA: 0s - loss: 1.7731 - accuracy: 0.2727 - precision: 0.5217 - recall: 0.034 - ETA: 0s - loss: 1.7701 - accuracy: 0.2716 - precision: 0.5600 - recall: 0.033 - 1s 1ms/sample - loss: 1.7798 - accuracy: 0.2676 - precision: 0.5600 - recall: 0.0329 - val_loss: 1.7270 - val_accuracy: 0.2535 - val_precision: 0.6923 - val_recall: 0.0634\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7069 - accuracy: 0.2812 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.7568 - accuracy: 0.2812 - precision: 0.5556 - recall: 0.052 - ETA: 0s - loss: 1.7541 - accuracy: 0.2875 - precision: 0.5833 - recall: 0.043 - ETA: 0s - loss: 1.7565 - accuracy: 0.2946 - precision: 0.5789 - recall: 0.049 - ETA: 0s - loss: 1.7660 - accuracy: 0.2812 - precision: 0.5417 - recall: 0.045 - ETA: 0s - loss: 1.7763 - accuracy: 0.2585 - precision: 0.5000 - recall: 0.039 - ETA: 0s - loss: 1.7650 - accuracy: 0.2620 - precision: 0.5476 - recall: 0.055 - 1s 1ms/sample - loss: 1.7662 - accuracy: 0.2559 - precision: 0.5349 - recall: 0.0540 - val_loss: 1.7031 - val_accuracy: 0.2254 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8043 - accuracy: 0.2188 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.6172 - accuracy: 0.3438 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.7509 - accuracy: 0.2812 - precision: 0.6522 - recall: 0.093 - ETA: 0s - loss: 1.7179 - accuracy: 0.2723 - precision: 0.5862 - recall: 0.075 - ETA: 0s - loss: 1.7119 - accuracy: 0.2708 - precision: 0.6364 - recall: 0.072 - ETA: 0s - loss: 1.7242 - accuracy: 0.2557 - precision: 0.6389 - recall: 0.065 - ETA: 0s - loss: 1.7476 - accuracy: 0.2500 - precision: 0.6486 - recall: 0.057 - 1s 1ms/sample - loss: 1.7455 - accuracy: 0.2512 - precision: 0.6486 - recall: 0.0563 - val_loss: 1.7110 - val_accuracy: 0.2254 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7605 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7603 - accuracy: 0.3333 - precision: 0.4000 - recall: 0.0417        - ETA: 0s - loss: 1.7533 - accuracy: 0.3250 - precision: 0.5926 - recall: 0.100 - ETA: 0s - loss: 1.7593 - accuracy: 0.2902 - precision: 0.5128 - recall: 0.089 - ETA: 0s - loss: 1.7677 - accuracy: 0.2743 - precision: 0.5106 - recall: 0.083 - ETA: 0s - loss: 1.7634 - accuracy: 0.2642 - precision: 0.5306 - recall: 0.073 - ETA: 0s - loss: 1.7582 - accuracy: 0.2548 - precision: 0.5400 - recall: 0.064 - 1s 1ms/sample - loss: 1.7499 - accuracy: 0.2606 - precision: 0.5400 - recall: 0.0634 - val_loss: 1.7113 - val_accuracy: 0.2606 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8302 - accuracy: 0.3125 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7342 - accuracy: 0.2604 - precision: 1.0000 - recall: 0.0208        - ETA: 0s - loss: 1.7606 - accuracy: 0.2625 - precision: 1.0000 - recall: 0.018 - ETA: 0s - loss: 1.7422 - accuracy: 0.2455 - precision: 0.5000 - recall: 0.026 - ETA: 0s - loss: 1.7429 - accuracy: 0.2465 - precision: 0.5789 - recall: 0.038 - ETA: 0s - loss: 1.7394 - accuracy: 0.2528 - precision: 0.5172 - recall: 0.042 - ETA: 0s - loss: 1.7394 - accuracy: 0.2620 - precision: 0.5946 - recall: 0.052 - 1s 1ms/sample - loss: 1.7380 - accuracy: 0.2606 - precision: 0.5897 - recall: 0.0540 - val_loss: 1.7090 - val_accuracy: 0.2465 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6316 - accuracy: 0.2188 - precision: 0.3333 - recall: 0.062 - ETA: 0s - loss: 1.6919 - accuracy: 0.3125 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.7136 - accuracy: 0.2812 - precision: 0.6522 - recall: 0.093 - ETA: 0s - loss: 1.7278 - accuracy: 0.2589 - precision: 0.5556 - recall: 0.067 - ETA: 0s - loss: 1.7181 - accuracy: 0.2743 - precision: 0.6286 - recall: 0.076 - ETA: 0s - loss: 1.7230 - accuracy: 0.2699 - precision: 0.6042 - recall: 0.082 - ETA: 0s - loss: 1.7151 - accuracy: 0.2692 - precision: 0.6078 - recall: 0.074 - 1s 1ms/sample - loss: 1.7199 - accuracy: 0.2676 - precision: 0.5849 - recall: 0.0728 - val_loss: 1.7200 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0352\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6681 - accuracy: 0.2812 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.7064 - accuracy: 0.2708 - precision: 0.6250 - recall: 0.052 - ETA: 0s - loss: 1.7089 - accuracy: 0.2375 - precision: 0.6250 - recall: 0.031 - ETA: 0s - loss: 1.7208 - accuracy: 0.2411 - precision: 0.6250 - recall: 0.022 - ETA: 0s - loss: 1.7490 - accuracy: 0.2569 - precision: 0.6250 - recall: 0.017 - ETA: 0s - loss: 1.7421 - accuracy: 0.2557 - precision: 0.7273 - recall: 0.022 - ETA: 0s - loss: 1.7145 - accuracy: 0.2668 - precision: 0.7000 - recall: 0.033 - 1s 1ms/sample - loss: 1.7166 - accuracy: 0.2629 - precision: 0.7000 - recall: 0.0329 - val_loss: 1.7273 - val_accuracy: 0.2254 - val_precision: 0.5417 - val_recall: 0.0915\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7636 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7779 - accuracy: 0.2917 - precision: 0.5000 - recall: 0.072 - ETA: 0s - loss: 1.7528 - accuracy: 0.2875 - precision: 0.5312 - recall: 0.106 - ETA: 0s - loss: 1.7225 - accuracy: 0.2902 - precision: 0.5581 - recall: 0.107 - ETA: 0s - loss: 1.7284 - accuracy: 0.2951 - precision: 0.5833 - recall: 0.097 - ETA: 0s - loss: 1.7211 - accuracy: 0.2926 - precision: 0.5926 - recall: 0.090 - ETA: 0s - loss: 1.7311 - accuracy: 0.2837 - precision: 0.5690 - recall: 0.079 - 1s 1ms/sample - loss: 1.7342 - accuracy: 0.2840 - precision: 0.5500 - recall: 0.0775 - val_loss: 1.7020 - val_accuracy: 0.2465 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5471 - accuracy: 0.4062 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.6180 - accuracy: 0.3021 - precision: 0.7222 - recall: 0.135 - ETA: 0s - loss: 1.6808 - accuracy: 0.2750 - precision: 0.5667 - recall: 0.106 - ETA: 0s - loss: 1.6553 - accuracy: 0.2991 - precision: 0.6286 - recall: 0.098 - ETA: 0s - loss: 1.6892 - accuracy: 0.2708 - precision: 0.6410 - recall: 0.086 - ETA: 0s - loss: 1.7116 - accuracy: 0.2614 - precision: 0.6500 - recall: 0.073 - ETA: 0s - loss: 1.7045 - accuracy: 0.2644 - precision: 0.6341 - recall: 0.062 - 1s 1ms/sample - loss: 1.7070 - accuracy: 0.2606 - precision: 0.6341 - recall: 0.0610 - val_loss: 1.7330 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8008 - accuracy: 0.2188 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 1.7406 - accuracy: 0.3021 - precision: 1.0000 - recall: 0.020 - ETA: 0s - loss: 1.7224 - accuracy: 0.2969 - precision: 0.8000 - recall: 0.031 - ETA: 0s - loss: 1.7429 - accuracy: 0.2760 - precision: 0.6667 - recall: 0.020 - ETA: 0s - loss: 1.7257 - accuracy: 0.2773 - precision: 0.7778 - recall: 0.027 - ETA: 0s - loss: 1.7164 - accuracy: 0.2750 - precision: 0.6500 - recall: 0.040 - ETA: 0s - loss: 1.7351 - accuracy: 0.2708 - precision: 0.5588 - recall: 0.049 - 1s 1ms/sample - loss: 1.7603 - accuracy: 0.2582 - precision: 0.5128 - recall: 0.0469 - val_loss: 1.7332 - val_accuracy: 0.2465 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.6775 - accuracy: 0.2812 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.7354 - accuracy: 0.3021 - precision: 0.6667 - recall: 0.041 - ETA: 0s - loss: 1.7581 - accuracy: 0.2875 - precision: 0.7143 - recall: 0.031 - ETA: 0s - loss: 1.7340 - accuracy: 0.2723 - precision: 0.6000 - recall: 0.026 - ETA: 0s - loss: 1.7292 - accuracy: 0.2708 - precision: 0.6364 - recall: 0.024 - ETA: 0s - loss: 1.7382 - accuracy: 0.2727 - precision: 0.6667 - recall: 0.022 - ETA: 0s - loss: 1.7260 - accuracy: 0.2788 - precision: 0.7143 - recall: 0.036 - 1s 1ms/sample - loss: 1.7283 - accuracy: 0.2770 - precision: 0.6818 - recall: 0.0352 - val_loss: 1.6986 - val_accuracy: 0.2394 - val_precision: 0.5200 - val_recall: 0.0915\n",
      "Epoch 96/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6400 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.7123 - accuracy: 0.3021 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.7751 - accuracy: 0.2812 - precision: 0.6190 - recall: 0.081 - ETA: 0s - loss: 1.7145 - accuracy: 0.2946 - precision: 0.6552 - recall: 0.084 - ETA: 0s - loss: 1.7280 - accuracy: 0.2674 - precision: 0.6471 - recall: 0.076 - ETA: 0s - loss: 1.7138 - accuracy: 0.2784 - precision: 0.6250 - recall: 0.071 - ETA: 0s - loss: 1.7216 - accuracy: 0.2788 - precision: 0.6531 - recall: 0.076 - 1s 1ms/sample - loss: 1.7189 - accuracy: 0.2770 - precision: 0.6531 - recall: 0.0751 - val_loss: 1.7220 - val_accuracy: 0.2465 - val_precision: 0.7778 - val_recall: 0.0493\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6359 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.062 - ETA: 0s - loss: 1.6686 - accuracy: 0.3021 - precision: 0.7500 - recall: 0.062 - ETA: 0s - loss: 1.7448 - accuracy: 0.2688 - precision: 0.6667 - recall: 0.050 - ETA: 0s - loss: 1.7246 - accuracy: 0.2723 - precision: 0.7222 - recall: 0.058 - ETA: 0s - loss: 1.7570 - accuracy: 0.2639 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7303 - accuracy: 0.2727 - precision: 0.6667 - recall: 0.068 - ETA: 0s - loss: 1.7270 - accuracy: 0.2740 - precision: 0.6429 - recall: 0.064 - 1s 1ms/sample - loss: 1.7310 - accuracy: 0.2676 - precision: 0.6429 - recall: 0.0634 - val_loss: 1.6975 - val_accuracy: 0.2676 - val_precision: 0.7059 - val_recall: 0.0845\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7536 - accuracy: 0.1875 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.6007 - accuracy: 0.3125 - precision: 0.5625 - recall: 0.093 - ETA: 0s - loss: 1.6137 - accuracy: 0.3125 - precision: 0.6500 - recall: 0.081 - ETA: 0s - loss: 1.6261 - accuracy: 0.2991 - precision: 0.6923 - recall: 0.080 - ETA: 0s - loss: 1.6624 - accuracy: 0.2674 - precision: 0.7241 - recall: 0.072 - ETA: 0s - loss: 1.6612 - accuracy: 0.2670 - precision: 0.7353 - recall: 0.071 - ETA: 0s - loss: 1.7020 - accuracy: 0.2644 - precision: 0.6512 - recall: 0.067 - 1s 1ms/sample - loss: 1.7063 - accuracy: 0.2606 - precision: 0.6512 - recall: 0.0657 - val_loss: 1.6911 - val_accuracy: 0.2465 - val_precision: 0.5909 - val_recall: 0.0915\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6273 - accuracy: 0.4062 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.6178 - accuracy: 0.3958 - precision: 0.5500 - recall: 0.114 - ETA: 0s - loss: 1.6213 - accuracy: 0.3313 - precision: 0.5769 - recall: 0.093 - ETA: 0s - loss: 1.6702 - accuracy: 0.2768 - precision: 0.5862 - recall: 0.075 - ETA: 0s - loss: 1.6759 - accuracy: 0.2917 - precision: 0.6111 - recall: 0.076 - ETA: 0s - loss: 1.6953 - accuracy: 0.2841 - precision: 0.6341 - recall: 0.073 - ETA: 0s - loss: 1.7034 - accuracy: 0.2740 - precision: 0.6444 - recall: 0.069 - 1s 1ms/sample - loss: 1.7044 - accuracy: 0.2723 - precision: 0.6444 - recall: 0.0681 - val_loss: 1.6955 - val_accuracy: 0.2394 - val_precision: 0.7500 - val_recall: 0.0845\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9314 - accuracy: 0.1875 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.8100 - accuracy: 0.2188 - precision: 0.4286 - recall: 0.031 - ETA: 0s - loss: 1.7418 - accuracy: 0.2875 - precision: 0.5882 - recall: 0.062 - ETA: 0s - loss: 1.7251 - accuracy: 0.2768 - precision: 0.6000 - recall: 0.053 - ETA: 0s - loss: 1.6802 - accuracy: 0.3021 - precision: 0.6923 - recall: 0.062 - ETA: 0s - loss: 1.6922 - accuracy: 0.2955 - precision: 0.6452 - recall: 0.056 - ETA: 0s - loss: 1.7033 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.052 - 1s 1ms/sample - loss: 1.7066 - accuracy: 0.2817 - precision: 0.6765 - recall: 0.0540 - val_loss: 1.6966 - val_accuracy: 0.2535 - val_precision: 0.6471 - val_recall: 0.0775\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6594 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6164 - accuracy: 0.3229 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.6529 - accuracy: 0.3187 - precision: 0.7308 - recall: 0.118 - ETA: 0s - loss: 1.6730 - accuracy: 0.3080 - precision: 0.7333 - recall: 0.098 - ETA: 0s - loss: 1.6656 - accuracy: 0.3229 - precision: 0.6579 - recall: 0.086 - ETA: 0s - loss: 1.6811 - accuracy: 0.2983 - precision: 0.6087 - recall: 0.079 - ETA: 0s - loss: 1.6864 - accuracy: 0.2812 - precision: 0.6327 - recall: 0.074 - 1s 1ms/sample - loss: 1.6835 - accuracy: 0.2817 - precision: 0.6346 - recall: 0.0775 - val_loss: 1.7006 - val_accuracy: 0.2606 - val_precision: 0.7059 - val_recall: 0.0845\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6871 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7084 - accuracy: 0.1875 - precision: 0.4000 - recall: 0.041 - ETA: 0s - loss: 1.7280 - accuracy: 0.2250 - precision: 0.5333 - recall: 0.050 - ETA: 0s - loss: 1.7168 - accuracy: 0.2500 - precision: 0.5385 - recall: 0.062 - ETA: 0s - loss: 1.7138 - accuracy: 0.2708 - precision: 0.5938 - recall: 0.066 - ETA: 0s - loss: 1.7223 - accuracy: 0.2688 - precision: 0.5714 - recall: 0.062 - ETA: 0s - loss: 1.7054 - accuracy: 0.2708 - precision: 0.6000 - recall: 0.062 - 1s 2ms/sample - loss: 1.6939 - accuracy: 0.2793 - precision: 0.6531 - recall: 0.0751 - val_loss: 1.7059 - val_accuracy: 0.2535 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7551 - accuracy: 0.2500 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.7317 - accuracy: 0.2396 - precision: 0.6364 - recall: 0.072 - ETA: 0s - loss: 1.6836 - accuracy: 0.2500 - precision: 0.6250 - recall: 0.093 - ETA: 0s - loss: 1.6983 - accuracy: 0.2723 - precision: 0.5806 - recall: 0.080 - ETA: 0s - loss: 1.6909 - accuracy: 0.2674 - precision: 0.6316 - recall: 0.083 - ETA: 0s - loss: 1.6859 - accuracy: 0.2585 - precision: 0.6889 - recall: 0.088 - ETA: 0s - loss: 1.6907 - accuracy: 0.2596 - precision: 0.6800 - recall: 0.081 - 1s 1ms/sample - loss: 1.6940 - accuracy: 0.2629 - precision: 0.6667 - recall: 0.0798 - val_loss: 1.6947 - val_accuracy: 0.2394 - val_precision: 0.6842 - val_recall: 0.0915\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6964 - accuracy: 0.1875 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.6697 - accuracy: 0.2500 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6612 - accuracy: 0.2750 - precision: 0.6364 - recall: 0.087 - ETA: 0s - loss: 1.6722 - accuracy: 0.2812 - precision: 0.6970 - recall: 0.102 - ETA: 0s - loss: 1.6932 - accuracy: 0.2812 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.6880 - accuracy: 0.2869 - precision: 0.5926 - recall: 0.090 - ETA: 0s - loss: 1.6670 - accuracy: 0.3005 - precision: 0.6230 - recall: 0.091 - 1s 1ms/sample - loss: 1.6740 - accuracy: 0.2958 - precision: 0.6129 - recall: 0.0892 - val_loss: 1.7115 - val_accuracy: 0.2958 - val_precision: 0.5556 - val_recall: 0.0704\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6895 - accuracy: 0.2500 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6581 - accuracy: 0.3125 - precision: 0.7273 - recall: 0.083 - ETA: 0s - loss: 1.6563 - accuracy: 0.3063 - precision: 0.7059 - recall: 0.075 - ETA: 0s - loss: 1.6585 - accuracy: 0.2946 - precision: 0.6000 - recall: 0.067 - ETA: 0s - loss: 1.6641 - accuracy: 0.2951 - precision: 0.5714 - recall: 0.069 - ETA: 0s - loss: 1.6662 - accuracy: 0.2983 - precision: 0.6047 - recall: 0.073 - ETA: 0s - loss: 1.6876 - accuracy: 0.2885 - precision: 0.6275 - recall: 0.076 - 1s 1ms/sample - loss: 1.6872 - accuracy: 0.2864 - precision: 0.6226 - recall: 0.0775 - val_loss: 1.7072 - val_accuracy: 0.2535 - val_precision: 0.5556 - val_recall: 0.0704\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7436 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.6992 - accuracy: 0.3438 - precision: 0.8571 - recall: 0.0625        - ETA: 0s - loss: 1.6934 - accuracy: 0.3250 - precision: 0.6923 - recall: 0.056 - ETA: 0s - loss: 1.7136 - accuracy: 0.3080 - precision: 0.7368 - recall: 0.062 - ETA: 0s - loss: 1.7089 - accuracy: 0.2986 - precision: 0.7143 - recall: 0.069 - ETA: 0s - loss: 1.6541 - accuracy: 0.3267 - precision: 0.7381 - recall: 0.088 - ETA: 0s - loss: 1.6788 - accuracy: 0.3029 - precision: 0.6957 - recall: 0.076 - 1s 1ms/sample - loss: 1.6755 - accuracy: 0.3005 - precision: 0.7021 - recall: 0.0775 - val_loss: 1.7127 - val_accuracy: 0.2113 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8149 - accuracy: 0.1562 - precision: 0.4000 - recall: 0.062 - ETA: 0s - loss: 1.8103 - accuracy: 0.2292 - precision: 0.2857 - recall: 0.041 - ETA: 0s - loss: 1.7324 - accuracy: 0.2438 - precision: 0.4545 - recall: 0.062 - ETA: 0s - loss: 1.7116 - accuracy: 0.2589 - precision: 0.4545 - recall: 0.067 - ETA: 0s - loss: 1.6822 - accuracy: 0.2569 - precision: 0.5238 - recall: 0.076 - ETA: 0s - loss: 1.6758 - accuracy: 0.2614 - precision: 0.5306 - recall: 0.073 - ETA: 0s - loss: 1.6993 - accuracy: 0.2524 - precision: 0.5370 - recall: 0.069 - 1s 1ms/sample - loss: 1.7018 - accuracy: 0.2582 - precision: 0.5370 - recall: 0.0681 - val_loss: 1.6850 - val_accuracy: 0.2676 - val_precision: 0.7647 - val_recall: 0.0915\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5516 - accuracy: 0.3750 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.6126 - accuracy: 0.3125 - precision: 0.6154 - recall: 0.083 - ETA: 0s - loss: 1.6277 - accuracy: 0.3313 - precision: 0.6842 - recall: 0.081 - ETA: 0s - loss: 1.6614 - accuracy: 0.2902 - precision: 0.7200 - recall: 0.080 - ETA: 0s - loss: 1.6836 - accuracy: 0.2743 - precision: 0.6216 - recall: 0.079 - ETA: 0s - loss: 1.7126 - accuracy: 0.2642 - precision: 0.5800 - recall: 0.082 - ETA: 0s - loss: 1.7082 - accuracy: 0.2788 - precision: 0.6034 - recall: 0.084 - 1s 1ms/sample - loss: 1.7006 - accuracy: 0.2817 - precision: 0.6066 - recall: 0.0869 - val_loss: 1.7043 - val_accuracy: 0.2535 - val_precision: 0.5909 - val_recall: 0.0915\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6348 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7404 - accuracy: 0.2917 - precision: 0.5455 - recall: 0.062 - ETA: 0s - loss: 1.7567 - accuracy: 0.2688 - precision: 0.5385 - recall: 0.043 - ETA: 0s - loss: 1.7229 - accuracy: 0.2589 - precision: 0.6000 - recall: 0.040 - ETA: 0s - loss: 1.7081 - accuracy: 0.2604 - precision: 0.5882 - recall: 0.034 - ETA: 0s - loss: 1.7175 - accuracy: 0.2557 - precision: 0.6190 - recall: 0.036 - ETA: 0s - loss: 1.7085 - accuracy: 0.2668 - precision: 0.6800 - recall: 0.040 - 1s 1ms/sample - loss: 1.7082 - accuracy: 0.2653 - precision: 0.6800 - recall: 0.0399 - val_loss: 1.7120 - val_accuracy: 0.2465 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7965 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+0 - ETA: 0s - loss: 1.7182 - accuracy: 0.2812 - precision: 0.8333 - recall: 0.0521        - ETA: 0s - loss: 1.6515 - accuracy: 0.3187 - precision: 0.6364 - recall: 0.087 - ETA: 0s - loss: 1.6896 - accuracy: 0.2991 - precision: 0.5862 - recall: 0.075 - ETA: 0s - loss: 1.6870 - accuracy: 0.2917 - precision: 0.5750 - recall: 0.079 - ETA: 0s - loss: 1.6985 - accuracy: 0.3011 - precision: 0.6078 - recall: 0.088 - ETA: 0s - loss: 1.7087 - accuracy: 0.2909 - precision: 0.5873 - recall: 0.088 - 1s 1ms/sample - loss: 1.7132 - accuracy: 0.2911 - precision: 0.5606 - recall: 0.0869 - val_loss: 1.7191 - val_accuracy: 0.2606 - val_precision: 0.5333 - val_recall: 0.1127\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9725 - accuracy: 0.2188 - precision: 0.2000 - recall: 0.031 - ETA: 0s - loss: 1.7132 - accuracy: 0.2812 - precision: 0.5789 - recall: 0.114 - ETA: 0s - loss: 1.7059 - accuracy: 0.2812 - precision: 0.5667 - recall: 0.106 - ETA: 0s - loss: 1.7036 - accuracy: 0.2812 - precision: 0.5833 - recall: 0.093 - ETA: 0s - loss: 1.6874 - accuracy: 0.2708 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.6789 - accuracy: 0.2869 - precision: 0.6034 - recall: 0.099 - ETA: 0s - loss: 1.6852 - accuracy: 0.2764 - precision: 0.5846 - recall: 0.091 - 1s 1ms/sample - loss: 1.6912 - accuracy: 0.2770 - precision: 0.5909 - recall: 0.0915 - val_loss: 1.6969 - val_accuracy: 0.2887 - val_precision: 0.8750 - val_recall: 0.0493\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6141 - accuracy: 0.2812 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.6247 - accuracy: 0.3021 - precision: 0.7143 - recall: 0.104 - ETA: 0s - loss: 1.6985 - accuracy: 0.2625 - precision: 0.7368 - recall: 0.087 - ETA: 0s - loss: 1.6664 - accuracy: 0.2902 - precision: 0.6818 - recall: 0.067 - ETA: 0s - loss: 1.6692 - accuracy: 0.2986 - precision: 0.7333 - recall: 0.076 - ETA: 0s - loss: 1.6829 - accuracy: 0.2841 - precision: 0.7222 - recall: 0.073 - ETA: 0s - loss: 1.6858 - accuracy: 0.2909 - precision: 0.7209 - recall: 0.074 - 1s 1ms/sample - loss: 1.6784 - accuracy: 0.2934 - precision: 0.7234 - recall: 0.0798 - val_loss: 1.7102 - val_accuracy: 0.2535 - val_precision: 0.5200 - val_recall: 0.0915\n",
      "Epoch 113/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7800 - accuracy: 0.1875 - precision: 0.3333 - recall: 0.031 - ETA: 0s - loss: 1.7661 - accuracy: 0.2500 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.7310 - accuracy: 0.2500 - precision: 0.6667 - recall: 0.112 - ETA: 0s - loss: 1.7372 - accuracy: 0.2634 - precision: 0.6176 - recall: 0.093 - ETA: 0s - loss: 1.7380 - accuracy: 0.2604 - precision: 0.5581 - recall: 0.083 - ETA: 0s - loss: 1.7149 - accuracy: 0.2670 - precision: 0.5600 - recall: 0.079 - ETA: 0s - loss: 1.7042 - accuracy: 0.2764 - precision: 0.6140 - recall: 0.084 - 1s 1ms/sample - loss: 1.7011 - accuracy: 0.2770 - precision: 0.6140 - recall: 0.0822 - val_loss: 1.6922 - val_accuracy: 0.2746 - val_precision: 0.7143 - val_recall: 0.0704\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5911 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5869 - accuracy: 0.3542 - precision: 0.7273 - recall: 0.083 - ETA: 0s - loss: 1.6736 - accuracy: 0.3375 - precision: 0.8125 - recall: 0.081 - ETA: 0s - loss: 1.6485 - accuracy: 0.3482 - precision: 0.7308 - recall: 0.084 - ETA: 0s - loss: 1.6410 - accuracy: 0.3333 - precision: 0.7353 - recall: 0.086 - ETA: 0s - loss: 1.6697 - accuracy: 0.3097 - precision: 0.7368 - recall: 0.079 - ETA: 0s - loss: 1.6528 - accuracy: 0.3077 - precision: 0.7400 - recall: 0.088 - 1s 1ms/sample - loss: 1.6730 - accuracy: 0.3028 - precision: 0.6852 - recall: 0.0869 - val_loss: 1.6940 - val_accuracy: 0.2746 - val_precision: 0.5909 - val_recall: 0.0915\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 0.3750 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.5562 - accuracy: 0.3542 - precision: 0.7391 - recall: 0.177 - ETA: 0s - loss: 1.5737 - accuracy: 0.3000 - precision: 0.7188 - recall: 0.143 - ETA: 0s - loss: 1.6059 - accuracy: 0.3036 - precision: 0.7317 - recall: 0.133 - ETA: 0s - loss: 1.6251 - accuracy: 0.2986 - precision: 0.7170 - recall: 0.131 - ETA: 0s - loss: 1.6378 - accuracy: 0.2983 - precision: 0.7167 - recall: 0.122 - ETA: 0s - loss: 1.6554 - accuracy: 0.2812 - precision: 0.7121 - recall: 0.113 - 1s 1ms/sample - loss: 1.6590 - accuracy: 0.2817 - precision: 0.7121 - recall: 0.1103 - val_loss: 1.6906 - val_accuracy: 0.2606 - val_precision: 0.6190 - val_recall: 0.0915\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5548 - accuracy: 0.3438 - precision: 1.0000 - recall: 0.156 - ETA: 0s - loss: 1.5622 - accuracy: 0.3333 - precision: 0.9444 - recall: 0.177 - ETA: 0s - loss: 1.6177 - accuracy: 0.3063 - precision: 0.9231 - recall: 0.150 - ETA: 0s - loss: 1.6299 - accuracy: 0.3036 - precision: 0.7436 - recall: 0.129 - ETA: 0s - loss: 1.6392 - accuracy: 0.3021 - precision: 0.6939 - recall: 0.118 - ETA: 0s - loss: 1.6461 - accuracy: 0.3097 - precision: 0.6842 - recall: 0.110 - ETA: 0s - loss: 1.6563 - accuracy: 0.3077 - precision: 0.6769 - recall: 0.105 - 1s 1ms/sample - loss: 1.6614 - accuracy: 0.3028 - precision: 0.6769 - recall: 0.1033 - val_loss: 1.6982 - val_accuracy: 0.3239 - val_precision: 0.6667 - val_recall: 0.0986\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.4375 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.5617 - accuracy: 0.4479 - precision: 0.7692 - recall: 0.104 - ETA: 0s - loss: 1.5808 - accuracy: 0.3875 - precision: 0.8333 - recall: 0.093 - ETA: 0s - loss: 1.5904 - accuracy: 0.3750 - precision: 0.8889 - recall: 0.107 - ETA: 0s - loss: 1.6062 - accuracy: 0.3507 - precision: 0.7381 - recall: 0.107 - ETA: 0s - loss: 1.6296 - accuracy: 0.3409 - precision: 0.7059 - recall: 0.102 - ETA: 0s - loss: 1.6412 - accuracy: 0.3365 - precision: 0.6875 - recall: 0.105 - 1s 1ms/sample - loss: 1.6357 - accuracy: 0.3380 - precision: 0.7015 - recall: 0.1103 - val_loss: 1.6969 - val_accuracy: 0.3169 - val_precision: 0.6000 - val_recall: 0.0845\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7031 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.6618 - accuracy: 0.2812 - precision: 0.3750 - recall: 0.062 - ETA: 0s - loss: 1.5862 - accuracy: 0.3375 - precision: 0.5833 - recall: 0.087 - ETA: 0s - loss: 1.5749 - accuracy: 0.3527 - precision: 0.6667 - recall: 0.107 - ETA: 0s - loss: 1.6243 - accuracy: 0.3299 - precision: 0.6829 - recall: 0.097 - ETA: 0s - loss: 1.6201 - accuracy: 0.3324 - precision: 0.6800 - recall: 0.096 - ETA: 0s - loss: 1.6237 - accuracy: 0.3245 - precision: 0.6964 - recall: 0.093 - 1s 1ms/sample - loss: 1.6263 - accuracy: 0.3216 - precision: 0.7018 - recall: 0.0939 - val_loss: 1.7021 - val_accuracy: 0.2746 - val_precision: 0.6087 - val_recall: 0.0986\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6883 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.5857 - accuracy: 0.3542 - precision: 0.6818 - recall: 0.156 - ETA: 0s - loss: 1.6056 - accuracy: 0.3313 - precision: 0.7000 - recall: 0.131 - ETA: 0s - loss: 1.6228 - accuracy: 0.3125 - precision: 0.7073 - recall: 0.129 - ETA: 0s - loss: 1.6501 - accuracy: 0.2917 - precision: 0.6735 - recall: 0.114 - ETA: 0s - loss: 1.6542 - accuracy: 0.2812 - precision: 0.6724 - recall: 0.110 - ETA: 0s - loss: 1.6570 - accuracy: 0.2885 - precision: 0.6765 - recall: 0.110 - 1s 2ms/sample - loss: 1.6665 - accuracy: 0.2840 - precision: 0.6667 - recall: 0.1080 - val_loss: 1.6860 - val_accuracy: 0.2606 - val_precision: 0.6316 - val_recall: 0.0845\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6019 - accuracy: 0.3750 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.6561 - accuracy: 0.2500 - precision: 0.6250 - recall: 0.052 - ETA: 0s - loss: 1.6154 - accuracy: 0.2750 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5869 - accuracy: 0.3125 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6191 - accuracy: 0.3090 - precision: 0.7500 - recall: 0.093 - ETA: 0s - loss: 1.6301 - accuracy: 0.3125 - precision: 0.6875 - recall: 0.093 - ETA: 0s - loss: 1.6186 - accuracy: 0.3221 - precision: 0.7321 - recall: 0.098 - 1s 1ms/sample - loss: 1.6221 - accuracy: 0.3192 - precision: 0.7321 - recall: 0.0962 - val_loss: 1.7192 - val_accuracy: 0.2394 - val_precision: 0.5714 - val_recall: 0.1127\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8163 - accuracy: 0.2812 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6144 - accuracy: 0.3438 - precision: 0.6471 - recall: 0.114 - ETA: 0s - loss: 1.6623 - accuracy: 0.3063 - precision: 0.5556 - recall: 0.093 - ETA: 0s - loss: 1.6525 - accuracy: 0.3393 - precision: 0.6154 - recall: 0.107 - ETA: 0s - loss: 1.6281 - accuracy: 0.3576 - precision: 0.6531 - recall: 0.111 - ETA: 0s - loss: 1.6247 - accuracy: 0.3438 - precision: 0.6271 - recall: 0.105 - ETA: 0s - loss: 1.6070 - accuracy: 0.3438 - precision: 0.6267 - recall: 0.113 - 1s 1ms/sample - loss: 1.6156 - accuracy: 0.3404 - precision: 0.6282 - recall: 0.1150 - val_loss: 1.7117 - val_accuracy: 0.2394 - val_precision: 0.5833 - val_recall: 0.0986\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4427 - accuracy: 0.4062 - precision: 0.5556 - recall: 0.156 - ETA: 0s - loss: 1.5559 - accuracy: 0.3854 - precision: 0.4667 - recall: 0.072 - ETA: 0s - loss: 1.5142 - accuracy: 0.4125 - precision: 0.6250 - recall: 0.093 - ETA: 0s - loss: 1.5651 - accuracy: 0.3750 - precision: 0.6471 - recall: 0.098 - ETA: 0s - loss: 1.5681 - accuracy: 0.3576 - precision: 0.6383 - recall: 0.104 - ETA: 0s - loss: 1.5841 - accuracy: 0.3409 - precision: 0.6271 - recall: 0.105 - ETA: 0s - loss: 1.6174 - accuracy: 0.3341 - precision: 0.5882 - recall: 0.096 - 1s 1ms/sample - loss: 1.6211 - accuracy: 0.3310 - precision: 0.5714 - recall: 0.0939 - val_loss: 1.7314 - val_accuracy: 0.2465 - val_precision: 0.5600 - val_recall: 0.0986\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6415 - accuracy: 0.3750 - precision: 0.5000 - recall: 0.062 - ETA: 0s - loss: 1.6459 - accuracy: 0.3958 - precision: 0.4667 - recall: 0.072 - ETA: 0s - loss: 1.6057 - accuracy: 0.3938 - precision: 0.5152 - recall: 0.106 - ETA: 0s - loss: 1.6036 - accuracy: 0.3571 - precision: 0.5652 - recall: 0.116 - ETA: 0s - loss: 1.6334 - accuracy: 0.3333 - precision: 0.5636 - recall: 0.107 - ETA: 0s - loss: 1.6073 - accuracy: 0.3608 - precision: 0.5775 - recall: 0.116 - ETA: 0s - loss: 1.6151 - accuracy: 0.3606 - precision: 0.5930 - recall: 0.122 - 1s 1ms/sample - loss: 1.6180 - accuracy: 0.3638 - precision: 0.5930 - recall: 0.1197 - val_loss: 1.7051 - val_accuracy: 0.2887 - val_precision: 0.6087 - val_recall: 0.0986\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4134 - accuracy: 0.5625 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.5697 - accuracy: 0.3854 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.5608 - accuracy: 0.3938 - precision: 0.6585 - recall: 0.168 - ETA: 0s - loss: 1.5861 - accuracy: 0.3482 - precision: 0.6481 - recall: 0.156 - ETA: 0s - loss: 1.6120 - accuracy: 0.3403 - precision: 0.6418 - recall: 0.149 - ETA: 0s - loss: 1.6368 - accuracy: 0.3267 - precision: 0.6220 - recall: 0.144 - ETA: 0s - loss: 1.6449 - accuracy: 0.3197 - precision: 0.6082 - recall: 0.141 - 1s 1ms/sample - loss: 1.6472 - accuracy: 0.3192 - precision: 0.6122 - recall: 0.1408 - val_loss: 1.6792 - val_accuracy: 0.2606 - val_precision: 0.5484 - val_recall: 0.1197\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6476 - accuracy: 0.4062 - precision: 0.6667 - recall: 0.125 - ETA: 0s - loss: 1.6476 - accuracy: 0.3542 - precision: 0.6842 - recall: 0.135 - ETA: 0s - loss: 1.6400 - accuracy: 0.3250 - precision: 0.6129 - recall: 0.118 - ETA: 0s - loss: 1.6694 - accuracy: 0.3125 - precision: 0.5870 - recall: 0.120 - ETA: 0s - loss: 1.6431 - accuracy: 0.3194 - precision: 0.5909 - recall: 0.135 - ETA: 0s - loss: 1.6388 - accuracy: 0.3295 - precision: 0.6104 - recall: 0.133 - ETA: 0s - loss: 1.6365 - accuracy: 0.3413 - precision: 0.6196 - recall: 0.137 - 1s 1ms/sample - loss: 1.6275 - accuracy: 0.3451 - precision: 0.6354 - recall: 0.1432 - val_loss: 1.6943 - val_accuracy: 0.2746 - val_precision: 0.6154 - val_recall: 0.1127\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6953 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.093 - ETA: 0s - loss: 1.5912 - accuracy: 0.3438 - precision: 0.6500 - recall: 0.135 - ETA: 0s - loss: 1.5771 - accuracy: 0.3562 - precision: 0.6857 - recall: 0.150 - ETA: 0s - loss: 1.5788 - accuracy: 0.3393 - precision: 0.6735 - recall: 0.147 - ETA: 0s - loss: 1.5882 - accuracy: 0.3333 - precision: 0.6364 - recall: 0.145 - ETA: 0s - loss: 1.6070 - accuracy: 0.3182 - precision: 0.6145 - recall: 0.144 - ETA: 0s - loss: 1.6212 - accuracy: 0.3173 - precision: 0.5859 - recall: 0.139 - 1s 2ms/sample - loss: 1.6237 - accuracy: 0.3146 - precision: 0.5859 - recall: 0.1362 - val_loss: 1.6918 - val_accuracy: 0.3028 - val_precision: 0.6316 - val_recall: 0.0845\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6366 - accuracy: 0.3438 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.5390 - accuracy: 0.3854 - precision: 0.7500 - recall: 0.156 - ETA: 0s - loss: 1.5402 - accuracy: 0.4141 - precision: 0.7778 - recall: 0.164 - ETA: 0s - loss: 1.5607 - accuracy: 0.3906 - precision: 0.7647 - recall: 0.135 - ETA: 0s - loss: 1.5623 - accuracy: 0.3750 - precision: 0.7619 - recall: 0.125 - ETA: 0s - loss: 1.5578 - accuracy: 0.3875 - precision: 0.7593 - recall: 0.128 - ETA: 0s - loss: 1.5782 - accuracy: 0.3724 - precision: 0.7385 - recall: 0.125 - 1s 2ms/sample - loss: 1.5783 - accuracy: 0.3756 - precision: 0.7260 - recall: 0.1244 - val_loss: 1.7167 - val_accuracy: 0.2535 - val_precision: 0.6154 - val_recall: 0.1127\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3315 - accuracy: 0.5938 - precision: 0.8571 - recall: 0.187 - ETA: 0s - loss: 1.5476 - accuracy: 0.3750 - precision: 0.5556 - recall: 0.104 - ETA: 0s - loss: 1.4995 - accuracy: 0.3938 - precision: 0.6774 - recall: 0.131 - ETA: 0s - loss: 1.5411 - accuracy: 0.3705 - precision: 0.7045 - recall: 0.138 - ETA: 0s - loss: 1.5857 - accuracy: 0.3472 - precision: 0.6531 - recall: 0.111 - ETA: 0s - loss: 1.5747 - accuracy: 0.3438 - precision: 0.6780 - recall: 0.113 - ETA: 0s - loss: 1.5772 - accuracy: 0.3558 - precision: 0.6970 - recall: 0.110 - 1s 1ms/sample - loss: 1.5744 - accuracy: 0.3568 - precision: 0.6912 - recall: 0.1103 - val_loss: 1.7186 - val_accuracy: 0.3028 - val_precision: 0.5556 - val_recall: 0.1056\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4942 - accuracy: 0.2500 - precision: 0.6000 - recall: 0.093 - ETA: 0s - loss: 1.5532 - accuracy: 0.3229 - precision: 0.6111 - recall: 0.114 - ETA: 0s - loss: 1.5487 - accuracy: 0.3688 - precision: 0.6286 - recall: 0.137 - ETA: 0s - loss: 1.5119 - accuracy: 0.3884 - precision: 0.6458 - recall: 0.138 - ETA: 0s - loss: 1.4878 - accuracy: 0.3958 - precision: 0.7049 - recall: 0.149 - ETA: 0s - loss: 1.5045 - accuracy: 0.3977 - precision: 0.7162 - recall: 0.150 - ETA: 0s - loss: 1.5142 - accuracy: 0.3870 - precision: 0.7273 - recall: 0.153 - 1s 1ms/sample - loss: 1.5105 - accuracy: 0.3944 - precision: 0.7273 - recall: 0.1502 - val_loss: 1.6736 - val_accuracy: 0.3028 - val_precision: 0.5667 - val_recall: 0.1197\n",
      "Epoch 130/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5415 - accuracy: 0.4062 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.5155 - accuracy: 0.3854 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.5487 - accuracy: 0.3812 - precision: 0.7250 - recall: 0.181 - ETA: 0s - loss: 1.5784 - accuracy: 0.3973 - precision: 0.7167 - recall: 0.192 - ETA: 0s - loss: 1.5725 - accuracy: 0.3924 - precision: 0.6753 - recall: 0.180 - ETA: 0s - loss: 1.5959 - accuracy: 0.3778 - precision: 0.6818 - recall: 0.170 - ETA: 0s - loss: 1.5836 - accuracy: 0.3870 - precision: 0.6733 - recall: 0.163 - 1s 1ms/sample - loss: 1.5753 - accuracy: 0.3897 - precision: 0.6827 - recall: 0.1667 - val_loss: 1.7064 - val_accuracy: 0.3099 - val_precision: 0.6053 - val_recall: 0.1620\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5369 - accuracy: 0.4688 - precision: 0.8750 - recall: 0.218 - ETA: 0s - loss: 1.4580 - accuracy: 0.4479 - precision: 0.8846 - recall: 0.239 - ETA: 0s - loss: 1.5155 - accuracy: 0.4000 - precision: 0.7556 - recall: 0.212 - ETA: 0s - loss: 1.5098 - accuracy: 0.4062 - precision: 0.6528 - recall: 0.209 - ETA: 0s - loss: 1.5367 - accuracy: 0.3924 - precision: 0.6477 - recall: 0.197 - ETA: 0s - loss: 1.5363 - accuracy: 0.3864 - precision: 0.6228 - recall: 0.201 - ETA: 0s - loss: 1.5373 - accuracy: 0.3894 - precision: 0.6136 - recall: 0.194 - 1s 1ms/sample - loss: 1.5513 - accuracy: 0.3873 - precision: 0.6074 - recall: 0.1925 - val_loss: 1.7376 - val_accuracy: 0.3239 - val_precision: 0.5405 - val_recall: 0.1408\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6244 - accuracy: 0.4062 - precision: 0.5833 - recall: 0.218 - ETA: 0s - loss: 1.5491 - accuracy: 0.4062 - precision: 0.6207 - recall: 0.187 - ETA: 0s - loss: 1.5878 - accuracy: 0.3688 - precision: 0.6047 - recall: 0.162 - ETA: 0s - loss: 1.5643 - accuracy: 0.3750 - precision: 0.6429 - recall: 0.160 - ETA: 0s - loss: 1.5430 - accuracy: 0.3785 - precision: 0.6667 - recall: 0.173 - ETA: 0s - loss: 1.5335 - accuracy: 0.3892 - precision: 0.6701 - recall: 0.184 - ETA: 0s - loss: 1.5270 - accuracy: 0.3918 - precision: 0.6638 - recall: 0.185 - 1s 1ms/sample - loss: 1.5320 - accuracy: 0.3920 - precision: 0.6525 - recall: 0.1808 - val_loss: 1.6604 - val_accuracy: 0.3732 - val_precision: 0.5333 - val_recall: 0.1127\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3405 - accuracy: 0.5938 - precision: 0.5000 - recall: 0.093 - ETA: 0s - loss: 1.3980 - accuracy: 0.5000 - precision: 0.6818 - recall: 0.156 - ETA: 0s - loss: 1.4478 - accuracy: 0.4313 - precision: 0.6757 - recall: 0.156 - ETA: 0s - loss: 1.4843 - accuracy: 0.3839 - precision: 0.6200 - recall: 0.138 - ETA: 0s - loss: 1.5072 - accuracy: 0.3785 - precision: 0.6197 - recall: 0.152 - ETA: 0s - loss: 1.5170 - accuracy: 0.3864 - precision: 0.6512 - recall: 0.159 - ETA: 0s - loss: 1.5060 - accuracy: 0.3942 - precision: 0.6729 - recall: 0.173 - 1s 1ms/sample - loss: 1.5153 - accuracy: 0.3897 - precision: 0.6636 - recall: 0.1714 - val_loss: 1.7034 - val_accuracy: 0.3310 - val_precision: 0.5143 - val_recall: 0.1268\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2104 - accuracy: 0.5938 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.3311 - accuracy: 0.5000 - precision: 0.8571 - recall: 0.312 - ETA: 0s - loss: 1.3705 - accuracy: 0.4766 - precision: 0.7551 - recall: 0.289 - ETA: 0s - loss: 1.4283 - accuracy: 0.4375 - precision: 0.7059 - recall: 0.250 - ETA: 0s - loss: 1.4151 - accuracy: 0.4509 - precision: 0.6883 - recall: 0.236 - ETA: 0s - loss: 1.4451 - accuracy: 0.4258 - precision: 0.6444 - recall: 0.226 - ETA: 0s - loss: 1.4405 - accuracy: 0.4281 - precision: 0.6330 - recall: 0.215 - ETA: 0s - loss: 1.4465 - accuracy: 0.4290 - precision: 0.6290 - recall: 0.221 - ETA: 0s - loss: 1.4617 - accuracy: 0.4219 - precision: 0.6391 - recall: 0.221 - 1s 2ms/sample - loss: 1.4856 - accuracy: 0.4202 - precision: 0.6122 - recall: 0.2113 - val_loss: 1.7272 - val_accuracy: 0.3592 - val_precision: 0.4800 - val_recall: 0.1690\n",
      "Epoch 135/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4317 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.250 - ETA: 0s - loss: 1.4868 - accuracy: 0.4896 - precision: 0.6765 - recall: 0.239 - ETA: 0s - loss: 1.5238 - accuracy: 0.4500 - precision: 0.6545 - recall: 0.225 - ETA: 0s - loss: 1.5739 - accuracy: 0.4115 - precision: 0.6613 - recall: 0.213 - ETA: 0s - loss: 1.5806 - accuracy: 0.3906 - precision: 0.6533 - recall: 0.191 - ETA: 0s - loss: 1.5785 - accuracy: 0.3844 - precision: 0.6591 - recall: 0.181 - ETA: 0s - loss: 1.5976 - accuracy: 0.3906 - precision: 0.6346 - recall: 0.171 - 1s 1ms/sample - loss: 1.6095 - accuracy: 0.3756 - precision: 0.6422 - recall: 0.1643 - val_loss: 1.6893 - val_accuracy: 0.2958 - val_precision: 0.5294 - val_recall: 0.1268\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3741 - accuracy: 0.5000 - precision: 0.8000 - recall: 0.250 - ETA: 0s - loss: 1.4354 - accuracy: 0.4375 - precision: 0.6129 - recall: 0.197 - ETA: 0s - loss: 1.5617 - accuracy: 0.3688 - precision: 0.5490 - recall: 0.175 - ETA: 0s - loss: 1.5702 - accuracy: 0.3393 - precision: 0.5507 - recall: 0.169 - ETA: 0s - loss: 1.5908 - accuracy: 0.3472 - precision: 0.5783 - recall: 0.166 - ETA: 0s - loss: 1.5830 - accuracy: 0.3608 - precision: 0.5686 - recall: 0.164 - ETA: 0s - loss: 1.5814 - accuracy: 0.3582 - precision: 0.5738 - recall: 0.168 - 1s 1ms/sample - loss: 1.5865 - accuracy: 0.3592 - precision: 0.5726 - recall: 0.1667 - val_loss: 1.7614 - val_accuracy: 0.2958 - val_precision: 0.4186 - val_recall: 0.1268\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6498 - accuracy: 0.3750 - precision: 0.5455 - recall: 0.187 - ETA: 0s - loss: 1.4594 - accuracy: 0.4479 - precision: 0.6452 - recall: 0.208 - ETA: 0s - loss: 1.5129 - accuracy: 0.4250 - precision: 0.6400 - recall: 0.200 - ETA: 0s - loss: 1.5320 - accuracy: 0.4107 - precision: 0.6154 - recall: 0.178 - ETA: 0s - loss: 1.5212 - accuracy: 0.4097 - precision: 0.6154 - recall: 0.166 - ETA: 0s - loss: 1.5363 - accuracy: 0.3949 - precision: 0.6020 - recall: 0.167 - ETA: 0s - loss: 1.5252 - accuracy: 0.3966 - precision: 0.6154 - recall: 0.173 - 1s 1ms/sample - loss: 1.5381 - accuracy: 0.3944 - precision: 0.6134 - recall: 0.1714 - val_loss: 1.5899 - val_accuracy: 0.3944 - val_precision: 0.6400 - val_recall: 0.1127\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5139 - accuracy: 0.3438 - precision: 0.5714 - recall: 0.125 - ETA: 0s - loss: 1.4725 - accuracy: 0.4167 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.6029 - accuracy: 0.3375 - precision: 0.6364 - recall: 0.131 - ETA: 0s - loss: 1.6462 - accuracy: 0.3304 - precision: 0.5682 - recall: 0.111 - ETA: 0s - loss: 1.6424 - accuracy: 0.3090 - precision: 0.4912 - recall: 0.097 - ETA: 0s - loss: 1.6744 - accuracy: 0.2969 - precision: 0.4638 - recall: 0.100 - ETA: 0s - loss: 1.6974 - accuracy: 0.2865 - precision: 0.4368 - recall: 0.099 - 1s 2ms/sample - loss: 1.7076 - accuracy: 0.2723 - precision: 0.4368 - recall: 0.0892 - val_loss: 1.8622 - val_accuracy: 0.2465 - val_precision: 0.6667 - val_recall: 0.0141\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7820 - accuracy: 0.3125 - precision: 1.0000 - recall: 0.031 - ETA: 0s - loss: 2.1708 - accuracy: 0.2812 - precision: 1.0000 - recall: 0.010 - ETA: 0s - loss: 2.1722 - accuracy: 0.2750 - precision: 1.0000 - recall: 0.018 - ETA: 0s - loss: 2.0369 - accuracy: 0.2634 - precision: 0.4444 - recall: 0.017 - ETA: 0s - loss: 1.9696 - accuracy: 0.2674 - precision: 0.4333 - recall: 0.045 - ETA: 0s - loss: 1.9638 - accuracy: 0.2699 - precision: 0.3778 - recall: 0.048 - ETA: 0s - loss: 1.9661 - accuracy: 0.2716 - precision: 0.3636 - recall: 0.057 - 1s 2ms/sample - loss: 1.9583 - accuracy: 0.2676 - precision: 0.3676 - recall: 0.0587 - val_loss: 1.7173 - val_accuracy: 0.3099 - val_precision: 0.5238 - val_recall: 0.0775\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.3125 - precision: 0.8000 - recall: 0.125 - ETA: 0s - loss: 1.6723 - accuracy: 0.3229 - precision: 0.7000 - recall: 0.072 - ETA: 0s - loss: 1.6935 - accuracy: 0.3125 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.7196 - accuracy: 0.2946 - precision: 0.6250 - recall: 0.044 - ETA: 0s - loss: 1.7266 - accuracy: 0.2812 - precision: 0.6087 - recall: 0.048 - ETA: 0s - loss: 1.6967 - accuracy: 0.2898 - precision: 0.6452 - recall: 0.056 - ETA: 0s - loss: 1.6927 - accuracy: 0.2861 - precision: 0.5854 - recall: 0.057 - 1s 1ms/sample - loss: 1.6974 - accuracy: 0.2864 - precision: 0.5714 - recall: 0.0563 - val_loss: 1.7766 - val_accuracy: 0.2887 - val_precision: 0.5625 - val_recall: 0.0634\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.3125 - precision: 0.5000 - recall: 0.156 - ETA: 0s - loss: 1.6771 - accuracy: 0.2604 - precision: 0.4667 - recall: 0.072 - ETA: 0s - loss: 1.6777 - accuracy: 0.2688 - precision: 0.4375 - recall: 0.043 - ETA: 0s - loss: 1.6439 - accuracy: 0.2991 - precision: 0.4375 - recall: 0.031 - ETA: 0s - loss: 1.6017 - accuracy: 0.3194 - precision: 0.5909 - recall: 0.045 - ETA: 0s - loss: 1.5897 - accuracy: 0.3281 - precision: 0.5909 - recall: 0.040 - ETA: 0s - loss: 1.5977 - accuracy: 0.3177 - precision: 0.5769 - recall: 0.039 - 1s 2ms/sample - loss: 1.5968 - accuracy: 0.3169 - precision: 0.6061 - recall: 0.0469 - val_loss: 1.7702 - val_accuracy: 0.2817 - val_precision: 0.5000 - val_recall: 0.0493\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6538 - accuracy: 0.1875 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5531 - accuracy: 0.2917 - precision: 0.9000 - recall: 0.093 - ETA: 0s - loss: 1.5179 - accuracy: 0.3500 - precision: 0.8000 - recall: 0.075 - ETA: 0s - loss: 1.5362 - accuracy: 0.3393 - precision: 0.7000 - recall: 0.062 - ETA: 0s - loss: 1.4974 - accuracy: 0.3611 - precision: 0.7407 - recall: 0.069 - ETA: 0s - loss: 1.5173 - accuracy: 0.3693 - precision: 0.6875 - recall: 0.062 - ETA: 0s - loss: 1.5381 - accuracy: 0.3606 - precision: 0.6757 - recall: 0.060 - 1s 2ms/sample - loss: 1.5366 - accuracy: 0.3592 - precision: 0.6667 - recall: 0.0610 - val_loss: 1.6287 - val_accuracy: 0.3451 - val_precision: 0.5714 - val_recall: 0.0563\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3711 - accuracy: 0.4688 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.4722 - accuracy: 0.4583 - precision: 0.9000 - recall: 0.093 - ETA: 0s - loss: 1.5048 - accuracy: 0.4375 - precision: 0.8125 - recall: 0.081 - ETA: 0s - loss: 1.4942 - accuracy: 0.4286 - precision: 0.7083 - recall: 0.075 - ETA: 0s - loss: 1.4767 - accuracy: 0.4306 - precision: 0.7500 - recall: 0.083 - ETA: 0s - loss: 1.4876 - accuracy: 0.4219 - precision: 0.6757 - recall: 0.078 - ETA: 0s - loss: 1.4778 - accuracy: 0.4167 - precision: 0.6250 - recall: 0.078 - 1s 2ms/sample - loss: 1.4983 - accuracy: 0.4014 - precision: 0.6346 - recall: 0.0775 - val_loss: 1.6003 - val_accuracy: 0.3310 - val_precision: 0.7857 - val_recall: 0.0775\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6970 - accuracy: 0.1875 - precision: 0.5000 - recall: 0.031 - ETA: 0s - loss: 1.5721 - accuracy: 0.3333 - precision: 0.6667 - recall: 0.062 - ETA: 0s - loss: 1.5375 - accuracy: 0.3250 - precision: 0.6429 - recall: 0.056 - ETA: 0s - loss: 1.5024 - accuracy: 0.3438 - precision: 0.7143 - recall: 0.078 - ETA: 0s - loss: 1.4840 - accuracy: 0.3672 - precision: 0.7368 - recall: 0.109 - ETA: 0s - loss: 1.5135 - accuracy: 0.3688 - precision: 0.6923 - recall: 0.112 - ETA: 0s - loss: 1.5124 - accuracy: 0.3646 - precision: 0.6875 - recall: 0.114 - ETA: 0s - loss: 1.4937 - accuracy: 0.3726 - precision: 0.7027 - recall: 0.125 - 1s 2ms/sample - loss: 1.4901 - accuracy: 0.3756 - precision: 0.7143 - recall: 0.1291 - val_loss: 1.6689 - val_accuracy: 0.3662 - val_precision: 0.7407 - val_recall: 0.1408\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4141 - accuracy: 0.4062 - precision: 0.6000 - recall: 0.187 - ETA: 0s - loss: 1.3907 - accuracy: 0.4375 - precision: 0.7500 - recall: 0.187 - ETA: 0s - loss: 1.4445 - accuracy: 0.4187 - precision: 0.7027 - recall: 0.162 - ETA: 0s - loss: 1.4509 - accuracy: 0.4018 - precision: 0.7045 - recall: 0.138 - ETA: 0s - loss: 1.4480 - accuracy: 0.4062 - precision: 0.7544 - recall: 0.149 - ETA: 0s - loss: 1.4357 - accuracy: 0.4091 - precision: 0.7260 - recall: 0.150 - ETA: 0s - loss: 1.4404 - accuracy: 0.4014 - precision: 0.7108 - recall: 0.141 - 1s 2ms/sample - loss: 1.4393 - accuracy: 0.4038 - precision: 0.7176 - recall: 0.1432 - val_loss: 1.5261 - val_accuracy: 0.3803 - val_precision: 0.6800 - val_recall: 0.1197\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4491 - accuracy: 0.5312 - precision: 0.8333 - recall: 0.156 - ETA: 0s - loss: 1.4203 - accuracy: 0.4688 - precision: 0.6364 - recall: 0.145 - ETA: 0s - loss: 1.4122 - accuracy: 0.4437 - precision: 0.5349 - recall: 0.143 - ETA: 0s - loss: 1.4070 - accuracy: 0.4420 - precision: 0.5902 - recall: 0.160 - ETA: 0s - loss: 1.3693 - accuracy: 0.4653 - precision: 0.6329 - recall: 0.173 - ETA: 0s - loss: 1.3840 - accuracy: 0.4688 - precision: 0.6429 - recall: 0.179 - ETA: 0s - loss: 1.4206 - accuracy: 0.4557 - precision: 0.5926 - recall: 0.166 - 1s 2ms/sample - loss: 1.4102 - accuracy: 0.4554 - precision: 0.6000 - recall: 0.1690 - val_loss: 1.5991 - val_accuracy: 0.3873 - val_precision: 0.7000 - val_recall: 0.1479\n",
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3104 - accuracy: 0.5312 - precision: 0.7143 - recall: 0.156 - ETA: 0s - loss: 1.3059 - accuracy: 0.5156 - precision: 0.7857 - recall: 0.171 - ETA: 0s - loss: 1.3569 - accuracy: 0.5078 - precision: 0.8148 - recall: 0.171 - ETA: 0s - loss: 1.3911 - accuracy: 0.4844 - precision: 0.7619 - recall: 0.166 - ETA: 0s - loss: 1.3623 - accuracy: 0.4766 - precision: 0.7719 - recall: 0.171 - ETA: 0s - loss: 1.3791 - accuracy: 0.4844 - precision: 0.7160 - recall: 0.181 - ETA: 0s - loss: 1.4142 - accuracy: 0.4792 - precision: 0.6832 - recall: 0.179 - ETA: 0s - loss: 1.4163 - accuracy: 0.4736 - precision: 0.6847 - recall: 0.182 - 1s 2ms/sample - loss: 1.4122 - accuracy: 0.4742 - precision: 0.6847 - recall: 0.1784 - val_loss: 1.6051 - val_accuracy: 0.3592 - val_precision: 0.5472 - val_recall: 0.2042\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2108 - accuracy: 0.5625 - precision: 0.8333 - recall: 0.312 - ETA: 0s - loss: 1.2887 - accuracy: 0.5312 - precision: 0.7000 - recall: 0.291 - ETA: 0s - loss: 1.3902 - accuracy: 0.4688 - precision: 0.5789 - recall: 0.275 - ETA: 0s - loss: 1.4377 - accuracy: 0.4509 - precision: 0.5333 - recall: 0.250 - ETA: 0s - loss: 1.4254 - accuracy: 0.4492 - precision: 0.5372 - recall: 0.253 - ETA: 0s - loss: 1.4584 - accuracy: 0.4250 - precision: 0.5507 - recall: 0.237 - ETA: 0s - loss: 1.4816 - accuracy: 0.4089 - precision: 0.5478 - recall: 0.224 - 1s 2ms/sample - loss: 1.4772 - accuracy: 0.4131 - precision: 0.5439 - recall: 0.2183 - val_loss: 1.5674 - val_accuracy: 0.3380 - val_precision: 0.6087 - val_recall: 0.0986\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3903 - accuracy: 0.4062 - precision: 0.4286 - recall: 0.093 - ETA: 0s - loss: 1.3275 - accuracy: 0.4271 - precision: 0.7500 - recall: 0.156 - ETA: 0s - loss: 1.2739 - accuracy: 0.4375 - precision: 0.8148 - recall: 0.171 - ETA: 0s - loss: 1.2869 - accuracy: 0.4531 - precision: 0.8537 - recall: 0.182 - ETA: 0s - loss: 1.2937 - accuracy: 0.4509 - precision: 0.8077 - recall: 0.187 - ETA: 0s - loss: 1.3105 - accuracy: 0.4444 - precision: 0.7941 - recall: 0.187 - ETA: 0s - loss: 1.3425 - accuracy: 0.4517 - precision: 0.7273 - recall: 0.181 - ETA: 0s - loss: 1.3585 - accuracy: 0.4447 - precision: 0.6972 - recall: 0.182 - 1s 2ms/sample - loss: 1.3544 - accuracy: 0.4460 - precision: 0.7080 - recall: 0.1878 - val_loss: 1.5012 - val_accuracy: 0.3521 - val_precision: 0.6341 - val_recall: 0.1831\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2663 - accuracy: 0.4688 - precision: 0.7500 - recall: 0.281 - ETA: 0s - loss: 1.2673 - accuracy: 0.4896 - precision: 0.7667 - recall: 0.239 - ETA: 0s - loss: 1.2221 - accuracy: 0.5391 - precision: 0.8205 - recall: 0.250 - ETA: 0s - loss: 1.2249 - accuracy: 0.5312 - precision: 0.8226 - recall: 0.265 - ETA: 0s - loss: 1.2339 - accuracy: 0.5195 - precision: 0.8101 - recall: 0.250 - ETA: 0s - loss: 1.2494 - accuracy: 0.5188 - precision: 0.7692 - recall: 0.250 - ETA: 0s - loss: 1.2676 - accuracy: 0.5114 - precision: 0.7692 - recall: 0.255 - ETA: 0s - loss: 1.2635 - accuracy: 0.5048 - precision: 0.7669 - recall: 0.245 - 1s 2ms/sample - loss: 1.2623 - accuracy: 0.5070 - precision: 0.7609 - recall: 0.2465 - val_loss: 1.4878 - val_accuracy: 0.4225 - val_precision: 0.6800 - val_recall: 0.2394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 07990e3ca75d1cf40418312e5e17675b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.577464759349823</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          344832    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 256)          459776    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           82176     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 1,301,004\n",
      "Trainable params: 1,301,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      " 32/426 [=>............................] - ETA: 1:26WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-4951a3697c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             validation_data=(x_val,y_val))\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_feed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[1;32m---> 85\u001b[1;33m         per_replica_function, args=args)\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[0;32m    762\u001b[0m                                 convert_by_default=False)\n\u001b[1;32m--> 763\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1817\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1819\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2164\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[0;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m   metrics_results = _eager_metrics_fn(\n\u001b[1;32m--> 316\u001b[1;33m       model, outs, targets, sample_weights=sample_weights, masks=masks)\n\u001b[0m\u001b[0;32m    317\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m   return {'total_loss': total_loss,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_eager_metrics_fn\u001b[1;34m(model, outputs, targets, sample_weights, masks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mmasks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mreturn_weighted_and_unweighted_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         skip_target_masks=model._prepare_skip_target_masks())\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[1;31m# Add metric results from the `add_metric` metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[1;34m(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)\u001b[0m\n\u001b[0;32m   2002\u001b[0m           metric_results.extend(\n\u001b[0;32m   2003\u001b[0m               self._handle_per_output_metrics(self._per_output_metrics[i],\n\u001b[1;32m-> 2004\u001b[1;33m                                               target, output, output_mask))\n\u001b[0m\u001b[0;32m   2005\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_weighted_and_unweighted_metrics\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_weighted_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m           metric_results.extend(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[1;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[0;32m   1953\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1954\u001b[0m         metric_result = training_utils.call_metric_function(\n\u001b[1;32m-> 1955\u001b[1;33m             metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[0;32m   1956\u001b[0m         \u001b[0mmetric_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmetric_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcall_metric_function\u001b[1;34m(metric_fn, y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1156\u001b[0m   \u001b[1;31m# `Mean` metric only takes a single value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m  \u001b[1;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     return distributed_training_utils.call_replica_local_fn(\n\u001b[1;32m--> 196\u001b[1;33m         replica_local_fn, *args, **kwargs)\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mcall_replica_local_fn\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreplica_local_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# We are adding the metric object as metadata on the result tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mreplica_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_strategy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreplica_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m       \u001b[1;31m# TODO(psv): Test distribution of metrics using different distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1218\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m     result = math_ops.div_no_nan(self.true_positives,\n\u001b[1;32m-> 1220\u001b[1;33m                                  self.true_positives + self.false_positives)\n\u001b[0m\u001b[0;32m   1221\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[1;34m(a, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    913\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    481\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m--> 483\u001b[1;33m         \"AddV2\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m    484\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1786\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1594\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m   op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n\u001b[1;32m-> 1596\u001b[1;33m                                   compat.as_str(node_def.name))\n\u001b[0m\u001b[0;32m   1597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m     \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner  = RandomSearch(\n",
    "    build_model,     #Function to use search in\n",
    "    objective = \"val_accuracy\",  #Chooses \"best model\" looking for highest value of val_accuracy\n",
    "    max_trials = 15,       # Number of different combinations tried Nodes and layers\n",
    "    executions_per_trial = 1, \n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train,      #syntax just like in fit\n",
    "                y= y_train,\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "import winsound\n",
    "frequency = 500  # Set Frequency To 2500 Hertz\n",
    "duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Hyperband\n",
    "Variation of RandomSearch http://jmlr.org/papers/volume18/16-558/16-558.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner  = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=150,\n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train, \n",
    "            y= y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "import winsound\n",
    "frequency = 500  # Set Frequency To 2500 Hertz\n",
    "duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 222,476\n",
      "Trainable params: 222,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/500\n",
      "426/426 [==============================] - ETA: 56s - loss: 2.4806 - accuracy: 0.0938 - precision_6: 0.0000e+00 - recall_6: 0.0000e+ - ETA: 26s - loss: 2.4741 - accuracy: 0.1719 - precision_6: 0.0000e+00 - recall_6: 0.0000e+ - ETA: 11s - loss: 2.4626 - accuracy: 0.1562 - precision_6: 0.0000e+00 - recall_6: 0.0000e+ - ETA: 5s - loss: 2.4282 - accuracy: 0.1406 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - ETA: 4s - loss: 2.4237 - accuracy: 0.1384 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 3s - loss: 2.4265 - accuracy: 0.1367 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 1s - loss: 2.3966 - accuracy: 0.1437 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.3907 - accuracy: 0.1484 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - 7s 16ms/sample - loss: 2.3810 - accuracy: 0.1408 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 2.1535 - val_accuracy: 0.2817 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1624 - accuracy: 0.1875 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0930 - accuracy: 0.1797 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0294 - accuracy: 0.1927 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0902 - accuracy: 0.1992 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.1303 - accuracy: 0.1969 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.1823 - accuracy: 0.1849 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - 0s 1ms/sample - loss: 2.2015 - accuracy: 0.1761 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 2.1463 - val_accuracy: 0.1690 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4104 - accuracy: 0.1562 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.1466 - accuracy: 0.1562 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0989 - accuracy: 0.1562 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0941 - accuracy: 0.1701 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0721 - accuracy: 0.1733 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0561 - accuracy: 0.1731 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - 0s 995us/sample - loss: 2.0544 - accuracy: 0.1714 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 2.0222 - val_accuracy: 0.1479 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 4/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0464 - accuracy: 0.1250 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0899 - accuracy: 0.1250 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0220 - accuracy: 0.1510 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0239 - accuracy: 0.1328 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0004 - accuracy: 0.1531 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 2.0066 - accuracy: 0.1510 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - 0s 1ms/sample - loss: 2.0034 - accuracy: 0.1502 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 1.9493 - val_accuracy: 0.2113 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 5/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0337 - accuracy: 0.0625 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.9408 - accuracy: 0.1146 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.8739 - accuracy: 0.1625 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.8896 - accuracy: 0.1741 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.8919 - accuracy: 0.1771 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.9156 - accuracy: 0.1818 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.9408 - accuracy: 0.1731 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - 0s 1ms/sample - loss: 1.9382 - accuracy: 0.1737 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 1.9147 - val_accuracy: 0.2254 - val_precision_6: 1.0000 - val_recall_6: 0.0141\n",
      "Epoch 6/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9293 - accuracy: 0.2812 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.9515 - accuracy: 0.2708 - precision_6: 1.0000 - recall_6: 0.0104        - ETA: 0s - loss: 1.8624 - accuracy: 0.2937 - precision_6: 0.7143 - recall_6: 0.031 - ETA: 0s - loss: 1.8645 - accuracy: 0.2634 - precision_6: 0.6667 - recall_6: 0.026 - ETA: 0s - loss: 1.8850 - accuracy: 0.2639 - precision_6: 0.6923 - recall_6: 0.031 - ETA: 0s - loss: 1.8927 - accuracy: 0.2670 - precision_6: 0.6471 - recall_6: 0.031 - ETA: 0s - loss: 1.9058 - accuracy: 0.2476 - precision_6: 0.5238 - recall_6: 0.026 - 0s 1ms/sample - loss: 1.9061 - accuracy: 0.2441 - precision_6: 0.5455 - recall_6: 0.0282 - val_loss: 1.8395 - val_accuracy: 0.2324 - val_precision_6: 1.0000 - val_recall_6: 0.0211\n",
      "Epoch 7/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7678 - accuracy: 0.2812 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.7898 - accuracy: 0.2292 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.7623 - accuracy: 0.2688 - precision_6: 0.6667 - recall_6: 0.0125        - ETA: 0s - loss: 1.7797 - accuracy: 0.2545 - precision_6: 0.6667 - recall_6: 0.008 - ETA: 0s - loss: 1.8012 - accuracy: 0.2604 - precision_6: 0.7500 - recall_6: 0.010 - ETA: 0s - loss: 1.8194 - accuracy: 0.2614 - precision_6: 0.8000 - recall_6: 0.011 - ETA: 0s - loss: 1.8277 - accuracy: 0.2572 - precision_6: 0.5714 - recall_6: 0.009 - 0s 1ms/sample - loss: 1.8261 - accuracy: 0.2559 - precision_6: 0.6250 - recall_6: 0.0117 - val_loss: 1.7643 - val_accuracy: 0.2324 - val_precision_6: 0.6667 - val_recall_6: 0.0282\n",
      "Epoch 8/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7723 - accuracy: 0.1562 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.8198 - accuracy: 0.1953 - precision_6: 0.5000 - recall_6: 0.023 - ETA: 0s - loss: 1.7698 - accuracy: 0.2292 - precision_6: 0.6364 - recall_6: 0.036 - ETA: 0s - loss: 1.8003 - accuracy: 0.2383 - precision_6: 0.6667 - recall_6: 0.031 - ETA: 0s - loss: 1.8136 - accuracy: 0.2594 - precision_6: 0.7143 - recall_6: 0.031 - ETA: 0s - loss: 1.8241 - accuracy: 0.2500 - precision_6: 0.7143 - recall_6: 0.026 - 0s 1ms/sample - loss: 1.8308 - accuracy: 0.2418 - precision_6: 0.6875 - recall_6: 0.0258 - val_loss: 1.7712 - val_accuracy: 0.2324 - val_precision_6: 0.8000 - val_recall_6: 0.0282\n",
      "Epoch 9/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7171 - accuracy: 0.3438 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.7058 - accuracy: 0.3021 - precision_6: 1.0000 - recall_6: 0.0208        - ETA: 0s - loss: 1.7067 - accuracy: 0.2937 - precision_6: 0.6667 - recall_6: 0.037 - ETA: 0s - loss: 1.7459 - accuracy: 0.2634 - precision_6: 0.6364 - recall_6: 0.031 - ETA: 0s - loss: 1.7684 - accuracy: 0.2743 - precision_6: 0.7143 - recall_6: 0.034 - ETA: 0s - loss: 1.7814 - accuracy: 0.2784 - precision_6: 0.6667 - recall_6: 0.034 - ETA: 0s - loss: 1.8011 - accuracy: 0.2596 - precision_6: 0.5714 - recall_6: 0.028 - 1s 1ms/sample - loss: 1.7977 - accuracy: 0.2582 - precision_6: 0.5909 - recall_6: 0.0305 - val_loss: 1.7772 - val_accuracy: 0.2606 - val_precision_6: 0.8333 - val_recall_6: 0.0352\n",
      "Epoch 10/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8423 - accuracy: 0.2812 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.8058 - accuracy: 0.3125 - precision_6: 0.5000 - recall_6: 0.015 - ETA: 0s - loss: 1.7243 - accuracy: 0.3214 - precision_6: 0.7778 - recall_6: 0.031 - ETA: 0s - loss: 1.7382 - accuracy: 0.3125 - precision_6: 0.8333 - recall_6: 0.034 - ETA: 0s - loss: 1.7468 - accuracy: 0.3099 - precision_6: 0.8000 - recall_6: 0.031 - 0s 1ms/sample - loss: 1.7573 - accuracy: 0.2887 - precision_6: 0.7222 - recall_6: 0.0305 - val_loss: 1.7290 - val_accuracy: 0.2324 - val_precision_6: 0.8000 - val_recall_6: 0.0282\n",
      "Epoch 11/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7193 - accuracy: 0.3125 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6914 - accuracy: 0.3333 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6764 - accuracy: 0.3500 - precision_6: 0.7778 - recall_6: 0.043 - ETA: 0s - loss: 1.6643 - accuracy: 0.3527 - precision_6: 0.8000 - recall_6: 0.035 - ETA: 0s - loss: 1.6824 - accuracy: 0.3472 - precision_6: 0.8462 - recall_6: 0.038 - ETA: 0s - loss: 1.6966 - accuracy: 0.3494 - precision_6: 0.8125 - recall_6: 0.036 - ETA: 0s - loss: 1.7093 - accuracy: 0.3389 - precision_6: 0.7222 - recall_6: 0.031 - 0s 1ms/sample - loss: 1.7065 - accuracy: 0.3357 - precision_6: 0.7368 - recall_6: 0.0329 - val_loss: 1.7435 - val_accuracy: 0.2324 - val_precision_6: 0.8333 - val_recall_6: 0.0352\n",
      "Epoch 12/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7199 - accuracy: 0.2812 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6687 - accuracy: 0.3125 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6561 - accuracy: 0.2937 - precision_6: 0.7778 - recall_6: 0.043 - ETA: 0s - loss: 1.6583 - accuracy: 0.3125 - precision_6: 0.8182 - recall_6: 0.040 - ETA: 0s - loss: 1.6702 - accuracy: 0.3160 - precision_6: 0.7692 - recall_6: 0.034 - ETA: 0s - loss: 1.6748 - accuracy: 0.3281 - precision_6: 0.8000 - recall_6: 0.037 - ETA: 0s - loss: 1.6797 - accuracy: 0.3203 - precision_6: 0.7500 - recall_6: 0.031 - 1s 1ms/sample - loss: 1.6929 - accuracy: 0.3052 - precision_6: 0.7222 - recall_6: 0.0305 - val_loss: 1.7549 - val_accuracy: 0.2606 - val_precision_6: 0.6000 - val_recall_6: 0.0211\n",
      "Epoch 13/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6997 - accuracy: 0.3125 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6844 - accuracy: 0.2917 - precision_6: 0.6667 - recall_6: 0.041 - ETA: 0s - loss: 1.6796 - accuracy: 0.3000 - precision_6: 0.6000 - recall_6: 0.056 - ETA: 0s - loss: 1.7093 - accuracy: 0.2991 - precision_6: 0.5789 - recall_6: 0.049 - ETA: 0s - loss: 1.7416 - accuracy: 0.2847 - precision_6: 0.6087 - recall_6: 0.048 - ETA: 0s - loss: 1.7507 - accuracy: 0.2955 - precision_6: 0.6154 - recall_6: 0.045 - ETA: 0s - loss: 1.7744 - accuracy: 0.2812 - precision_6: 0.5517 - recall_6: 0.038 - 1s 1ms/sample - loss: 1.7718 - accuracy: 0.2770 - precision_6: 0.5667 - recall_6: 0.0399 - val_loss: 1.8023 - val_accuracy: 0.2394 - val_precision_6: 0.6000 - val_recall_6: 0.0423\n",
      "Epoch 14/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6973 - accuracy: 0.3438 - precision_6: 0.5000 - recall_6: 0.031 - ETA: 0s - loss: 1.6564 - accuracy: 0.3438 - precision_6: 0.8000 - recall_6: 0.041 - ETA: 0s - loss: 1.6360 - accuracy: 0.3438 - precision_6: 0.5714 - recall_6: 0.050 - ETA: 0s - loss: 1.6736 - accuracy: 0.3304 - precision_6: 0.5556 - recall_6: 0.044 - ETA: 0s - loss: 1.6960 - accuracy: 0.3056 - precision_6: 0.6000 - recall_6: 0.052 - ETA: 0s - loss: 1.7005 - accuracy: 0.3210 - precision_6: 0.6071 - recall_6: 0.048 - 0s 1ms/sample - loss: 1.7096 - accuracy: 0.3075 - precision_6: 0.6250 - recall_6: 0.0469 - val_loss: 1.7998 - val_accuracy: 0.2254 - val_precision_6: 0.5000 - val_recall_6: 0.0211\n",
      "Epoch 15/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6894 - accuracy: 0.3438 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.7200 - accuracy: 0.3125 - precision_6: 0.7500 - recall_6: 0.0312        - ETA: 0s - loss: 1.6945 - accuracy: 0.3187 - precision_6: 0.5385 - recall_6: 0.043 - ETA: 0s - loss: 1.6740 - accuracy: 0.3170 - precision_6: 0.5882 - recall_6: 0.044 - ETA: 0s - loss: 1.6755 - accuracy: 0.3160 - precision_6: 0.6364 - recall_6: 0.048 - ETA: 0s - loss: 1.6833 - accuracy: 0.3182 - precision_6: 0.6538 - recall_6: 0.048 - ETA: 0s - loss: 1.6900 - accuracy: 0.3149 - precision_6: 0.6552 - recall_6: 0.045 - 0s 1ms/sample - loss: 1.6844 - accuracy: 0.3169 - precision_6: 0.6667 - recall_6: 0.0469 - val_loss: 1.7210 - val_accuracy: 0.2394 - val_precision_6: 0.8889 - val_recall_6: 0.0563\n",
      "Epoch 16/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6717 - accuracy: 0.2500 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.6486 - accuracy: 0.3021 - precision_6: 0.6667 - recall_6: 0.0417        - ETA: 0s - loss: 1.6148 - accuracy: 0.3250 - precision_6: 0.5000 - recall_6: 0.050 - ETA: 0s - loss: 1.5996 - accuracy: 0.3080 - precision_6: 0.5263 - recall_6: 0.044 - ETA: 0s - loss: 1.6230 - accuracy: 0.3056 - precision_6: 0.5455 - recall_6: 0.041 - ETA: 0s - loss: 1.6722 - accuracy: 0.3097 - precision_6: 0.5556 - recall_6: 0.042 - ETA: 0s - loss: 1.6852 - accuracy: 0.2885 - precision_6: 0.5667 - recall_6: 0.040 - 0s 1ms/sample - loss: 1.6824 - accuracy: 0.2887 - precision_6: 0.5806 - recall_6: 0.0423 - val_loss: 1.7192 - val_accuracy: 0.3099 - val_precision_6: 0.5714 - val_recall_6: 0.0282\n",
      "Epoch 17/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5981 - accuracy: 0.4688 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6697 - accuracy: 0.3646 - precision_6: 0.6667 - recall_6: 0.041 - ETA: 0s - loss: 1.6313 - accuracy: 0.3375 - precision_6: 0.5333 - recall_6: 0.050 - ETA: 0s - loss: 1.6312 - accuracy: 0.3214 - precision_6: 0.5000 - recall_6: 0.040 - ETA: 0s - loss: 1.6552 - accuracy: 0.3090 - precision_6: 0.5714 - recall_6: 0.041 - ETA: 0s - loss: 1.6851 - accuracy: 0.3040 - precision_6: 0.5833 - recall_6: 0.039 - ETA: 0s - loss: 1.6897 - accuracy: 0.3077 - precision_6: 0.6154 - recall_6: 0.038 - 0s 1ms/sample - loss: 1.6850 - accuracy: 0.3122 - precision_6: 0.6296 - recall_6: 0.0399 - val_loss: 1.6593 - val_accuracy: 0.3099 - val_precision_6: 1.0000 - val_recall_6: 0.0211\n",
      "Epoch 18/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5428 - accuracy: 0.4688 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.5701 - accuracy: 0.4167 - precision_6: 0.5000 - recall_6: 0.0208        - ETA: 0s - loss: 1.5603 - accuracy: 0.3812 - precision_6: 0.5000 - recall_6: 0.037 - ETA: 0s - loss: 1.5419 - accuracy: 0.3839 - precision_6: 0.6000 - recall_6: 0.040 - ETA: 0s - loss: 1.5485 - accuracy: 0.3715 - precision_6: 0.6316 - recall_6: 0.041 - ETA: 0s - loss: 1.5640 - accuracy: 0.3722 - precision_6: 0.6522 - recall_6: 0.042 - ETA: 0s - loss: 1.5802 - accuracy: 0.3534 - precision_6: 0.6667 - recall_6: 0.043 - 0s 1ms/sample - loss: 1.5729 - accuracy: 0.3592 - precision_6: 0.6897 - recall_6: 0.0469 - val_loss: 1.7195 - val_accuracy: 0.3380 - val_precision_6: 0.6364 - val_recall_6: 0.0493\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5312 - accuracy: 0.4375 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.5823 - accuracy: 0.3672 - precision_6: 0.3077 - recall_6: 0.0312        - ETA: 0s - loss: 1.5440 - accuracy: 0.3854 - precision_6: 0.4500 - recall_6: 0.046 - ETA: 0s - loss: 1.5452 - accuracy: 0.3789 - precision_6: 0.5000 - recall_6: 0.050 - ETA: 0s - loss: 1.5701 - accuracy: 0.3844 - precision_6: 0.5556 - recall_6: 0.062 - ETA: 0s - loss: 1.5650 - accuracy: 0.3802 - precision_6: 0.5952 - recall_6: 0.065 - 0s 1ms/sample - loss: 1.5800 - accuracy: 0.3638 - precision_6: 0.5745 - recall_6: 0.0634 - val_loss: 1.6313 - val_accuracy: 0.3028 - val_precision_6: 0.6667 - val_recall_6: 0.0704\n",
      "Epoch 20/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5171 - accuracy: 0.3750 - precision_6: 1.0000 - recall_6: 0.062 - ETA: 0s - loss: 1.5162 - accuracy: 0.3229 - precision_6: 0.6000 - recall_6: 0.093 - ETA: 0s - loss: 1.5076 - accuracy: 0.3562 - precision_6: 0.5417 - recall_6: 0.081 - ETA: 0s - loss: 1.4823 - accuracy: 0.3616 - precision_6: 0.5517 - recall_6: 0.071 - ETA: 0s - loss: 1.5048 - accuracy: 0.3646 - precision_6: 0.6053 - recall_6: 0.079 - ETA: 0s - loss: 1.5287 - accuracy: 0.3807 - precision_6: 0.6226 - recall_6: 0.093 - ETA: 0s - loss: 1.5544 - accuracy: 0.3654 - precision_6: 0.6094 - recall_6: 0.093 - 0s 1ms/sample - loss: 1.5481 - accuracy: 0.3662 - precision_6: 0.6324 - recall_6: 0.1009 - val_loss: 1.8133 - val_accuracy: 0.2676 - val_precision_6: 0.4762 - val_recall_6: 0.1408\n",
      "Epoch 21/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7856 - accuracy: 0.2500 - precision_6: 0.3636 - recall_6: 0.125 - ETA: 0s - loss: 1.8228 - accuracy: 0.2500 - precision_6: 0.3000 - recall_6: 0.093 - ETA: 0s - loss: 1.7226 - accuracy: 0.3021 - precision_6: 0.3250 - recall_6: 0.067 - ETA: 0s - loss: 1.7036 - accuracy: 0.2930 - precision_6: 0.3256 - recall_6: 0.054 - ETA: 0s - loss: 1.7322 - accuracy: 0.3031 - precision_6: 0.3462 - recall_6: 0.056 - ETA: 0s - loss: 1.7400 - accuracy: 0.2943 - precision_6: 0.3509 - recall_6: 0.052 - 0s 1ms/sample - loss: 1.7593 - accuracy: 0.2793 - precision_6: 0.3621 - recall_6: 0.0493 - val_loss: 1.7620 - val_accuracy: 0.2676 - val_precision_6: 0.5714 - val_recall_6: 0.0282\n",
      "Epoch 22/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7235 - accuracy: 0.2812 - precision_6: 1.0000 - recall_6: 0.062 - ETA: 0s - loss: 1.6848 - accuracy: 0.3333 - precision_6: 0.7500 - recall_6: 0.062 - ETA: 0s - loss: 2.2407 - accuracy: 0.2750 - precision_6: 0.3200 - recall_6: 0.050 - ETA: 0s - loss: 2.1859 - accuracy: 0.2679 - precision_6: 0.3704 - recall_6: 0.044 - ETA: 0s - loss: 2.1007 - accuracy: 0.2708 - precision_6: 0.4138 - recall_6: 0.041 - ETA: 0s - loss: 2.0515 - accuracy: 0.2812 - precision_6: 0.4333 - recall_6: 0.036 - ETA: 0s - loss: 2.0088 - accuracy: 0.2788 - precision_6: 0.4333 - recall_6: 0.031 - 0s 1ms/sample - loss: 1.9917 - accuracy: 0.2864 - precision_6: 0.4516 - recall_6: 0.0329 - val_loss: 1.6912 - val_accuracy: 0.2887 - val_precision_6: 1.0000 - val_recall_6: 0.0141\n",
      "Epoch 23/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6542 - accuracy: 0.2812 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.7334 - accuracy: 0.2604 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.6880 - accuracy: 0.3000 - precision_6: 0.8333 - recall_6: 0.0312        - ETA: 0s - loss: 1.6746 - accuracy: 0.3393 - precision_6: 0.7500 - recall_6: 0.026 - ETA: 0s - loss: 1.6917 - accuracy: 0.3264 - precision_6: 0.7500 - recall_6: 0.031 - ETA: 0s - loss: 1.7046 - accuracy: 0.3381 - precision_6: 0.6316 - recall_6: 0.034 - ETA: 0s - loss: 1.7151 - accuracy: 0.3438 - precision_6: 0.5000 - recall_6: 0.028 - 0s 1ms/sample - loss: 1.7072 - accuracy: 0.3451 - precision_6: 0.5200 - recall_6: 0.0305 - val_loss: 1.6947 - val_accuracy: 0.3169 - val_precision_6: 0.6364 - val_recall_6: 0.0493\n",
      "Epoch 24/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 0.3438 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6484 - accuracy: 0.2917 - precision_6: 1.0000 - recall_6: 0.041 - ETA: 0s - loss: 1.6283 - accuracy: 0.3250 - precision_6: 0.7692 - recall_6: 0.062 - ETA: 0s - loss: 1.6479 - accuracy: 0.3214 - precision_6: 0.8235 - recall_6: 0.062 - ETA: 0s - loss: 1.6553 - accuracy: 0.3090 - precision_6: 0.8095 - recall_6: 0.059 - ETA: 0s - loss: 1.6754 - accuracy: 0.3210 - precision_6: 0.8400 - recall_6: 0.059 - ETA: 0s - loss: 1.6719 - accuracy: 0.3221 - precision_6: 0.8571 - recall_6: 0.057 - 0s 1ms/sample - loss: 1.6605 - accuracy: 0.3263 - precision_6: 0.8710 - recall_6: 0.0634 - val_loss: 1.7253 - val_accuracy: 0.2887 - val_precision_6: 0.8125 - val_recall_6: 0.0915\n",
      "Epoch 25/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7731 - accuracy: 0.3125 - precision_6: 1.0000 - recall_6: 0.031 - ETA: 0s - loss: 1.6780 - accuracy: 0.3333 - precision_6: 0.8571 - recall_6: 0.062 - ETA: 0s - loss: 1.6438 - accuracy: 0.3375 - precision_6: 0.6316 - recall_6: 0.075 - ETA: 0s - loss: 1.6500 - accuracy: 0.3348 - precision_6: 0.6538 - recall_6: 0.075 - ETA: 0s - loss: 1.6923 - accuracy: 0.3368 - precision_6: 0.6000 - recall_6: 0.072 - ETA: 0s - loss: 1.6896 - accuracy: 0.3409 - precision_6: 0.6410 - recall_6: 0.071 - 0s 1ms/sample - loss: 1.6743 - accuracy: 0.3310 - precision_6: 0.7021 - recall_6: 0.0775 - val_loss: 1.8450 - val_accuracy: 0.2958 - val_precision_6: 0.9231 - val_recall_6: 0.0845\n",
      "Epoch 26/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0304 - accuracy: 0.3125 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.8252 - accuracy: 0.3438 - precision_6: 0.8333 - recall_6: 0.0521        - ETA: 0s - loss: 1.7251 - accuracy: 0.3562 - precision_6: 0.7500 - recall_6: 0.075 - ETA: 0s - loss: 1.7086 - accuracy: 0.3571 - precision_6: 0.7200 - recall_6: 0.080 - ETA: 0s - loss: 1.7179 - accuracy: 0.3472 - precision_6: 0.6562 - recall_6: 0.072 - ETA: 0s - loss: 1.7346 - accuracy: 0.3608 - precision_6: 0.6944 - recall_6: 0.071 - ETA: 0s - loss: 1.7325 - accuracy: 0.3534 - precision_6: 0.6522 - recall_6: 0.072 - 0s 1ms/sample - loss: 1.7256 - accuracy: 0.3568 - precision_6: 0.6800 - recall_6: 0.0798 - val_loss: 1.6361 - val_accuracy: 0.3451 - val_precision_6: 0.9412 - val_recall_6: 0.1127\n",
      "Epoch 27/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7131 - accuracy: 0.3750 - precision_6: 1.0000 - recall_6: 0.093 - ETA: 0s - loss: 1.6888 - accuracy: 0.3750 - precision_6: 1.0000 - recall_6: 0.083 - ETA: 0s - loss: 1.6069 - accuracy: 0.3688 - precision_6: 0.7778 - recall_6: 0.087 - ETA: 0s - loss: 1.5723 - accuracy: 0.3705 - precision_6: 0.7917 - recall_6: 0.084 - ETA: 0s - loss: 1.5898 - accuracy: 0.3681 - precision_6: 0.7857 - recall_6: 0.076 - ETA: 0s - loss: 1.5982 - accuracy: 0.3636 - precision_6: 0.8000 - recall_6: 0.068 - ETA: 0s - loss: 1.6109 - accuracy: 0.3558 - precision_6: 0.8000 - recall_6: 0.067 - 0s 1ms/sample - loss: 1.6032 - accuracy: 0.3592 - precision_6: 0.8158 - recall_6: 0.0728 - val_loss: 1.6314 - val_accuracy: 0.3239 - val_precision_6: 0.9231 - val_recall_6: 0.0845\n",
      "Epoch 28/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5906 - accuracy: 0.3750 - precision_6: 0.7500 - recall_6: 0.093 - ETA: 0s - loss: 1.5490 - accuracy: 0.3750 - precision_6: 0.7778 - recall_6: 0.072 - ETA: 0s - loss: 1.5142 - accuracy: 0.3875 - precision_6: 0.7647 - recall_6: 0.081 - ETA: 0s - loss: 1.4989 - accuracy: 0.3795 - precision_6: 0.7826 - recall_6: 0.080 - ETA: 0s - loss: 1.5100 - accuracy: 0.3715 - precision_6: 0.7586 - recall_6: 0.076 - ETA: 0s - loss: 1.5172 - accuracy: 0.3949 - precision_6: 0.7576 - recall_6: 0.071 - ETA: 0s - loss: 1.5271 - accuracy: 0.3870 - precision_6: 0.7143 - recall_6: 0.072 - 0s 1ms/sample - loss: 1.5151 - accuracy: 0.3897 - precision_6: 0.7391 - recall_6: 0.0798 - val_loss: 1.5513 - val_accuracy: 0.3803 - val_precision_6: 0.8696 - val_recall_6: 0.1408\n",
      "Epoch 29/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.5312 - precision_6: 1.0000 - recall_6: 0.125 - ETA: 0s - loss: 1.4782 - accuracy: 0.4167 - precision_6: 0.9167 - recall_6: 0.114 - ETA: 0s - loss: 1.5503 - accuracy: 0.3688 - precision_6: 0.5938 - recall_6: 0.118 - ETA: 0s - loss: 1.4801 - accuracy: 0.3795 - precision_6: 0.6750 - recall_6: 0.120 - ETA: 0s - loss: 1.4813 - accuracy: 0.3854 - precision_6: 0.7045 - recall_6: 0.107 - ETA: 0s - loss: 1.5053 - accuracy: 0.3778 - precision_6: 0.7234 - recall_6: 0.096 - ETA: 0s - loss: 1.5189 - accuracy: 0.3630 - precision_6: 0.7091 - recall_6: 0.093 - 0s 1ms/sample - loss: 1.5027 - accuracy: 0.3709 - precision_6: 0.7333 - recall_6: 0.1033 - val_loss: 1.5543 - val_accuracy: 0.3521 - val_precision_6: 0.7826 - val_recall_6: 0.1268\n",
      "Epoch 30/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4688 - precision_6: 1.0000 - recall_6: 0.093 - ETA: 0s - loss: 1.4344 - accuracy: 0.4375 - precision_6: 0.6667 - recall_6: 0.104 - ETA: 0s - loss: 1.4664 - accuracy: 0.4250 - precision_6: 0.5294 - recall_6: 0.112 - ETA: 0s - loss: 1.4631 - accuracy: 0.4018 - precision_6: 0.5556 - recall_6: 0.111 - ETA: 0s - loss: 1.4793 - accuracy: 0.4028 - precision_6: 0.5636 - recall_6: 0.107 - ETA: 0s - loss: 1.4805 - accuracy: 0.4119 - precision_6: 0.6094 - recall_6: 0.110 - ETA: 0s - loss: 1.4812 - accuracy: 0.4062 - precision_6: 0.6316 - recall_6: 0.115 - 0s 1ms/sample - loss: 1.4651 - accuracy: 0.4131 - precision_6: 0.6585 - recall_6: 0.1268 - val_loss: 1.5953 - val_accuracy: 0.3310 - val_precision_6: 0.7778 - val_recall_6: 0.1479\n",
      "Epoch 31/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5425 - accuracy: 0.3438 - precision_6: 1.0000 - recall_6: 0.156 - ETA: 0s - loss: 1.5187 - accuracy: 0.4167 - precision_6: 0.7895 - recall_6: 0.156 - ETA: 0s - loss: 1.4453 - accuracy: 0.4125 - precision_6: 0.6944 - recall_6: 0.156 - ETA: 0s - loss: 1.4132 - accuracy: 0.4062 - precision_6: 0.7021 - recall_6: 0.147 - ETA: 0s - loss: 1.4326 - accuracy: 0.4097 - precision_6: 0.6909 - recall_6: 0.131 - ETA: 0s - loss: 1.4431 - accuracy: 0.4233 - precision_6: 0.6970 - recall_6: 0.130 - ETA: 0s - loss: 1.4519 - accuracy: 0.4183 - precision_6: 0.7037 - recall_6: 0.137 - 0s 1ms/sample - loss: 1.4356 - accuracy: 0.4225 - precision_6: 0.7241 - recall_6: 0.1479 - val_loss: 1.5848 - val_accuracy: 0.3310 - val_precision_6: 0.7826 - val_recall_6: 0.1268\n",
      "Epoch 32/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4583 - accuracy: 0.4375 - precision_6: 1.0000 - recall_6: 0.156 - ETA: 0s - loss: 1.4296 - accuracy: 0.3906 - precision_6: 0.6667 - recall_6: 0.140 - ETA: 0s - loss: 1.3930 - accuracy: 0.4115 - precision_6: 0.7333 - recall_6: 0.171 - ETA: 0s - loss: 1.4428 - accuracy: 0.3984 - precision_6: 0.6909 - recall_6: 0.148 - ETA: 0s - loss: 1.4321 - accuracy: 0.4125 - precision_6: 0.6944 - recall_6: 0.156 - ETA: 0s - loss: 1.4293 - accuracy: 0.4062 - precision_6: 0.7011 - recall_6: 0.158 - 0s 1ms/sample - loss: 1.4347 - accuracy: 0.3991 - precision_6: 0.6863 - recall_6: 0.1643 - val_loss: 1.6869 - val_accuracy: 0.3592 - val_precision_6: 0.6786 - val_recall_6: 0.1338\n",
      "Epoch 33/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6103 - accuracy: 0.4375 - precision_6: 1.0000 - recall_6: 0.156 - ETA: 0s - loss: 1.4858 - accuracy: 0.4479 - precision_6: 0.8000 - recall_6: 0.166 - ETA: 0s - loss: 1.4436 - accuracy: 0.4375 - precision_6: 0.6944 - recall_6: 0.156 - ETA: 0s - loss: 1.4170 - accuracy: 0.4196 - precision_6: 0.6923 - recall_6: 0.160 - ETA: 0s - loss: 1.4315 - accuracy: 0.4167 - precision_6: 0.6885 - recall_6: 0.145 - ETA: 0s - loss: 1.4353 - accuracy: 0.4318 - precision_6: 0.6933 - recall_6: 0.147 - ETA: 0s - loss: 1.4333 - accuracy: 0.4231 - precision_6: 0.6897 - recall_6: 0.144 - 0s 1ms/sample - loss: 1.4164 - accuracy: 0.4319 - precision_6: 0.7097 - recall_6: 0.1549 - val_loss: 1.5544 - val_accuracy: 0.3099 - val_precision_6: 0.7308 - val_recall_6: 0.1338\n",
      "Epoch 34/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4442 - accuracy: 0.4062 - precision_6: 1.0000 - recall_6: 0.125 - ETA: 0s - loss: 1.4139 - accuracy: 0.4375 - precision_6: 0.7647 - recall_6: 0.135 - ETA: 0s - loss: 1.3856 - accuracy: 0.4437 - precision_6: 0.7353 - recall_6: 0.156 - ETA: 0s - loss: 1.3661 - accuracy: 0.4464 - precision_6: 0.7500 - recall_6: 0.160 - ETA: 0s - loss: 1.3750 - accuracy: 0.4444 - precision_6: 0.7213 - recall_6: 0.152 - ETA: 0s - loss: 1.3776 - accuracy: 0.4574 - precision_6: 0.7143 - recall_6: 0.156 - ETA: 0s - loss: 1.3911 - accuracy: 0.4423 - precision_6: 0.7033 - recall_6: 0.153 - 0s 1ms/sample - loss: 1.3745 - accuracy: 0.4484 - precision_6: 0.7216 - recall_6: 0.1643 - val_loss: 1.5012 - val_accuracy: 0.3944 - val_precision_6: 0.7188 - val_recall_6: 0.1620\n",
      "Epoch 35/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3273 - accuracy: 0.4375 - precision_6: 0.8889 - recall_6: 0.250 - ETA: 0s - loss: 1.3295 - accuracy: 0.4896 - precision_6: 0.8148 - recall_6: 0.229 - ETA: 0s - loss: 1.3267 - accuracy: 0.4750 - precision_6: 0.7500 - recall_6: 0.225 - ETA: 0s - loss: 1.3253 - accuracy: 0.4643 - precision_6: 0.7231 - recall_6: 0.209 - ETA: 0s - loss: 1.3636 - accuracy: 0.4514 - precision_6: 0.7073 - recall_6: 0.201 - ETA: 0s - loss: 1.4267 - accuracy: 0.4517 - precision_6: 0.6667 - recall_6: 0.198 - ETA: 0s - loss: 1.4299 - accuracy: 0.4423 - precision_6: 0.6429 - recall_6: 0.194 - 0s 1ms/sample - loss: 1.4128 - accuracy: 0.4507 - precision_6: 0.6591 - recall_6: 0.2042 - val_loss: 1.5884 - val_accuracy: 0.3732 - val_precision_6: 0.6739 - val_recall_6: 0.2183\n",
      "Epoch 36/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.4688 - precision_6: 1.0000 - recall_6: 0.187 - ETA: 0s - loss: 1.3978 - accuracy: 0.4792 - precision_6: 0.8636 - recall_6: 0.197 - ETA: 0s - loss: 1.3557 - accuracy: 0.4375 - precision_6: 0.7619 - recall_6: 0.200 - ETA: 0s - loss: 1.3277 - accuracy: 0.4420 - precision_6: 0.7586 - recall_6: 0.196 - ETA: 0s - loss: 1.3641 - accuracy: 0.4514 - precision_6: 0.7571 - recall_6: 0.184 - ETA: 0s - loss: 1.3735 - accuracy: 0.4716 - precision_6: 0.7711 - recall_6: 0.181 - ETA: 0s - loss: 1.3767 - accuracy: 0.4712 - precision_6: 0.7525 - recall_6: 0.182 - 0s 1ms/sample - loss: 1.3599 - accuracy: 0.4765 - precision_6: 0.7685 - recall_6: 0.1948 - val_loss: 1.4782 - val_accuracy: 0.4225 - val_precision_6: 0.8485 - val_recall_6: 0.1972\n",
      "Epoch 37/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3208 - accuracy: 0.4688 - precision_6: 0.8889 - recall_6: 0.250 - ETA: 0s - loss: 1.3103 - accuracy: 0.5000 - precision_6: 0.8276 - recall_6: 0.250 - ETA: 0s - loss: 1.2689 - accuracy: 0.4750 - precision_6: 0.8222 - recall_6: 0.231 - ETA: 0s - loss: 1.2564 - accuracy: 0.4866 - precision_6: 0.8065 - recall_6: 0.223 - ETA: 0s - loss: 1.3004 - accuracy: 0.4757 - precision_6: 0.7722 - recall_6: 0.211 - ETA: 0s - loss: 1.3148 - accuracy: 0.4801 - precision_6: 0.7789 - recall_6: 0.210 - ETA: 0s - loss: 1.3255 - accuracy: 0.4784 - precision_6: 0.7500 - recall_6: 0.201 - 0s 1ms/sample - loss: 1.3119 - accuracy: 0.4836 - precision_6: 0.7607 - recall_6: 0.2089 - val_loss: 1.5730 - val_accuracy: 0.3521 - val_precision_6: 0.8000 - val_recall_6: 0.1690\n",
      "Epoch 38/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4526 - accuracy: 0.4688 - precision_6: 1.0000 - recall_6: 0.218 - ETA: 0s - loss: 1.4764 - accuracy: 0.4375 - precision_6: 0.6744 - recall_6: 0.226 - ETA: 0s - loss: 1.4029 - accuracy: 0.4635 - precision_6: 0.7164 - recall_6: 0.250 - ETA: 0s - loss: 1.4154 - accuracy: 0.4531 - precision_6: 0.7200 - recall_6: 0.210 - ETA: 0s - loss: 1.4162 - accuracy: 0.4656 - precision_6: 0.7386 - recall_6: 0.203 - ETA: 0s - loss: 1.4106 - accuracy: 0.4531 - precision_6: 0.7282 - recall_6: 0.195 - 0s 1ms/sample - loss: 1.4138 - accuracy: 0.4531 - precision_6: 0.7193 - recall_6: 0.1925 - val_loss: 1.6269 - val_accuracy: 0.3732 - val_precision_6: 0.7097 - val_recall_6: 0.1549\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4510 - accuracy: 0.4688 - precision_6: 0.7778 - recall_6: 0.218 - ETA: 0s - loss: 1.3998 - accuracy: 0.4688 - precision_6: 0.7333 - recall_6: 0.229 - ETA: 0s - loss: 1.4205 - accuracy: 0.4563 - precision_6: 0.6531 - recall_6: 0.200 - ETA: 0s - loss: 1.5501 - accuracy: 0.4152 - precision_6: 0.5735 - recall_6: 0.174 - ETA: 0s - loss: 1.6470 - accuracy: 0.3924 - precision_6: 0.5556 - recall_6: 0.173 - ETA: 0s - loss: 1.6579 - accuracy: 0.4034 - precision_6: 0.5577 - recall_6: 0.164 - ETA: 0s - loss: 1.6848 - accuracy: 0.3942 - precision_6: 0.5410 - recall_6: 0.158 - 0s 1ms/sample - loss: 1.6999 - accuracy: 0.3897 - precision_6: 0.5317 - recall_6: 0.1573 - val_loss: 1.9200 - val_accuracy: 0.3099 - val_precision_6: 0.4167 - val_recall_6: 0.0704\n",
      "Epoch 40/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9859 - accuracy: 0.2500 - precision_6: 0.5000 - recall_6: 0.125 - ETA: 0s - loss: 1.7547 - accuracy: 0.3542 - precision_6: 0.6471 - recall_6: 0.114 - ETA: 0s - loss: 1.6304 - accuracy: 0.3875 - precision_6: 0.6774 - recall_6: 0.131 - ETA: 0s - loss: 1.6432 - accuracy: 0.3661 - precision_6: 0.6923 - recall_6: 0.120 - ETA: 0s - loss: 1.6616 - accuracy: 0.3438 - precision_6: 0.6818 - recall_6: 0.104 - ETA: 0s - loss: 1.7200 - accuracy: 0.3438 - precision_6: 0.6415 - recall_6: 0.096 - ETA: 0s - loss: 1.7472 - accuracy: 0.3245 - precision_6: 0.6034 - recall_6: 0.084 - 0s 1ms/sample - loss: 1.7608 - accuracy: 0.3239 - precision_6: 0.6000 - recall_6: 0.0845 - val_loss: 1.9264 - val_accuracy: 0.2746 - val_precision_6: 0.7778 - val_recall_6: 0.0493\n",
      "Epoch 41/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8897 - accuracy: 0.2812 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.8407 - accuracy: 0.2292 - precision_6: 0.6667 - recall_6: 0.0208        - ETA: 0s - loss: 1.7451 - accuracy: 0.2750 - precision_6: 0.5833 - recall_6: 0.043 - ETA: 0s - loss: 1.7671 - accuracy: 0.2679 - precision_6: 0.4737 - recall_6: 0.040 - ETA: 0s - loss: 1.7666 - accuracy: 0.2847 - precision_6: 0.4400 - recall_6: 0.038 - ETA: 0s - loss: 1.7553 - accuracy: 0.3011 - precision_6: 0.4828 - recall_6: 0.039 - ETA: 0s - loss: 1.7525 - accuracy: 0.2909 - precision_6: 0.5294 - recall_6: 0.043 - 1s 1ms/sample - loss: 1.7391 - accuracy: 0.2958 - precision_6: 0.5676 - recall_6: 0.0493 - val_loss: 1.6492 - val_accuracy: 0.3451 - val_precision_6: 0.9375 - val_recall_6: 0.1056\n",
      "Epoch 42/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7916 - accuracy: 0.3438 - precision_6: 0.0000e+00 - recall_6: 0.0000e+0 - ETA: 0s - loss: 1.6496 - accuracy: 0.3594 - precision_6: 0.5000 - recall_6: 0.0469        - ETA: 0s - loss: 1.5539 - accuracy: 0.3571 - precision_6: 0.6538 - recall_6: 0.075 - ETA: 0s - loss: 1.5524 - accuracy: 0.3507 - precision_6: 0.6562 - recall_6: 0.072 - ETA: 0s - loss: 1.5413 - accuracy: 0.3776 - precision_6: 0.7000 - recall_6: 0.072 - 0s 1ms/sample - loss: 1.5335 - accuracy: 0.3732 - precision_6: 0.7292 - recall_6: 0.0822 - val_loss: 1.4869 - val_accuracy: 0.4155 - val_precision_6: 1.0000 - val_recall_6: 0.1268\n",
      "Epoch 43/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5073 - accuracy: 0.4375 - precision_6: 1.0000 - recall_6: 0.062 - ETA: 0s - loss: 1.5172 - accuracy: 0.4062 - precision_6: 0.8571 - recall_6: 0.062 - ETA: 0s - loss: 1.5018 - accuracy: 0.4125 - precision_6: 0.8333 - recall_6: 0.093 - ETA: 0s - loss: 1.4714 - accuracy: 0.4196 - precision_6: 0.8462 - recall_6: 0.098 - ETA: 0s - loss: 1.4823 - accuracy: 0.4028 - precision_6: 0.8065 - recall_6: 0.086 - ETA: 0s - loss: 1.4928 - accuracy: 0.4176 - precision_6: 0.8108 - recall_6: 0.085 - ETA: 0s - loss: 1.4884 - accuracy: 0.4159 - precision_6: 0.7600 - recall_6: 0.091 - 1s 1ms/sample - loss: 1.4762 - accuracy: 0.4202 - precision_6: 0.7679 - recall_6: 0.1009 - val_loss: 1.4828 - val_accuracy: 0.3662 - val_precision_6: 0.8929 - val_recall_6: 0.1761\n",
      "Epoch 44/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4486 - accuracy: 0.4062 - precision_6: 1.0000 - recall_6: 0.187 - ETA: 0s - loss: 1.4822 - accuracy: 0.4531 - precision_6: 0.8333 - recall_6: 0.156 - ETA: 0s - loss: 1.4422 - accuracy: 0.4583 - precision_6: 0.8205 - recall_6: 0.166 - ETA: 0s - loss: 1.4505 - accuracy: 0.4414 - precision_6: 0.7907 - recall_6: 0.132 - ETA: 0s - loss: 1.4625 - accuracy: 0.4469 - precision_6: 0.7959 - recall_6: 0.121 - ETA: 0s - loss: 1.4731 - accuracy: 0.4297 - precision_6: 0.7627 - recall_6: 0.117 - 0s 1ms/sample - loss: 1.4662 - accuracy: 0.4296 - precision_6: 0.7429 - recall_6: 0.1221 - val_loss: 1.4753 - val_accuracy: 0.4155 - val_precision_6: 0.9091 - val_recall_6: 0.1408\n",
      "Epoch 45/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4134 - accuracy: 0.3750 - precision_6: 1.0000 - recall_6: 0.218 - ETA: 0s - loss: 1.4874 - accuracy: 0.3984 - precision_6: 0.7667 - recall_6: 0.179 - ETA: 0s - loss: 1.4241 - accuracy: 0.4062 - precision_6: 0.7551 - recall_6: 0.192 - ETA: 0s - loss: 1.4368 - accuracy: 0.4141 - precision_6: 0.7636 - recall_6: 0.164 - ETA: 0s - loss: 1.4504 - accuracy: 0.4281 - precision_6: 0.7581 - recall_6: 0.146 - ETA: 0s - loss: 1.4430 - accuracy: 0.4207 - precision_6: 0.7436 - recall_6: 0.139 - 0s 988us/sample - loss: 1.4302 - accuracy: 0.4225 - precision_6: 0.7590 - recall_6: 0.1479 - val_loss: 1.5659 - val_accuracy: 0.3662 - val_precision_6: 0.8696 - val_recall_6: 0.1408\n",
      "Epoch 46/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5114 - accuracy: 0.3438 - precision_6: 1.0000 - recall_6: 0.156 - ETA: 0s - loss: 1.4891 - accuracy: 0.3958 - precision_6: 0.8421 - recall_6: 0.166 - ETA: 0s - loss: 1.4490 - accuracy: 0.4375 - precision_6: 0.8529 - recall_6: 0.181 - ETA: 0s - loss: 1.4140 - accuracy: 0.4464 - precision_6: 0.8409 - recall_6: 0.165 - ETA: 0s - loss: 1.4278 - accuracy: 0.4549 - precision_6: 0.8269 - recall_6: 0.149 - ETA: 0s - loss: 1.4366 - accuracy: 0.4659 - precision_6: 0.8333 - recall_6: 0.142 - ETA: 0s - loss: 1.4252 - accuracy: 0.4663 - precision_6: 0.8194 - recall_6: 0.141 - 0s 1ms/sample - loss: 1.4122 - accuracy: 0.4695 - precision_6: 0.8312 - recall_6: 0.1502 - val_loss: 1.5045 - val_accuracy: 0.3592 - val_precision_6: 0.8696 - val_recall_6: 0.1408\n",
      "Epoch 47/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4010 - accuracy: 0.4688 - precision_6: 1.0000 - recall_6: 0.156 - ETA: 0s - loss: 1.4593 - accuracy: 0.4375 - precision_6: 0.8148 - recall_6: 0.171 - ETA: 0s - loss: 1.3887 - accuracy: 0.4427 - precision_6: 0.8780 - recall_6: 0.187 - ETA: 0s - loss: 1.3821 - accuracy: 0.4653 - precision_6: 0.8704 - recall_6: 0.163 - ETA: 0s - loss: 1.3831 - accuracy: 0.4830 - precision_6: 0.8548 - recall_6: 0.150 - ETA: 0s - loss: 1.3810 - accuracy: 0.4760 - precision_6: 0.8158 - recall_6: 0.149 - 0s 1ms/sample - loss: 1.3666 - accuracy: 0.4812 - precision_6: 0.8293 - recall_6: 0.1596 - val_loss: 1.4777 - val_accuracy: 0.4225 - val_precision_6: 0.8214 - val_recall_6: 0.1620\n",
      "Epoch 48/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.4688 - precision_6: 0.8750 - recall_6: 0.218 - ETA: 0s - loss: 1.3954 - accuracy: 0.4583 - precision_6: 0.7727 - recall_6: 0.177 - ETA: 0s - loss: 1.4172 - accuracy: 0.4375 - precision_6: 0.7742 - recall_6: 0.187 - ETA: 0s - loss: 1.3393 - accuracy: 0.4531 - precision_6: 0.7925 - recall_6: 0.218 - ETA: 0s - loss: 1.3426 - accuracy: 0.4570 - precision_6: 0.8103 - recall_6: 0.183 - ETA: 0s - loss: 1.3467 - accuracy: 0.4688 - precision_6: 0.8000 - recall_6: 0.175 - ETA: 0s - loss: 1.3407 - accuracy: 0.4688 - precision_6: 0.7647 - recall_6: 0.169 - 1s 1ms/sample - loss: 1.3294 - accuracy: 0.4765 - precision_6: 0.7647 - recall_6: 0.1831 - val_loss: 1.4774 - val_accuracy: 0.4085 - val_precision_6: 0.7647 - val_recall_6: 0.1831\n",
      "Epoch 49/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4145 - accuracy: 0.4375 - precision_6: 0.8750 - recall_6: 0.218 - ETA: 0s - loss: 1.4761 - accuracy: 0.4167 - precision_6: 0.6429 - recall_6: 0.187 - ETA: 0s - loss: 1.5382 - accuracy: 0.4125 - precision_6: 0.5424 - recall_6: 0.200 - ETA: 0s - loss: 1.5007 - accuracy: 0.4152 - precision_6: 0.5366 - recall_6: 0.196 - ETA: 0s - loss: 1.4726 - accuracy: 0.4271 - precision_6: 0.5556 - recall_6: 0.191 - ETA: 0s - loss: 1.4564 - accuracy: 0.4489 - precision_6: 0.5766 - recall_6: 0.181 - ETA: 0s - loss: 1.4507 - accuracy: 0.4495 - precision_6: 0.5827 - recall_6: 0.177 - 0s 1ms/sample - loss: 1.4417 - accuracy: 0.4507 - precision_6: 0.5954 - recall_6: 0.1831 - val_loss: 1.5094 - val_accuracy: 0.3873 - val_precision_6: 0.7200 - val_recall_6: 0.1268\n",
      "Epoch 50/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4263 - accuracy: 0.3438 - precision_6: 0.7143 - recall_6: 0.156 - ETA: 0s - loss: 1.4187 - accuracy: 0.4062 - precision_6: 0.7778 - recall_6: 0.145 - ETA: 0s - loss: 1.4020 - accuracy: 0.4187 - precision_6: 0.8276 - recall_6: 0.150 - ETA: 0s - loss: 1.3968 - accuracy: 0.4375 - precision_6: 0.8158 - recall_6: 0.138 - ETA: 0s - loss: 1.4145 - accuracy: 0.4479 - precision_6: 0.8140 - recall_6: 0.121 - ETA: 0s - loss: 1.4275 - accuracy: 0.4489 - precision_6: 0.7843 - recall_6: 0.113 - ETA: 0s - loss: 1.4201 - accuracy: 0.4471 - precision_6: 0.7656 - recall_6: 0.117 - 0s 1ms/sample - loss: 1.4078 - accuracy: 0.4507 - precision_6: 0.7794 - recall_6: 0.1244 - val_loss: 1.4636 - val_accuracy: 0.4296 - val_precision_6: 0.8462 - val_recall_6: 0.1549\n",
      "Epoch 51/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.5312 - precision_6: 1.0000 - recall_6: 0.250 - ETA: 0s - loss: 1.3942 - accuracy: 0.4844 - precision_6: 0.9000 - recall_6: 0.140 - ETA: 0s - loss: 1.3537 - accuracy: 0.4844 - precision_6: 0.9118 - recall_6: 0.161 - ETA: 0s - loss: 1.3725 - accuracy: 0.4766 - precision_6: 0.9167 - recall_6: 0.128 - ETA: 0s - loss: 1.3763 - accuracy: 0.4906 - precision_6: 0.8750 - recall_6: 0.131 - ETA: 0s - loss: 1.3670 - accuracy: 0.4818 - precision_6: 0.8136 - recall_6: 0.125 - 0s 1ms/sample - loss: 1.3596 - accuracy: 0.4812 - precision_6: 0.8056 - recall_6: 0.1362 - val_loss: 1.5163 - val_accuracy: 0.4014 - val_precision_6: 0.7667 - val_recall_6: 0.1620\n",
      "Epoch 52/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3234 - accuracy: 0.5000 - precision_6: 0.9167 - recall_6: 0.343 - ETA: 0s - loss: 1.4040 - accuracy: 0.4844 - precision_6: 0.8056 - recall_6: 0.226 - ETA: 0s - loss: 1.3484 - accuracy: 0.4844 - precision_6: 0.8491 - recall_6: 0.234 - ETA: 0s - loss: 1.3721 - accuracy: 0.4844 - precision_6: 0.8154 - recall_6: 0.207 - ETA: 0s - loss: 1.3628 - accuracy: 0.5125 - precision_6: 0.8214 - recall_6: 0.215 - ETA: 0s - loss: 1.3492 - accuracy: 0.5104 - precision_6: 0.8163 - recall_6: 0.208 - 0s 1ms/sample - loss: 1.3414 - accuracy: 0.5047 - precision_6: 0.8053 - recall_6: 0.2136 - val_loss: 1.4577 - val_accuracy: 0.4155 - val_precision_6: 0.7073 - val_recall_6: 0.2042\n",
      "Epoch 53/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2842 - accuracy: 0.5625 - precision_6: 0.8462 - recall_6: 0.343 - ETA: 0s - loss: 1.3885 - accuracy: 0.5000 - precision_6: 0.7576 - recall_6: 0.260 - ETA: 0s - loss: 1.3246 - accuracy: 0.5125 - precision_6: 0.8333 - recall_6: 0.281 - ETA: 0s - loss: 1.2650 - accuracy: 0.5357 - precision_6: 0.8514 - recall_6: 0.281 - ETA: 0s - loss: 1.2745 - accuracy: 0.5312 - precision_6: 0.8506 - recall_6: 0.256 - ETA: 0s - loss: 1.2873 - accuracy: 0.5369 - precision_6: 0.8224 - recall_6: 0.250 - ETA: 0s - loss: 1.2918 - accuracy: 0.5385 - precision_6: 0.7727 - recall_6: 0.245 - 0s 1ms/sample - loss: 1.2783 - accuracy: 0.5399 - precision_6: 0.7826 - recall_6: 0.2535 - val_loss: 1.3639 - val_accuracy: 0.4859 - val_precision_6: 0.8125 - val_recall_6: 0.2746\n",
      "Epoch 54/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2174 - accuracy: 0.5312 - precision_6: 0.8000 - recall_6: 0.375 - ETA: 0s - loss: 1.3475 - accuracy: 0.4583 - precision_6: 0.6842 - recall_6: 0.270 - ETA: 0s - loss: 1.3072 - accuracy: 0.4812 - precision_6: 0.7258 - recall_6: 0.281 - ETA: 0s - loss: 1.2825 - accuracy: 0.5000 - precision_6: 0.7436 - recall_6: 0.258 - ETA: 0s - loss: 1.2962 - accuracy: 0.5069 - precision_6: 0.7582 - recall_6: 0.239 - ETA: 0s - loss: 1.3662 - accuracy: 0.4943 - precision_6: 0.7257 - recall_6: 0.233 - ETA: 0s - loss: 1.4101 - accuracy: 0.4784 - precision_6: 0.6940 - recall_6: 0.223 - 0s 1ms/sample - loss: 1.4081 - accuracy: 0.4812 - precision_6: 0.7029 - recall_6: 0.2277 - val_loss: 1.4436 - val_accuracy: 0.4859 - val_precision_6: 0.6724 - val_recall_6: 0.2746\n",
      "Epoch 55/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5821 - accuracy: 0.4375 - precision_6: 0.6923 - recall_6: 0.281 - ETA: 0s - loss: 1.4878 - accuracy: 0.4219 - precision_6: 0.6471 - recall_6: 0.257 - ETA: 0s - loss: 1.4261 - accuracy: 0.4583 - precision_6: 0.6622 - recall_6: 0.255 - ETA: 0s - loss: 1.3915 - accuracy: 0.4757 - precision_6: 0.7188 - recall_6: 0.239 - ETA: 0s - loss: 1.3917 - accuracy: 0.4766 - precision_6: 0.7068 - recall_6: 0.244 - 0s 958us/sample - loss: 1.3791 - accuracy: 0.4789 - precision_6: 0.7114 - recall_6: 0.2488 - val_loss: 1.4185 - val_accuracy: 0.4085 - val_precision_6: 0.7381 - val_recall_6: 0.2183\n",
      "Epoch 56/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4285 - accuracy: 0.4688 - precision_6: 0.8333 - recall_6: 0.312 - ETA: 0s - loss: 1.3471 - accuracy: 0.5000 - precision_6: 0.7750 - recall_6: 0.242 - ETA: 0s - loss: 1.3216 - accuracy: 0.4866 - precision_6: 0.7812 - recall_6: 0.223 - ETA: 0s - loss: 1.3268 - accuracy: 0.5156 - precision_6: 0.8118 - recall_6: 0.215 - ETA: 0s - loss: 1.3405 - accuracy: 0.5052 - precision_6: 0.7745 - recall_6: 0.205 - 0s 962us/sample - loss: 1.3487 - accuracy: 0.5023 - precision_6: 0.7563 - recall_6: 0.2113 - val_loss: 1.5598 - val_accuracy: 0.4155 - val_precision_6: 0.6290 - val_recall_6: 0.2746\n",
      "Epoch 57/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5446 - accuracy: 0.4688 - precision_6: 0.8333 - recall_6: 0.312 - ETA: 0s - loss: 1.5285 - accuracy: 0.4297 - precision_6: 0.6415 - recall_6: 0.265 - ETA: 0s - loss: 1.4511 - accuracy: 0.4427 - precision_6: 0.6420 - recall_6: 0.270 - ETA: 0s - loss: 1.3978 - accuracy: 0.4618 - precision_6: 0.6757 - recall_6: 0.260 - ETA: 0s - loss: 1.4386 - accuracy: 0.4609 - precision_6: 0.6597 - recall_6: 0.247 - 0s 965us/sample - loss: 1.4242 - accuracy: 0.4601 - precision_6: 0.6584 - recall_6: 0.2488 - val_loss: 1.5363 - val_accuracy: 0.4085 - val_precision_6: 0.6458 - val_recall_6: 0.2183\n",
      "Epoch 58/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7187 - accuracy: 0.3750 - precision_6: 0.6000 - recall_6: 0.187 - ETA: 0s - loss: 1.5040 - accuracy: 0.4297 - precision_6: 0.6429 - recall_6: 0.210 - ETA: 0s - loss: 1.4465 - accuracy: 0.4479 - precision_6: 0.7049 - recall_6: 0.224 - ETA: 0s - loss: 1.4405 - accuracy: 0.4414 - precision_6: 0.6944 - recall_6: 0.195 - ETA: 0s - loss: 1.4285 - accuracy: 0.4574 - precision_6: 0.6701 - recall_6: 0.184 - ETA: 0s - loss: 1.4202 - accuracy: 0.4567 - precision_6: 0.6549 - recall_6: 0.177 - 0s 1ms/sample - loss: 1.4043 - accuracy: 0.4624 - precision_6: 0.6695 - recall_6: 0.1854 - val_loss: 1.5550 - val_accuracy: 0.3380 - val_precision_6: 0.7241 - val_recall_6: 0.1479\n",
      "Epoch 59/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5859 - accuracy: 0.3438 - precision_6: 0.7500 - recall_6: 0.187 - ETA: 0s - loss: 1.5805 - accuracy: 0.4167 - precision_6: 0.7895 - recall_6: 0.156 - ETA: 0s - loss: 1.4822 - accuracy: 0.4250 - precision_6: 0.7742 - recall_6: 0.150 - ETA: 0s - loss: 1.4267 - accuracy: 0.4241 - precision_6: 0.7955 - recall_6: 0.156 - ETA: 0s - loss: 1.4341 - accuracy: 0.4344 - precision_6: 0.7313 - recall_6: 0.153 - ETA: 0s - loss: 1.4717 - accuracy: 0.4245 - precision_6: 0.6786 - recall_6: 0.148 - 0s 1ms/sample - loss: 1.4825 - accuracy: 0.4249 - precision_6: 0.6809 - recall_6: 0.1502 - val_loss: 1.7385 - val_accuracy: 0.4225 - val_precision_6: 0.8846 - val_recall_6: 0.1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9665 - accuracy: 0.3750 - precision_6: 1.0000 - recall_6: 0.093 - ETA: 0s - loss: 1.7694 - accuracy: 0.3828 - precision_6: 0.6087 - recall_6: 0.109 - ETA: 0s - loss: 1.7238 - accuracy: 0.4271 - precision_6: 0.7179 - recall_6: 0.145 - ETA: 0s - loss: 1.6246 - accuracy: 0.4492 - precision_6: 0.7200 - recall_6: 0.140 - ETA: 0s - loss: 1.6257 - accuracy: 0.4403 - precision_6: 0.7089 - recall_6: 0.159 - ETA: 0s - loss: 1.6009 - accuracy: 0.4375 - precision_6: 0.6863 - recall_6: 0.168 - 0s 984us/sample - loss: 1.5858 - accuracy: 0.4437 - precision_6: 0.7037 - recall_6: 0.1784 - val_loss: 1.4470 - val_accuracy: 0.4507 - val_precision_6: 0.7547 - val_recall_6: 0.2817\n",
      "Epoch 61/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.5312 - precision_6: 1.0000 - recall_6: 0.312 - ETA: 0s - loss: 1.4346 - accuracy: 0.4766 - precision_6: 0.8095 - recall_6: 0.265 - ETA: 0s - loss: 1.3384 - accuracy: 0.5052 - precision_6: 0.8254 - recall_6: 0.270 - ETA: 0s - loss: 1.3393 - accuracy: 0.5069 - precision_6: 0.8118 - recall_6: 0.239 - ETA: 0s - loss: 1.3323 - accuracy: 0.5208 - precision_6: 0.7826 - recall_6: 0.234 - 0s 965us/sample - loss: 1.3181 - accuracy: 0.5235 - precision_6: 0.7923 - recall_6: 0.2418 - val_loss: 1.3944 - val_accuracy: 0.4366 - val_precision_6: 0.6000 - val_recall_6: 0.2113\n",
      "Epoch 62/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4469 - accuracy: 0.3750 - precision_6: 0.5385 - recall_6: 0.218 - ETA: 0s - loss: 1.3923 - accuracy: 0.4219 - precision_6: 0.6078 - recall_6: 0.242 - ETA: 0s - loss: 1.3142 - accuracy: 0.4732 - precision_6: 0.6818 - recall_6: 0.267 - ETA: 0s - loss: 1.3125 - accuracy: 0.4757 - precision_6: 0.7048 - recall_6: 0.256 - ETA: 0s - loss: 1.3073 - accuracy: 0.4886 - precision_6: 0.7087 - recall_6: 0.255 - ETA: 0s - loss: 1.3158 - accuracy: 0.4808 - precision_6: 0.7013 - recall_6: 0.259 - 0s 977us/sample - loss: 1.3046 - accuracy: 0.4859 - precision_6: 0.7081 - recall_6: 0.2676 - val_loss: 1.3937 - val_accuracy: 0.4507 - val_precision_6: 0.7500 - val_recall_6: 0.2958\n",
      "Epoch 63/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4871 - accuracy: 0.5000 - precision_6: 0.7692 - recall_6: 0.312 - ETA: 0s - loss: 1.4129 - accuracy: 0.4896 - precision_6: 0.6923 - recall_6: 0.281 - ETA: 0s - loss: 1.3545 - accuracy: 0.5156 - precision_6: 0.6824 - recall_6: 0.302 - ETA: 0s - loss: 1.3434 - accuracy: 0.5278 - precision_6: 0.7155 - recall_6: 0.288 - ETA: 0s - loss: 1.3127 - accuracy: 0.5443 - precision_6: 0.7244 - recall_6: 0.294 - 0s 958us/sample - loss: 1.3126 - accuracy: 0.5423 - precision_6: 0.7151 - recall_6: 0.3005 - val_loss: 1.2910 - val_accuracy: 0.5141 - val_precision_6: 0.6970 - val_recall_6: 0.3239\n",
      "Epoch 64/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1822 - accuracy: 0.5625 - precision_6: 0.7059 - recall_6: 0.375 - ETA: 0s - loss: 1.2697 - accuracy: 0.5156 - precision_6: 0.6949 - recall_6: 0.320 - ETA: 0s - loss: 1.2595 - accuracy: 0.5208 - precision_6: 0.6703 - recall_6: 0.317 - ETA: 0s - loss: 1.2769 - accuracy: 0.5273 - precision_6: 0.6786 - recall_6: 0.296 - ETA: 0s - loss: 1.2564 - accuracy: 0.5483 - precision_6: 0.7170 - recall_6: 0.323 - ETA: 0s - loss: 1.2533 - accuracy: 0.5529 - precision_6: 0.7181 - recall_6: 0.324 - 0s 984us/sample - loss: 1.2424 - accuracy: 0.5540 - precision_6: 0.7268 - recall_6: 0.3310 - val_loss: 1.3674 - val_accuracy: 0.4930 - val_precision_6: 0.7500 - val_recall_6: 0.2958\n",
      "Epoch 65/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1704 - accuracy: 0.6250 - precision_6: 0.6875 - recall_6: 0.343 - ETA: 0s - loss: 1.2281 - accuracy: 0.5312 - precision_6: 0.6508 - recall_6: 0.320 - ETA: 0s - loss: 1.1898 - accuracy: 0.5521 - precision_6: 0.7111 - recall_6: 0.333 - ETA: 0s - loss: 1.2197 - accuracy: 0.5664 - precision_6: 0.7037 - recall_6: 0.296 - ETA: 0s - loss: 1.2481 - accuracy: 0.5719 - precision_6: 0.7132 - recall_6: 0.303 - ETA: 0s - loss: 1.2403 - accuracy: 0.5755 - precision_6: 0.7333 - recall_6: 0.315 - 0s 1ms/sample - loss: 1.2324 - accuracy: 0.5681 - precision_6: 0.7243 - recall_6: 0.3146 - val_loss: 1.2551 - val_accuracy: 0.5000 - val_precision_6: 0.7101 - val_recall_6: 0.3451\n",
      "Epoch 66/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.7188 - precision_6: 0.8750 - recall_6: 0.437 - ETA: 0s - loss: 1.1518 - accuracy: 0.5938 - precision_6: 0.7458 - recall_6: 0.343 - ETA: 0s - loss: 1.1285 - accuracy: 0.5833 - precision_6: 0.7416 - recall_6: 0.343 - ETA: 0s - loss: 1.2209 - accuracy: 0.5417 - precision_6: 0.7328 - recall_6: 0.333 - ETA: 0s - loss: 1.2873 - accuracy: 0.5284 - precision_6: 0.7037 - recall_6: 0.323 - ETA: 0s - loss: 1.3209 - accuracy: 0.5120 - precision_6: 0.6935 - recall_6: 0.310 - 0s 1ms/sample - loss: 1.3047 - accuracy: 0.5164 - precision_6: 0.7047 - recall_6: 0.3192 - val_loss: 1.5554 - val_accuracy: 0.4155 - val_precision_6: 0.5135 - val_recall_6: 0.2676\n",
      "Epoch 67/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5202 - accuracy: 0.5000 - precision_6: 0.6111 - recall_6: 0.343 - ETA: 0s - loss: 1.4051 - accuracy: 0.4922 - precision_6: 0.6087 - recall_6: 0.328 - ETA: 0s - loss: 1.3431 - accuracy: 0.4777 - precision_6: 0.6569 - recall_6: 0.299 - ETA: 0s - loss: 1.3477 - accuracy: 0.4781 - precision_6: 0.6794 - recall_6: 0.278 - ETA: 0s - loss: 1.3282 - accuracy: 0.4792 - precision_6: 0.7013 - recall_6: 0.281 - 0s 974us/sample - loss: 1.3179 - accuracy: 0.4765 - precision_6: 0.7076 - recall_6: 0.2840 - val_loss: 1.3817 - val_accuracy: 0.4296 - val_precision_6: 0.7213 - val_recall_6: 0.3099\n",
      "Epoch 68/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2006 - accuracy: 0.6250 - precision_6: 0.8333 - recall_6: 0.468 - ETA: 0s - loss: 1.3185 - accuracy: 0.5391 - precision_6: 0.7167 - recall_6: 0.335 - ETA: 0s - loss: 1.2493 - accuracy: 0.5365 - precision_6: 0.7558 - recall_6: 0.338 - ETA: 0s - loss: 1.2693 - accuracy: 0.5195 - precision_6: 0.7500 - recall_6: 0.304 - ETA: 0s - loss: 1.2900 - accuracy: 0.5125 - precision_6: 0.7226 - recall_6: 0.309 - ETA: 0s - loss: 1.3132 - accuracy: 0.5000 - precision_6: 0.6919 - recall_6: 0.286 - 0s 974us/sample - loss: 1.2967 - accuracy: 0.5047 - precision_6: 0.7039 - recall_6: 0.2958 - val_loss: 1.3529 - val_accuracy: 0.4789 - val_precision_6: 0.7255 - val_recall_6: 0.2606\n",
      "Epoch 69/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2537 - accuracy: 0.5000 - precision_6: 0.9231 - recall_6: 0.375 - ETA: 0s - loss: 1.2821 - accuracy: 0.4792 - precision_6: 0.8611 - recall_6: 0.322 - ETA: 0s - loss: 1.2437 - accuracy: 0.5000 - precision_6: 0.8226 - recall_6: 0.318 - ETA: 0s - loss: 1.2033 - accuracy: 0.5089 - precision_6: 0.8193 - recall_6: 0.303 - ETA: 0s - loss: 1.2133 - accuracy: 0.5000 - precision_6: 0.8218 - recall_6: 0.288 - ETA: 0s - loss: 1.2149 - accuracy: 0.5284 - precision_6: 0.8279 - recall_6: 0.286 - ETA: 0s - loss: 1.2249 - accuracy: 0.5144 - precision_6: 0.8041 - recall_6: 0.286 - 0s 1ms/sample - loss: 1.2074 - accuracy: 0.5211 - precision_6: 0.8129 - recall_6: 0.2958 - val_loss: 1.3405 - val_accuracy: 0.4930 - val_precision_6: 0.7736 - val_recall_6: 0.2887\n",
      "Epoch 70/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1452 - accuracy: 0.5938 - precision_6: 0.9333 - recall_6: 0.437 - ETA: 0s - loss: 1.2761 - accuracy: 0.5417 - precision_6: 0.9394 - recall_6: 0.322 - ETA: 0s - loss: 1.2185 - accuracy: 0.5312 - precision_6: 0.9123 - recall_6: 0.325 - ETA: 0s - loss: 1.1756 - accuracy: 0.5312 - precision_6: 0.8889 - recall_6: 0.321 - ETA: 0s - loss: 1.2063 - accuracy: 0.5344 - precision_6: 0.8609 - recall_6: 0.309 - ETA: 0s - loss: 1.1973 - accuracy: 0.5339 - precision_6: 0.8429 - recall_6: 0.307 - 0s 993us/sample - loss: 1.1986 - accuracy: 0.5305 - precision_6: 0.8261 - recall_6: 0.3122 - val_loss: 1.3533 - val_accuracy: 0.4718 - val_precision_6: 0.7213 - val_recall_6: 0.3099\n",
      "Epoch 71/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1211 - accuracy: 0.5625 - precision_6: 0.8824 - recall_6: 0.468 - ETA: 0s - loss: 1.2935 - accuracy: 0.5000 - precision_6: 0.7241 - recall_6: 0.328 - ETA: 0s - loss: 1.2695 - accuracy: 0.5000 - precision_6: 0.7159 - recall_6: 0.328 - ETA: 0s - loss: 1.3174 - accuracy: 0.4766 - precision_6: 0.7030 - recall_6: 0.277 - ETA: 0s - loss: 1.3492 - accuracy: 0.4875 - precision_6: 0.6905 - recall_6: 0.271 - ETA: 0s - loss: 1.3487 - accuracy: 0.4904 - precision_6: 0.6667 - recall_6: 0.259 - 0s 974us/sample - loss: 1.3353 - accuracy: 0.4953 - precision_6: 0.6766 - recall_6: 0.2653 - val_loss: 1.4066 - val_accuracy: 0.4507 - val_precision_6: 0.8293 - val_recall_6: 0.2394\n",
      "Epoch 72/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2189 - accuracy: 0.5625 - precision_6: 1.0000 - recall_6: 0.343 - ETA: 0s - loss: 1.2658 - accuracy: 0.5078 - precision_6: 0.7955 - recall_6: 0.273 - ETA: 0s - loss: 1.2235 - accuracy: 0.5208 - precision_6: 0.8154 - recall_6: 0.276 - ETA: 0s - loss: 1.2752 - accuracy: 0.4883 - precision_6: 0.7821 - recall_6: 0.238 - ETA: 0s - loss: 1.2876 - accuracy: 0.5170 - precision_6: 0.7570 - recall_6: 0.230 - 0s 955us/sample - loss: 1.2722 - accuracy: 0.5094 - precision_6: 0.7721 - recall_6: 0.2465 - val_loss: 1.3519 - val_accuracy: 0.4648 - val_precision_6: 0.7358 - val_recall_6: 0.2746\n",
      "Epoch 73/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0565 - accuracy: 0.5625 - precision_6: 1.0000 - recall_6: 0.375 - ETA: 0s - loss: 1.2291 - accuracy: 0.4922 - precision_6: 0.7692 - recall_6: 0.312 - ETA: 0s - loss: 1.1673 - accuracy: 0.5134 - precision_6: 0.7889 - recall_6: 0.317 - ETA: 0s - loss: 1.1968 - accuracy: 0.5035 - precision_6: 0.7748 - recall_6: 0.298 - ETA: 0s - loss: 1.2035 - accuracy: 0.5182 - precision_6: 0.7785 - recall_6: 0.302 - 0s 974us/sample - loss: 1.1904 - accuracy: 0.5258 - precision_6: 0.7738 - recall_6: 0.3052 - val_loss: 1.3126 - val_accuracy: 0.4789 - val_precision_6: 0.7333 - val_recall_6: 0.3099\n",
      "Epoch 74/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0403 - accuracy: 0.5625 - precision_6: 0.9375 - recall_6: 0.468 - ETA: 0s - loss: 1.1848 - accuracy: 0.5000 - precision_6: 0.8205 - recall_6: 0.333 - ETA: 0s - loss: 1.1417 - accuracy: 0.5312 - precision_6: 0.7711 - recall_6: 0.333 - ETA: 0s - loss: 1.1604 - accuracy: 0.5430 - precision_6: 0.7900 - recall_6: 0.308 - ETA: 0s - loss: 1.2141 - accuracy: 0.5483 - precision_6: 0.7445 - recall_6: 0.289 - 0s 962us/sample - loss: 1.1980 - accuracy: 0.5563 - precision_6: 0.7529 - recall_6: 0.3005 - val_loss: 1.3175 - val_accuracy: 0.5070 - val_precision_6: 0.7586 - val_recall_6: 0.3099\n",
      "Epoch 75/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0772 - accuracy: 0.5625 - precision_6: 1.0000 - recall_6: 0.406 - ETA: 0s - loss: 1.1694 - accuracy: 0.5312 - precision_6: 0.7966 - recall_6: 0.367 - ETA: 0s - loss: 1.1367 - accuracy: 0.5417 - precision_6: 0.8068 - recall_6: 0.369 - ETA: 0s - loss: 1.1674 - accuracy: 0.5273 - precision_6: 0.8218 - recall_6: 0.324 - ETA: 0s - loss: 1.1609 - accuracy: 0.5531 - precision_6: 0.8154 - recall_6: 0.331 - ETA: 0s - loss: 1.1803 - accuracy: 0.5481 - precision_6: 0.7941 - recall_6: 0.324 - 0s 974us/sample - loss: 1.1632 - accuracy: 0.5563 - precision_6: 0.8011 - recall_6: 0.3310 - val_loss: 1.3423 - val_accuracy: 0.4859 - val_precision_6: 0.7460 - val_recall_6: 0.3310\n",
      "Epoch 76/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.6250 - precision_6: 0.9333 - recall_6: 0.437 - ETA: 0s - loss: 1.1668 - accuracy: 0.5312 - precision_6: 0.8302 - recall_6: 0.343 - ETA: 0s - loss: 1.1386 - accuracy: 0.5625 - precision_6: 0.8171 - recall_6: 0.349 - ETA: 0s - loss: 1.1773 - accuracy: 0.5586 - precision_6: 0.7980 - recall_6: 0.308 - ETA: 0s - loss: 1.1838 - accuracy: 0.5653 - precision_6: 0.7958 - recall_6: 0.321 - 0s 969us/sample - loss: 1.1680 - accuracy: 0.5681 - precision_6: 0.8000 - recall_6: 0.3286 - val_loss: 1.3243 - val_accuracy: 0.5070 - val_precision_6: 0.6912 - val_recall_6: 0.3310\n",
      "Epoch 77/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0032 - accuracy: 0.5625 - precision_6: 0.9333 - recall_6: 0.437 - ETA: 0s - loss: 1.1428 - accuracy: 0.5234 - precision_6: 0.7931 - recall_6: 0.359 - ETA: 0s - loss: 1.1106 - accuracy: 0.5469 - precision_6: 0.8068 - recall_6: 0.369 - ETA: 0s - loss: 1.1755 - accuracy: 0.5243 - precision_6: 0.7750 - recall_6: 0.322 - ETA: 0s - loss: 1.1748 - accuracy: 0.5483 - precision_6: 0.7770 - recall_6: 0.326 - ETA: 0s - loss: 1.1769 - accuracy: 0.5433 - precision_6: 0.7803 - recall_6: 0.324 - 0s 972us/sample - loss: 1.1609 - accuracy: 0.5516 - precision_6: 0.7877 - recall_6: 0.3310 - val_loss: 1.2800 - val_accuracy: 0.4930 - val_precision_6: 0.7183 - val_recall_6: 0.3592\n",
      "Epoch 78/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0315 - accuracy: 0.5938 - precision_6: 0.8824 - recall_6: 0.468 - ETA: 0s - loss: 1.1220 - accuracy: 0.5234 - precision_6: 0.7857 - recall_6: 0.343 - ETA: 0s - loss: 1.1034 - accuracy: 0.5417 - precision_6: 0.7976 - recall_6: 0.349 - ETA: 0s - loss: 1.1282 - accuracy: 0.5382 - precision_6: 0.8036 - recall_6: 0.312 - ETA: 0s - loss: 1.1427 - accuracy: 0.5483 - precision_6: 0.7899 - recall_6: 0.309 - ETA: 0s - loss: 1.1450 - accuracy: 0.5457 - precision_6: 0.7901 - recall_6: 0.307 - 0s 977us/sample - loss: 1.1277 - accuracy: 0.5540 - precision_6: 0.7988 - recall_6: 0.3169 - val_loss: 1.2791 - val_accuracy: 0.4930 - val_precision_6: 0.6818 - val_recall_6: 0.3169\n",
      "Epoch 79/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0211 - accuracy: 0.5938 - precision_6: 1.0000 - recall_6: 0.500 - ETA: 0s - loss: 1.1194 - accuracy: 0.5312 - precision_6: 0.8033 - recall_6: 0.382 - ETA: 0s - loss: 1.0751 - accuracy: 0.5536 - precision_6: 0.8039 - recall_6: 0.366 - ETA: 0s - loss: 1.0932 - accuracy: 0.5781 - precision_6: 0.8099 - recall_6: 0.359 - ETA: 0s - loss: 1.0784 - accuracy: 0.5885 - precision_6: 0.8107 - recall_6: 0.356 - 0s 960us/sample - loss: 1.0737 - accuracy: 0.5869 - precision_6: 0.8053 - recall_6: 0.3592 - val_loss: 1.3352 - val_accuracy: 0.4789 - val_precision_6: 0.6533 - val_recall_6: 0.3451\n",
      "Epoch 80/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.5938 - precision_6: 0.8333 - recall_6: 0.468 - ETA: 0s - loss: 1.0706 - accuracy: 0.5625 - precision_6: 0.8197 - recall_6: 0.390 - ETA: 0s - loss: 1.0333 - accuracy: 0.5885 - precision_6: 0.8298 - recall_6: 0.406 - ETA: 0s - loss: 1.0661 - accuracy: 0.5764 - precision_6: 0.8527 - recall_6: 0.381 - ETA: 0s - loss: 1.0592 - accuracy: 0.5964 - precision_6: 0.8480 - recall_6: 0.377 - 0s 991us/sample - loss: 1.0535 - accuracy: 0.5986 - precision_6: 0.8385 - recall_6: 0.3779 - val_loss: 1.2765 - val_accuracy: 0.5211 - val_precision_6: 0.7324 - val_recall_6: 0.3662\n",
      "Epoch 81/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9760 - accuracy: 0.6562 - precision_6: 0.9412 - recall_6: 0.500 - ETA: 0s - loss: 1.0331 - accuracy: 0.5703 - precision_6: 0.8594 - recall_6: 0.429 - ETA: 0s - loss: 0.9955 - accuracy: 0.5982 - precision_6: 0.8482 - recall_6: 0.424 - ETA: 0s - loss: 1.0146 - accuracy: 0.6111 - precision_6: 0.8451 - recall_6: 0.416 - ETA: 0s - loss: 1.0198 - accuracy: 0.6250 - precision_6: 0.8368 - recall_6: 0.414 - 0s 981us/sample - loss: 1.0218 - accuracy: 0.6221 - precision_6: 0.8263 - recall_6: 0.4131 - val_loss: 1.2965 - val_accuracy: 0.4930 - val_precision_6: 0.7143 - val_recall_6: 0.3873\n",
      "Epoch 82/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9167 - accuracy: 0.7500 - precision_6: 0.8947 - recall_6: 0.531 - ETA: 0s - loss: 1.0418 - accuracy: 0.6146 - precision_6: 0.8511 - recall_6: 0.416 - ETA: 0s - loss: 1.0060 - accuracy: 0.6000 - precision_6: 0.8193 - recall_6: 0.425 - ETA: 0s - loss: 0.9832 - accuracy: 0.6250 - precision_6: 0.8174 - recall_6: 0.419 - ETA: 0s - loss: 0.9943 - accuracy: 0.6181 - precision_6: 0.7973 - recall_6: 0.409 - ETA: 0s - loss: 0.9963 - accuracy: 0.6250 - precision_6: 0.8030 - recall_6: 0.424 - 0s 1ms/sample - loss: 1.0028 - accuracy: 0.6221 - precision_6: 0.7920 - recall_6: 0.4202 - val_loss: 1.2364 - val_accuracy: 0.5493 - val_precision_6: 0.7500 - val_recall_6: 0.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8449 - accuracy: 0.7500 - precision_6: 0.9474 - recall_6: 0.562 - ETA: 0s - loss: 0.9835 - accuracy: 0.6328 - precision_6: 0.8143 - recall_6: 0.445 - ETA: 0s - loss: 1.0031 - accuracy: 0.6198 - precision_6: 0.8095 - recall_6: 0.442 - ETA: 0s - loss: 1.0022 - accuracy: 0.6319 - precision_6: 0.8013 - recall_6: 0.434 - ETA: 0s - loss: 1.0198 - accuracy: 0.6222 - precision_6: 0.7887 - recall_6: 0.434 - ETA: 0s - loss: 1.0194 - accuracy: 0.6274 - precision_6: 0.7911 - recall_6: 0.427 - 0s 1ms/sample - loss: 1.0038 - accuracy: 0.6315 - precision_6: 0.7983 - recall_6: 0.4366 - val_loss: 1.1864 - val_accuracy: 0.5563 - val_precision_6: 0.7011 - val_recall_6: 0.4296\n",
      "Epoch 84/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9734 - accuracy: 0.6875 - precision_6: 0.8571 - recall_6: 0.562 - ETA: 0s - loss: 0.9430 - accuracy: 0.6250 - precision_6: 0.8194 - recall_6: 0.460 - ETA: 0s - loss: 0.9250 - accuracy: 0.6562 - precision_6: 0.8148 - recall_6: 0.458 - ETA: 0s - loss: 0.9233 - accuracy: 0.6680 - precision_6: 0.8296 - recall_6: 0.437 - ETA: 0s - loss: 0.9247 - accuracy: 0.6781 - precision_6: 0.8222 - recall_6: 0.462 - ETA: 0s - loss: 0.9438 - accuracy: 0.6611 - precision_6: 0.7884 - recall_6: 0.456 - 0s 1ms/sample - loss: 0.9262 - accuracy: 0.6690 - precision_6: 0.7968 - recall_6: 0.4695 - val_loss: 1.1684 - val_accuracy: 0.5704 - val_precision_6: 0.6699 - val_recall_6: 0.4859\n",
      "Epoch 85/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8499 - accuracy: 0.6875 - precision_6: 0.9048 - recall_6: 0.593 - ETA: 0s - loss: 0.9923 - accuracy: 0.6354 - precision_6: 0.7344 - recall_6: 0.489 - ETA: 0s - loss: 0.9587 - accuracy: 0.6313 - precision_6: 0.7222 - recall_6: 0.487 - ETA: 0s - loss: 0.9842 - accuracy: 0.6384 - precision_6: 0.7279 - recall_6: 0.477 - ETA: 0s - loss: 0.9932 - accuracy: 0.6375 - precision_6: 0.7487 - recall_6: 0.465 - ETA: 0s - loss: 1.0063 - accuracy: 0.6224 - precision_6: 0.7415 - recall_6: 0.455 - 0s 1ms/sample - loss: 1.0032 - accuracy: 0.6244 - precision_6: 0.7378 - recall_6: 0.4624 - val_loss: 1.4767 - val_accuracy: 0.4577 - val_precision_6: 0.5591 - val_recall_6: 0.3662\n",
      "Epoch 86/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4586 - accuracy: 0.5312 - precision_6: 0.6500 - recall_6: 0.406 - ETA: 0s - loss: 1.1499 - accuracy: 0.5469 - precision_6: 0.7125 - recall_6: 0.445 - ETA: 0s - loss: 1.1620 - accuracy: 0.5521 - precision_6: 0.6885 - recall_6: 0.437 - ETA: 0s - loss: 1.1265 - accuracy: 0.5820 - precision_6: 0.7170 - recall_6: 0.445 - ETA: 0s - loss: 1.1289 - accuracy: 0.5938 - precision_6: 0.7171 - recall_6: 0.459 - ETA: 0s - loss: 1.1284 - accuracy: 0.5745 - precision_6: 0.7054 - recall_6: 0.437 - 0s 1ms/sample - loss: 1.1091 - accuracy: 0.5822 - precision_6: 0.7116 - recall_6: 0.4460 - val_loss: 1.3285 - val_accuracy: 0.5070 - val_precision_6: 0.5926 - val_recall_6: 0.3380\n",
      "Epoch 87/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0975 - accuracy: 0.5938 - precision_6: 0.6364 - recall_6: 0.437 - ETA: 0s - loss: 0.9682 - accuracy: 0.6406 - precision_6: 0.7561 - recall_6: 0.484 - ETA: 0s - loss: 0.9206 - accuracy: 0.6562 - precision_6: 0.7883 - recall_6: 0.482 - ETA: 0s - loss: 0.9497 - accuracy: 0.6656 - precision_6: 0.7784 - recall_6: 0.450 - ETA: 0s - loss: 0.9425 - accuracy: 0.6615 - precision_6: 0.7818 - recall_6: 0.447 - 0s 998us/sample - loss: 0.9454 - accuracy: 0.6596 - precision_6: 0.7823 - recall_6: 0.4554 - val_loss: 1.2430 - val_accuracy: 0.5000 - val_precision_6: 0.6100 - val_recall_6: 0.4296\n",
      "Epoch 88/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.6875 - precision_6: 0.8000 - recall_6: 0.500 - ETA: 0s - loss: 0.9079 - accuracy: 0.6562 - precision_6: 0.7529 - recall_6: 0.500 - ETA: 0s - loss: 0.8774 - accuracy: 0.6823 - precision_6: 0.7561 - recall_6: 0.484 - ETA: 0s - loss: 0.8771 - accuracy: 0.6992 - precision_6: 0.7885 - recall_6: 0.480 - ETA: 0s - loss: 0.8815 - accuracy: 0.7031 - precision_6: 0.7941 - recall_6: 0.506 - ETA: 0s - loss: 0.8859 - accuracy: 0.6979 - precision_6: 0.7903 - recall_6: 0.510 - 0s 1ms/sample - loss: 0.8888 - accuracy: 0.6878 - precision_6: 0.7875 - recall_6: 0.5047 - val_loss: 1.1129 - val_accuracy: 0.5775 - val_precision_6: 0.6667 - val_recall_6: 0.4930\n",
      "Epoch 89/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8980 - accuracy: 0.6875 - precision_6: 0.7500 - recall_6: 0.562 - ETA: 0s - loss: 0.8569 - accuracy: 0.7031 - precision_6: 0.7667 - recall_6: 0.539 - ETA: 0s - loss: 0.8156 - accuracy: 0.7188 - precision_6: 0.7664 - recall_6: 0.546 - ETA: 0s - loss: 0.8150 - accuracy: 0.7266 - precision_6: 0.7977 - recall_6: 0.539 - ETA: 0s - loss: 0.8233 - accuracy: 0.7188 - precision_6: 0.8000 - recall_6: 0.556 - ETA: 0s - loss: 0.8372 - accuracy: 0.7043 - precision_6: 0.7889 - recall_6: 0.548 - 0s 984us/sample - loss: 0.8218 - accuracy: 0.7113 - precision_6: 0.7960 - recall_6: 0.5587 - val_loss: 1.1193 - val_accuracy: 0.5845 - val_precision_6: 0.6460 - val_recall_6: 0.5141\n",
      "Epoch 90/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.6562 - precision_6: 0.7200 - recall_6: 0.562 - ETA: 0s - loss: 0.8700 - accuracy: 0.6875 - precision_6: 0.7612 - recall_6: 0.531 - ETA: 0s - loss: 0.8757 - accuracy: 0.6750 - precision_6: 0.7414 - recall_6: 0.537 - ETA: 0s - loss: 0.8351 - accuracy: 0.7098 - precision_6: 0.7669 - recall_6: 0.558 - ETA: 0s - loss: 0.8738 - accuracy: 0.7000 - precision_6: 0.7639 - recall_6: 0.556 - ETA: 0s - loss: 0.8815 - accuracy: 0.6953 - precision_6: 0.7563 - recall_6: 0.549 - 0s 1ms/sample - loss: 0.8984 - accuracy: 0.6784 - precision_6: 0.7443 - recall_6: 0.5399 - val_loss: 1.2102 - val_accuracy: 0.5352 - val_precision_6: 0.5865 - val_recall_6: 0.4296\n",
      "Epoch 91/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9028 - accuracy: 0.6562 - precision_6: 0.6923 - recall_6: 0.562 - ETA: 0s - loss: 0.8294 - accuracy: 0.6250 - precision_6: 0.7500 - recall_6: 0.539 - ETA: 0s - loss: 0.8194 - accuracy: 0.6354 - precision_6: 0.7391 - recall_6: 0.531 - ETA: 0s - loss: 0.7930 - accuracy: 0.6736 - precision_6: 0.7843 - recall_6: 0.555 - ETA: 0s - loss: 0.8273 - accuracy: 0.6648 - precision_6: 0.7686 - recall_6: 0.556 - ETA: 0s - loss: 0.8266 - accuracy: 0.6635 - precision_6: 0.7600 - recall_6: 0.548 - 0s 1ms/sample - loss: 0.8112 - accuracy: 0.6714 - precision_6: 0.7670 - recall_6: 0.5563 - val_loss: 1.1143 - val_accuracy: 0.5493 - val_precision_6: 0.6273 - val_recall_6: 0.4859\n",
      "Epoch 92/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7839 - accuracy: 0.7188 - precision_6: 0.8000 - recall_6: 0.625 - ETA: 0s - loss: 0.8406 - accuracy: 0.6979 - precision_6: 0.7424 - recall_6: 0.510 - ETA: 0s - loss: 0.7524 - accuracy: 0.7063 - precision_6: 0.8018 - recall_6: 0.556 - ETA: 0s - loss: 0.7158 - accuracy: 0.7321 - precision_6: 0.8232 - recall_6: 0.602 - ETA: 0s - loss: 0.7518 - accuracy: 0.7312 - precision_6: 0.8143 - recall_6: 0.603 - ETA: 0s - loss: 0.7576 - accuracy: 0.7266 - precision_6: 0.8000 - recall_6: 0.604 - 0s 1ms/sample - loss: 0.7692 - accuracy: 0.7183 - precision_6: 0.7950 - recall_6: 0.6009 - val_loss: 1.0822 - val_accuracy: 0.5775 - val_precision_6: 0.6610 - val_recall_6: 0.5493\n",
      "Epoch 93/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8189 - accuracy: 0.7188 - precision_6: 0.8148 - recall_6: 0.687 - ETA: 0s - loss: 0.7228 - accuracy: 0.7188 - precision_6: 0.8000 - recall_6: 0.656 - ETA: 0s - loss: 0.7202 - accuracy: 0.7083 - precision_6: 0.7742 - recall_6: 0.625 - ETA: 0s - loss: 0.7046 - accuracy: 0.7326 - precision_6: 0.8070 - recall_6: 0.638 - ETA: 0s - loss: 0.7292 - accuracy: 0.7273 - precision_6: 0.7964 - recall_6: 0.633 - ETA: 0s - loss: 0.7423 - accuracy: 0.7260 - precision_6: 0.7838 - recall_6: 0.627 - 0s 1ms/sample - loss: 0.7274 - accuracy: 0.7324 - precision_6: 0.7901 - recall_6: 0.6362 - val_loss: 1.1187 - val_accuracy: 0.5845 - val_precision_6: 0.6198 - val_recall_6: 0.5282\n",
      "Epoch 94/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.7188 - precision_6: 0.7667 - recall_6: 0.718 - ETA: 0s - loss: 0.7138 - accuracy: 0.7266 - precision_6: 0.7788 - recall_6: 0.632 - ETA: 0s - loss: 0.7310 - accuracy: 0.7031 - precision_6: 0.7748 - recall_6: 0.609 - ETA: 0s - loss: 0.7172 - accuracy: 0.7227 - precision_6: 0.8000 - recall_6: 0.640 - ETA: 0s - loss: 0.7411 - accuracy: 0.7281 - precision_6: 0.7923 - recall_6: 0.643 - ETA: 0s - loss: 0.7741 - accuracy: 0.7109 - precision_6: 0.7756 - recall_6: 0.630 - 0s 1ms/sample - loss: 0.7941 - accuracy: 0.7019 - precision_6: 0.7652 - recall_6: 0.6197 - val_loss: 1.2810 - val_accuracy: 0.4859 - val_precision_6: 0.5794 - val_recall_6: 0.4366\n",
      "Epoch 95/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1500 - accuracy: 0.5625 - precision_6: 0.6667 - recall_6: 0.562 - ETA: 0s - loss: 1.1338 - accuracy: 0.5417 - precision_6: 0.6104 - recall_6: 0.489 - ETA: 0s - loss: 0.9520 - accuracy: 0.6250 - precision_6: 0.6867 - recall_6: 0.536 - ETA: 0s - loss: 0.9293 - accuracy: 0.6367 - precision_6: 0.7092 - recall_6: 0.543 - ETA: 0s - loss: 0.9203 - accuracy: 0.6500 - precision_6: 0.7114 - recall_6: 0.546 - ETA: 0s - loss: 0.8893 - accuracy: 0.6615 - precision_6: 0.7220 - recall_6: 0.554 - 0s 1ms/sample - loss: 0.8790 - accuracy: 0.6620 - precision_6: 0.7209 - recall_6: 0.5516 - val_loss: 1.0321 - val_accuracy: 0.6197 - val_precision_6: 0.6818 - val_recall_6: 0.4225\n",
      "Epoch 96/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.8125 - precision_6: 0.8333 - recall_6: 0.625 - ETA: 0s - loss: 0.8093 - accuracy: 0.6562 - precision_6: 0.7619 - recall_6: 0.500 - ETA: 0s - loss: 0.7977 - accuracy: 0.6771 - precision_6: 0.7556 - recall_6: 0.531 - ETA: 0s - loss: 0.8173 - accuracy: 0.6875 - precision_6: 0.7809 - recall_6: 0.543 - ETA: 0s - loss: 0.8475 - accuracy: 0.6960 - precision_6: 0.7698 - recall_6: 0.551 - ETA: 0s - loss: 0.8640 - accuracy: 0.6899 - precision_6: 0.7583 - recall_6: 0.550 - 0s 1ms/sample - loss: 0.8477 - accuracy: 0.6948 - precision_6: 0.7653 - recall_6: 0.5587 - val_loss: 1.1156 - val_accuracy: 0.5704 - val_precision_6: 0.6154 - val_recall_6: 0.4507\n",
      "Epoch 97/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.6875 - precision_6: 0.8148 - recall_6: 0.687 - ETA: 0s - loss: 0.8102 - accuracy: 0.6406 - precision_6: 0.7692 - recall_6: 0.546 - ETA: 0s - loss: 0.7712 - accuracy: 0.6667 - precision_6: 0.7868 - recall_6: 0.557 - ETA: 0s - loss: 0.7297 - accuracy: 0.7222 - precision_6: 0.8301 - recall_6: 0.593 - ETA: 0s - loss: 0.7489 - accuracy: 0.7131 - precision_6: 0.8214 - recall_6: 0.588 - ETA: 0s - loss: 0.7544 - accuracy: 0.7115 - precision_6: 0.8121 - recall_6: 0.581 - 0s 1ms/sample - loss: 0.7405 - accuracy: 0.7183 - precision_6: 0.8176 - recall_6: 0.5892 - val_loss: 1.0488 - val_accuracy: 0.5986 - val_precision_6: 0.7447 - val_recall_6: 0.4930\n",
      "Epoch 98/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.6875 - precision_6: 0.8462 - recall_6: 0.687 - ETA: 0s - loss: 0.8259 - accuracy: 0.6667 - precision_6: 0.7632 - recall_6: 0.604 - ETA: 0s - loss: 0.8047 - accuracy: 0.6927 - precision_6: 0.7740 - recall_6: 0.588 - ETA: 0s - loss: 0.8207 - accuracy: 0.6758 - precision_6: 0.7742 - recall_6: 0.562 - ETA: 0s - loss: 0.8198 - accuracy: 0.6844 - precision_6: 0.7722 - recall_6: 0.571 - ETA: 0s - loss: 0.8355 - accuracy: 0.6779 - precision_6: 0.7581 - recall_6: 0.564 - 0s 1000us/sample - loss: 0.8212 - accuracy: 0.6831 - precision_6: 0.7649 - recall_6: 0.5728 - val_loss: 1.1225 - val_accuracy: 0.5423 - val_precision_6: 0.6355 - val_recall_6: 0.4789\n",
      "Epoch 99/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0744 - accuracy: 0.5938 - precision_6: 0.7308 - recall_6: 0.593 - ETA: 0s - loss: 0.9092 - accuracy: 0.6042 - precision_6: 0.7308 - recall_6: 0.593 - ETA: 0s - loss: 0.8625 - accuracy: 0.6375 - precision_6: 0.7385 - recall_6: 0.600 - ETA: 0s - loss: 0.8624 - accuracy: 0.6607 - precision_6: 0.7514 - recall_6: 0.607 - ETA: 0s - loss: 0.8740 - accuracy: 0.6667 - precision_6: 0.7632 - recall_6: 0.604 - ETA: 0s - loss: 0.8659 - accuracy: 0.6797 - precision_6: 0.7708 - recall_6: 0.604 - 0s 1ms/sample - loss: 0.8681 - accuracy: 0.6761 - precision_6: 0.7665 - recall_6: 0.6009 - val_loss: 1.1833 - val_accuracy: 0.5563 - val_precision_6: 0.6132 - val_recall_6: 0.4577\n",
      "Epoch 100/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.6562 - precision_6: 0.6452 - recall_6: 0.625 - ETA: 0s - loss: 0.9023 - accuracy: 0.6172 - precision_6: 0.6545 - recall_6: 0.562 - ETA: 0s - loss: 0.8446 - accuracy: 0.6510 - precision_6: 0.6835 - recall_6: 0.562 - ETA: 0s - loss: 0.8106 - accuracy: 0.6836 - precision_6: 0.7374 - recall_6: 0.570 - ETA: 0s - loss: 0.8070 - accuracy: 0.6969 - precision_6: 0.7500 - recall_6: 0.581 - ETA: 0s - loss: 0.7767 - accuracy: 0.7083 - precision_6: 0.7774 - recall_6: 0.591 - 0s 1ms/sample - loss: 0.7992 - accuracy: 0.6995 - precision_6: 0.7676 - recall_6: 0.5892 - val_loss: 0.9774 - val_accuracy: 0.6197 - val_precision_6: 0.7113 - val_recall_6: 0.4859\n",
      "Epoch 101/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.8125 - precision_6: 0.8148 - recall_6: 0.687 - ETA: 0s - loss: 0.6583 - accuracy: 0.7734 - precision_6: 0.8384 - recall_6: 0.648 - ETA: 0s - loss: 0.6519 - accuracy: 0.7500 - precision_6: 0.8284 - recall_6: 0.625 - ETA: 0s - loss: 0.6583 - accuracy: 0.7535 - precision_6: 0.8295 - recall_6: 0.625 - ETA: 0s - loss: 0.6737 - accuracy: 0.7472 - precision_6: 0.8229 - recall_6: 0.633 - 0s 1ms/sample - loss: 0.6977 - accuracy: 0.7394 - precision_6: 0.8138 - recall_6: 0.6362 - val_loss: 1.0508 - val_accuracy: 0.5704 - val_precision_6: 0.6607 - val_recall_6: 0.5211\n",
      "Epoch 102/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.7188 - precision_6: 0.7857 - recall_6: 0.687 - ETA: 0s - loss: 0.7686 - accuracy: 0.6458 - precision_6: 0.7125 - recall_6: 0.593 - ETA: 0s - loss: 0.6780 - accuracy: 0.7125 - precision_6: 0.7574 - recall_6: 0.643 - ETA: 0s - loss: 0.6637 - accuracy: 0.7321 - precision_6: 0.7819 - recall_6: 0.656 - ETA: 0s - loss: 0.6622 - accuracy: 0.7431 - precision_6: 0.7908 - recall_6: 0.656 - ETA: 0s - loss: 0.6921 - accuracy: 0.7415 - precision_6: 0.7838 - recall_6: 0.659 - ETA: 0s - loss: 0.7167 - accuracy: 0.7332 - precision_6: 0.7739 - recall_6: 0.641 - 0s 981us/sample - loss: 0.7035 - accuracy: 0.7394 - precision_6: 0.7803 - recall_6: 0.6502 - val_loss: 1.1444 - val_accuracy: 0.5634 - val_precision_6: 0.6182 - val_recall_6: 0.4789\n",
      "Epoch 103/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.6562 - precision_6: 0.7200 - recall_6: 0.562 - ETA: 0s - loss: 0.7841 - accuracy: 0.6458 - precision_6: 0.7297 - recall_6: 0.562 - ETA: 0s - loss: 0.7453 - accuracy: 0.6771 - precision_6: 0.7333 - recall_6: 0.572 - ETA: 0s - loss: 0.7503 - accuracy: 0.6875 - precision_6: 0.7512 - recall_6: 0.589 - ETA: 0s - loss: 0.7948 - accuracy: 0.6875 - precision_6: 0.7562 - recall_6: 0.608 - ETA: 0s - loss: 0.7932 - accuracy: 0.6899 - precision_6: 0.7500 - recall_6: 0.605 - 0s 979us/sample - loss: 0.7780 - accuracy: 0.6972 - precision_6: 0.7572 - recall_6: 0.6150 - val_loss: 1.0172 - val_accuracy: 0.6127 - val_precision_6: 0.6916 - val_recall_6: 0.5211\n",
      "Epoch 104/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7091 - accuracy: 0.7188 - precision_6: 0.7586 - recall_6: 0.687 - ETA: 0s - loss: 0.6657 - accuracy: 0.7292 - precision_6: 0.7674 - recall_6: 0.687 - ETA: 0s - loss: 0.6126 - accuracy: 0.7656 - precision_6: 0.7939 - recall_6: 0.682 - ETA: 0s - loss: 0.6195 - accuracy: 0.7656 - precision_6: 0.8216 - recall_6: 0.683 - ETA: 0s - loss: 0.6795 - accuracy: 0.7358 - precision_6: 0.8028 - recall_6: 0.659 - 0s 1ms/sample - loss: 0.6582 - accuracy: 0.7441 - precision_6: 0.8080 - recall_6: 0.6620 - val_loss: 1.0164 - val_accuracy: 0.6408 - val_precision_6: 0.6916 - val_recall_6: 0.5211\n",
      "Epoch 105/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.7556 - accuracy: 0.7500 - precision_6: 0.8077 - recall_6: 0.656 - ETA: 0s - loss: 0.6016 - accuracy: 0.7500 - precision_6: 0.8381 - recall_6: 0.687 - ETA: 0s - loss: 0.6010 - accuracy: 0.7656 - precision_6: 0.8323 - recall_6: 0.697 - ETA: 0s - loss: 0.6028 - accuracy: 0.7743 - precision_6: 0.8410 - recall_6: 0.697 - ETA: 0s - loss: 0.6262 - accuracy: 0.7656 - precision_6: 0.8241 - recall_6: 0.695 - 0s 958us/sample - loss: 0.6318 - accuracy: 0.7653 - precision_6: 0.8207 - recall_6: 0.6878 - val_loss: 1.0079 - val_accuracy: 0.6268 - val_precision_6: 0.6452 - val_recall_6: 0.5634\n",
      "Epoch 106/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.7812 - precision_6: 0.8000 - recall_6: 0.750 - ETA: 0s - loss: 0.6008 - accuracy: 0.7734 - precision_6: 0.8036 - recall_6: 0.703 - ETA: 0s - loss: 0.5949 - accuracy: 0.7865 - precision_6: 0.8095 - recall_6: 0.708 - ETA: 0s - loss: 0.6086 - accuracy: 0.7743 - precision_6: 0.8279 - recall_6: 0.701 - ETA: 0s - loss: 0.6368 - accuracy: 0.7614 - precision_6: 0.8173 - recall_6: 0.698 - 0s 1ms/sample - loss: 0.6338 - accuracy: 0.7606 - precision_6: 0.8204 - recall_6: 0.6972 - val_loss: 0.9619 - val_accuracy: 0.6408 - val_precision_6: 0.6838 - val_recall_6: 0.5634\n",
      "Epoch 107/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.7500 - precision_6: 0.7586 - recall_6: 0.687 - ETA: 0s - loss: 0.5659 - accuracy: 0.7734 - precision_6: 0.8000 - recall_6: 0.687 - ETA: 0s - loss: 0.5277 - accuracy: 0.8021 - precision_6: 0.8373 - recall_6: 0.724 - ETA: 0s - loss: 0.5255 - accuracy: 0.8086 - precision_6: 0.8493 - recall_6: 0.726 - ETA: 0s - loss: 0.5745 - accuracy: 0.7898 - precision_6: 0.8182 - recall_6: 0.715 - 0s 962us/sample - loss: 0.5771 - accuracy: 0.7817 - precision_6: 0.8069 - recall_6: 0.7160 - val_loss: 1.0771 - val_accuracy: 0.6197 - val_precision_6: 0.6500 - val_recall_6: 0.5493\n",
      "Epoch 108/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.6875 - precision_6: 0.6875 - recall_6: 0.687 - ETA: 0s - loss: 0.6174 - accuracy: 0.7578 - precision_6: 0.7965 - recall_6: 0.703 - ETA: 0s - loss: 0.5989 - accuracy: 0.7708 - precision_6: 0.8118 - recall_6: 0.718 - ETA: 0s - loss: 0.5778 - accuracy: 0.7812 - precision_6: 0.8371 - recall_6: 0.722 - ETA: 0s - loss: 0.6158 - accuracy: 0.7656 - precision_6: 0.8231 - recall_6: 0.712 - ETA: 0s - loss: 0.6297 - accuracy: 0.7578 - precision_6: 0.8196 - recall_6: 0.697 - 0s 1ms/sample - loss: 0.6414 - accuracy: 0.7488 - precision_6: 0.8022 - recall_6: 0.6854 - val_loss: 0.9607 - val_accuracy: 0.6549 - val_precision_6: 0.6983 - val_recall_6: 0.5704\n",
      "Epoch 109/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.8125 - precision_6: 0.8276 - recall_6: 0.750 - ETA: 0s - loss: 0.5762 - accuracy: 0.8229 - precision_6: 0.8506 - recall_6: 0.770 - ETA: 0s - loss: 0.6584 - accuracy: 0.7875 - precision_6: 0.8194 - recall_6: 0.737 - ETA: 0s - loss: 0.7057 - accuracy: 0.7617 - precision_6: 0.8072 - recall_6: 0.703 - ETA: 0s - loss: 0.6999 - accuracy: 0.7500 - precision_6: 0.7987 - recall_6: 0.698 - 0s 977us/sample - loss: 0.6891 - accuracy: 0.7559 - precision_6: 0.7952 - recall_6: 0.7019 - val_loss: 0.9701 - val_accuracy: 0.6690 - val_precision_6: 0.7257 - val_recall_6: 0.5775\n",
      "Epoch 110/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.7188 - precision_6: 0.7586 - recall_6: 0.687 - ETA: 0s - loss: 0.6625 - accuracy: 0.7266 - precision_6: 0.7679 - recall_6: 0.671 - ETA: 0s - loss: 0.5770 - accuracy: 0.7812 - precision_6: 0.8299 - recall_6: 0.718 - ETA: 0s - loss: 0.5990 - accuracy: 0.7812 - precision_6: 0.8346 - recall_6: 0.709 - ETA: 0s - loss: 0.5882 - accuracy: 0.7812 - precision_6: 0.8328 - recall_6: 0.713 - 0s 991us/sample - loss: 0.5985 - accuracy: 0.7723 - precision_6: 0.8184 - recall_6: 0.7089 - val_loss: 0.9757 - val_accuracy: 0.6408 - val_precision_6: 0.6800 - val_recall_6: 0.5986\n",
      "Epoch 111/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7500 - precision_6: 0.7742 - recall_6: 0.750 - ETA: 0s - loss: 0.5487 - accuracy: 0.7812 - precision_6: 0.8230 - recall_6: 0.726 - ETA: 0s - loss: 0.5448 - accuracy: 0.7865 - precision_6: 0.8304 - recall_6: 0.739 - ETA: 0s - loss: 0.5429 - accuracy: 0.7891 - precision_6: 0.8407 - recall_6: 0.742 - ETA: 0s - loss: 0.5935 - accuracy: 0.7699 - precision_6: 0.8232 - recall_6: 0.727 - ETA: 0s - loss: 0.5911 - accuracy: 0.7692 - precision_6: 0.8197 - recall_6: 0.721 - 0s 993us/sample - loss: 0.5794 - accuracy: 0.7746 - precision_6: 0.8245 - recall_6: 0.7277 - val_loss: 1.0543 - val_accuracy: 0.5915 - val_precision_6: 0.6172 - val_recall_6: 0.5563\n",
      "Epoch 112/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.7812 - precision_6: 0.8000 - recall_6: 0.750 - ETA: 0s - loss: 0.5747 - accuracy: 0.7969 - precision_6: 0.8142 - recall_6: 0.718 - ETA: 0s - loss: 0.5185 - accuracy: 0.8125 - precision_6: 0.8400 - recall_6: 0.750 - ETA: 0s - loss: 0.5597 - accuracy: 0.7986 - precision_6: 0.8366 - recall_6: 0.746 - ETA: 0s - loss: 0.5627 - accuracy: 0.7943 - precision_6: 0.8353 - recall_6: 0.739 - 0s 958us/sample - loss: 0.5793 - accuracy: 0.7840 - precision_6: 0.8298 - recall_6: 0.7324 - val_loss: 0.9530 - val_accuracy: 0.6549 - val_precision_6: 0.7000 - val_recall_6: 0.5915\n",
      "Epoch 113/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.7500 - precision_6: 0.8276 - recall_6: 0.750 - ETA: 0s - loss: 0.5783 - accuracy: 0.7604 - precision_6: 0.8214 - recall_6: 0.718 - ETA: 0s - loss: 0.5483 - accuracy: 0.7917 - precision_6: 0.8402 - recall_6: 0.739 - ETA: 0s - loss: 0.5561 - accuracy: 0.7930 - precision_6: 0.8475 - recall_6: 0.738 - ETA: 0s - loss: 0.5892 - accuracy: 0.7841 - precision_6: 0.8350 - recall_6: 0.733 - ETA: 0s - loss: 0.6447 - accuracy: 0.7668 - precision_6: 0.8172 - recall_6: 0.709 - 0s 1ms/sample - loss: 0.6384 - accuracy: 0.7700 - precision_6: 0.8194 - recall_6: 0.7136 - val_loss: 1.2046 - val_accuracy: 0.5704 - val_precision_6: 0.6379 - val_recall_6: 0.5211\n",
      "Epoch 114/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.7812 - precision_6: 0.8519 - recall_6: 0.718 - ETA: 0s - loss: 0.7245 - accuracy: 0.7109 - precision_6: 0.7778 - recall_6: 0.656 - ETA: 0s - loss: 0.6967 - accuracy: 0.7366 - precision_6: 0.7917 - recall_6: 0.678 - ETA: 0s - loss: 0.7177 - accuracy: 0.7292 - precision_6: 0.7823 - recall_6: 0.673 - ETA: 0s - loss: 0.7297 - accuracy: 0.7214 - precision_6: 0.7809 - recall_6: 0.658 - 0s 962us/sample - loss: 0.7367 - accuracy: 0.7207 - precision_6: 0.7756 - recall_6: 0.6573 - val_loss: 1.0287 - val_accuracy: 0.6338 - val_precision_6: 0.6975 - val_recall_6: 0.5845\n",
      "Epoch 115/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.7188 - precision_6: 0.7857 - recall_6: 0.687 - ETA: 0s - loss: 0.7275 - accuracy: 0.6875 - precision_6: 0.7411 - recall_6: 0.648 - ETA: 0s - loss: 0.6441 - accuracy: 0.7292 - precision_6: 0.7857 - recall_6: 0.687 - ETA: 0s - loss: 0.6261 - accuracy: 0.7500 - precision_6: 0.8072 - recall_6: 0.703 - ETA: 0s - loss: 0.6457 - accuracy: 0.7415 - precision_6: 0.7948 - recall_6: 0.693 - ETA: 0s - loss: 0.6579 - accuracy: 0.7284 - precision_6: 0.7905 - recall_6: 0.680 - 0s 1ms/sample - loss: 0.6463 - accuracy: 0.7347 - precision_6: 0.7962 - recall_6: 0.6878 - val_loss: 1.0427 - val_accuracy: 0.6338 - val_precision_6: 0.6777 - val_recall_6: 0.5775\n",
      "Epoch 116/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.5319 - accuracy: 0.7812 - precision_6: 0.8455 - recall_6: 0.726 - ETA: 0s - loss: 0.5074 - accuracy: 0.7917 - precision_6: 0.8537 - recall_6: 0.729 - ETA: 0s - loss: 0.5113 - accuracy: 0.8021 - precision_6: 0.8648 - recall_6: 0.732 - ETA: 0s - loss: 0.5442 - accuracy: 0.7839 - precision_6: 0.8492 - recall_6: 0.718 - 0s 965us/sample - loss: 0.5658 - accuracy: 0.7770 - precision_6: 0.8352 - recall_6: 0.7136 - val_loss: 1.0556 - val_accuracy: 0.6197 - val_precision_6: 0.6504 - val_recall_6: 0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8125 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.5508 - accuracy: 0.7734 - precision_6: 0.8174 - recall_6: 0.734 - ETA: 0s - loss: 0.5265 - accuracy: 0.7946 - precision_6: 0.8434 - recall_6: 0.745 - ETA: 0s - loss: 0.5479 - accuracy: 0.7906 - precision_6: 0.8453 - recall_6: 0.734 - ETA: 0s - loss: 0.5467 - accuracy: 0.7865 - precision_6: 0.8438 - recall_6: 0.731 - 0s 991us/sample - loss: 0.5790 - accuracy: 0.7770 - precision_6: 0.8324 - recall_6: 0.7230 - val_loss: 1.0941 - val_accuracy: 0.6127 - val_precision_6: 0.6364 - val_recall_6: 0.5423\n",
      "Epoch 118/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.5523 - accuracy: 0.7500 - precision_6: 0.7913 - recall_6: 0.710 - ETA: 0s - loss: 0.5374 - accuracy: 0.7812 - precision_6: 0.8259 - recall_6: 0.741 - ETA: 0s - loss: 0.5684 - accuracy: 0.7812 - precision_6: 0.8228 - recall_6: 0.725 - ETA: 0s - loss: 0.5722 - accuracy: 0.7760 - precision_6: 0.8293 - recall_6: 0.721 - 0s 974us/sample - loss: 0.5750 - accuracy: 0.7746 - precision_6: 0.8293 - recall_6: 0.7183 - val_loss: 1.0800 - val_accuracy: 0.6056 - val_precision_6: 0.6638 - val_recall_6: 0.5423\n",
      "Epoch 119/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.7500 - precision_6: 0.9231 - recall_6: 0.750 - ETA: 0s - loss: 0.5320 - accuracy: 0.7891 - precision_6: 0.8679 - recall_6: 0.718 - ETA: 0s - loss: 0.5808 - accuracy: 0.7552 - precision_6: 0.8323 - recall_6: 0.697 - ETA: 0s - loss: 0.5654 - accuracy: 0.7695 - precision_6: 0.8519 - recall_6: 0.718 - ETA: 0s - loss: 0.5574 - accuracy: 0.7727 - precision_6: 0.8454 - recall_6: 0.730 - ETA: 0s - loss: 0.5796 - accuracy: 0.7620 - precision_6: 0.8283 - recall_6: 0.718 - 0s 974us/sample - loss: 0.5696 - accuracy: 0.7653 - precision_6: 0.8302 - recall_6: 0.7230 - val_loss: 1.1126 - val_accuracy: 0.5704 - val_precision_6: 0.6190 - val_recall_6: 0.5493\n",
      "Epoch 120/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.7188 - precision_6: 0.7586 - recall_6: 0.687 - ETA: 0s - loss: 0.5802 - accuracy: 0.7578 - precision_6: 0.8000 - recall_6: 0.687 - ETA: 0s - loss: 0.5331 - accuracy: 0.7865 - precision_6: 0.8263 - recall_6: 0.718 - ETA: 0s - loss: 0.5156 - accuracy: 0.7930 - precision_6: 0.8611 - recall_6: 0.726 - ETA: 0s - loss: 0.5366 - accuracy: 0.7841 - precision_6: 0.8490 - recall_6: 0.718 - ETA: 0s - loss: 0.5552 - accuracy: 0.7740 - precision_6: 0.8414 - recall_6: 0.713 - 0s 1ms/sample - loss: 0.5440 - accuracy: 0.7793 - precision_6: 0.8457 - recall_6: 0.7207 - val_loss: 0.9882 - val_accuracy: 0.6690 - val_precision_6: 0.6810 - val_recall_6: 0.5563\n",
      "Epoch 121/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8438 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.4541 - accuracy: 0.8047 - precision_6: 0.8390 - recall_6: 0.773 - ETA: 0s - loss: 0.4581 - accuracy: 0.8080 - precision_6: 0.8507 - recall_6: 0.763 - ETA: 0s - loss: 0.4892 - accuracy: 0.8031 - precision_6: 0.8475 - recall_6: 0.746 - ETA: 0s - loss: 0.5313 - accuracy: 0.7995 - precision_6: 0.8421 - recall_6: 0.750 - 0s 967us/sample - loss: 0.5312 - accuracy: 0.7934 - precision_6: 0.8346 - recall_6: 0.7465 - val_loss: 1.0330 - val_accuracy: 0.6408 - val_precision_6: 0.6800 - val_recall_6: 0.5986\n",
      "Epoch 122/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.4468 - accuracy: 0.7891 - precision_6: 0.8475 - recall_6: 0.781 - ETA: 0s - loss: 0.4486 - accuracy: 0.7969 - precision_6: 0.8523 - recall_6: 0.781 - ETA: 0s - loss: 0.4433 - accuracy: 0.8160 - precision_6: 0.8774 - recall_6: 0.795 - ETA: 0s - loss: 0.4645 - accuracy: 0.8125 - precision_6: 0.8644 - recall_6: 0.778 - ETA: 0s - loss: 0.4997 - accuracy: 0.7957 - precision_6: 0.8518 - recall_6: 0.759 - 0s 1ms/sample - loss: 0.4894 - accuracy: 0.8005 - precision_6: 0.8556 - recall_6: 0.7653 - val_loss: 0.9894 - val_accuracy: 0.6831 - val_precision_6: 0.6917 - val_recall_6: 0.5845\n",
      "Epoch 123/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.8750 - precision_6: 0.9000 - recall_6: 0.843 - ETA: 0s - loss: 0.3732 - accuracy: 0.8359 - precision_6: 0.8879 - recall_6: 0.804 - ETA: 0s - loss: 0.3797 - accuracy: 0.8527 - precision_6: 0.8971 - recall_6: 0.817 - ETA: 0s - loss: 0.3951 - accuracy: 0.8542 - precision_6: 0.8889 - recall_6: 0.805 - ETA: 0s - loss: 0.4435 - accuracy: 0.8333 - precision_6: 0.8699 - recall_6: 0.783 - 0s 969us/sample - loss: 0.4481 - accuracy: 0.8286 - precision_6: 0.8646 - recall_6: 0.7793 - val_loss: 1.0486 - val_accuracy: 0.6549 - val_precision_6: 0.6967 - val_recall_6: 0.5986\n",
      "Epoch 124/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4105 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.3830 - accuracy: 0.8516 - precision_6: 0.8678 - recall_6: 0.820 - ETA: 0s - loss: 0.3774 - accuracy: 0.8542 - precision_6: 0.8771 - recall_6: 0.817 - ETA: 0s - loss: 0.3778 - accuracy: 0.8594 - precision_6: 0.8861 - recall_6: 0.820 - ETA: 0s - loss: 0.4076 - accuracy: 0.8523 - precision_6: 0.8769 - recall_6: 0.809 - ETA: 0s - loss: 0.4216 - accuracy: 0.8413 - precision_6: 0.8665 - recall_6: 0.795 - 0s 977us/sample - loss: 0.4131 - accuracy: 0.8451 - precision_6: 0.8699 - recall_6: 0.8005 - val_loss: 0.9946 - val_accuracy: 0.6690 - val_precision_6: 0.6769 - val_recall_6: 0.6197\n",
      "Epoch 125/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.8438 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.3844 - accuracy: 0.8333 - precision_6: 0.8681 - recall_6: 0.822 - ETA: 0s - loss: 0.3825 - accuracy: 0.8375 - precision_6: 0.8742 - recall_6: 0.825 - ETA: 0s - loss: 0.3630 - accuracy: 0.8571 - precision_6: 0.8905 - recall_6: 0.834 - ETA: 0s - loss: 0.3725 - accuracy: 0.8611 - precision_6: 0.8959 - recall_6: 0.836 - ETA: 0s - loss: 0.3956 - accuracy: 0.8464 - precision_6: 0.8824 - recall_6: 0.820 - 0s 1ms/sample - loss: 0.4042 - accuracy: 0.8357 - precision_6: 0.8776 - recall_6: 0.8075 - val_loss: 0.9798 - val_accuracy: 0.6761 - val_precision_6: 0.7188 - val_recall_6: 0.6479\n",
      "Epoch 126/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8750 - precision_6: 0.9000 - recall_6: 0.843 - ETA: 0s - loss: 0.3641 - accuracy: 0.8359 - precision_6: 0.8678 - recall_6: 0.820 - ETA: 0s - loss: 0.3785 - accuracy: 0.8385 - precision_6: 0.8619 - recall_6: 0.812 - ETA: 0s - loss: 0.3716 - accuracy: 0.8542 - precision_6: 0.8848 - recall_6: 0.826 - ETA: 0s - loss: 0.3897 - accuracy: 0.8438 - precision_6: 0.8777 - recall_6: 0.815 - 0s 962us/sample - loss: 0.4073 - accuracy: 0.8310 - precision_6: 0.8662 - recall_6: 0.8052 - val_loss: 1.1067 - val_accuracy: 0.6690 - val_precision_6: 0.6880 - val_recall_6: 0.6056\n",
      "Epoch 127/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.8125 - precision_6: 0.8621 - recall_6: 0.781 - ETA: 0s - loss: 0.5113 - accuracy: 0.8047 - precision_6: 0.8571 - recall_6: 0.750 - ETA: 0s - loss: 0.4915 - accuracy: 0.8125 - precision_6: 0.8639 - recall_6: 0.760 - ETA: 0s - loss: 0.4728 - accuracy: 0.8264 - precision_6: 0.8654 - recall_6: 0.781 - ETA: 0s - loss: 0.4734 - accuracy: 0.8267 - precision_6: 0.8656 - recall_6: 0.786 - ETA: 0s - loss: 0.4844 - accuracy: 0.8101 - precision_6: 0.8511 - recall_6: 0.769 - 0s 1ms/sample - loss: 0.4741 - accuracy: 0.8146 - precision_6: 0.8549 - recall_6: 0.7746 - val_loss: 1.0201 - val_accuracy: 0.6831 - val_precision_6: 0.7188 - val_recall_6: 0.6479\n",
      "Epoch 128/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8750 - precision_6: 0.8667 - recall_6: 0.812 - ETA: 0s - loss: 0.4225 - accuracy: 0.8594 - precision_6: 0.8729 - recall_6: 0.804 - ETA: 0s - loss: 0.4958 - accuracy: 0.8333 - precision_6: 0.8497 - recall_6: 0.765 - ETA: 0s - loss: 0.4658 - accuracy: 0.8472 - precision_6: 0.8604 - recall_6: 0.791 - ETA: 0s - loss: 0.4751 - accuracy: 0.8381 - precision_6: 0.8488 - recall_6: 0.781 - ETA: 0s - loss: 0.4939 - accuracy: 0.8197 - precision_6: 0.8333 - recall_6: 0.769 - 0s 967us/sample - loss: 0.4833 - accuracy: 0.8239 - precision_6: 0.8376 - recall_6: 0.7746 - val_loss: 1.1615 - val_accuracy: 0.6268 - val_precision_6: 0.6364 - val_recall_6: 0.5915\n",
      "Epoch 129/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3856 - accuracy: 0.8438 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.3873 - accuracy: 0.8527 - precision_6: 0.8932 - recall_6: 0.821 - ETA: 0s - loss: 0.3913 - accuracy: 0.8576 - precision_6: 0.9015 - recall_6: 0.826 - ETA: 0s - loss: 0.4192 - accuracy: 0.8359 - precision_6: 0.8847 - recall_6: 0.799 - 0s 967us/sample - loss: 0.4264 - accuracy: 0.8239 - precision_6: 0.8799 - recall_6: 0.7911 - val_loss: 0.9498 - val_accuracy: 0.7113 - val_precision_6: 0.7188 - val_recall_6: 0.6479\n",
      "Epoch 130/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.9062 - precision_6: 0.9310 - recall_6: 0.843 - ETA: 0s - loss: 0.3678 - accuracy: 0.8854 - precision_6: 0.8876 - recall_6: 0.822 - ETA: 0s - loss: 0.3538 - accuracy: 0.8698 - precision_6: 0.8798 - recall_6: 0.838 - ETA: 0s - loss: 0.3472 - accuracy: 0.8672 - precision_6: 0.8807 - recall_6: 0.835 - ETA: 0s - loss: 0.3727 - accuracy: 0.8608 - precision_6: 0.8724 - recall_6: 0.835 - 0s 988us/sample - loss: 0.3883 - accuracy: 0.8474 - precision_6: 0.8600 - recall_6: 0.8216 - val_loss: 1.0239 - val_accuracy: 0.6972 - val_precision_6: 0.7165 - val_recall_6: 0.6408\n",
      "Epoch 131/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3661 - accuracy: 0.8672 - precision_6: 0.8862 - recall_6: 0.851 - ETA: 0s - loss: 0.3791 - accuracy: 0.8698 - precision_6: 0.8907 - recall_6: 0.849 - ETA: 0s - loss: 0.3602 - accuracy: 0.8854 - precision_6: 0.8978 - recall_6: 0.854 - ETA: 0s - loss: 0.3916 - accuracy: 0.8698 - precision_6: 0.8874 - recall_6: 0.841 - 0s 991us/sample - loss: 0.4046 - accuracy: 0.8568 - precision_6: 0.8806 - recall_6: 0.8310 - val_loss: 1.1109 - val_accuracy: 0.6268 - val_precision_6: 0.6744 - val_recall_6: 0.6127\n",
      "Epoch 132/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8438 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.3423 - accuracy: 0.8750 - precision_6: 0.8843 - recall_6: 0.835 - ETA: 0s - loss: 0.3331 - accuracy: 0.8750 - precision_6: 0.8804 - recall_6: 0.843 - ETA: 0s - loss: 0.3420 - accuracy: 0.8715 - precision_6: 0.8777 - recall_6: 0.847 - ETA: 0s - loss: 0.3756 - accuracy: 0.8542 - precision_6: 0.8629 - recall_6: 0.835 - 0s 974us/sample - loss: 0.3824 - accuracy: 0.8474 - precision_6: 0.8568 - recall_6: 0.8286 - val_loss: 1.1163 - val_accuracy: 0.6620 - val_precision_6: 0.6565 - val_recall_6: 0.6056\n",
      "Epoch 133/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.7500 - precision_6: 0.8000 - recall_6: 0.750 - ETA: 0s - loss: 0.4010 - accuracy: 0.8203 - precision_6: 0.8374 - recall_6: 0.804 - ETA: 0s - loss: 0.3661 - accuracy: 0.8438 - precision_6: 0.8571 - recall_6: 0.812 - ETA: 0s - loss: 0.3866 - accuracy: 0.8472 - precision_6: 0.8708 - recall_6: 0.819 - ETA: 0s - loss: 0.3888 - accuracy: 0.8438 - precision_6: 0.8627 - recall_6: 0.821 - 0s 967us/sample - loss: 0.3783 - accuracy: 0.8451 - precision_6: 0.8667 - recall_6: 0.8239 - val_loss: 0.9771 - val_accuracy: 0.6690 - val_precision_6: 0.7280 - val_recall_6: 0.6408\n",
      "Epoch 134/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9062 - precision_6: 0.9310 - recall_6: 0.843 - ETA: 0s - loss: 0.2997 - accuracy: 0.8672 - precision_6: 0.8992 - recall_6: 0.835 - ETA: 0s - loss: 0.2883 - accuracy: 0.8839 - precision_6: 0.9147 - recall_6: 0.861 - ETA: 0s - loss: 0.2911 - accuracy: 0.8889 - precision_6: 0.9194 - recall_6: 0.871 - ETA: 0s - loss: 0.3140 - accuracy: 0.8778 - precision_6: 0.9154 - recall_6: 0.860 - 0s 1ms/sample - loss: 0.3373 - accuracy: 0.8662 - precision_6: 0.9005 - recall_6: 0.8498 - val_loss: 0.9361 - val_accuracy: 0.7042 - val_precision_6: 0.7642 - val_recall_6: 0.6620\n",
      "Epoch 135/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9062 - precision_6: 0.9655 - recall_6: 0.875 - ETA: 0s - loss: 0.2833 - accuracy: 0.8750 - precision_6: 0.9091 - recall_6: 0.859 - ETA: 0s - loss: 0.2906 - accuracy: 0.8802 - precision_6: 0.9066 - recall_6: 0.859 - ETA: 0s - loss: 0.2791 - accuracy: 0.8889 - precision_6: 0.9127 - recall_6: 0.871 - ETA: 0s - loss: 0.2957 - accuracy: 0.8892 - precision_6: 0.9139 - recall_6: 0.875 - 0s 981us/sample - loss: 0.3426 - accuracy: 0.8685 - precision_6: 0.8914 - recall_6: 0.8474 - val_loss: 1.1201 - val_accuracy: 0.6620 - val_precision_6: 0.6947 - val_recall_6: 0.6408\n",
      "Epoch 136/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9062 - precision_6: 0.9667 - recall_6: 0.906 - ETA: 0s - loss: 0.4093 - accuracy: 0.8203 - precision_6: 0.8512 - recall_6: 0.804 - ETA: 0s - loss: 0.4054 - accuracy: 0.8438 - precision_6: 0.8715 - recall_6: 0.812 - ETA: 0s - loss: 0.3920 - accuracy: 0.8516 - precision_6: 0.8776 - recall_6: 0.812 - ETA: 0s - loss: 0.3983 - accuracy: 0.8531 - precision_6: 0.8758 - recall_6: 0.815 - ETA: 0s - loss: 0.3797 - accuracy: 0.8568 - precision_6: 0.8792 - recall_6: 0.815 - 0s 1000us/sample - loss: 0.4310 - accuracy: 0.8404 - precision_6: 0.8593 - recall_6: 0.8028 - val_loss: 1.0431 - val_accuracy: 0.6690 - val_precision_6: 0.6870 - val_recall_6: 0.6338\n",
      "Epoch 137/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.8125 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.4403 - accuracy: 0.8333 - precision_6: 0.8478 - recall_6: 0.812 - ETA: 0s - loss: 0.4779 - accuracy: 0.8125 - precision_6: 0.8187 - recall_6: 0.776 - ETA: 0s - loss: 0.4949 - accuracy: 0.8008 - precision_6: 0.8101 - recall_6: 0.750 - ETA: 0s - loss: 0.4927 - accuracy: 0.7983 - precision_6: 0.8165 - recall_6: 0.758 - ETA: 0s - loss: 0.4903 - accuracy: 0.7957 - precision_6: 0.8123 - recall_6: 0.759 - 0s 1ms/sample - loss: 0.4834 - accuracy: 0.7981 - precision_6: 0.8145 - recall_6: 0.7629 - val_loss: 1.1198 - val_accuracy: 0.6197 - val_precision_6: 0.6434 - val_recall_6: 0.5845\n",
      "Epoch 138/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.9062 - precision_6: 0.9310 - recall_6: 0.843 - ETA: 0s - loss: 0.4157 - accuracy: 0.8594 - precision_6: 0.8783 - recall_6: 0.789 - ETA: 0s - loss: 0.4017 - accuracy: 0.8542 - precision_6: 0.8793 - recall_6: 0.796 - ETA: 0s - loss: 0.3843 - accuracy: 0.8672 - precision_6: 0.8927 - recall_6: 0.812 - ETA: 0s - loss: 0.3969 - accuracy: 0.8636 - precision_6: 0.8916 - recall_6: 0.818 - 0s 960us/sample - loss: 0.3961 - accuracy: 0.8592 - precision_6: 0.8869 - recall_6: 0.8099 - val_loss: 1.0264 - val_accuracy: 0.6901 - val_precision_6: 0.7280 - val_recall_6: 0.6408\n",
      "Epoch 139/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8438 - precision_6: 0.9310 - recall_6: 0.843 - ETA: 0s - loss: 0.4306 - accuracy: 0.8281 - precision_6: 0.8824 - recall_6: 0.820 - ETA: 0s - loss: 0.4742 - accuracy: 0.8177 - precision_6: 0.8508 - recall_6: 0.802 - ETA: 0s - loss: 0.4319 - accuracy: 0.8398 - precision_6: 0.8719 - recall_6: 0.824 - ETA: 0s - loss: 0.4524 - accuracy: 0.8313 - precision_6: 0.8675 - recall_6: 0.818 - ETA: 0s - loss: 0.4290 - accuracy: 0.8365 - precision_6: 0.8740 - recall_6: 0.817 - 0s 1ms/sample - loss: 0.4215 - accuracy: 0.8404 - precision_6: 0.8769 - recall_6: 0.8192 - val_loss: 1.0373 - val_accuracy: 0.6761 - val_precision_6: 0.7231 - val_recall_6: 0.6620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8125 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.3620 - accuracy: 0.8359 - precision_6: 0.8678 - recall_6: 0.820 - ETA: 0s - loss: 0.3498 - accuracy: 0.8616 - precision_6: 0.8837 - recall_6: 0.848 - ETA: 0s - loss: 0.3549 - accuracy: 0.8531 - precision_6: 0.8820 - recall_6: 0.840 - ETA: 0s - loss: 0.3710 - accuracy: 0.8510 - precision_6: 0.8766 - recall_6: 0.836 - 0s 962us/sample - loss: 0.3633 - accuracy: 0.8545 - precision_6: 0.8796 - recall_6: 0.8404 - val_loss: 1.0255 - val_accuracy: 0.7183 - val_precision_6: 0.7323 - val_recall_6: 0.6549\n",
      "Epoch 141/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.3588 - accuracy: 0.8594 - precision_6: 0.8560 - recall_6: 0.835 - ETA: 0s - loss: 0.3543 - accuracy: 0.8490 - precision_6: 0.8634 - recall_6: 0.822 - ETA: 0s - loss: 0.3178 - accuracy: 0.8828 - precision_6: 0.8939 - recall_6: 0.855 - ETA: 0s - loss: 0.3095 - accuracy: 0.8977 - precision_6: 0.9110 - recall_6: 0.872 - ETA: 0s - loss: 0.3336 - accuracy: 0.8846 - precision_6: 0.9015 - recall_6: 0.858 - 0s 1ms/sample - loss: 0.3262 - accuracy: 0.8873 - precision_6: 0.9039 - recall_6: 0.8615 - val_loss: 1.0176 - val_accuracy: 0.6901 - val_precision_6: 0.7344 - val_recall_6: 0.6620\n",
      "Epoch 142/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.2629 - accuracy: 0.9167 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.2787 - accuracy: 0.9062 - precision_6: 0.9247 - recall_6: 0.895 - ETA: 0s - loss: 0.2483 - accuracy: 0.9201 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.2621 - accuracy: 0.9141 - precision_6: 0.9270 - recall_6: 0.893 - 0s 969us/sample - loss: 0.2710 - accuracy: 0.9108 - precision_6: 0.9221 - recall_6: 0.8897 - val_loss: 0.9848 - val_accuracy: 0.6901 - val_precision_6: 0.7252 - val_recall_6: 0.6690\n",
      "Epoch 143/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.2171 - accuracy: 0.9219 - precision_6: 0.9213 - recall_6: 0.914 - ETA: 0s - loss: 0.2265 - accuracy: 0.9271 - precision_6: 0.9263 - recall_6: 0.916 - ETA: 0s - loss: 0.2312 - accuracy: 0.9297 - precision_6: 0.9289 - recall_6: 0.918 - ETA: 0s - loss: 0.2498 - accuracy: 0.9205 - precision_6: 0.9249 - recall_6: 0.909 - ETA: 0s - loss: 0.2693 - accuracy: 0.9087 - precision_6: 0.9118 - recall_6: 0.894 - 0s 1ms/sample - loss: 0.2634 - accuracy: 0.9108 - precision_6: 0.9139 - recall_6: 0.8967 - val_loss: 1.0314 - val_accuracy: 0.7042 - val_precision_6: 0.7388 - val_recall_6: 0.6972\n",
      "Epoch 144/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.8750 - precision_6: 0.9655 - recall_6: 0.875 - ETA: 0s - loss: 0.4635 - accuracy: 0.8516 - precision_6: 0.8814 - recall_6: 0.812 - ETA: 0s - loss: 0.4016 - accuracy: 0.8646 - precision_6: 0.8895 - recall_6: 0.838 - ETA: 0s - loss: 0.3404 - accuracy: 0.8819 - precision_6: 0.9048 - recall_6: 0.857 - ETA: 0s - loss: 0.3509 - accuracy: 0.8750 - precision_6: 0.8937 - recall_6: 0.854 - 0s 962us/sample - loss: 0.3601 - accuracy: 0.8732 - precision_6: 0.8894 - recall_6: 0.8498 - val_loss: 1.0267 - val_accuracy: 0.6901 - val_precision_6: 0.7059 - val_recall_6: 0.6761\n",
      "Epoch 145/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.2371 - accuracy: 0.9062 - precision_6: 0.9187 - recall_6: 0.882 - ETA: 0s - loss: 0.2555 - accuracy: 0.8958 - precision_6: 0.9176 - recall_6: 0.869 - ETA: 0s - loss: 0.2675 - accuracy: 0.9028 - precision_6: 0.9170 - recall_6: 0.881 - ETA: 0s - loss: 0.2855 - accuracy: 0.8880 - precision_6: 0.9079 - recall_6: 0.872 - 0s 955us/sample - loss: 0.2953 - accuracy: 0.8850 - precision_6: 0.9024 - recall_6: 0.8685 - val_loss: 1.0837 - val_accuracy: 0.6972 - val_precision_6: 0.7080 - val_recall_6: 0.6831\n",
      "Epoch 146/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.9375 - precision_6: 0.9333 - recall_6: 0.875 - ETA: 0s - loss: 0.3260 - accuracy: 0.9167 - precision_6: 0.9222 - recall_6: 0.864 - ETA: 0s - loss: 0.2917 - accuracy: 0.9125 - precision_6: 0.9156 - recall_6: 0.881 - ETA: 0s - loss: 0.3020 - accuracy: 0.9018 - precision_6: 0.9116 - recall_6: 0.875 - ETA: 0s - loss: 0.3242 - accuracy: 0.8958 - precision_6: 0.9097 - recall_6: 0.875 - ETA: 0s - loss: 0.3305 - accuracy: 0.8892 - precision_6: 0.9000 - recall_6: 0.869 - 0s 1ms/sample - loss: 0.3258 - accuracy: 0.8803 - precision_6: 0.8908 - recall_6: 0.8615 - val_loss: 1.0702 - val_accuracy: 0.6761 - val_precision_6: 0.6912 - val_recall_6: 0.6620\n",
      "Epoch 147/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.3996 - accuracy: 0.8021 - precision_6: 0.8172 - recall_6: 0.791 - ETA: 0s - loss: 0.4325 - accuracy: 0.7865 - precision_6: 0.8043 - recall_6: 0.770 - ETA: 0s - loss: 0.4761 - accuracy: 0.7708 - precision_6: 0.7875 - recall_6: 0.746 - ETA: 0s - loss: 0.5088 - accuracy: 0.7760 - precision_6: 0.7906 - recall_6: 0.747 - 0s 953us/sample - loss: 0.5262 - accuracy: 0.7746 - precision_6: 0.7886 - recall_6: 0.7441 - val_loss: 1.2639 - val_accuracy: 0.5704 - val_precision_6: 0.6063 - val_recall_6: 0.5423\n",
      "Epoch 148/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8125 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.5730 - accuracy: 0.7500 - precision_6: 0.7841 - recall_6: 0.718 - ETA: 0s - loss: 0.4510 - accuracy: 0.8125 - precision_6: 0.8503 - recall_6: 0.781 - ETA: 0s - loss: 0.4425 - accuracy: 0.8170 - precision_6: 0.8564 - recall_6: 0.772 - ETA: 0s - loss: 0.4491 - accuracy: 0.8125 - precision_6: 0.8538 - recall_6: 0.770 - ETA: 0s - loss: 0.5057 - accuracy: 0.7995 - precision_6: 0.8382 - recall_6: 0.755 - 0s 1000us/sample - loss: 0.5120 - accuracy: 0.7981 - precision_6: 0.8364 - recall_6: 0.7559 - val_loss: 1.1531 - val_accuracy: 0.6549 - val_precision_6: 0.6929 - val_recall_6: 0.6197\n",
      "Epoch 149/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.8438 - precision_6: 0.8438 - recall_6: 0.843 - ETA: 0s - loss: 0.5002 - accuracy: 0.8438 - precision_6: 0.8595 - recall_6: 0.812 - ETA: 0s - loss: 0.4583 - accuracy: 0.8438 - precision_6: 0.8556 - recall_6: 0.802 - ETA: 0s - loss: 0.4245 - accuracy: 0.8438 - precision_6: 0.8614 - recall_6: 0.798 - ETA: 0s - loss: 0.4505 - accuracy: 0.8267 - precision_6: 0.8502 - recall_6: 0.789 - ETA: 0s - loss: 0.4621 - accuracy: 0.8221 - precision_6: 0.8432 - recall_6: 0.788 - 0s 986us/sample - loss: 0.4526 - accuracy: 0.8263 - precision_6: 0.8471 - recall_6: 0.7934 - val_loss: 1.1748 - val_accuracy: 0.6479 - val_precision_6: 0.6746 - val_recall_6: 0.5986\n",
      "Epoch 150/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8125 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.4741 - accuracy: 0.7969 - precision_6: 0.8033 - recall_6: 0.765 - ETA: 0s - loss: 0.4528 - accuracy: 0.8177 - precision_6: 0.8261 - recall_6: 0.791 - ETA: 0s - loss: 0.4101 - accuracy: 0.8398 - precision_6: 0.8484 - recall_6: 0.808 - ETA: 0s - loss: 0.4292 - accuracy: 0.8344 - precision_6: 0.8393 - recall_6: 0.800 - ETA: 0s - loss: 0.4374 - accuracy: 0.8245 - precision_6: 0.8363 - recall_6: 0.798 - 0s 995us/sample - loss: 0.4297 - accuracy: 0.8286 - precision_6: 0.8399 - recall_6: 0.8005 - val_loss: 1.0511 - val_accuracy: 0.6549 - val_precision_6: 0.6794 - val_recall_6: 0.6268\n",
      "Epoch 151/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.3428 - accuracy: 0.8438 - precision_6: 0.8640 - recall_6: 0.843 - ETA: 0s - loss: 0.3507 - accuracy: 0.8385 - precision_6: 0.8743 - recall_6: 0.833 - ETA: 0s - loss: 0.3414 - accuracy: 0.8611 - precision_6: 0.8905 - recall_6: 0.847 - ETA: 0s - loss: 0.3467 - accuracy: 0.8608 - precision_6: 0.8882 - recall_6: 0.835 - ETA: 0s - loss: 0.3567 - accuracy: 0.8534 - precision_6: 0.8824 - recall_6: 0.829 - 0s 1ms/sample - loss: 0.3494 - accuracy: 0.8568 - precision_6: 0.8853 - recall_6: 0.8333 - val_loss: 1.1130 - val_accuracy: 0.6620 - val_precision_6: 0.7023 - val_recall_6: 0.6479\n",
      "Epoch 152/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9062 - precision_6: 0.9667 - recall_6: 0.906 - ETA: 0s - loss: 0.2487 - accuracy: 0.8984 - precision_6: 0.9339 - recall_6: 0.882 - ETA: 0s - loss: 0.2895 - accuracy: 0.8906 - precision_6: 0.9130 - recall_6: 0.875 - ETA: 0s - loss: 0.2722 - accuracy: 0.9023 - precision_6: 0.9194 - recall_6: 0.890 - ETA: 0s - loss: 0.2763 - accuracy: 0.9034 - precision_6: 0.9208 - recall_6: 0.892 - 0s 965us/sample - loss: 0.2693 - accuracy: 0.9038 - precision_6: 0.9179 - recall_6: 0.8920 - val_loss: 1.1035 - val_accuracy: 0.6831 - val_precision_6: 0.7037 - val_recall_6: 0.6690\n",
      "Epoch 153/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.2105 - accuracy: 0.9167 - precision_6: 0.9263 - recall_6: 0.916 - ETA: 0s - loss: 0.2127 - accuracy: 0.9187 - precision_6: 0.9241 - recall_6: 0.912 - ETA: 0s - loss: 0.2104 - accuracy: 0.9330 - precision_6: 0.9364 - recall_6: 0.919 - ETA: 0s - loss: 0.2141 - accuracy: 0.9312 - precision_6: 0.9335 - recall_6: 0.921 - ETA: 0s - loss: 0.2099 - accuracy: 0.9297 - precision_6: 0.9340 - recall_6: 0.921 - 0s 1ms/sample - loss: 0.2200 - accuracy: 0.9249 - precision_6: 0.9286 - recall_6: 0.9155 - val_loss: 1.1240 - val_accuracy: 0.6831 - val_precision_6: 0.6906 - val_recall_6: 0.6761\n",
      "Epoch 154/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1799 - accuracy: 0.9219 - precision_6: 0.9286 - recall_6: 0.914 - ETA: 0s - loss: 0.2039 - accuracy: 0.9115 - precision_6: 0.9158 - recall_6: 0.906 - ETA: 0s - loss: 0.1864 - accuracy: 0.9297 - precision_6: 0.9328 - recall_6: 0.921 - ETA: 0s - loss: 0.1912 - accuracy: 0.9318 - precision_6: 0.9368 - recall_6: 0.926 - ETA: 0s - loss: 0.2011 - accuracy: 0.9255 - precision_6: 0.9317 - recall_6: 0.918 - 0s 969us/sample - loss: 0.1969 - accuracy: 0.9272 - precision_6: 0.9333 - recall_6: 0.9202 - val_loss: 1.0989 - val_accuracy: 0.6690 - val_precision_6: 0.6889 - val_recall_6: 0.6549\n",
      "Epoch 155/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9688 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1482 - accuracy: 0.9531 - precision_6: 0.9528 - recall_6: 0.945 - ETA: 0s - loss: 0.1652 - accuracy: 0.9598 - precision_6: 0.9636 - recall_6: 0.946 - ETA: 0s - loss: 0.1741 - accuracy: 0.9500 - precision_6: 0.9524 - recall_6: 0.937 - ETA: 0s - loss: 0.1691 - accuracy: 0.9531 - precision_6: 0.9577 - recall_6: 0.942 - 0s 1ms/sample - loss: 0.1922 - accuracy: 0.9390 - precision_6: 0.9474 - recall_6: 0.9296 - val_loss: 1.1483 - val_accuracy: 0.6479 - val_precision_6: 0.6691 - val_recall_6: 0.6408\n",
      "Epoch 156/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1651 - accuracy: 0.9297 - precision_6: 0.9444 - recall_6: 0.929 - ETA: 0s - loss: 0.1759 - accuracy: 0.9167 - precision_6: 0.9362 - recall_6: 0.916 - ETA: 0s - loss: 0.1777 - accuracy: 0.9236 - precision_6: 0.9366 - recall_6: 0.923 - ETA: 0s - loss: 0.1866 - accuracy: 0.9271 - precision_6: 0.9392 - recall_6: 0.924 - 0s 965us/sample - loss: 0.2279 - accuracy: 0.9155 - precision_6: 0.9282 - recall_6: 0.9108 - val_loss: 1.2360 - val_accuracy: 0.6690 - val_precision_6: 0.6667 - val_recall_6: 0.6479\n",
      "Epoch 157/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3182 - accuracy: 0.8750 - precision_6: 0.8889 - recall_6: 0.875 - ETA: 0s - loss: 0.3074 - accuracy: 0.8802 - precision_6: 0.8889 - recall_6: 0.875 - ETA: 0s - loss: 0.2837 - accuracy: 0.8984 - precision_6: 0.9084 - recall_6: 0.890 - ETA: 0s - loss: 0.2847 - accuracy: 0.9031 - precision_6: 0.9108 - recall_6: 0.893 - ETA: 0s - loss: 0.3057 - accuracy: 0.8958 - precision_6: 0.9043 - recall_6: 0.885 - 0s 984us/sample - loss: 0.3126 - accuracy: 0.8920 - precision_6: 0.9038 - recall_6: 0.8826 - val_loss: 1.2804 - val_accuracy: 0.6056 - val_precision_6: 0.6277 - val_recall_6: 0.6056\n",
      "Epoch 158/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.9375 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.3242 - accuracy: 0.8958 - precision_6: 0.8936 - recall_6: 0.875 - ETA: 0s - loss: 0.2980 - accuracy: 0.9000 - precision_6: 0.8981 - recall_6: 0.881 - ETA: 0s - loss: 0.2839 - accuracy: 0.8945 - precision_6: 0.9073 - recall_6: 0.878 - ETA: 0s - loss: 0.2950 - accuracy: 0.8864 - precision_6: 0.9029 - recall_6: 0.872 - 0s 986us/sample - loss: 0.2907 - accuracy: 0.8897 - precision_6: 0.9049 - recall_6: 0.8709 - val_loss: 1.1282 - val_accuracy: 0.6690 - val_precision_6: 0.6842 - val_recall_6: 0.6408\n",
      "Epoch 159/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.3368 - accuracy: 0.8438 - precision_6: 0.8833 - recall_6: 0.828 - ETA: 0s - loss: 0.3129 - accuracy: 0.8616 - precision_6: 0.9048 - recall_6: 0.848 - ETA: 0s - loss: 0.2962 - accuracy: 0.8625 - precision_6: 0.9033 - recall_6: 0.846 - ETA: 0s - loss: 0.3133 - accuracy: 0.8620 - precision_6: 0.8978 - recall_6: 0.846 - 0s 962us/sample - loss: 0.3096 - accuracy: 0.8662 - precision_6: 0.9005 - recall_6: 0.8498 - val_loss: 1.2074 - val_accuracy: 0.6761 - val_precision_6: 0.6912 - val_recall_6: 0.6620\n",
      "Epoch 160/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1970 - accuracy: 0.9297 - precision_6: 0.9297 - recall_6: 0.929 - ETA: 0s - loss: 0.2154 - accuracy: 0.9167 - precision_6: 0.9162 - recall_6: 0.911 - ETA: 0s - loss: 0.2062 - accuracy: 0.9167 - precision_6: 0.9196 - recall_6: 0.913 - ETA: 0s - loss: 0.2049 - accuracy: 0.9176 - precision_6: 0.9226 - recall_6: 0.914 - 0s 1ms/sample - loss: 0.2123 - accuracy: 0.9178 - precision_6: 0.9262 - recall_6: 0.9131 - val_loss: 1.2181 - val_accuracy: 0.6620 - val_precision_6: 0.6619 - val_recall_6: 0.6479\n",
      "Epoch 161/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2612 - accuracy: 0.8828 - precision_6: 0.8898 - recall_6: 0.882 - ETA: 0s - loss: 0.2516 - accuracy: 0.8802 - precision_6: 0.8895 - recall_6: 0.880 - ETA: 0s - loss: 0.2212 - accuracy: 0.9062 - precision_6: 0.9130 - recall_6: 0.902 - ETA: 0s - loss: 0.2298 - accuracy: 0.9091 - precision_6: 0.9133 - recall_6: 0.897 - ETA: 0s - loss: 0.2361 - accuracy: 0.9062 - precision_6: 0.9098 - recall_6: 0.896 - 0s 969us/sample - loss: 0.2309 - accuracy: 0.9085 - precision_6: 0.9119 - recall_6: 0.8991 - val_loss: 1.1058 - val_accuracy: 0.7042 - val_precision_6: 0.7226 - val_recall_6: 0.6972\n",
      "Epoch 162/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2300 - accuracy: 0.8906 - precision_6: 0.8906 - recall_6: 0.890 - ETA: 0s - loss: 0.2340 - accuracy: 0.8884 - precision_6: 0.8959 - recall_6: 0.883 - ETA: 0s - loss: 0.2243 - accuracy: 0.8993 - precision_6: 0.9085 - recall_6: 0.895 - ETA: 0s - loss: 0.2263 - accuracy: 0.8977 - precision_6: 0.9130 - recall_6: 0.894 - 0s 995us/sample - loss: 0.2363 - accuracy: 0.8944 - precision_6: 0.9069 - recall_6: 0.8920 - val_loss: 1.1587 - val_accuracy: 0.7113 - val_precision_6: 0.7226 - val_recall_6: 0.6972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.2351 - accuracy: 0.8854 - precision_6: 0.8947 - recall_6: 0.885 - ETA: 0s - loss: 0.1990 - accuracy: 0.9167 - precision_6: 0.9215 - recall_6: 0.916 - ETA: 0s - loss: 0.1852 - accuracy: 0.9336 - precision_6: 0.9405 - recall_6: 0.925 - ETA: 0s - loss: 0.1851 - accuracy: 0.9347 - precision_6: 0.9424 - recall_6: 0.929 - ETA: 0s - loss: 0.1953 - accuracy: 0.9303 - precision_6: 0.9366 - recall_6: 0.923 - 0s 977us/sample - loss: 0.1912 - accuracy: 0.9319 - precision_6: 0.9381 - recall_6: 0.9249 - val_loss: 1.1195 - val_accuracy: 0.6831 - val_precision_6: 0.6934 - val_recall_6: 0.6690\n",
      "Epoch 164/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.2100 - accuracy: 0.8828 - precision_6: 0.8898 - recall_6: 0.882 - ETA: 0s - loss: 0.1775 - accuracy: 0.9241 - precision_6: 0.9279 - recall_6: 0.919 - ETA: 0s - loss: 0.1731 - accuracy: 0.9271 - precision_6: 0.9366 - recall_6: 0.923 - ETA: 0s - loss: 0.1721 - accuracy: 0.9375 - precision_6: 0.9452 - recall_6: 0.931 - ETA: 0s - loss: 0.1782 - accuracy: 0.9327 - precision_6: 0.9390 - recall_6: 0.925 - 0s 984us/sample - loss: 0.1744 - accuracy: 0.9343 - precision_6: 0.9405 - recall_6: 0.9272 - val_loss: 1.1936 - val_accuracy: 0.6972 - val_precision_6: 0.7185 - val_recall_6: 0.6831\n",
      "Epoch 165/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1701 - accuracy: 0.9219 - precision_6: 0.9360 - recall_6: 0.914 - ETA: 0s - loss: 0.1744 - accuracy: 0.9219 - precision_6: 0.9358 - recall_6: 0.911 - ETA: 0s - loss: 0.1597 - accuracy: 0.9375 - precision_6: 0.9468 - recall_6: 0.927 - ETA: 0s - loss: 0.1612 - accuracy: 0.9347 - precision_6: 0.9449 - recall_6: 0.926 - ETA: 0s - loss: 0.1881 - accuracy: 0.9279 - precision_6: 0.9364 - recall_6: 0.920 - 0s 1ms/sample - loss: 0.1840 - accuracy: 0.9296 - precision_6: 0.9379 - recall_6: 0.9225 - val_loss: 1.1634 - val_accuracy: 0.7113 - val_precision_6: 0.7174 - val_recall_6: 0.6972\n",
      "Epoch 166/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1714 - accuracy: 0.9375 - precision_6: 0.9370 - recall_6: 0.929 - ETA: 0s - loss: 0.1472 - accuracy: 0.9554 - precision_6: 0.9550 - recall_6: 0.946 - ETA: 0s - loss: 0.1562 - accuracy: 0.9500 - precision_6: 0.9527 - recall_6: 0.943 - ETA: 0s - loss: 0.1861 - accuracy: 0.9375 - precision_6: 0.9393 - recall_6: 0.930 - 0s 960us/sample - loss: 0.1823 - accuracy: 0.9390 - precision_6: 0.9408 - recall_6: 0.9319 - val_loss: 1.1821 - val_accuracy: 0.6761 - val_precision_6: 0.6963 - val_recall_6: 0.6620\n",
      "Epoch 167/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2180 - accuracy: 0.8906 - precision_6: 0.8968 - recall_6: 0.882 - ETA: 0s - loss: 0.2025 - accuracy: 0.9062 - precision_6: 0.9153 - recall_6: 0.901 - ETA: 0s - loss: 0.1774 - accuracy: 0.9236 - precision_6: 0.9364 - recall_6: 0.920 - ETA: 0s - loss: 0.1824 - accuracy: 0.9233 - precision_6: 0.9364 - recall_6: 0.920 - ETA: 0s - loss: 0.1923 - accuracy: 0.9135 - precision_6: 0.9335 - recall_6: 0.911 - 0s 1ms/sample - loss: 0.1881 - accuracy: 0.9155 - precision_6: 0.9351 - recall_6: 0.9131 - val_loss: 1.1901 - val_accuracy: 0.6901 - val_precision_6: 0.7080 - val_recall_6: 0.6831\n",
      "Epoch 168/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.3699 - accuracy: 0.9167 - precision_6: 0.9263 - recall_6: 0.916 - ETA: 0s - loss: 0.2475 - accuracy: 0.9427 - precision_6: 0.9521 - recall_6: 0.932 - ETA: 0s - loss: 0.2270 - accuracy: 0.9414 - precision_6: 0.9484 - recall_6: 0.933 - ETA: 0s - loss: 0.2039 - accuracy: 0.9517 - precision_6: 0.9568 - recall_6: 0.943 - 0s 958us/sample - loss: 0.2093 - accuracy: 0.9460 - precision_6: 0.9500 - recall_6: 0.9366 - val_loss: 1.2613 - val_accuracy: 0.6831 - val_precision_6: 0.6985 - val_recall_6: 0.6690\n",
      "Epoch 169/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.3602 - accuracy: 0.8333 - precision_6: 0.8421 - recall_6: 0.833 - ETA: 0s - loss: 0.2680 - accuracy: 0.8958 - precision_6: 0.8995 - recall_6: 0.885 - ETA: 0s - loss: 0.2672 - accuracy: 0.9062 - precision_6: 0.9091 - recall_6: 0.898 - ETA: 0s - loss: 0.2593 - accuracy: 0.9119 - precision_6: 0.9135 - recall_6: 0.900 - ETA: 0s - loss: 0.2666 - accuracy: 0.9087 - precision_6: 0.9095 - recall_6: 0.894 - 0s 1ms/sample - loss: 0.2605 - accuracy: 0.9108 - precision_6: 0.9117 - recall_6: 0.8967 - val_loss: 1.3947 - val_accuracy: 0.6338 - val_precision_6: 0.6444 - val_recall_6: 0.6127\n",
      "Epoch 170/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0571 - accuracy: 0.7812 - precision_6: 0.7812 - recall_6: 0.781 - ETA: 0s - loss: 0.8554 - accuracy: 0.7656 - precision_6: 0.7680 - recall_6: 0.750 - ETA: 0s - loss: 0.7122 - accuracy: 0.7969 - precision_6: 0.7989 - recall_6: 0.786 - ETA: 0s - loss: 0.6424 - accuracy: 0.8125 - precision_6: 0.8163 - recall_6: 0.802 - ETA: 0s - loss: 0.6505 - accuracy: 0.8040 - precision_6: 0.8069 - recall_6: 0.795 - 0s 981us/sample - loss: 0.6122 - accuracy: 0.8075 - precision_6: 0.8100 - recall_6: 0.8005 - val_loss: 1.2313 - val_accuracy: 0.6972 - val_precision_6: 0.6992 - val_recall_6: 0.6549\n",
      "Epoch 171/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.5041 - accuracy: 0.8203 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.5807 - accuracy: 0.8021 - precision_6: 0.8172 - recall_6: 0.791 - ETA: 0s - loss: 0.5754 - accuracy: 0.8047 - precision_6: 0.8211 - recall_6: 0.789 - ETA: 0s - loss: 0.5885 - accuracy: 0.8040 - precision_6: 0.8182 - recall_6: 0.792 - 0s 988us/sample - loss: 0.5701 - accuracy: 0.7981 - precision_6: 0.8186 - recall_6: 0.7840 - val_loss: 1.1319 - val_accuracy: 0.6549 - val_precision_6: 0.6815 - val_recall_6: 0.6479\n",
      "Epoch 172/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.8438 - precision_6: 0.8966 - recall_6: 0.812 - ETA: 0s - loss: 0.4174 - accuracy: 0.8438 - precision_6: 0.8760 - recall_6: 0.828 - ETA: 0s - loss: 0.5230 - accuracy: 0.8177 - precision_6: 0.8516 - recall_6: 0.807 - ETA: 0s - loss: 0.4535 - accuracy: 0.8398 - precision_6: 0.8683 - recall_6: 0.824 - ETA: 0s - loss: 0.4430 - accuracy: 0.8344 - precision_6: 0.8595 - recall_6: 0.821 - ETA: 0s - loss: 0.4534 - accuracy: 0.8173 - precision_6: 0.8460 - recall_6: 0.805 - 0s 1ms/sample - loss: 0.4432 - accuracy: 0.8216 - precision_6: 0.8498 - recall_6: 0.8099 - val_loss: 1.2212 - val_accuracy: 0.6690 - val_precision_6: 0.6838 - val_recall_6: 0.6549\n",
      "Epoch 173/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.8125 - precision_6: 0.8333 - recall_6: 0.781 - ETA: 0s - loss: 0.4998 - accuracy: 0.8125 - precision_6: 0.8403 - recall_6: 0.781 - ETA: 0s - loss: 0.6456 - accuracy: 0.7812 - precision_6: 0.8136 - recall_6: 0.750 - ETA: 0s - loss: 0.6118 - accuracy: 0.7852 - precision_6: 0.8067 - recall_6: 0.750 - ETA: 0s - loss: 0.5653 - accuracy: 0.7926 - precision_6: 0.8116 - recall_6: 0.758 - 0s 972us/sample - loss: 0.5402 - accuracy: 0.7981 - precision_6: 0.8155 - recall_6: 0.7676 - val_loss: 1.1984 - val_accuracy: 0.6479 - val_precision_6: 0.6923 - val_recall_6: 0.6338\n",
      "Epoch 174/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.8125 - precision_6: 0.8966 - recall_6: 0.812 - ETA: 0s - loss: 0.4422 - accuracy: 0.7917 - precision_6: 0.9012 - recall_6: 0.760 - ETA: 0s - loss: 0.3930 - accuracy: 0.8542 - precision_6: 0.9075 - recall_6: 0.817 - ETA: 0s - loss: 0.3682 - accuracy: 0.8672 - precision_6: 0.9142 - recall_6: 0.832 - ETA: 0s - loss: 0.3470 - accuracy: 0.8750 - precision_6: 0.9164 - recall_6: 0.840 - ETA: 0s - loss: 0.3989 - accuracy: 0.8510 - precision_6: 0.8871 - recall_6: 0.812 - 0s 1ms/sample - loss: 0.3943 - accuracy: 0.8521 - precision_6: 0.8875 - recall_6: 0.8146 - val_loss: 0.9818 - val_accuracy: 0.7113 - val_precision_6: 0.7500 - val_recall_6: 0.6761\n",
      "Epoch 175/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8750 - precision_6: 0.9310 - recall_6: 0.843 - ETA: 0s - loss: 0.2433 - accuracy: 0.9062 - precision_6: 0.9444 - recall_6: 0.885 - ETA: 0s - loss: 0.2336 - accuracy: 0.9187 - precision_6: 0.9416 - recall_6: 0.906 - ETA: 0s - loss: 0.2199 - accuracy: 0.9330 - precision_6: 0.9493 - recall_6: 0.919 - ETA: 0s - loss: 0.2642 - accuracy: 0.9031 - precision_6: 0.9279 - recall_6: 0.884 - ETA: 0s - loss: 0.3025 - accuracy: 0.8846 - precision_6: 0.9116 - recall_6: 0.867 - 0s 986us/sample - loss: 0.2957 - accuracy: 0.8873 - precision_6: 0.9138 - recall_6: 0.8709 - val_loss: 1.2907 - val_accuracy: 0.6127 - val_precision_6: 0.6370 - val_recall_6: 0.6056\n",
      "Epoch 176/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.8750 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.3326 - accuracy: 0.8828 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3144 - accuracy: 0.8802 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3024 - accuracy: 0.8906 - precision_6: 0.9076 - recall_6: 0.882 - ETA: 0s - loss: 0.3613 - accuracy: 0.8687 - precision_6: 0.8846 - recall_6: 0.862 - ETA: 0s - loss: 0.4331 - accuracy: 0.8594 - precision_6: 0.8743 - recall_6: 0.851 - 0s 1ms/sample - loss: 0.4424 - accuracy: 0.8545 - precision_6: 0.8692 - recall_6: 0.8427 - val_loss: 1.3954 - val_accuracy: 0.6127 - val_precision_6: 0.6232 - val_recall_6: 0.6056\n",
      "Epoch 177/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.8125 - precision_6: 0.8621 - recall_6: 0.781 - ETA: 0s - loss: 0.4550 - accuracy: 0.8047 - precision_6: 0.8226 - recall_6: 0.796 - ETA: 0s - loss: 0.4518 - accuracy: 0.8073 - precision_6: 0.8306 - recall_6: 0.791 - ETA: 0s - loss: 0.4260 - accuracy: 0.8264 - precision_6: 0.8484 - recall_6: 0.816 - ETA: 0s - loss: 0.4816 - accuracy: 0.8099 - precision_6: 0.8365 - recall_6: 0.799 - 0s 965us/sample - loss: 0.5134 - accuracy: 0.8075 - precision_6: 0.8350 - recall_6: 0.7958 - val_loss: 1.3322 - val_accuracy: 0.6268 - val_precision_6: 0.6825 - val_recall_6: 0.6056\n",
      "Epoch 178/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.7500 - precision_6: 0.7742 - recall_6: 0.750 - ETA: 0s - loss: 0.5799 - accuracy: 0.7734 - precision_6: 0.7917 - recall_6: 0.742 - ETA: 0s - loss: 0.5445 - accuracy: 0.8304 - precision_6: 0.8396 - recall_6: 0.794 - ETA: 0s - loss: 0.5460 - accuracy: 0.8368 - precision_6: 0.8413 - recall_6: 0.791 - ETA: 0s - loss: 0.5186 - accuracy: 0.8438 - precision_6: 0.8489 - recall_6: 0.804 - 0s 981us/sample - loss: 0.5408 - accuracy: 0.8310 - precision_6: 0.8391 - recall_6: 0.7958 - val_loss: 1.3878 - val_accuracy: 0.6197 - val_precision_6: 0.6434 - val_recall_6: 0.5845\n",
      "Epoch 179/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.6250 - precision_6: 0.6552 - recall_6: 0.593 - ETA: 0s - loss: 0.9738 - accuracy: 0.6354 - precision_6: 0.6860 - recall_6: 0.614 - ETA: 0s - loss: 0.9722 - accuracy: 0.6812 - precision_6: 0.7279 - recall_6: 0.668 - ETA: 0s - loss: 0.9397 - accuracy: 0.6875 - precision_6: 0.7282 - recall_6: 0.669 - ETA: 0s - loss: 0.9389 - accuracy: 0.6910 - precision_6: 0.7290 - recall_6: 0.663 - ETA: 0s - loss: 0.9575 - accuracy: 0.6901 - precision_6: 0.7299 - recall_6: 0.661 - 0s 1ms/sample - loss: 0.9284 - accuracy: 0.6878 - precision_6: 0.7235 - recall_6: 0.6573 - val_loss: 1.1265 - val_accuracy: 0.6479 - val_precision_6: 0.6667 - val_recall_6: 0.5915\n",
      "Epoch 180/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7827 - accuracy: 0.7188 - precision_6: 0.7333 - recall_6: 0.687 - ETA: 0s - loss: 0.7794 - accuracy: 0.7266 - precision_6: 0.7458 - recall_6: 0.687 - ETA: 0s - loss: 0.7964 - accuracy: 0.7396 - precision_6: 0.7654 - recall_6: 0.713 - ETA: 0s - loss: 0.6798 - accuracy: 0.7674 - precision_6: 0.7875 - recall_6: 0.746 - ETA: 0s - loss: 0.7135 - accuracy: 0.7552 - precision_6: 0.7827 - recall_6: 0.731 - 0s 955us/sample - loss: 0.7000 - accuracy: 0.7582 - precision_6: 0.7825 - recall_6: 0.7347 - val_loss: 1.2579 - val_accuracy: 0.6197 - val_precision_6: 0.6412 - val_recall_6: 0.5915\n",
      "Epoch 181/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6116 - accuracy: 0.8125 - precision_6: 0.8571 - recall_6: 0.750 - ETA: 0s - loss: 0.5888 - accuracy: 0.7578 - precision_6: 0.8158 - recall_6: 0.726 - ETA: 0s - loss: 0.6504 - accuracy: 0.7552 - precision_6: 0.8046 - recall_6: 0.729 - ETA: 0s - loss: 0.5980 - accuracy: 0.7812 - precision_6: 0.8248 - recall_6: 0.753 - ETA: 0s - loss: 0.6407 - accuracy: 0.7642 - precision_6: 0.8050 - recall_6: 0.727 - ETA: 0s - loss: 0.6210 - accuracy: 0.7596 - precision_6: 0.7989 - recall_6: 0.726 - 0s 1ms/sample - loss: 0.6293 - accuracy: 0.7559 - precision_6: 0.7953 - recall_6: 0.7207 - val_loss: 1.0884 - val_accuracy: 0.6268 - val_precision_6: 0.6484 - val_recall_6: 0.5845\n",
      "Epoch 182/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.8125 - precision_6: 0.8571 - recall_6: 0.750 - ETA: 0s - loss: 0.6376 - accuracy: 0.7578 - precision_6: 0.7931 - recall_6: 0.718 - ETA: 0s - loss: 0.6995 - accuracy: 0.7604 - precision_6: 0.7907 - recall_6: 0.708 - ETA: 0s - loss: 0.7678 - accuracy: 0.7344 - precision_6: 0.7629 - recall_6: 0.691 - ETA: 0s - loss: 0.7910 - accuracy: 0.7301 - precision_6: 0.7712 - recall_6: 0.670 - ETA: 0s - loss: 0.7934 - accuracy: 0.7236 - precision_6: 0.7616 - recall_6: 0.668 - 0s 993us/sample - loss: 0.7887 - accuracy: 0.7207 - precision_6: 0.7655 - recall_6: 0.6667 - val_loss: 1.2493 - val_accuracy: 0.5634 - val_precision_6: 0.5789 - val_recall_6: 0.4648\n",
      "Epoch 183/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.6875 - precision_6: 0.8000 - recall_6: 0.625 - ETA: 0s - loss: 0.7447 - accuracy: 0.7292 - precision_6: 0.7564 - recall_6: 0.614 - ETA: 0s - loss: 0.7101 - accuracy: 0.7375 - precision_6: 0.7910 - recall_6: 0.662 - ETA: 0s - loss: 0.7006 - accuracy: 0.7461 - precision_6: 0.7909 - recall_6: 0.679 - ETA: 0s - loss: 0.7189 - accuracy: 0.7406 - precision_6: 0.7912 - recall_6: 0.675 - ETA: 0s - loss: 0.7770 - accuracy: 0.7214 - precision_6: 0.7651 - recall_6: 0.661 - 0s 1ms/sample - loss: 0.8298 - accuracy: 0.7066 - precision_6: 0.7500 - recall_6: 0.6479 - val_loss: 1.2097 - val_accuracy: 0.5986 - val_precision_6: 0.6290 - val_recall_6: 0.5493\n",
      "Epoch 184/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.6748 - accuracy: 0.7578 - precision_6: 0.7797 - recall_6: 0.718 - ETA: 0s - loss: 0.7151 - accuracy: 0.7500 - precision_6: 0.7670 - recall_6: 0.703 - ETA: 0s - loss: 0.7355 - accuracy: 0.7535 - precision_6: 0.7731 - recall_6: 0.697 - ETA: 0s - loss: 0.7778 - accuracy: 0.7396 - precision_6: 0.7602 - recall_6: 0.677 - 0s 972us/sample - loss: 0.8151 - accuracy: 0.7207 - precision_6: 0.7460 - recall_6: 0.6620 - val_loss: 1.1366 - val_accuracy: 0.6338 - val_precision_6: 0.6777 - val_recall_6: 0.5775\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.8125 - precision_6: 0.8966 - recall_6: 0.812 - ETA: 0s - loss: 0.5376 - accuracy: 0.7812 - precision_6: 0.8596 - recall_6: 0.765 - ETA: 0s - loss: 0.5723 - accuracy: 0.7708 - precision_6: 0.8554 - recall_6: 0.739 - ETA: 0s - loss: 0.6119 - accuracy: 0.7708 - precision_6: 0.8434 - recall_6: 0.729 - ETA: 0s - loss: 0.6260 - accuracy: 0.7670 - precision_6: 0.8295 - recall_6: 0.718 - ETA: 0s - loss: 0.6592 - accuracy: 0.7500 - precision_6: 0.8144 - recall_6: 0.706 - 0s 1ms/sample - loss: 0.6462 - accuracy: 0.7559 - precision_6: 0.8194 - recall_6: 0.7136 - val_loss: 1.0362 - val_accuracy: 0.6549 - val_precision_6: 0.6875 - val_recall_6: 0.6197\n",
      "Epoch 186/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.4625 - accuracy: 0.8438 - precision_6: 0.8793 - recall_6: 0.796 - ETA: 0s - loss: 0.4798 - accuracy: 0.8385 - precision_6: 0.8678 - recall_6: 0.786 - ETA: 0s - loss: 0.4935 - accuracy: 0.8359 - precision_6: 0.8728 - recall_6: 0.777 - ETA: 0s - loss: 0.4960 - accuracy: 0.8210 - precision_6: 0.8590 - recall_6: 0.761 - 0s 977us/sample - loss: 0.5183 - accuracy: 0.8099 - precision_6: 0.8443 - recall_6: 0.7512 - val_loss: 0.9325 - val_accuracy: 0.7042 - val_precision_6: 0.7364 - val_recall_6: 0.6690\n",
      "Epoch 187/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.3415 - accuracy: 0.8906 - precision_6: 0.9113 - recall_6: 0.882 - ETA: 0s - loss: 0.3584 - accuracy: 0.8906 - precision_6: 0.9126 - recall_6: 0.869 - ETA: 0s - loss: 0.3638 - accuracy: 0.8854 - precision_6: 0.9114 - recall_6: 0.857 - ETA: 0s - loss: 0.3944 - accuracy: 0.8724 - precision_6: 0.8923 - recall_6: 0.841 - 0s 955us/sample - loss: 0.4065 - accuracy: 0.8638 - precision_6: 0.8828 - recall_6: 0.8310 - val_loss: 0.9454 - val_accuracy: 0.6620 - val_precision_6: 0.7154 - val_recall_6: 0.6549\n",
      "Epoch 188/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2625 - accuracy: 0.9297 - precision_6: 0.9350 - recall_6: 0.898 - ETA: 0s - loss: 0.2627 - accuracy: 0.9375 - precision_6: 0.9526 - recall_6: 0.897 - ETA: 0s - loss: 0.2859 - accuracy: 0.9201 - precision_6: 0.9517 - recall_6: 0.888 - ETA: 0s - loss: 0.3012 - accuracy: 0.9062 - precision_6: 0.9366 - recall_6: 0.880 - ETA: 0s - loss: 0.3268 - accuracy: 0.8942 - precision_6: 0.9282 - recall_6: 0.870 - 0s 1ms/sample - loss: 0.3198 - accuracy: 0.8967 - precision_6: 0.9300 - recall_6: 0.8732 - val_loss: 0.9189 - val_accuracy: 0.7183 - val_precision_6: 0.7462 - val_recall_6: 0.6831\n",
      "Epoch 189/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2633 - accuracy: 0.8958 - precision_6: 0.9149 - recall_6: 0.895 - ETA: 0s - loss: 0.2419 - accuracy: 0.9187 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.2273 - accuracy: 0.9241 - precision_6: 0.9361 - recall_6: 0.915 - ETA: 0s - loss: 0.2416 - accuracy: 0.9132 - precision_6: 0.9288 - recall_6: 0.906 - ETA: 0s - loss: 0.2662 - accuracy: 0.9062 - precision_6: 0.9211 - recall_6: 0.894 - ETA: 0s - loss: 0.2913 - accuracy: 0.9038 - precision_6: 0.9181 - recall_6: 0.889 - 0s 1ms/sample - loss: 0.2851 - accuracy: 0.9061 - precision_6: 0.9201 - recall_6: 0.8920 - val_loss: 1.0179 - val_accuracy: 0.6408 - val_precision_6: 0.6642 - val_recall_6: 0.6408\n",
      "Epoch 190/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2678 - accuracy: 0.9062 - precision_6: 0.9053 - recall_6: 0.895 - ETA: 0s - loss: 0.2380 - accuracy: 0.9250 - precision_6: 0.9295 - recall_6: 0.906 - ETA: 0s - loss: 0.2162 - accuracy: 0.9375 - precision_6: 0.9406 - recall_6: 0.919 - ETA: 0s - loss: 0.2374 - accuracy: 0.9187 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.2516 - accuracy: 0.9167 - precision_6: 0.9301 - recall_6: 0.901 - 0s 1ms/sample - loss: 0.2578 - accuracy: 0.9202 - precision_6: 0.9343 - recall_6: 0.9014 - val_loss: 1.0073 - val_accuracy: 0.6831 - val_precision_6: 0.6861 - val_recall_6: 0.6620\n",
      "Epoch 191/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.1756 - accuracy: 0.9375 - precision_6: 0.9365 - recall_6: 0.921 - ETA: 0s - loss: 0.1697 - accuracy: 0.9479 - precision_6: 0.9524 - recall_6: 0.937 - ETA: 0s - loss: 0.1851 - accuracy: 0.9375 - precision_6: 0.9444 - recall_6: 0.929 - ETA: 0s - loss: 0.1911 - accuracy: 0.9344 - precision_6: 0.9427 - recall_6: 0.925 - ETA: 0s - loss: 0.2069 - accuracy: 0.9323 - precision_6: 0.9415 - recall_6: 0.921 - 0s 1ms/sample - loss: 0.2133 - accuracy: 0.9343 - precision_6: 0.9446 - recall_6: 0.9202 - val_loss: 1.0093 - val_accuracy: 0.6549 - val_precision_6: 0.6815 - val_recall_6: 0.6479\n",
      "Epoch 192/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.2106 - accuracy: 0.9062 - precision_6: 0.9053 - recall_6: 0.895 - ETA: 0s - loss: 0.1761 - accuracy: 0.9375 - precision_6: 0.9371 - recall_6: 0.931 - ETA: 0s - loss: 0.1700 - accuracy: 0.9427 - precision_6: 0.9424 - recall_6: 0.937 - ETA: 0s - loss: 0.1591 - accuracy: 0.9509 - precision_6: 0.9507 - recall_6: 0.946 - ETA: 0s - loss: 0.1686 - accuracy: 0.9514 - precision_6: 0.9509 - recall_6: 0.941 - ETA: 0s - loss: 0.1825 - accuracy: 0.9432 - precision_6: 0.9478 - recall_6: 0.929 - ETA: 0s - loss: 0.2061 - accuracy: 0.9399 - precision_6: 0.9461 - recall_6: 0.927 - 1s 2ms/sample - loss: 0.2017 - accuracy: 0.9413 - precision_6: 0.9474 - recall_6: 0.9296 - val_loss: 1.0024 - val_accuracy: 0.6831 - val_precision_6: 0.7080 - val_recall_6: 0.6831\n",
      "Epoch 193/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9062 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.1604 - accuracy: 0.9297 - precision_6: 0.9370 - recall_6: 0.929 - ETA: 0s - loss: 0.1557 - accuracy: 0.9427 - precision_6: 0.9476 - recall_6: 0.942 - ETA: 0s - loss: 0.1463 - accuracy: 0.9583 - precision_6: 0.9615 - recall_6: 0.954 - ETA: 0s - loss: 0.1539 - accuracy: 0.9574 - precision_6: 0.9599 - recall_6: 0.951 - ETA: 0s - loss: 0.1788 - accuracy: 0.9543 - precision_6: 0.9586 - recall_6: 0.947 - 0s 1ms/sample - loss: 0.1750 - accuracy: 0.9554 - precision_6: 0.9596 - recall_6: 0.9484 - val_loss: 0.9509 - val_accuracy: 0.7113 - val_precision_6: 0.7279 - val_recall_6: 0.6972\n",
      "Epoch 194/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9375 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.1632 - accuracy: 0.9375 - precision_6: 0.9370 - recall_6: 0.929 - ETA: 0s - loss: 0.1460 - accuracy: 0.9531 - precision_6: 0.9529 - recall_6: 0.947 - ETA: 0s - loss: 0.1406 - accuracy: 0.9609 - precision_6: 0.9606 - recall_6: 0.953 - ETA: 0s - loss: 0.1435 - accuracy: 0.9625 - precision_6: 0.9652 - recall_6: 0.953 - ETA: 0s - loss: 0.1541 - accuracy: 0.9635 - precision_6: 0.9657 - recall_6: 0.953 - 0s 1ms/sample - loss: 0.1623 - accuracy: 0.9577 - precision_6: 0.9619 - recall_6: 0.9484 - val_loss: 0.9664 - val_accuracy: 0.6972 - val_precision_6: 0.7037 - val_recall_6: 0.6690\n",
      "Epoch 195/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1424 - accuracy: 0.9219 - precision_6: 0.9440 - recall_6: 0.921 - ETA: 0s - loss: 0.1308 - accuracy: 0.9427 - precision_6: 0.9577 - recall_6: 0.942 - ETA: 0s - loss: 0.1304 - accuracy: 0.9492 - precision_6: 0.9602 - recall_6: 0.941 - ETA: 0s - loss: 0.1263 - accuracy: 0.9563 - precision_6: 0.9651 - recall_6: 0.950 - ETA: 0s - loss: 0.1346 - accuracy: 0.9609 - precision_6: 0.9683 - recall_6: 0.955 - 0s 1ms/sample - loss: 0.1418 - accuracy: 0.9577 - precision_6: 0.9667 - recall_6: 0.9531 - val_loss: 1.0331 - val_accuracy: 0.6831 - val_precision_6: 0.7080 - val_recall_6: 0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1337 - accuracy: 0.9271 - precision_6: 0.9368 - recall_6: 0.927 - ETA: 0s - loss: 0.1055 - accuracy: 0.9500 - precision_6: 0.9560 - recall_6: 0.950 - ETA: 0s - loss: 0.0938 - accuracy: 0.9643 - precision_6: 0.9686 - recall_6: 0.964 - ETA: 0s - loss: 0.0989 - accuracy: 0.9688 - precision_6: 0.9754 - recall_6: 0.965 - ETA: 0s - loss: 0.1034 - accuracy: 0.9688 - precision_6: 0.9742 - recall_6: 0.965 - ETA: 0s - loss: 0.1219 - accuracy: 0.9688 - precision_6: 0.9733 - recall_6: 0.963 - 0s 1ms/sample - loss: 0.1194 - accuracy: 0.9695 - precision_6: 0.9739 - recall_6: 0.9648 - val_loss: 0.9949 - val_accuracy: 0.7254 - val_precision_6: 0.7391 - val_recall_6: 0.7183\n",
      "Epoch 197/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9375 - precision_6: 0.9667 - recall_6: 0.906 - ETA: 0s - loss: 0.1556 - accuracy: 0.9375 - precision_6: 0.9462 - recall_6: 0.916 - ETA: 0s - loss: 0.1243 - accuracy: 0.9563 - precision_6: 0.9615 - recall_6: 0.937 - ETA: 0s - loss: 0.1266 - accuracy: 0.9598 - precision_6: 0.9680 - recall_6: 0.946 - ETA: 0s - loss: 0.1246 - accuracy: 0.9656 - precision_6: 0.9714 - recall_6: 0.956 - ETA: 0s - loss: 0.1322 - accuracy: 0.9661 - precision_6: 0.9710 - recall_6: 0.958 - 1s 1ms/sample - loss: 0.1379 - accuracy: 0.9624 - precision_6: 0.9667 - recall_6: 0.9531 - val_loss: 1.0340 - val_accuracy: 0.7042 - val_precision_6: 0.7333 - val_recall_6: 0.6972\n",
      "Epoch 198/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.1629 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1225 - accuracy: 0.9563 - precision_6: 0.9563 - recall_6: 0.956 - ETA: 0s - loss: 0.1318 - accuracy: 0.9609 - precision_6: 0.9644 - recall_6: 0.953 - ETA: 0s - loss: 0.1683 - accuracy: 0.9469 - precision_6: 0.9495 - recall_6: 0.940 - ETA: 0s - loss: 0.1862 - accuracy: 0.9401 - precision_6: 0.9447 - recall_6: 0.934 - 1s 1ms/sample - loss: 0.2243 - accuracy: 0.9296 - precision_6: 0.9357 - recall_6: 0.9225 - val_loss: 1.1560 - val_accuracy: 0.6831 - val_precision_6: 0.6963 - val_recall_6: 0.6620\n",
      "Epoch 199/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.8438 - precision_6: 0.8438 - recall_6: 0.843 - ETA: 0s - loss: 0.3314 - accuracy: 0.8646 - precision_6: 0.8723 - recall_6: 0.854 - ETA: 0s - loss: 0.2959 - accuracy: 0.8687 - precision_6: 0.8782 - recall_6: 0.856 - ETA: 0s - loss: 0.3326 - accuracy: 0.8633 - precision_6: 0.8755 - recall_6: 0.851 - ETA: 0s - loss: 0.3435 - accuracy: 0.8636 - precision_6: 0.8721 - recall_6: 0.852 - ETA: 0s - loss: 0.3709 - accuracy: 0.8654 - precision_6: 0.8719 - recall_6: 0.851 - 0s 1ms/sample - loss: 0.3629 - accuracy: 0.8685 - precision_6: 0.8750 - recall_6: 0.8545 - val_loss: 1.3549 - val_accuracy: 0.6268 - val_precision_6: 0.6444 - val_recall_6: 0.6127\n",
      "Epoch 200/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.8438 - precision_6: 0.8333 - recall_6: 0.781 - ETA: 0s - loss: 0.5826 - accuracy: 0.7917 - precision_6: 0.8022 - recall_6: 0.760 - ETA: 0s - loss: 0.5068 - accuracy: 0.8125 - precision_6: 0.8247 - recall_6: 0.793 - ETA: 0s - loss: 0.4629 - accuracy: 0.8259 - precision_6: 0.8426 - recall_6: 0.812 - ETA: 0s - loss: 0.4299 - accuracy: 0.8250 - precision_6: 0.8414 - recall_6: 0.812 - ETA: 0s - loss: 0.4475 - accuracy: 0.8203 - precision_6: 0.8333 - recall_6: 0.807 - 0s 1ms/sample - loss: 0.4483 - accuracy: 0.8263 - precision_6: 0.8415 - recall_6: 0.8099 - val_loss: 1.0904 - val_accuracy: 0.6831 - val_precision_6: 0.6963 - val_recall_6: 0.6620\n",
      "Epoch 201/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.8438 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.5018 - accuracy: 0.8047 - precision_6: 0.8049 - recall_6: 0.773 - ETA: 0s - loss: 0.4092 - accuracy: 0.8438 - precision_6: 0.8449 - recall_6: 0.822 - ETA: 0s - loss: 0.3674 - accuracy: 0.8672 - precision_6: 0.8669 - recall_6: 0.839 - ETA: 0s - loss: 0.3465 - accuracy: 0.8785 - precision_6: 0.8781 - recall_6: 0.850 - ETA: 0s - loss: 0.3505 - accuracy: 0.8722 - precision_6: 0.8765 - recall_6: 0.846 - ETA: 0s - loss: 0.3871 - accuracy: 0.8534 - precision_6: 0.8668 - recall_6: 0.829 - 0s 1ms/sample - loss: 0.3785 - accuracy: 0.8568 - precision_6: 0.8701 - recall_6: 0.8333 - val_loss: 1.1418 - val_accuracy: 0.6268 - val_precision_6: 0.6418 - val_recall_6: 0.6056\n",
      "Epoch 202/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.4621 - accuracy: 0.8333 - precision_6: 0.8333 - recall_6: 0.833 - ETA: 0s - loss: 0.4329 - accuracy: 0.8188 - precision_6: 0.8228 - recall_6: 0.812 - ETA: 0s - loss: 0.4030 - accuracy: 0.8259 - precision_6: 0.8394 - recall_6: 0.817 - ETA: 0s - loss: 0.4109 - accuracy: 0.8333 - precision_6: 0.8434 - recall_6: 0.822 - ETA: 0s - loss: 0.4384 - accuracy: 0.8182 - precision_6: 0.8304 - recall_6: 0.806 - ETA: 0s - loss: 0.4348 - accuracy: 0.8269 - precision_6: 0.8379 - recall_6: 0.807 - 1s 1ms/sample - loss: 0.4254 - accuracy: 0.8310 - precision_6: 0.8418 - recall_6: 0.8122 - val_loss: 1.2696 - val_accuracy: 0.6620 - val_precision_6: 0.6791 - val_recall_6: 0.6408\n",
      "Epoch 203/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8438 - precision_6: 0.8438 - recall_6: 0.843 - ETA: 0s - loss: 0.3988 - accuracy: 0.8542 - precision_6: 0.8526 - recall_6: 0.843 - ETA: 0s - loss: 0.3783 - accuracy: 0.8625 - precision_6: 0.8701 - recall_6: 0.837 - ETA: 0s - loss: 0.3739 - accuracy: 0.8571 - precision_6: 0.8704 - recall_6: 0.839 - ETA: 0s - loss: 0.3733 - accuracy: 0.8611 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.4019 - accuracy: 0.8523 - precision_6: 0.8647 - recall_6: 0.835 - ETA: 0s - loss: 0.4592 - accuracy: 0.8269 - precision_6: 0.8535 - recall_6: 0.812 - 0s 1ms/sample - loss: 0.4521 - accuracy: 0.8286 - precision_6: 0.8547 - recall_6: 0.8146 - val_loss: 1.4543 - val_accuracy: 0.6127 - val_precision_6: 0.6357 - val_recall_6: 0.5775\n",
      "Epoch 204/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.7500 - precision_6: 0.8000 - recall_6: 0.750 - ETA: 0s - loss: 0.6773 - accuracy: 0.7500 - precision_6: 0.8000 - recall_6: 0.750 - ETA: 0s - loss: 0.6464 - accuracy: 0.7875 - precision_6: 0.8182 - recall_6: 0.787 - ETA: 0s - loss: 0.6355 - accuracy: 0.7723 - precision_6: 0.7936 - recall_6: 0.772 - ETA: 0s - loss: 0.6635 - accuracy: 0.7708 - precision_6: 0.7929 - recall_6: 0.770 - ETA: 0s - loss: 0.6537 - accuracy: 0.7812 - precision_6: 0.8024 - recall_6: 0.772 - ETA: 0s - loss: 0.7286 - accuracy: 0.7572 - precision_6: 0.7789 - recall_6: 0.745 - 0s 1ms/sample - loss: 0.7158 - accuracy: 0.7606 - precision_6: 0.7819 - recall_6: 0.7488 - val_loss: 1.3922 - val_accuracy: 0.5634 - val_precision_6: 0.5940 - val_recall_6: 0.5563\n",
      "Epoch 205/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8335 - accuracy: 0.6562 - precision_6: 0.7000 - recall_6: 0.656 - ETA: 0s - loss: 0.5866 - accuracy: 0.7734 - precision_6: 0.8220 - recall_6: 0.757 - ETA: 0s - loss: 0.5565 - accuracy: 0.7969 - precision_6: 0.8315 - recall_6: 0.770 - ETA: 0s - loss: 0.5906 - accuracy: 0.7930 - precision_6: 0.8248 - recall_6: 0.753 - ETA: 0s - loss: 0.6426 - accuracy: 0.7844 - precision_6: 0.8197 - recall_6: 0.753 - ETA: 0s - loss: 0.6516 - accuracy: 0.7716 - precision_6: 0.8158 - recall_6: 0.745 - 0s 975us/sample - loss: 0.6390 - accuracy: 0.7770 - precision_6: 0.8205 - recall_6: 0.7512 - val_loss: 1.3770 - val_accuracy: 0.5845 - val_precision_6: 0.5891 - val_recall_6: 0.5352\n",
      "Epoch 206/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.6875 - precision_6: 0.7000 - recall_6: 0.656 - ETA: 0s - loss: 0.5583 - accuracy: 0.8125 - precision_6: 0.8333 - recall_6: 0.729 - ETA: 0s - loss: 0.5296 - accuracy: 0.8073 - precision_6: 0.8218 - recall_6: 0.744 - ETA: 0s - loss: 0.4841 - accuracy: 0.8320 - precision_6: 0.8426 - recall_6: 0.773 - ETA: 0s - loss: 0.4787 - accuracy: 0.8381 - precision_6: 0.8576 - recall_6: 0.786 - ETA: 0s - loss: 0.4857 - accuracy: 0.8269 - precision_6: 0.8511 - recall_6: 0.769 - 0s 1ms/sample - loss: 0.4755 - accuracy: 0.8310 - precision_6: 0.8549 - recall_6: 0.7746 - val_loss: 1.1010 - val_accuracy: 0.6690 - val_precision_6: 0.6716 - val_recall_6: 0.6338\n",
      "Epoch 207/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.9062 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.3485 - accuracy: 0.8906 - precision_6: 0.8934 - recall_6: 0.851 - ETA: 0s - loss: 0.3419 - accuracy: 0.8958 - precision_6: 0.9016 - recall_6: 0.859 - ETA: 0s - loss: 0.3184 - accuracy: 0.9023 - precision_6: 0.9106 - recall_6: 0.875 - ETA: 0s - loss: 0.3437 - accuracy: 0.8835 - precision_6: 0.8988 - recall_6: 0.858 - ETA: 0s - loss: 0.3658 - accuracy: 0.8702 - precision_6: 0.8841 - recall_6: 0.843 - 0s 995us/sample - loss: 0.3579 - accuracy: 0.8732 - precision_6: 0.8870 - recall_6: 0.8474 - val_loss: 1.0505 - val_accuracy: 0.6972 - val_precision_6: 0.7185 - val_recall_6: 0.6831\n",
      "Epoch 208/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.9062 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.2857 - accuracy: 0.8854 - precision_6: 0.8925 - recall_6: 0.864 - ETA: 0s - loss: 0.3194 - accuracy: 0.8813 - precision_6: 0.8910 - recall_6: 0.868 - ETA: 0s - loss: 0.3096 - accuracy: 0.8884 - precision_6: 0.9070 - recall_6: 0.870 - ETA: 0s - loss: 0.3112 - accuracy: 0.8924 - precision_6: 0.9091 - recall_6: 0.868 - ETA: 0s - loss: 0.3904 - accuracy: 0.8608 - precision_6: 0.8806 - recall_6: 0.838 - ETA: 0s - loss: 0.4221 - accuracy: 0.8462 - precision_6: 0.8640 - recall_6: 0.824 - 0s 1ms/sample - loss: 0.4171 - accuracy: 0.8474 - precision_6: 0.8649 - recall_6: 0.8263 - val_loss: 1.2009 - val_accuracy: 0.6761 - val_precision_6: 0.6899 - val_recall_6: 0.6268\n",
      "Epoch 209/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8750 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.4988 - accuracy: 0.8125 - precision_6: 0.8191 - recall_6: 0.802 - ETA: 0s - loss: 0.4257 - accuracy: 0.8542 - precision_6: 0.8656 - recall_6: 0.838 - ETA: 0s - loss: 0.4090 - accuracy: 0.8633 - precision_6: 0.8704 - recall_6: 0.839 - ETA: 0s - loss: 0.4351 - accuracy: 0.8523 - precision_6: 0.8665 - recall_6: 0.829 - ETA: 0s - loss: 0.4450 - accuracy: 0.8413 - precision_6: 0.8529 - recall_6: 0.822 - 0s 1ms/sample - loss: 0.4360 - accuracy: 0.8451 - precision_6: 0.8564 - recall_6: 0.8263 - val_loss: 1.0915 - val_accuracy: 0.6972 - val_precision_6: 0.7252 - val_recall_6: 0.6690\n",
      "Epoch 210/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.9062 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.3172 - accuracy: 0.8646 - precision_6: 0.8925 - recall_6: 0.864 - ETA: 0s - loss: 0.2883 - accuracy: 0.8938 - precision_6: 0.9161 - recall_6: 0.887 - ETA: 0s - loss: 0.2477 - accuracy: 0.9180 - precision_6: 0.9393 - recall_6: 0.906 - ETA: 0s - loss: 0.2625 - accuracy: 0.9148 - precision_6: 0.9351 - recall_6: 0.900 - ETA: 0s - loss: 0.2708 - accuracy: 0.9087 - precision_6: 0.9252 - recall_6: 0.891 - 0s 1ms/sample - loss: 0.2654 - accuracy: 0.9108 - precision_6: 0.9270 - recall_6: 0.8944 - val_loss: 1.0698 - val_accuracy: 0.7113 - val_precision_6: 0.7293 - val_recall_6: 0.6831\n",
      "Epoch 211/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.2986 - accuracy: 0.8750 - precision_6: 0.8925 - recall_6: 0.864 - ETA: 0s - loss: 0.2703 - accuracy: 0.8938 - precision_6: 0.9038 - recall_6: 0.881 - ETA: 0s - loss: 0.2345 - accuracy: 0.9196 - precision_6: 0.9273 - recall_6: 0.910 - ETA: 0s - loss: 0.2432 - accuracy: 0.9097 - precision_6: 0.9187 - recall_6: 0.902 - ETA: 0s - loss: 0.2732 - accuracy: 0.8977 - precision_6: 0.9128 - recall_6: 0.892 - ETA: 0s - loss: 0.2999 - accuracy: 0.8894 - precision_6: 0.9015 - recall_6: 0.879 - 0s 1ms/sample - loss: 0.2974 - accuracy: 0.8897 - precision_6: 0.9014 - recall_6: 0.8803 - val_loss: 1.0613 - val_accuracy: 0.7042 - val_precision_6: 0.7153 - val_recall_6: 0.6901\n",
      "Epoch 212/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.2909 - accuracy: 0.8906 - precision_6: 0.8880 - recall_6: 0.867 - ETA: 0s - loss: 0.2639 - accuracy: 0.9062 - precision_6: 0.9086 - recall_6: 0.880 - ETA: 0s - loss: 0.2374 - accuracy: 0.9141 - precision_6: 0.9197 - recall_6: 0.894 - ETA: 0s - loss: 0.2410 - accuracy: 0.9176 - precision_6: 0.9294 - recall_6: 0.897 - ETA: 0s - loss: 0.2539 - accuracy: 0.9111 - precision_6: 0.9229 - recall_6: 0.891 - 0s 1ms/sample - loss: 0.2488 - accuracy: 0.9131 - precision_6: 0.9248 - recall_6: 0.8944 - val_loss: 1.0551 - val_accuracy: 0.7183 - val_precision_6: 0.7353 - val_recall_6: 0.7042\n",
      "Epoch 213/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.2019 - accuracy: 0.9271 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.1952 - accuracy: 0.9250 - precision_6: 0.9481 - recall_6: 0.912 - ETA: 0s - loss: 0.1835 - accuracy: 0.9375 - precision_6: 0.9539 - recall_6: 0.924 - ETA: 0s - loss: 0.1707 - accuracy: 0.9479 - precision_6: 0.9604 - recall_6: 0.927 - ETA: 0s - loss: 0.1881 - accuracy: 0.9403 - precision_6: 0.9503 - recall_6: 0.923 - ETA: 0s - loss: 0.2003 - accuracy: 0.9327 - precision_6: 0.9455 - recall_6: 0.918 - 0s 1ms/sample - loss: 0.1961 - accuracy: 0.9343 - precision_6: 0.9469 - recall_6: 0.9202 - val_loss: 1.3361 - val_accuracy: 0.6620 - val_precision_6: 0.6894 - val_recall_6: 0.6408\n",
      "Epoch 214/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.8750 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.2864 - accuracy: 0.8828 - precision_6: 0.8952 - recall_6: 0.867 - ETA: 0s - loss: 0.4658 - accuracy: 0.8698 - precision_6: 0.8871 - recall_6: 0.859 - ETA: 0s - loss: 0.4668 - accuracy: 0.8711 - precision_6: 0.8911 - recall_6: 0.863 - ETA: 0s - loss: 0.4386 - accuracy: 0.8687 - precision_6: 0.8900 - recall_6: 0.859 - ETA: 0s - loss: 0.4334 - accuracy: 0.8672 - precision_6: 0.8847 - recall_6: 0.859 - 0s 1ms/sample - loss: 0.4391 - accuracy: 0.8638 - precision_6: 0.8816 - recall_6: 0.8568 - val_loss: 1.1566 - val_accuracy: 0.6690 - val_precision_6: 0.6842 - val_recall_6: 0.6408\n",
      "Epoch 215/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.2773 - accuracy: 0.9062 - precision_6: 0.9149 - recall_6: 0.895 - ETA: 0s - loss: 0.2592 - accuracy: 0.9187 - precision_6: 0.9241 - recall_6: 0.912 - ETA: 0s - loss: 0.2892 - accuracy: 0.9018 - precision_6: 0.9136 - recall_6: 0.897 - ETA: 0s - loss: 0.2942 - accuracy: 0.9028 - precision_6: 0.9152 - recall_6: 0.899 - ETA: 0s - loss: 0.3255 - accuracy: 0.8835 - precision_6: 0.8957 - recall_6: 0.877 - ETA: 0s - loss: 0.3353 - accuracy: 0.8774 - precision_6: 0.8894 - recall_6: 0.870 - 0s 1ms/sample - loss: 0.3318 - accuracy: 0.8779 - precision_6: 0.8897 - recall_6: 0.8709 - val_loss: 1.1754 - val_accuracy: 0.6761 - val_precision_6: 0.6866 - val_recall_6: 0.6479\n",
      "Epoch 216/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.3797 - accuracy: 0.8984 - precision_6: 0.8984 - recall_6: 0.898 - ETA: 0s - loss: 0.3838 - accuracy: 0.8906 - precision_6: 0.8942 - recall_6: 0.880 - ETA: 0s - loss: 0.6335 - accuracy: 0.8398 - precision_6: 0.8480 - recall_6: 0.828 - ETA: 0s - loss: 0.6552 - accuracy: 0.8375 - precision_6: 0.8494 - recall_6: 0.828 - ETA: 0s - loss: 0.7002 - accuracy: 0.8229 - precision_6: 0.8320 - recall_6: 0.812 - 0s 1ms/sample - loss: 0.6973 - accuracy: 0.8192 - precision_6: 0.8333 - recall_6: 0.8099 - val_loss: 1.5005 - val_accuracy: 0.5915 - val_precision_6: 0.6587 - val_recall_6: 0.5845\n",
      "Epoch 217/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.7812 - precision_6: 0.7742 - recall_6: 0.750 - ETA: 0s - loss: 0.5690 - accuracy: 0.7969 - precision_6: 0.8235 - recall_6: 0.765 - ETA: 0s - loss: 0.5263 - accuracy: 0.7969 - precision_6: 0.8466 - recall_6: 0.776 - ETA: 0s - loss: 0.5314 - accuracy: 0.8047 - precision_6: 0.8504 - recall_6: 0.777 - ETA: 0s - loss: 0.5530 - accuracy: 0.8094 - precision_6: 0.8475 - recall_6: 0.781 - ETA: 0s - loss: 0.5421 - accuracy: 0.8125 - precision_6: 0.8487 - recall_6: 0.789 - 0s 1ms/sample - loss: 0.5498 - accuracy: 0.8122 - precision_6: 0.8467 - recall_6: 0.7911 - val_loss: 1.2130 - val_accuracy: 0.6620 - val_precision_6: 0.6718 - val_recall_6: 0.6197\n",
      "Epoch 218/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8438 - precision_6: 0.8667 - recall_6: 0.812 - ETA: 0s - loss: 0.4584 - accuracy: 0.8438 - precision_6: 0.8478 - recall_6: 0.812 - ETA: 0s - loss: 0.3879 - accuracy: 0.8687 - precision_6: 0.8750 - recall_6: 0.831 - ETA: 0s - loss: 0.3779 - accuracy: 0.8594 - precision_6: 0.8689 - recall_6: 0.828 - ETA: 0s - loss: 0.3839 - accuracy: 0.8633 - precision_6: 0.8787 - recall_6: 0.820 - ETA: 0s - loss: 0.3547 - accuracy: 0.8636 - precision_6: 0.8799 - recall_6: 0.832 - ETA: 0s - loss: 0.4352 - accuracy: 0.8438 - precision_6: 0.8597 - recall_6: 0.810 - 1s 1ms/sample - loss: 0.4262 - accuracy: 0.8474 - precision_6: 0.8632 - recall_6: 0.8146 - val_loss: 1.2672 - val_accuracy: 0.6338 - val_precision_6: 0.6418 - val_recall_6: 0.6056\n",
      "Epoch 219/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8806 - accuracy: 0.7812 - precision_6: 0.8065 - recall_6: 0.781 - ETA: 0s - loss: 0.5040 - accuracy: 0.8646 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.4956 - accuracy: 0.8500 - precision_6: 0.8684 - recall_6: 0.825 - ETA: 0s - loss: 0.4955 - accuracy: 0.8527 - precision_6: 0.8692 - recall_6: 0.830 - ETA: 0s - loss: 0.4756 - accuracy: 0.8507 - precision_6: 0.8664 - recall_6: 0.833 - ETA: 0s - loss: 0.4659 - accuracy: 0.8523 - precision_6: 0.8643 - recall_6: 0.832 - ETA: 0s - loss: 0.4605 - accuracy: 0.8486 - precision_6: 0.8582 - recall_6: 0.829 - 0s 1ms/sample - loss: 0.4504 - accuracy: 0.8521 - precision_6: 0.8617 - recall_6: 0.8333 - val_loss: 1.1711 - val_accuracy: 0.6197 - val_precision_6: 0.6565 - val_recall_6: 0.6056\n",
      "Epoch 220/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.8438 - precision_6: 0.8438 - recall_6: 0.843 - ETA: 0s - loss: 0.3611 - accuracy: 0.8438 - precision_6: 0.8681 - recall_6: 0.822 - ETA: 0s - loss: 0.3268 - accuracy: 0.8687 - precision_6: 0.8874 - recall_6: 0.837 - ETA: 0s - loss: 0.2976 - accuracy: 0.8750 - precision_6: 0.8995 - recall_6: 0.839 - ETA: 0s - loss: 0.3255 - accuracy: 0.8719 - precision_6: 0.8963 - recall_6: 0.837 - ETA: 0s - loss: 0.3175 - accuracy: 0.8750 - precision_6: 0.8997 - recall_6: 0.841 - 0s 1ms/sample - loss: 0.3305 - accuracy: 0.8709 - precision_6: 0.8928 - recall_6: 0.8404 - val_loss: 1.0090 - val_accuracy: 0.6761 - val_precision_6: 0.7197 - val_recall_6: 0.6690\n",
      "Epoch 221/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.2408 - accuracy: 0.8958 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.2301 - accuracy: 0.8938 - precision_6: 0.9038 - recall_6: 0.881 - ETA: 0s - loss: 0.2242 - accuracy: 0.9107 - precision_6: 0.9174 - recall_6: 0.892 - ETA: 0s - loss: 0.2229 - accuracy: 0.9097 - precision_6: 0.9211 - recall_6: 0.892 - ETA: 0s - loss: 0.2289 - accuracy: 0.9062 - precision_6: 0.9152 - recall_6: 0.889 - ETA: 0s - loss: 0.2492 - accuracy: 0.8990 - precision_6: 0.9064 - recall_6: 0.884 - 0s 1ms/sample - loss: 0.2438 - accuracy: 0.9014 - precision_6: 0.9087 - recall_6: 0.8873 - val_loss: 1.0750 - val_accuracy: 0.6690 - val_precision_6: 0.7037 - val_recall_6: 0.6690\n",
      "Epoch 222/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9062 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.1645 - accuracy: 0.9453 - precision_6: 0.9603 - recall_6: 0.945 - ETA: 0s - loss: 0.1992 - accuracy: 0.9375 - precision_6: 0.9500 - recall_6: 0.933 - ETA: 0s - loss: 0.1900 - accuracy: 0.9375 - precision_6: 0.9505 - recall_6: 0.934 - ETA: 0s - loss: 0.1896 - accuracy: 0.9347 - precision_6: 0.9452 - recall_6: 0.931 - ETA: 0s - loss: 0.2104 - accuracy: 0.9255 - precision_6: 0.9386 - recall_6: 0.918 - 0s 1ms/sample - loss: 0.2059 - accuracy: 0.9272 - precision_6: 0.9400 - recall_6: 0.9202 - val_loss: 1.0278 - val_accuracy: 0.7042 - val_precision_6: 0.7279 - val_recall_6: 0.6972\n",
      "Epoch 223/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.8750 - precision_6: 0.9032 - recall_6: 0.875 - ETA: 0s - loss: 0.1943 - accuracy: 0.9062 - precision_6: 0.9247 - recall_6: 0.895 - ETA: 0s - loss: 0.1773 - accuracy: 0.9187 - precision_6: 0.9299 - recall_6: 0.912 - ETA: 0s - loss: 0.1623 - accuracy: 0.9375 - precision_6: 0.9500 - recall_6: 0.933 - ETA: 0s - loss: 0.1759 - accuracy: 0.9375 - precision_6: 0.9492 - recall_6: 0.934 - ETA: 0s - loss: 0.1941 - accuracy: 0.9375 - precision_6: 0.9485 - recall_6: 0.930 - 0s 995us/sample - loss: 0.1898 - accuracy: 0.9390 - precision_6: 0.9498 - recall_6: 0.9319 - val_loss: 0.9905 - val_accuracy: 0.7324 - val_precision_6: 0.7687 - val_recall_6: 0.7254\n",
      "Epoch 224/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1407 - accuracy: 0.9453 - precision_6: 0.9600 - recall_6: 0.937 - ETA: 0s - loss: 0.1489 - accuracy: 0.9375 - precision_6: 0.9471 - recall_6: 0.932 - ETA: 0s - loss: 0.1412 - accuracy: 0.9492 - precision_6: 0.9563 - recall_6: 0.941 - ETA: 0s - loss: 0.1416 - accuracy: 0.9469 - precision_6: 0.9525 - recall_6: 0.940 - ETA: 0s - loss: 0.1432 - accuracy: 0.9427 - precision_6: 0.9497 - recall_6: 0.934 - 0s 986us/sample - loss: 0.1548 - accuracy: 0.9390 - precision_6: 0.9450 - recall_6: 0.9272 - val_loss: 1.0639 - val_accuracy: 0.7254 - val_precision_6: 0.7407 - val_recall_6: 0.7042\n",
      "Epoch 225/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9688 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.1123 - accuracy: 0.9609 - precision_6: 0.9685 - recall_6: 0.960 - ETA: 0s - loss: 0.1226 - accuracy: 0.9583 - precision_6: 0.9735 - recall_6: 0.958 - ETA: 0s - loss: 0.1177 - accuracy: 0.9618 - precision_6: 0.9719 - recall_6: 0.961 - ETA: 0s - loss: 0.1238 - accuracy: 0.9602 - precision_6: 0.9685 - recall_6: 0.960 - ETA: 0s - loss: 0.1390 - accuracy: 0.9519 - precision_6: 0.9611 - recall_6: 0.949 - 0s 988us/sample - loss: 0.1360 - accuracy: 0.9531 - precision_6: 0.9620 - recall_6: 0.9507 - val_loss: 1.0082 - val_accuracy: 0.7465 - val_precision_6: 0.7664 - val_recall_6: 0.7394\n",
      "Epoch 226/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9375 - precision_6: 0.9677 - recall_6: 0.937 - ETA: 0s - loss: 0.1258 - accuracy: 0.9453 - precision_6: 0.9603 - recall_6: 0.945 - ETA: 0s - loss: 0.1278 - accuracy: 0.9479 - precision_6: 0.9579 - recall_6: 0.947 - ETA: 0s - loss: 0.1210 - accuracy: 0.9570 - precision_6: 0.9646 - recall_6: 0.957 - ETA: 0s - loss: 0.1181 - accuracy: 0.9594 - precision_6: 0.9653 - recall_6: 0.956 - ETA: 0s - loss: 0.1241 - accuracy: 0.9567 - precision_6: 0.9613 - recall_6: 0.954 - 0s 974us/sample - loss: 0.1216 - accuracy: 0.9577 - precision_6: 0.9622 - recall_6: 0.9554 - val_loss: 1.0316 - val_accuracy: 0.7183 - val_precision_6: 0.7353 - val_recall_6: 0.7042\n",
      "Epoch 227/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9688 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.0883 - accuracy: 0.9609 - precision_6: 0.9760 - recall_6: 0.953 - ETA: 0s - loss: 0.0922 - accuracy: 0.9635 - precision_6: 0.9787 - recall_6: 0.958 - ETA: 0s - loss: 0.0873 - accuracy: 0.9688 - precision_6: 0.9802 - recall_6: 0.964 - ETA: 0s - loss: 0.0903 - accuracy: 0.9688 - precision_6: 0.9778 - recall_6: 0.965 - ETA: 0s - loss: 0.0897 - accuracy: 0.9688 - precision_6: 0.9763 - recall_6: 0.966 - 0s 984us/sample - loss: 0.0954 - accuracy: 0.9648 - precision_6: 0.9739 - recall_6: 0.9624 - val_loss: 1.0472 - val_accuracy: 0.7465 - val_precision_6: 0.7630 - val_recall_6: 0.7254\n",
      "Epoch 228/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9688 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.1035 - accuracy: 0.9479 - precision_6: 0.9574 - recall_6: 0.937 - ETA: 0s - loss: 0.0893 - accuracy: 0.9688 - precision_6: 0.9747 - recall_6: 0.962 - ETA: 0s - loss: 0.0867 - accuracy: 0.9688 - precision_6: 0.9774 - recall_6: 0.964 - ETA: 0s - loss: 0.0846 - accuracy: 0.9653 - precision_6: 0.9754 - recall_6: 0.961 - ETA: 0s - loss: 0.0896 - accuracy: 0.9635 - precision_6: 0.9711 - recall_6: 0.960 - 0s 988us/sample - loss: 0.0948 - accuracy: 0.9624 - precision_6: 0.9692 - recall_6: 0.9601 - val_loss: 1.0687 - val_accuracy: 0.7324 - val_precision_6: 0.7372 - val_recall_6: 0.7113\n",
      "Epoch 229/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.0716 - accuracy: 0.9766 - precision_6: 0.9840 - recall_6: 0.960 - ETA: 0s - loss: 0.0677 - accuracy: 0.9866 - precision_6: 0.9909 - recall_6: 0.973 - ETA: 0s - loss: 0.0702 - accuracy: 0.9826 - precision_6: 0.9859 - recall_6: 0.968 - ETA: 0s - loss: 0.0722 - accuracy: 0.9818 - precision_6: 0.9842 - recall_6: 0.971 - 0s 960us/sample - loss: 0.0758 - accuracy: 0.9789 - precision_6: 0.9810 - recall_6: 0.9695 - val_loss: 1.0700 - val_accuracy: 0.7394 - val_precision_6: 0.7445 - val_recall_6: 0.7183\n",
      "Epoch 230/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.0669 - accuracy: 0.9922 - precision_6: 0.9921 - recall_6: 0.976 - ETA: 0s - loss: 0.0644 - accuracy: 0.9911 - precision_6: 0.9910 - recall_6: 0.977 - ETA: 0s - loss: 0.0668 - accuracy: 0.9861 - precision_6: 0.9860 - recall_6: 0.975 - ETA: 0s - loss: 0.0697 - accuracy: 0.9830 - precision_6: 0.9828 - recall_6: 0.974 - ETA: 0s - loss: 0.0729 - accuracy: 0.9832 - precision_6: 0.9830 - recall_6: 0.973 - 0s 984us/sample - loss: 0.0714 - accuracy: 0.9836 - precision_6: 0.9834 - recall_6: 0.9742 - val_loss: 1.0892 - val_accuracy: 0.7394 - val_precision_6: 0.7556 - val_recall_6: 0.7183\n",
      "Epoch 231/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.0599 - accuracy: 0.9922 - precision_6: 0.9921 - recall_6: 0.976 - ETA: 0s - loss: 0.0603 - accuracy: 0.9948 - precision_6: 0.9947 - recall_6: 0.979 - ETA: 0s - loss: 0.0613 - accuracy: 0.9922 - precision_6: 0.9921 - recall_6: 0.980 - ETA: 0s - loss: 0.0595 - accuracy: 0.9915 - precision_6: 0.9914 - recall_6: 0.983 - ETA: 0s - loss: 0.0629 - accuracy: 0.9904 - precision_6: 0.9927 - recall_6: 0.983 - 0s 988us/sample - loss: 0.0616 - accuracy: 0.9906 - precision_6: 0.9929 - recall_6: 0.9836 - val_loss: 1.0716 - val_accuracy: 0.7535 - val_precision_6: 0.7664 - val_recall_6: 0.7394\n",
      "Epoch 232/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0505 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0496 - accuracy: 0.9955 - precision_6: 1.0000 - recall_6: 0.995 - ETA: 0s - loss: 0.0558 - accuracy: 0.9844 - precision_6: 0.9875 - recall_6: 0.984 - ETA: 0s - loss: 0.0530 - accuracy: 0.9870 - precision_6: 0.9896 - recall_6: 0.987 - 0s 955us/sample - loss: 0.0568 - accuracy: 0.9859 - precision_6: 0.9906 - recall_6: 0.9859 - val_loss: 1.0996 - val_accuracy: 0.7324 - val_precision_6: 0.7391 - val_recall_6: 0.7183\n",
      "Epoch 233/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0502 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0506 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0671 - accuracy: 0.9826 - precision_6: 0.9861 - recall_6: 0.982 - ETA: 0s - loss: 0.0634 - accuracy: 0.9858 - precision_6: 0.9886 - recall_6: 0.985 - ETA: 0s - loss: 0.0654 - accuracy: 0.9856 - precision_6: 0.9903 - recall_6: 0.983 - 0s 972us/sample - loss: 0.0640 - accuracy: 0.9859 - precision_6: 0.9905 - recall_6: 0.9836 - val_loss: 1.1303 - val_accuracy: 0.7113 - val_precision_6: 0.7214 - val_recall_6: 0.7113\n",
      "Epoch 234/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0822 - accuracy: 0.9688 - precision_6: 0.9764 - recall_6: 0.968 - ETA: 0s - loss: 0.0836 - accuracy: 0.9688 - precision_6: 0.9731 - recall_6: 0.968 - ETA: 0s - loss: 0.0853 - accuracy: 0.9688 - precision_6: 0.9721 - recall_6: 0.968 - ETA: 0s - loss: 0.0769 - accuracy: 0.9740 - precision_6: 0.9765 - recall_6: 0.974 - 0s 953us/sample - loss: 0.0786 - accuracy: 0.9718 - precision_6: 0.9764 - recall_6: 0.9718 - val_loss: 1.0679 - val_accuracy: 0.7254 - val_precision_6: 0.7391 - val_recall_6: 0.7183\n",
      "Epoch 235/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.0992 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - ETA: 0s - loss: 0.1054 - accuracy: 0.9583 - precision_6: 0.9634 - recall_6: 0.958 - ETA: 0s - loss: 0.1139 - accuracy: 0.9570 - precision_6: 0.9608 - recall_6: 0.957 - ETA: 0s - loss: 0.1010 - accuracy: 0.9659 - precision_6: 0.9687 - recall_6: 0.965 - ETA: 0s - loss: 0.0989 - accuracy: 0.9663 - precision_6: 0.9710 - recall_6: 0.966 - 0s 967us/sample - loss: 0.0967 - accuracy: 0.9671 - precision_6: 0.9717 - recall_6: 0.9671 - val_loss: 1.2202 - val_accuracy: 0.7324 - val_precision_6: 0.7353 - val_recall_6: 0.7042\n",
      "Epoch 236/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1754 - accuracy: 0.9297 - precision_6: 0.9297 - recall_6: 0.929 - ETA: 0s - loss: 0.1578 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1586 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1533 - accuracy: 0.9403 - precision_6: 0.9403 - recall_6: 0.940 - 0s 958us/sample - loss: 0.1482 - accuracy: 0.9413 - precision_6: 0.9435 - recall_6: 0.9413 - val_loss: 1.1553 - val_accuracy: 0.7113 - val_precision_6: 0.7214 - val_recall_6: 0.7113\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0658 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.1122 - accuracy: 0.9635 - precision_6: 0.9635 - recall_6: 0.963 - ETA: 0s - loss: 0.1273 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - ETA: 0s - loss: 0.1294 - accuracy: 0.9563 - precision_6: 0.9563 - recall_6: 0.956 - ETA: 0s - loss: 0.1195 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - 0s 988us/sample - loss: 0.1199 - accuracy: 0.9601 - precision_6: 0.9600 - recall_6: 0.9577 - val_loss: 1.0890 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 238/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0578 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0582 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.994 - ETA: 0s - loss: 0.0650 - accuracy: 0.9883 - precision_6: 0.9883 - recall_6: 0.988 - ETA: 0s - loss: 0.0643 - accuracy: 0.9915 - precision_6: 0.9915 - recall_6: 0.991 - ETA: 0s - loss: 0.0714 - accuracy: 0.9832 - precision_6: 0.9855 - recall_6: 0.983 - 0s 967us/sample - loss: 0.0699 - accuracy: 0.9836 - precision_6: 0.9859 - recall_6: 0.9836 - val_loss: 1.1794 - val_accuracy: 0.7324 - val_precision_6: 0.7391 - val_recall_6: 0.7183\n",
      "Epoch 239/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0773 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - ETA: 0s - loss: 0.0676 - accuracy: 0.9740 - precision_6: 0.9740 - recall_6: 0.974 - ETA: 0s - loss: 0.0768 - accuracy: 0.9757 - precision_6: 0.9757 - recall_6: 0.975 - ETA: 0s - loss: 0.0738 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - 0s 960us/sample - loss: 0.1080 - accuracy: 0.9695 - precision_6: 0.9718 - recall_6: 0.9695 - val_loss: 1.1885 - val_accuracy: 0.7183 - val_precision_6: 0.7122 - val_recall_6: 0.6972\n",
      "Epoch 240/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1478 - accuracy: 0.9531 - precision_6: 0.9606 - recall_6: 0.953 - ETA: 0s - loss: 0.1273 - accuracy: 0.9635 - precision_6: 0.9737 - recall_6: 0.963 - ETA: 0s - loss: 0.1521 - accuracy: 0.9653 - precision_6: 0.9720 - recall_6: 0.965 - ETA: 0s - loss: 0.1583 - accuracy: 0.9631 - precision_6: 0.9685 - recall_6: 0.960 - ETA: 0s - loss: 0.1754 - accuracy: 0.9543 - precision_6: 0.9588 - recall_6: 0.951 - 0s 974us/sample - loss: 0.1714 - accuracy: 0.9554 - precision_6: 0.9598 - recall_6: 0.9531 - val_loss: 1.1679 - val_accuracy: 0.7113 - val_precision_6: 0.7246 - val_recall_6: 0.7042\n",
      "Epoch 241/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1767 - accuracy: 0.9375 - precision_6: 0.9370 - recall_6: 0.929 - ETA: 0s - loss: 0.2397 - accuracy: 0.9330 - precision_6: 0.9324 - recall_6: 0.924 - ETA: 0s - loss: 0.2567 - accuracy: 0.9250 - precision_6: 0.9274 - recall_6: 0.918 - ETA: 0s - loss: 0.2396 - accuracy: 0.9303 - precision_6: 0.9343 - recall_6: 0.923 - 0s 951us/sample - loss: 0.2341 - accuracy: 0.9319 - precision_6: 0.9359 - recall_6: 0.9249 - val_loss: 1.2945 - val_accuracy: 0.6620 - val_precision_6: 0.6741 - val_recall_6: 0.6408\n",
      "Epoch 242/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.2579 - accuracy: 0.9062 - precision_6: 0.9127 - recall_6: 0.898 - ETA: 0s - loss: 0.2496 - accuracy: 0.9152 - precision_6: 0.9189 - recall_6: 0.910 - ETA: 0s - loss: 0.2165 - accuracy: 0.9236 - precision_6: 0.9266 - recall_6: 0.920 - ETA: 0s - loss: 0.2211 - accuracy: 0.9233 - precision_6: 0.9255 - recall_6: 0.917 - ETA: 0s - loss: 0.2323 - accuracy: 0.9159 - precision_6: 0.9177 - recall_6: 0.911 - 0s 1000us/sample - loss: 0.2271 - accuracy: 0.9178 - precision_6: 0.9196 - recall_6: 0.9131 - val_loss: 1.2428 - val_accuracy: 0.6761 - val_precision_6: 0.6934 - val_recall_6: 0.6690\n",
      "Epoch 243/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0894 - accuracy: 0.9766 - precision_6: 0.9766 - recall_6: 0.976 - ETA: 0s - loss: 0.0778 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0801 - accuracy: 0.9805 - precision_6: 0.9843 - recall_6: 0.980 - ETA: 0s - loss: 0.0932 - accuracy: 0.9750 - precision_6: 0.9781 - recall_6: 0.975 - ETA: 0s - loss: 0.0968 - accuracy: 0.9740 - precision_6: 0.9764 - recall_6: 0.971 - 0s 1ms/sample - loss: 0.1095 - accuracy: 0.9695 - precision_6: 0.9717 - recall_6: 0.9671 - val_loss: 1.1311 - val_accuracy: 0.7183 - val_precision_6: 0.7372 - val_recall_6: 0.7113\n",
      "Epoch 244/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0531 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.992 - ETA: 0s - loss: 0.0571 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.989 - ETA: 0s - loss: 0.0691 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.988 - ETA: 0s - loss: 0.0770 - accuracy: 0.9844 - precision_6: 0.9874 - recall_6: 0.981 - ETA: 0s - loss: 0.0805 - accuracy: 0.9844 - precision_6: 0.9869 - recall_6: 0.981 - 0s 991us/sample - loss: 0.0913 - accuracy: 0.9765 - precision_6: 0.9811 - recall_6: 0.9742 - val_loss: 1.1134 - val_accuracy: 0.7394 - val_precision_6: 0.7500 - val_recall_6: 0.7183\n",
      "Epoch 245/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0535 - accuracy: 0.9922 - precision_6: 0.9921 - recall_6: 0.984 - ETA: 0s - loss: 0.0504 - accuracy: 0.9955 - precision_6: 0.9955 - recall_6: 0.986 - ETA: 0s - loss: 0.0759 - accuracy: 0.9792 - precision_6: 0.9790 - recall_6: 0.972 - ETA: 0s - loss: 0.0866 - accuracy: 0.9714 - precision_6: 0.9712 - recall_6: 0.966 - 0s 960us/sample - loss: 0.0918 - accuracy: 0.9671 - precision_6: 0.9693 - recall_6: 0.9624 - val_loss: 1.0660 - val_accuracy: 0.7535 - val_precision_6: 0.7591 - val_recall_6: 0.7324\n",
      "Epoch 246/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.1733 - accuracy: 0.9531 - precision_6: 0.9603 - recall_6: 0.945 - ETA: 0s - loss: 0.1326 - accuracy: 0.9643 - precision_6: 0.9685 - recall_6: 0.959 - ETA: 0s - loss: 0.1218 - accuracy: 0.9653 - precision_6: 0.9685 - recall_6: 0.961 - ETA: 0s - loss: 0.1170 - accuracy: 0.9661 - precision_6: 0.9686 - recall_6: 0.963 - 0s 958us/sample - loss: 0.1216 - accuracy: 0.9624 - precision_6: 0.9646 - recall_6: 0.9601 - val_loss: 1.1391 - val_accuracy: 0.7324 - val_precision_6: 0.7391 - val_recall_6: 0.7183\n",
      "Epoch 247/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.1454 - accuracy: 0.9531 - precision_6: 0.9531 - recall_6: 0.953 - ETA: 0s - loss: 0.1285 - accuracy: 0.9598 - precision_6: 0.9598 - recall_6: 0.959 - ETA: 0s - loss: 0.1146 - accuracy: 0.9653 - precision_6: 0.9653 - recall_6: 0.965 - ETA: 0s - loss: 0.0998 - accuracy: 0.9740 - precision_6: 0.9740 - recall_6: 0.974 - 0s 972us/sample - loss: 0.1031 - accuracy: 0.9718 - precision_6: 0.9741 - recall_6: 0.9718 - val_loss: 1.1073 - val_accuracy: 0.7183 - val_precision_6: 0.7338 - val_recall_6: 0.7183\n",
      "Epoch 248/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.1067 - accuracy: 0.9583 - precision_6: 0.9583 - recall_6: 0.958 - ETA: 0s - loss: 0.0967 - accuracy: 0.9635 - precision_6: 0.9635 - recall_6: 0.963 - ETA: 0s - loss: 0.0832 - accuracy: 0.9722 - precision_6: 0.9722 - recall_6: 0.972 - ETA: 0s - loss: 0.0920 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - 0s 951us/sample - loss: 0.0996 - accuracy: 0.9648 - precision_6: 0.9648 - recall_6: 0.9648 - val_loss: 1.0594 - val_accuracy: 0.7394 - val_precision_6: 0.7410 - val_recall_6: 0.7254\n",
      "Epoch 249/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0714 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0599 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0634 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0730 - accuracy: 0.9830 - precision_6: 0.9830 - recall_6: 0.983 - 0s 965us/sample - loss: 0.0789 - accuracy: 0.9812 - precision_6: 0.9812 - recall_6: 0.9812 - val_loss: 1.1194 - val_accuracy: 0.7254 - val_precision_6: 0.7464 - val_recall_6: 0.7254\n",
      "Epoch 250/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0652 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0680 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0716 - accuracy: 0.9727 - precision_6: 0.9765 - recall_6: 0.972 - ETA: 0s - loss: 0.0794 - accuracy: 0.9716 - precision_6: 0.9744 - recall_6: 0.971 - ETA: 0s - loss: 0.0922 - accuracy: 0.9639 - precision_6: 0.9685 - recall_6: 0.961 - 0s 995us/sample - loss: 0.0903 - accuracy: 0.9648 - precision_6: 0.9693 - recall_6: 0.9624 - val_loss: 1.1018 - val_accuracy: 0.7254 - val_precision_6: 0.7410 - val_recall_6: 0.7254\n",
      "Epoch 251/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0542 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0709 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.1202 - accuracy: 0.9688 - precision_6: 0.9724 - recall_6: 0.964 - ETA: 0s - loss: 0.1171 - accuracy: 0.9688 - precision_6: 0.9716 - recall_6: 0.962 - ETA: 0s - loss: 0.1206 - accuracy: 0.9635 - precision_6: 0.9684 - recall_6: 0.958 - 0s 974us/sample - loss: 0.1206 - accuracy: 0.9648 - precision_6: 0.9691 - recall_6: 0.9577 - val_loss: 1.0792 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 252/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.1277 - accuracy: 0.9479 - precision_6: 0.9479 - recall_6: 0.947 - ETA: 0s - loss: 0.1074 - accuracy: 0.9583 - precision_6: 0.9583 - recall_6: 0.958 - ETA: 0s - loss: 0.1047 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - ETA: 0s - loss: 0.1173 - accuracy: 0.9563 - precision_6: 0.9563 - recall_6: 0.956 - ETA: 0s - loss: 0.1239 - accuracy: 0.9505 - precision_6: 0.9505 - recall_6: 0.950 - 0s 977us/sample - loss: 0.1299 - accuracy: 0.9484 - precision_6: 0.9482 - recall_6: 0.9460 - val_loss: 1.1340 - val_accuracy: 0.7254 - val_precision_6: 0.7464 - val_recall_6: 0.7254\n",
      "Epoch 253/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0997 - accuracy: 0.9583 - precision_6: 0.9583 - recall_6: 0.958 - ETA: 0s - loss: 0.0800 - accuracy: 0.9750 - precision_6: 0.9750 - recall_6: 0.975 - ETA: 0s - loss: 0.0814 - accuracy: 0.9732 - precision_6: 0.9732 - recall_6: 0.973 - ETA: 0s - loss: 0.0885 - accuracy: 0.9719 - precision_6: 0.9749 - recall_6: 0.971 - ETA: 0s - loss: 0.0874 - accuracy: 0.9688 - precision_6: 0.9713 - recall_6: 0.968 - 0s 979us/sample - loss: 0.0856 - accuracy: 0.9718 - precision_6: 0.9741 - recall_6: 0.9695 - val_loss: 1.1750 - val_accuracy: 0.7254 - val_precision_6: 0.7319 - val_recall_6: 0.7113\n",
      "Epoch 254/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0881 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0806 - accuracy: 0.9750 - precision_6: 0.9750 - recall_6: 0.975 - ETA: 0s - loss: 0.1052 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1097 - accuracy: 0.9602 - precision_6: 0.9602 - recall_6: 0.960 - 0s 962us/sample - loss: 0.1271 - accuracy: 0.9554 - precision_6: 0.9576 - recall_6: 0.9554 - val_loss: 1.3332 - val_accuracy: 0.6831 - val_precision_6: 0.7059 - val_recall_6: 0.6761\n",
      "Epoch 255/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.8750 - precision_6: 0.8750 - recall_6: 0.875 - ETA: 0s - loss: 0.1805 - accuracy: 0.9167 - precision_6: 0.9167 - recall_6: 0.916 - ETA: 0s - loss: 0.2423 - accuracy: 0.9062 - precision_6: 0.9119 - recall_6: 0.906 - ETA: 0s - loss: 0.2804 - accuracy: 0.9018 - precision_6: 0.9099 - recall_6: 0.901 - ETA: 0s - loss: 0.2974 - accuracy: 0.8958 - precision_6: 0.9053 - recall_6: 0.895 - ETA: 0s - loss: 0.2849 - accuracy: 0.9006 - precision_6: 0.9083 - recall_6: 0.900 - ETA: 0s - loss: 0.2743 - accuracy: 0.9038 - precision_6: 0.9104 - recall_6: 0.903 - 0s 1ms/sample - loss: 0.2680 - accuracy: 0.9061 - precision_6: 0.9125 - recall_6: 0.9061 - val_loss: 1.2703 - val_accuracy: 0.6761 - val_precision_6: 0.6884 - val_recall_6: 0.6690\n",
      "Epoch 256/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.1926 - accuracy: 0.8958 - precision_6: 0.8958 - recall_6: 0.895 - ETA: 0s - loss: 0.2524 - accuracy: 0.8958 - precision_6: 0.9005 - recall_6: 0.895 - ETA: 0s - loss: 0.2328 - accuracy: 0.9062 - precision_6: 0.9091 - recall_6: 0.898 - ETA: 0s - loss: 0.2212 - accuracy: 0.9094 - precision_6: 0.9117 - recall_6: 0.903 - ETA: 0s - loss: 0.2114 - accuracy: 0.9135 - precision_6: 0.9218 - recall_6: 0.906 - 0s 986us/sample - loss: 0.2094 - accuracy: 0.9131 - precision_6: 0.9212 - recall_6: 0.9061 - val_loss: 1.0451 - val_accuracy: 0.7254 - val_precision_6: 0.7410 - val_recall_6: 0.7254\n",
      "Epoch 257/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0751 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.1070 - accuracy: 0.9688 - precision_6: 0.9686 - recall_6: 0.962 - ETA: 0s - loss: 0.1208 - accuracy: 0.9598 - precision_6: 0.9683 - recall_6: 0.955 - ETA: 0s - loss: 0.1301 - accuracy: 0.9514 - precision_6: 0.9613 - recall_6: 0.947 - ETA: 0s - loss: 0.1358 - accuracy: 0.9517 - precision_6: 0.9598 - recall_6: 0.948 - ETA: 0s - loss: 0.1339 - accuracy: 0.9519 - precision_6: 0.9587 - recall_6: 0.949 - 0s 1ms/sample - loss: 0.1309 - accuracy: 0.9531 - precision_6: 0.9597 - recall_6: 0.9507 - val_loss: 1.0986 - val_accuracy: 0.7183 - val_precision_6: 0.7286 - val_recall_6: 0.7183\n",
      "Epoch 258/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0771 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0990 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1061 - accuracy: 0.9643 - precision_6: 0.9641 - recall_6: 0.959 - ETA: 0s - loss: 0.1083 - accuracy: 0.9653 - precision_6: 0.9652 - recall_6: 0.961 - ETA: 0s - loss: 0.1010 - accuracy: 0.9688 - precision_6: 0.9687 - recall_6: 0.965 - ETA: 0s - loss: 0.0967 - accuracy: 0.9712 - precision_6: 0.9734 - recall_6: 0.968 - 0s 1ms/sample - loss: 0.0946 - accuracy: 0.9718 - precision_6: 0.9741 - recall_6: 0.9695 - val_loss: 1.0917 - val_accuracy: 0.7254 - val_precision_6: 0.7286 - val_recall_6: 0.7183\n",
      "Epoch 259/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0556 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0824 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0935 - accuracy: 0.9635 - precision_6: 0.9686 - recall_6: 0.963 - ETA: 0s - loss: 0.0827 - accuracy: 0.9727 - precision_6: 0.9765 - recall_6: 0.972 - ETA: 0s - loss: 0.0786 - accuracy: 0.9781 - precision_6: 0.9812 - recall_6: 0.978 - ETA: 0s - loss: 0.0725 - accuracy: 0.9818 - precision_6: 0.9843 - recall_6: 0.981 - 1s 1ms/sample - loss: 0.0726 - accuracy: 0.9812 - precision_6: 0.9835 - recall_6: 0.9789 - val_loss: 1.1406 - val_accuracy: 0.7324 - val_precision_6: 0.7445 - val_recall_6: 0.7183\n",
      "Epoch 260/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0381 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0576 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0628 - accuracy: 0.9732 - precision_6: 0.9732 - recall_6: 0.973 - ETA: 0s - loss: 0.0651 - accuracy: 0.9722 - precision_6: 0.9756 - recall_6: 0.972 - ETA: 0s - loss: 0.0647 - accuracy: 0.9744 - precision_6: 0.9772 - recall_6: 0.974 - ETA: 0s - loss: 0.0660 - accuracy: 0.9760 - precision_6: 0.9783 - recall_6: 0.973 - 1s 1ms/sample - loss: 0.0646 - accuracy: 0.9765 - precision_6: 0.9788 - recall_6: 0.9742 - val_loss: 1.1332 - val_accuracy: 0.7183 - val_precision_6: 0.7266 - val_recall_6: 0.7113\n",
      "Epoch 261/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0711 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0893 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0867 - accuracy: 0.9688 - precision_6: 0.9731 - recall_6: 0.968 - ETA: 0s - loss: 0.0812 - accuracy: 0.9722 - precision_6: 0.9756 - recall_6: 0.972 - ETA: 0s - loss: 0.0805 - accuracy: 0.9744 - precision_6: 0.9772 - recall_6: 0.974 - ETA: 0s - loss: 0.0796 - accuracy: 0.9736 - precision_6: 0.9759 - recall_6: 0.973 - 0s 1ms/sample - loss: 0.0778 - accuracy: 0.9742 - precision_6: 0.9765 - recall_6: 0.9742 - val_loss: 1.0622 - val_accuracy: 0.7254 - val_precision_6: 0.7338 - val_recall_6: 0.7183\n",
      "Epoch 262/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0943 - accuracy: 0.9609 - precision_6: 0.9609 - recall_6: 0.960 - ETA: 0s - loss: 0.1015 - accuracy: 0.9598 - precision_6: 0.9640 - recall_6: 0.955 - ETA: 0s - loss: 0.1014 - accuracy: 0.9618 - precision_6: 0.9650 - recall_6: 0.958 - ETA: 0s - loss: 0.0882 - accuracy: 0.9688 - precision_6: 0.9712 - recall_6: 0.966 - 0s 965us/sample - loss: 0.0862 - accuracy: 0.9695 - precision_6: 0.9717 - recall_6: 0.9671 - val_loss: 1.1127 - val_accuracy: 0.7113 - val_precision_6: 0.7174 - val_recall_6: 0.6972\n",
      "Epoch 263/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0652 - accuracy: 0.9688 - precision_6: 0.9764 - recall_6: 0.968 - ETA: 0s - loss: 0.0627 - accuracy: 0.9732 - precision_6: 0.9820 - recall_6: 0.973 - ETA: 0s - loss: 0.0655 - accuracy: 0.9722 - precision_6: 0.9790 - recall_6: 0.972 - ETA: 0s - loss: 0.0749 - accuracy: 0.9688 - precision_6: 0.9738 - recall_6: 0.968 - 0s 974us/sample - loss: 0.0708 - accuracy: 0.9718 - precision_6: 0.9764 - recall_6: 0.9718 - val_loss: 1.2048 - val_accuracy: 0.7113 - val_precision_6: 0.7246 - val_recall_6: 0.7042\n",
      "Epoch 264/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.1867 - accuracy: 0.9167 - precision_6: 0.9167 - recall_6: 0.916 - ETA: 0s - loss: 0.1482 - accuracy: 0.9312 - precision_6: 0.9312 - recall_6: 0.931 - ETA: 0s - loss: 0.1320 - accuracy: 0.9330 - precision_6: 0.9330 - recall_6: 0.933 - ETA: 0s - loss: 0.1195 - accuracy: 0.9444 - precision_6: 0.9444 - recall_6: 0.944 - ETA: 0s - loss: 0.1132 - accuracy: 0.9489 - precision_6: 0.9489 - recall_6: 0.948 - ETA: 0s - loss: 0.1072 - accuracy: 0.9543 - precision_6: 0.9543 - recall_6: 0.954 - 0s 1ms/sample - loss: 0.1048 - accuracy: 0.9554 - precision_6: 0.9554 - recall_6: 0.9554 - val_loss: 1.1217 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 265/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0341 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0741 - accuracy: 0.9740 - precision_6: 0.9738 - recall_6: 0.968 - ETA: 0s - loss: 0.0982 - accuracy: 0.9688 - precision_6: 0.9683 - recall_6: 0.953 - ETA: 0s - loss: 0.0840 - accuracy: 0.9744 - precision_6: 0.9741 - recall_6: 0.963 - 0s 979us/sample - loss: 0.0769 - accuracy: 0.9789 - precision_6: 0.9787 - recall_6: 0.9695 - val_loss: 1.2030 - val_accuracy: 0.7113 - val_precision_6: 0.7214 - val_recall_6: 0.7113\n",
      "Epoch 266/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0812 - accuracy: 0.9609 - precision_6: 0.9685 - recall_6: 0.960 - ETA: 0s - loss: 0.0828 - accuracy: 0.9688 - precision_6: 0.9738 - recall_6: 0.968 - ETA: 0s - loss: 0.0735 - accuracy: 0.9722 - precision_6: 0.9756 - recall_6: 0.972 - ETA: 0s - loss: 0.0682 - accuracy: 0.9740 - precision_6: 0.9765 - recall_6: 0.974 - 0s 962us/sample - loss: 0.0655 - accuracy: 0.9765 - precision_6: 0.9788 - recall_6: 0.9765 - val_loss: 1.2889 - val_accuracy: 0.6972 - val_precision_6: 0.7071 - val_recall_6: 0.6972\n",
      "Epoch 267/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0798 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0738 - accuracy: 0.9750 - precision_6: 0.9750 - recall_6: 0.975 - ETA: 0s - loss: 0.0660 - accuracy: 0.9777 - precision_6: 0.9821 - recall_6: 0.977 - ETA: 0s - loss: 0.0619 - accuracy: 0.9792 - precision_6: 0.9826 - recall_6: 0.979 - ETA: 0s - loss: 0.0599 - accuracy: 0.9801 - precision_6: 0.9829 - recall_6: 0.980 - ETA: 0s - loss: 0.0571 - accuracy: 0.9808 - precision_6: 0.9831 - recall_6: 0.980 - 0s 1ms/sample - loss: 0.0559 - accuracy: 0.9812 - precision_6: 0.9835 - recall_6: 0.9812 - val_loss: 1.2529 - val_accuracy: 0.7183 - val_precision_6: 0.7246 - val_recall_6: 0.7042\n",
      "Epoch 268/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0537 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0505 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0502 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0533 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0477 - accuracy: 0.9870 - precision_6: 0.9870 - recall_6: 0.987 - 0s 1ms/sample - loss: 0.0473 - accuracy: 0.9859 - precision_6: 0.9882 - recall_6: 0.9859 - val_loss: 1.2395 - val_accuracy: 0.7324 - val_precision_6: 0.7299 - val_recall_6: 0.7042\n",
      "Epoch 269/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0219 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.989 - ETA: 0s - loss: 0.0357 - accuracy: 0.9896 - precision_6: 0.9895 - recall_6: 0.984 - ETA: 0s - loss: 0.0379 - accuracy: 0.9844 - precision_6: 0.9843 - recall_6: 0.980 - ETA: 0s - loss: 0.0369 - accuracy: 0.9875 - precision_6: 0.9875 - recall_6: 0.984 - ETA: 0s - loss: 0.0342 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.987 - 0s 1ms/sample - loss: 0.0331 - accuracy: 0.9906 - precision_6: 0.9906 - recall_6: 0.9883 - val_loss: 1.1907 - val_accuracy: 0.7324 - val_precision_6: 0.7407 - val_recall_6: 0.7042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0758 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0702 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0574 - accuracy: 0.9777 - precision_6: 0.9777 - recall_6: 0.977 - ETA: 0s - loss: 0.0513 - accuracy: 0.9826 - precision_6: 0.9826 - recall_6: 0.982 - ETA: 0s - loss: 0.0469 - accuracy: 0.9858 - precision_6: 0.9858 - recall_6: 0.985 - ETA: 0s - loss: 0.0433 - accuracy: 0.9880 - precision_6: 0.9880 - recall_6: 0.988 - 0s 1ms/sample - loss: 0.0423 - accuracy: 0.9883 - precision_6: 0.9883 - recall_6: 0.9883 - val_loss: 1.1980 - val_accuracy: 0.7465 - val_precision_6: 0.7464 - val_recall_6: 0.7254\n",
      "Epoch 271/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0383 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0366 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.994 - ETA: 0s - loss: 0.0459 - accuracy: 0.9883 - precision_6: 0.9883 - recall_6: 0.988 - ETA: 0s - loss: 0.0551 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0489 - accuracy: 0.9870 - precision_6: 0.9870 - recall_6: 0.987 - 0s 1ms/sample - loss: 0.0477 - accuracy: 0.9883 - precision_6: 0.9883 - recall_6: 0.9883 - val_loss: 1.2184 - val_accuracy: 0.7183 - val_precision_6: 0.7353 - val_recall_6: 0.7042\n",
      "Epoch 272/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0627 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.1323 - accuracy: 0.9500 - precision_6: 0.9500 - recall_6: 0.950 - ETA: 0s - loss: 0.1736 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.2530 - accuracy: 0.9236 - precision_6: 0.9333 - recall_6: 0.923 - ETA: 0s - loss: 0.3395 - accuracy: 0.9119 - precision_6: 0.9198 - recall_6: 0.911 - ETA: 0s - loss: 0.4590 - accuracy: 0.8942 - precision_6: 0.9095 - recall_6: 0.894 - 0s 1ms/sample - loss: 0.4522 - accuracy: 0.8944 - precision_6: 0.9115 - recall_6: 0.8944 - val_loss: 1.3685 - val_accuracy: 0.6972 - val_precision_6: 0.7029 - val_recall_6: 0.6831\n",
      "Epoch 273/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 0.9062 - precision_6: 0.9355 - recall_6: 0.906 - ETA: 0s - loss: 0.2423 - accuracy: 0.9375 - precision_6: 0.9474 - recall_6: 0.937 - ETA: 0s - loss: 0.3000 - accuracy: 0.9062 - precision_6: 0.9177 - recall_6: 0.906 - ETA: 0s - loss: 0.3043 - accuracy: 0.8929 - precision_6: 0.9005 - recall_6: 0.888 - ETA: 0s - loss: 0.3429 - accuracy: 0.8889 - precision_6: 0.8979 - recall_6: 0.885 - ETA: 0s - loss: 0.4089 - accuracy: 0.8750 - precision_6: 0.8844 - recall_6: 0.869 - ETA: 0s - loss: 0.4563 - accuracy: 0.8654 - precision_6: 0.8775 - recall_6: 0.860 - 0s 1ms/sample - loss: 0.4462 - accuracy: 0.8685 - precision_6: 0.8804 - recall_6: 0.8638 - val_loss: 1.3902 - val_accuracy: 0.6620 - val_precision_6: 0.6838 - val_recall_6: 0.6549\n",
      "Epoch 274/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.3138 - accuracy: 0.9062 - precision_6: 0.9043 - recall_6: 0.885 - ETA: 0s - loss: 0.3774 - accuracy: 0.8813 - precision_6: 0.8854 - recall_6: 0.868 - ETA: 0s - loss: 0.4240 - accuracy: 0.8482 - precision_6: 0.8744 - recall_6: 0.839 - ETA: 0s - loss: 0.4250 - accuracy: 0.8542 - precision_6: 0.8773 - recall_6: 0.843 - ETA: 0s - loss: 0.4509 - accuracy: 0.8438 - precision_6: 0.8669 - recall_6: 0.832 - ETA: 0s - loss: 0.4447 - accuracy: 0.8510 - precision_6: 0.8706 - recall_6: 0.841 - 0s 1ms/sample - loss: 0.4344 - accuracy: 0.8545 - precision_6: 0.8738 - recall_6: 0.8451 - val_loss: 1.4452 - val_accuracy: 0.6408 - val_precision_6: 0.6594 - val_recall_6: 0.6408\n",
      "Epoch 275/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.9062 - precision_6: 0.9062 - recall_6: 0.906 - ETA: 0s - loss: 0.5090 - accuracy: 0.8229 - precision_6: 0.8404 - recall_6: 0.822 - ETA: 0s - loss: 0.4092 - accuracy: 0.8562 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.3603 - accuracy: 0.8750 - precision_6: 0.8858 - recall_6: 0.866 - ETA: 0s - loss: 0.3789 - accuracy: 0.8681 - precision_6: 0.8786 - recall_6: 0.854 - ETA: 0s - loss: 0.4304 - accuracy: 0.8551 - precision_6: 0.8659 - recall_6: 0.843 - ETA: 0s - loss: 0.4201 - accuracy: 0.8558 - precision_6: 0.8691 - recall_6: 0.846 - 0s 1ms/sample - loss: 0.4113 - accuracy: 0.8592 - precision_6: 0.8723 - recall_6: 0.8498 - val_loss: 1.2644 - val_accuracy: 0.6972 - val_precision_6: 0.6917 - val_recall_6: 0.6479\n",
      "Epoch 276/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.8125 - precision_6: 0.8387 - recall_6: 0.812 - ETA: 0s - loss: 0.3822 - accuracy: 0.8750 - precision_6: 0.8817 - recall_6: 0.854 - ETA: 0s - loss: 0.3825 - accuracy: 0.8562 - precision_6: 0.8710 - recall_6: 0.843 - ETA: 0s - loss: 0.4207 - accuracy: 0.8259 - precision_6: 0.8465 - recall_6: 0.812 - ETA: 0s - loss: 0.5046 - accuracy: 0.8160 - precision_6: 0.8400 - recall_6: 0.802 - ETA: 0s - loss: 0.4734 - accuracy: 0.8307 - precision_6: 0.8521 - recall_6: 0.809 - 0s 986us/sample - loss: 0.4497 - accuracy: 0.8404 - precision_6: 0.8593 - recall_6: 0.8169 - val_loss: 1.3473 - val_accuracy: 0.6972 - val_precision_6: 0.7164 - val_recall_6: 0.6761\n",
      "Epoch 277/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.8125 - precision_6: 0.8333 - recall_6: 0.781 - ETA: 0s - loss: 0.3357 - accuracy: 0.8646 - precision_6: 0.8817 - recall_6: 0.854 - ETA: 0s - loss: 0.3409 - accuracy: 0.8687 - precision_6: 0.8846 - recall_6: 0.862 - ETA: 0s - loss: 0.3268 - accuracy: 0.8795 - precision_6: 0.8950 - recall_6: 0.875 - ETA: 0s - loss: 0.3355 - accuracy: 0.8785 - precision_6: 0.9000 - recall_6: 0.875 - ETA: 0s - loss: 0.3305 - accuracy: 0.8807 - precision_6: 0.9006 - recall_6: 0.875 - ETA: 0s - loss: 0.3296 - accuracy: 0.8774 - precision_6: 0.8963 - recall_6: 0.872 - 0s 1ms/sample - loss: 0.3220 - accuracy: 0.8803 - precision_6: 0.8988 - recall_6: 0.8756 - val_loss: 1.3567 - val_accuracy: 0.7042 - val_precision_6: 0.7050 - val_recall_6: 0.6901\n",
      "Epoch 278/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1628 - accuracy: 0.9479 - precision_6: 0.9579 - recall_6: 0.947 - ETA: 0s - loss: 0.1677 - accuracy: 0.9438 - precision_6: 0.9557 - recall_6: 0.943 - ETA: 0s - loss: 0.1705 - accuracy: 0.9375 - precision_6: 0.9502 - recall_6: 0.937 - ETA: 0s - loss: 0.1933 - accuracy: 0.9340 - precision_6: 0.9470 - recall_6: 0.930 - ETA: 0s - loss: 0.1913 - accuracy: 0.9323 - precision_6: 0.9469 - recall_6: 0.929 - 0s 1ms/sample - loss: 0.1821 - accuracy: 0.9366 - precision_6: 0.9499 - recall_6: 0.9343 - val_loss: 1.3018 - val_accuracy: 0.7042 - val_precision_6: 0.7122 - val_recall_6: 0.6972\n",
      "Epoch 279/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9375 - precision_6: 0.9375 - recall_6: 0.937 - ETA: 0s - loss: 0.1719 - accuracy: 0.9297 - precision_6: 0.9297 - recall_6: 0.929 - ETA: 0s - loss: 0.1629 - accuracy: 0.9375 - precision_6: 0.9372 - recall_6: 0.932 - ETA: 0s - loss: 0.1470 - accuracy: 0.9453 - precision_6: 0.9488 - recall_6: 0.941 - ETA: 0s - loss: 0.1611 - accuracy: 0.9344 - precision_6: 0.9429 - recall_6: 0.928 - ETA: 0s - loss: 0.1556 - accuracy: 0.9349 - precision_6: 0.9444 - recall_6: 0.929 - 0s 1ms/sample - loss: 0.1542 - accuracy: 0.9343 - precision_6: 0.9429 - recall_6: 0.9296 - val_loss: 1.1590 - val_accuracy: 0.7042 - val_precision_6: 0.7226 - val_recall_6: 0.6972\n",
      "Epoch 280/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.1543 - accuracy: 0.9297 - precision_6: 0.9516 - recall_6: 0.921 - ETA: 0s - loss: 0.1346 - accuracy: 0.9464 - precision_6: 0.9591 - recall_6: 0.942 - ETA: 0s - loss: 0.1389 - accuracy: 0.9514 - precision_6: 0.9645 - recall_6: 0.944 - ETA: 0s - loss: 0.1438 - accuracy: 0.9489 - precision_6: 0.9595 - recall_6: 0.943 - ETA: 0s - loss: 0.1544 - accuracy: 0.9447 - precision_6: 0.9537 - recall_6: 0.939 - 0s 995us/sample - loss: 0.1509 - accuracy: 0.9460 - precision_6: 0.9548 - recall_6: 0.9413 - val_loss: 1.3025 - val_accuracy: 0.7042 - val_precision_6: 0.7050 - val_recall_6: 0.6901\n",
      "Epoch 281/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1234 - accuracy: 0.9583 - precision_6: 0.9583 - recall_6: 0.958 - ETA: 0s - loss: 0.1382 - accuracy: 0.9453 - precision_6: 0.9453 - recall_6: 0.945 - ETA: 0s - loss: 0.1328 - accuracy: 0.9479 - precision_6: 0.9479 - recall_6: 0.947 - ETA: 0s - loss: 0.1198 - accuracy: 0.9609 - precision_6: 0.9606 - recall_6: 0.953 - ETA: 0s - loss: 0.1327 - accuracy: 0.9563 - precision_6: 0.9590 - recall_6: 0.950 - ETA: 0s - loss: 0.1254 - accuracy: 0.9609 - precision_6: 0.9633 - recall_6: 0.955 - 0s 1ms/sample - loss: 0.1196 - accuracy: 0.9624 - precision_6: 0.9668 - recall_6: 0.9577 - val_loss: 1.2386 - val_accuracy: 0.6901 - val_precision_6: 0.6957 - val_recall_6: 0.6761\n",
      "Epoch 282/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0594 - accuracy: 0.9896 - precision_6: 0.9895 - recall_6: 0.979 - ETA: 0s - loss: 0.0760 - accuracy: 0.9875 - precision_6: 0.9873 - recall_6: 0.975 - ETA: 0s - loss: 0.0737 - accuracy: 0.9821 - precision_6: 0.9820 - recall_6: 0.973 - ETA: 0s - loss: 0.0779 - accuracy: 0.9861 - precision_6: 0.9860 - recall_6: 0.975 - ETA: 0s - loss: 0.0830 - accuracy: 0.9830 - precision_6: 0.9828 - recall_6: 0.974 - ETA: 0s - loss: 0.0794 - accuracy: 0.9832 - precision_6: 0.9854 - recall_6: 0.976 - 0s 1ms/sample - loss: 0.0777 - accuracy: 0.9836 - precision_6: 0.9858 - recall_6: 0.9765 - val_loss: 1.1116 - val_accuracy: 0.7324 - val_precision_6: 0.7481 - val_recall_6: 0.7113\n",
      "Epoch 283/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.1087 - accuracy: 0.9453 - precision_6: 0.9453 - recall_6: 0.945 - ETA: 0s - loss: 0.1057 - accuracy: 0.9583 - precision_6: 0.9583 - recall_6: 0.958 - ETA: 0s - loss: 0.0911 - accuracy: 0.9688 - precision_6: 0.9686 - recall_6: 0.964 - ETA: 0s - loss: 0.0882 - accuracy: 0.9750 - precision_6: 0.9749 - recall_6: 0.971 - ETA: 0s - loss: 0.0830 - accuracy: 0.9792 - precision_6: 0.9791 - recall_6: 0.976 - 0s 993us/sample - loss: 0.0822 - accuracy: 0.9765 - precision_6: 0.9788 - recall_6: 0.9742 - val_loss: 1.1125 - val_accuracy: 0.7465 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 284/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9688 - precision_6: 1.0000 - recall_6: 0.968 - ETA: 0s - loss: 0.0500 - accuracy: 0.9766 - precision_6: 0.9843 - recall_6: 0.976 - ETA: 0s - loss: 0.0522 - accuracy: 0.9844 - precision_6: 0.9895 - recall_6: 0.984 - ETA: 0s - loss: 0.0526 - accuracy: 0.9883 - precision_6: 0.9921 - recall_6: 0.984 - ETA: 0s - loss: 0.0534 - accuracy: 0.9906 - precision_6: 0.9937 - recall_6: 0.987 - ETA: 0s - loss: 0.0508 - accuracy: 0.9922 - precision_6: 0.9948 - recall_6: 0.989 - 0s 1ms/sample - loss: 0.0500 - accuracy: 0.9906 - precision_6: 0.9953 - recall_6: 0.9883 - val_loss: 1.0810 - val_accuracy: 0.7535 - val_precision_6: 0.7609 - val_recall_6: 0.7394\n",
      "Epoch 285/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0312 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0452 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0432 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0429 - accuracy: 0.9937 - precision_6: 0.9937 - recall_6: 0.993 - ETA: 0s - loss: 0.0408 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.994 - 0s 979us/sample - loss: 0.0404 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.1620 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 286/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0407 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0358 - accuracy: 0.9911 - precision_6: 0.9911 - recall_6: 0.991 - ETA: 0s - loss: 0.0367 - accuracy: 0.9931 - precision_6: 0.9931 - recall_6: 0.993 - ETA: 0s - loss: 0.0367 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.994 - 0s 955us/sample - loss: 0.0361 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.1688 - val_accuracy: 0.7465 - val_precision_6: 0.7626 - val_recall_6: 0.7465\n",
      "Epoch 287/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0210 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0360 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0341 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0402 - accuracy: 0.9906 - precision_6: 0.9906 - recall_6: 0.990 - ETA: 0s - loss: 0.0382 - accuracy: 0.9928 - precision_6: 0.9928 - recall_6: 0.992 - 0s 972us/sample - loss: 0.0373 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.1759 - val_accuracy: 0.7394 - val_precision_6: 0.7500 - val_recall_6: 0.7394\n",
      "Epoch 288/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0343 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0302 - accuracy: 0.9911 - precision_6: 0.9911 - recall_6: 0.991 - ETA: 0s - loss: 0.0313 - accuracy: 0.9937 - precision_6: 0.9937 - recall_6: 0.993 - ETA: 0s - loss: 0.0308 - accuracy: 0.9952 - precision_6: 0.9952 - recall_6: 0.995 - 0s 1ms/sample - loss: 0.0301 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.1986 - val_accuracy: 0.7324 - val_precision_6: 0.7482 - val_recall_6: 0.7324\n",
      "Epoch 289/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0172 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0322 - accuracy: 0.9875 - precision_6: 0.9875 - recall_6: 0.987 - ETA: 0s - loss: 0.0276 - accuracy: 0.9911 - precision_6: 0.9911 - recall_6: 0.991 - ETA: 0s - loss: 0.0283 - accuracy: 0.9931 - precision_6: 0.9931 - recall_6: 0.993 - ETA: 0s - loss: 0.0290 - accuracy: 0.9943 - precision_6: 0.9943 - recall_6: 0.994 - ETA: 0s - loss: 0.0283 - accuracy: 0.9952 - precision_6: 0.9952 - recall_6: 0.995 - 0s 1ms/sample - loss: 0.0277 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.2025 - val_accuracy: 0.7465 - val_precision_6: 0.7500 - val_recall_6: 0.7394\n",
      "Epoch 290/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0156 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0298 - accuracy: 0.9875 - precision_6: 0.9875 - recall_6: 0.987 - ETA: 0s - loss: 0.0256 - accuracy: 0.9911 - precision_6: 0.9911 - recall_6: 0.991 - ETA: 0s - loss: 0.0262 - accuracy: 0.9931 - precision_6: 0.9931 - recall_6: 0.993 - ETA: 0s - loss: 0.0255 - accuracy: 0.9943 - precision_6: 0.9943 - recall_6: 0.994 - ETA: 0s - loss: 0.0281 - accuracy: 0.9928 - precision_6: 0.9928 - recall_6: 0.992 - 0s 1ms/sample - loss: 0.0275 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.1855 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0159 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0273 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0260 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0335 - accuracy: 0.9906 - precision_6: 0.9906 - recall_6: 0.990 - ETA: 0s - loss: 0.0312 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - 0s 1ms/sample - loss: 0.0312 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.2041 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 292/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0143 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0254 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0235 - accuracy: 0.9931 - precision_6: 0.9931 - recall_6: 0.993 - ETA: 0s - loss: 0.0260 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - 0s 962us/sample - loss: 0.0254 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.1978 - val_accuracy: 0.7606 - val_precision_6: 0.7606 - val_recall_6: 0.7606\n",
      "Epoch 293/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0445 - accuracy: 0.9844 - precision_6: 0.9844 - recall_6: 0.984 - ETA: 0s - loss: 0.0332 - accuracy: 0.9911 - precision_6: 0.9911 - recall_6: 0.991 - ETA: 0s - loss: 0.0394 - accuracy: 0.9906 - precision_6: 0.9906 - recall_6: 0.990 - ETA: 0s - loss: 0.0355 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - 0s 984us/sample - loss: 0.0354 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.1566 - val_accuracy: 0.7606 - val_precision_6: 0.7606 - val_recall_6: 0.7606\n",
      "Epoch 294/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0358 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0561 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0577 - accuracy: 0.9805 - precision_6: 0.9805 - recall_6: 0.980 - ETA: 0s - loss: 0.0593 - accuracy: 0.9812 - precision_6: 0.9812 - recall_6: 0.981 - ETA: 0s - loss: 0.0555 - accuracy: 0.9818 - precision_6: 0.9818 - recall_6: 0.981 - 0s 1ms/sample - loss: 0.0544 - accuracy: 0.9812 - precision_6: 0.9812 - recall_6: 0.9812 - val_loss: 1.1746 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 295/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0825 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0726 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0749 - accuracy: 0.9688 - precision_6: 0.9688 - recall_6: 0.968 - ETA: 0s - loss: 0.0722 - accuracy: 0.9722 - precision_6: 0.9722 - recall_6: 0.972 - ETA: 0s - loss: 0.0681 - accuracy: 0.9744 - precision_6: 0.9744 - recall_6: 0.974 - ETA: 0s - loss: 0.0652 - accuracy: 0.9760 - precision_6: 0.9760 - recall_6: 0.976 - 0s 1ms/sample - loss: 0.0637 - accuracy: 0.9765 - precision_6: 0.9765 - recall_6: 0.9765 - val_loss: 1.2508 - val_accuracy: 0.7254 - val_precision_6: 0.7234 - val_recall_6: 0.7183\n",
      "Epoch 296/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0686 - accuracy: 0.9792 - precision_6: 0.9792 - recall_6: 0.979 - ETA: 0s - loss: 0.0575 - accuracy: 0.9812 - precision_6: 0.9812 - recall_6: 0.981 - ETA: 0s - loss: 0.0480 - accuracy: 0.9821 - precision_6: 0.9865 - recall_6: 0.982 - ETA: 0s - loss: 0.0446 - accuracy: 0.9826 - precision_6: 0.9861 - recall_6: 0.982 - ETA: 0s - loss: 0.0428 - accuracy: 0.9830 - precision_6: 0.9858 - recall_6: 0.983 - ETA: 0s - loss: 0.0431 - accuracy: 0.9832 - precision_6: 0.9855 - recall_6: 0.983 - 0s 1ms/sample - loss: 0.0421 - accuracy: 0.9836 - precision_6: 0.9859 - recall_6: 0.9836 - val_loss: 1.2116 - val_accuracy: 0.7465 - val_precision_6: 0.7500 - val_recall_6: 0.7394\n",
      "Epoch 297/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0180 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0230 - accuracy: 0.9937 - precision_6: 0.9937 - recall_6: 0.993 - ETA: 0s - loss: 0.0323 - accuracy: 0.9911 - precision_6: 0.9910 - recall_6: 0.986 - ETA: 0s - loss: 0.0293 - accuracy: 0.9931 - precision_6: 0.9930 - recall_6: 0.989 - ETA: 0s - loss: 0.0323 - accuracy: 0.9915 - precision_6: 0.9915 - recall_6: 0.988 - ETA: 0s - loss: 0.0319 - accuracy: 0.9928 - precision_6: 0.9928 - recall_6: 0.990 - 0s 1ms/sample - loss: 0.0312 - accuracy: 0.9930 - precision_6: 0.9929 - recall_6: 0.9906 - val_loss: 1.2646 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 298/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0206 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0204 - accuracy: 0.9955 - precision_6: 0.9955 - recall_6: 0.995 - ETA: 0s - loss: 0.0244 - accuracy: 0.9931 - precision_6: 0.9931 - recall_6: 0.993 - ETA: 0s - loss: 0.0243 - accuracy: 0.9943 - precision_6: 0.9943 - recall_6: 0.994 - ETA: 0s - loss: 0.0261 - accuracy: 0.9928 - precision_6: 0.9928 - recall_6: 0.992 - 0s 1ms/sample - loss: 0.0255 - accuracy: 0.9930 - precision_6: 0.9930 - recall_6: 0.9930 - val_loss: 1.2221 - val_accuracy: 0.7606 - val_precision_6: 0.7660 - val_recall_6: 0.7606\n",
      "Epoch 299/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0295 - accuracy: 0.9896 - precision_6: 0.9896 - recall_6: 0.989 - ETA: 0s - loss: 0.0292 - accuracy: 0.9937 - precision_6: 0.9937 - recall_6: 0.987 - ETA: 0s - loss: 0.0236 - accuracy: 0.9955 - precision_6: 0.9955 - recall_6: 0.991 - ETA: 0s - loss: 0.0228 - accuracy: 0.9965 - precision_6: 0.9965 - recall_6: 0.993 - ETA: 0s - loss: 0.0258 - accuracy: 0.9943 - precision_6: 0.9943 - recall_6: 0.991 - ETA: 0s - loss: 0.0253 - accuracy: 0.9952 - precision_6: 0.9952 - recall_6: 0.992 - 0s 1ms/sample - loss: 0.0247 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9930 - val_loss: 1.1997 - val_accuracy: 0.7676 - val_precision_6: 0.7730 - val_recall_6: 0.7676\n",
      "Epoch 300/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0126 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0189 - accuracy: 0.9937 - precision_6: 0.9937 - recall_6: 0.993 - ETA: 0s - loss: 0.0169 - accuracy: 0.9961 - precision_6: 0.9961 - recall_6: 0.996 - ETA: 0s - loss: 0.0162 - accuracy: 0.9969 - precision_6: 0.9969 - recall_6: 0.996 - ETA: 0s - loss: 0.0197 - accuracy: 0.9948 - precision_6: 0.9948 - recall_6: 0.994 - 0s 1ms/sample - loss: 0.0191 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.2628 - val_accuracy: 0.7465 - val_precision_6: 0.7465 - val_recall_6: 0.7465\n",
      "Epoch 301/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0150 - accuracy: 0.9922 - precision_6: 0.9922 - recall_6: 0.992 - ETA: 0s - loss: 0.0143 - accuracy: 0.9955 - precision_6: 0.9955 - recall_6: 0.995 - ETA: 0s - loss: 0.0135 - accuracy: 0.9965 - precision_6: 0.9965 - recall_6: 0.996 - ETA: 0s - loss: 0.0181 - accuracy: 0.9943 - precision_6: 0.9943 - recall_6: 0.994 - 0s 967us/sample - loss: 0.0178 - accuracy: 0.9953 - precision_6: 0.9953 - recall_6: 0.9953 - val_loss: 1.2879 - val_accuracy: 0.7394 - val_precision_6: 0.7394 - val_recall_6: 0.7394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0100 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0166 - accuracy: 0.9937 - precision_6: 1.0000 - recall_6: 0.993 - ETA: 0s - loss: 0.0140 - accuracy: 0.9955 - precision_6: 1.0000 - recall_6: 0.995 - ETA: 0s - loss: 0.0133 - accuracy: 0.9965 - precision_6: 1.0000 - recall_6: 0.996 - ETA: 0s - loss: 0.0132 - accuracy: 0.9972 - precision_6: 1.0000 - recall_6: 0.997 - 0s 1ms/sample - loss: 0.0143 - accuracy: 0.9977 - precision_6: 1.0000 - recall_6: 0.9977 - val_loss: 1.3092 - val_accuracy: 0.7183 - val_precision_6: 0.7183 - val_recall_6: 0.7183\n",
      "Epoch 303/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0086 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0155 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0130 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0124 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0122 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0122 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2652 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 304/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0078 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0147 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0122 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0116 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0118 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0118 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0116 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.7465 - val_precision_6: 0.7482 - val_recall_6: 0.7324\n",
      "Epoch 305/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0074 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0142 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0119 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0113 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0110 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0110 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2695 - val_accuracy: 0.7465 - val_precision_6: 0.7482 - val_recall_6: 0.7324\n",
      "Epoch 306/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0117 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0115 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0108 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0105 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 0.0104 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2672 - val_accuracy: 0.7465 - val_precision_6: 0.7500 - val_recall_6: 0.7394\n",
      "Epoch 307/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0067 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0134 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0111 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0104 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0103 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0102 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0100 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2673 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 308/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0064 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0130 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0108 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0103 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0099 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 984us/sample - loss: 0.0097 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 309/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0107 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0104 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0098 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0094 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 0.0093 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.7535 - val_precision_6: 0.7554 - val_recall_6: 0.7394\n",
      "Epoch 310/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0105 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0112 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0094 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0092 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 967us/sample - loss: 0.0090 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2829 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 311/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0103 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0103 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0093 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0089 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0085 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 0.0084 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.2908 - val_accuracy: 0.7465 - val_precision_6: 0.7554 - val_recall_6: 0.7394\n",
      "Epoch 312/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0098 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0081 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0080 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0078 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0077 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3019 - val_accuracy: 0.7465 - val_precision_6: 0.7500 - val_recall_6: 0.7394\n",
      "Epoch 313/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0078 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0073 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0073 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0070 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 0.0070 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.7465 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 314/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0077 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0074 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0067 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 0.0067 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 315/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0071 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0065 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0064 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0065 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 0.0063 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 316/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0060 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0063 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0061 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 317/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0066 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0059 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0060 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0059 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 318/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0064 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0057 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0057 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 319/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0055 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 320/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0045 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0060 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3519 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 321/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0052 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3569 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 322/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1000us/sample - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3616 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 323/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0050 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0051 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0048 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 325/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0052 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 977us/sample - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3725 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 326/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 0.0045 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 327/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0045 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0045 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0044 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 328/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0044 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 329/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3801 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 330/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0044 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3816 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 331/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0044 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3835 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 332/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3857 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 333/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0042 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3883 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 334/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3912 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 335/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3943 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 336/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 337/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4007 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 338/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 977us/sample - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 339/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 969us/sample - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4072 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 340/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 341/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0035 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4136 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 342/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 991us/sample - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4168 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 343/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 344/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0033 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 984us/sample - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4231 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 969us/sample - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 346/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4293 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 347/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 951us/sample - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4324 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 348/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4355 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 349/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4386 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 350/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4417 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 351/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 352/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 353/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 979us/sample - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4512 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 354/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 979us/sample - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4545 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 355/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 356/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4615 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 357/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 358/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0025 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.7394 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 359/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4711 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 360/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4737 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 361/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0024 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 977us/sample - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 362/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4802 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 363/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 364/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 365/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 995us/sample - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4888 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 366/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 995us/sample - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 367/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4965 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 369/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.4986 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 370/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5011 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 371/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5037 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 372/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5061 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 373/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 979us/sample - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5089 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 374/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 977us/sample - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5109 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 375/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 981us/sample - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5153 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 376/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 377/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 378/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.7394 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 379/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5233 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 380/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 991us/sample - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5251 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 381/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.7324 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 382/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5296 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 383/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 970us/sample - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5325 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 384/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5342 - val_accuracy: 0.7324 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 385/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 386/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5391 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 387/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 979us/sample - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5408 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 388/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1000us/sample - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 389/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5455 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5473 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 391/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 939us/sample - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 392/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 393/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5543 - val_accuracy: 0.7465 - val_precision_6: 0.7429 - val_recall_6: 0.7324\n",
      "Epoch 394/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 969us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 395/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5580 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 396/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5613 - val_accuracy: 0.7394 - val_precision_6: 0.7376 - val_recall_6: 0.7324\n",
      "Epoch 397/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5632 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 398/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 974us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5650 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 399/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 400/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 401/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5715 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 402/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5735 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 403/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 404/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 405/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 406/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 407/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 408/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 409/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 410/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5911 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 411/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5933 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5955 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 413/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5976 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 414/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 979us/sample - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.5998 - val_accuracy: 0.7465 - val_precision_6: 0.7447 - val_recall_6: 0.7394\n",
      "Epoch 415/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.9521e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6019 - val_accuracy: 0.7535 - val_precision_6: 0.7518 - val_recall_6: 0.7465\n",
      "Epoch 416/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6041 - val_accuracy: 0.7535 - val_precision_6: 0.7518 - val_recall_6: 0.7465\n",
      "Epoch 417/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.9287e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 984us/sample - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6062 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 418/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.9708e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 9.8142e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 995us/sample - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 419/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.8685e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 9.5595e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.5061e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.8474e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - 0s 1ms/sample - loss: 9.9776e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 420/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.7615e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 9.4535e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3994e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.7369e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - 0s 1ms/sample - loss: 9.8666e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6126 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 421/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.9614e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.6585e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 9.3500e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.2950e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.6283e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.9232e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.7570e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 422/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.8496e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.5535e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000    - ETA: 0s - loss: 9.2468e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.1914e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.5211e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.8137e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.6494e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6168 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 423/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.7379e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.4581e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.9485e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.1486e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0918e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.2779e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.5443e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6189 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 424/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.6287e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3458e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.8320e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0443e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9879e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3104e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.5974e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.4370e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 425/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.5214e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.2487e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.7261e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9466e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3670e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0724e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.3350e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6230 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 426/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.4136e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.1592e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.6258e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.8538e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.7955e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.1102e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3918e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.2350e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6251 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 427/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.3088e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0502e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.5134e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.7536e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.6957e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.8739e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 9.1321e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 428/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.2055e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9607e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.4143e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9181e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0634e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.7792e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 981us/sample - loss: 9.0356e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6292 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 429/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.1014e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.8806e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3226e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.5756e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.5151e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.8190e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 8.9415e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 430/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 9.0000e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.4924e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.4800e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.8691e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9924e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 8.8427e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 431/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.9010e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.3849e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.3853e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.3260e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.4963e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 946us/sample - loss: 8.7463e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6355 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 8.8021e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.2841e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2953e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2360e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.4047e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 8.6527e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 433/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.7048e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.1875e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2080e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.1483e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.4406e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 8.5613e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6394 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 434/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.6075e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 9.0931e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.7134e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0627e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2273e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 8.4713e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6415 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 435/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.5121e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.9970e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0368e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.9763e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.1396e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 8.3819e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6434 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 436/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.4172e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2358e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.5319e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.8934e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0546e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 8.2947e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6456 - val_accuracy: 0.7535 - val_precision_6: 0.7571 - val_recall_6: 0.7465\n",
      "Epoch 437/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.3241e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.1442e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.5444e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0922e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2232e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.3448e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 8.2066e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6475 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 438/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.2315e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.7180e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.7877e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.7266e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0039e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 948us/sample - loss: 8.1212e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 439/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.1402e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.6293e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.7075e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.6462e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.9206e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.1726e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 974us/sample - loss: 8.0375e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6514 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 440/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 8.0490e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.9068e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.1846e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5697e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.8405e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 7.9561e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6535 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 441/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.9594e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.4504e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5488e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4872e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.6406e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 7.8711e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6557 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 442/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.8712e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.3693e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4740e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.8038e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5636e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 7.7925e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 443/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.7823e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.2938e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4052e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3412e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4896e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 967us/sample - loss: 7.7161e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6593 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.6948e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5898e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.9502e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3259e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2625e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5219e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.7624e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 7.6345e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6616 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 445/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.6094e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4965e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.8595e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2452e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1833e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4407e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 7.5534e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6637 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 446/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.5247e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 8.0293e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.6876e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3665e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4850e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2561e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 7.4775e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 447/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.4392e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3584e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.7079e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1041e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0411e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2926e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5274e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 7.4036e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6674 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 448/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.3544e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.8666e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0278e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9657e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2151e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4482e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 7.3259e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 449/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.2711e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1987e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.5445e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9569e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8949e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1420e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3736e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 7.2525e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6711 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 450/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.1878e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1356e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4742e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0738e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0722e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 7.1814e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6732 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 451/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.1051e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.6309e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8179e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.7559e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9977e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2251e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 7.1066e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6754 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 452/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 7.0232e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9756e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.2283e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6858e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9257e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1516e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 7.0344e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 453/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.9412e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.4756e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1569e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6192e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8564e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 6.9644e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6792 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 454/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.8593e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8298e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0806e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5500e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6856e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 6.8931e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6811 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 455/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.7775e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.3197e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0088e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.7156e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8236e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9376e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 6.8242e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6829 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 456/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.6955e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6899e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.0173e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4780e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4183e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6490e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8682e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 6.7560e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6848 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 457/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.6132e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6213e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.9462e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4132e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3538e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5824e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8000e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 6.6891e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.7535 - val_precision_6: 0.7589 - val_recall_6: 0.7535\n",
      "Epoch 458/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.5301e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5576e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 7.1028e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8009e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5159e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6204e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4223e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 6.6233e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6886 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 459/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.4463e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4817e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8035e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2842e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2258e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4501e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 6.5559e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6903 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 460/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.3615e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4138e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6599e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3822e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4853e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2925e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 6.4906e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6924 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 461/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.2746e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3467e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6651e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3176e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3213e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5329e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 6.4266e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 462/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.1859e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.8175e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0998e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3577e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.1693e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 965us/sample - loss: 6.3643e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 463/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.0942e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.7372e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0323e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2894e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.4019e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 6.2979e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 464/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 6.0007e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6707e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9726e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9176e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0443e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 6.2369e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.9072e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.6095e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9181e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.1683e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9870e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 951us/sample - loss: 6.1778e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 466/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.8144e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.5331e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2621e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7993e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9239e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 948us/sample - loss: 6.1134e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7038 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 467/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.7285e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9338e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.1921e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9385e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9465e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 967us/sample - loss: 6.0505e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 468/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.6524e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3908e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7307e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9771e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0896e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 960us/sample - loss: 5.9911e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7079 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 469/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.5831e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.3277e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0693e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.8210e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.8297e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0306e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 5.9331e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7094 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 470/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.5185e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7647e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0749e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7671e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7749e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9737e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 5.8772e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7117 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 471/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.4563e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.2019e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9487e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5142e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.6351e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 948us/sample - loss: 5.8178e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7138 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 472/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.3970e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.1440e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5102e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4615e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5815e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 958us/sample - loss: 5.7627e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7153 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 473/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.3392e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0913e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4615e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.6939e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5299e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 5.7093e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 474/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.2820e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 6.0243e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7771e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3560e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5515e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7442e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 5.6517e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7196 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 475/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.2267e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9725e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.7255e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4919e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5831e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4232e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 5.5999e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7208 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 476/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.1725e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.9254e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.6790e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4451e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4518e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 967us/sample - loss: 5.5497e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7228 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 477/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.1182e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.8634e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2563e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4780e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3210e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 5.4942e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7251 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 478/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.0658e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3224e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.6155e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3336e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3418e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 969us/sample - loss: 5.4392e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7270 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 479/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 5.0146e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2713e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5615e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1505e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1043e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2905e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4752e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 5.3873e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7287 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 480/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.9637e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2214e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5088e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1017e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3181e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1669e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 5.3361e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7306 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 481/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.9140e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1734e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4577e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1826e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2680e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1184e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 998us/sample - loss: 5.2862e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7320 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 482/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.8651e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5858e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3528e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1355e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2194e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0711e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 5.2373e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7341 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 483/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.8162e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.5312e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3003e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0855e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0933e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2717e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 988us/sample - loss: 5.1874e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7354 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 484/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.7686e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.4839e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2539e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8708e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0471e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2234e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 5.1399e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 485/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.7211e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9805e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2550e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8670e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0711e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9277e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 5.0898e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7392 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 486/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.6750e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3762e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1513e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9431e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0234e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8816e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 995us/sample - loss: 5.0422e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.7535 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.6292e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.3282e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1044e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7332e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8366e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 962us/sample - loss: 4.9959e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 488/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.5843e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2854e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0620e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8557e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9333e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7937e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 991us/sample - loss: 4.9513e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7444 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 489/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.5392e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.2276e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0081e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6447e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8127e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9818e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 969us/sample - loss: 4.9025e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 490/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.4953e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7568e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0180e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7624e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7691e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9368e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 977us/sample - loss: 4.8582e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 491/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.4524e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.1431e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6094e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7978e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6622e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 951us/sample - loss: 4.8157e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 492/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.4088e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0867e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8717e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5180e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6158e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 951us/sample - loss: 4.7682e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 493/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.3661e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0480e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8322e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4794e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6405e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.8035e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 974us/sample - loss: 4.7272e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7519 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 494/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.3253e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 5.0109e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4890e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4435e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5374e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 953us/sample - loss: 4.6867e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7537 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 495/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.2835e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9606e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7469e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.3997e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5567e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7161e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 986us/sample - loss: 4.6413e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7567 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 496/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.2422e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.9040e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6955e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.3545e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4481e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 967us/sample - loss: 4.5953e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7607 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 497/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.2016e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4623e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7071e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4651e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5356e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4084e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 1ms/sample - loss: 4.5544e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7591 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 498/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.1629e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4322e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.6713e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4282e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4320e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5874e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 993us/sample - loss: 4.5147e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7615 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 499/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.1234e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7755e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5707e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.3851e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.4536e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.3282e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 972us/sample - loss: 4.4715e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7653 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n",
      "Epoch 500/500\n",
      "426/426 [==============================] - ETA: 0s - loss: 4.0839e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.7241e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.5234e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.1957e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - ETA: 0s - loss: 4.2860e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.000 - 0s 955us/sample - loss: 4.4284e-04 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.7606 - val_precision_6: 0.7643 - val_recall_6: 0.7535\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True)) \n",
    "model.add(layers.LSTM(96))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_val,y_val),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 100, 96)           135552    \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 1,120,140\n",
      "Trainable params: 1,120,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/150\n",
      "426/426 [==============================] - ETA: 1:44 - loss: 2.4852 - accuracy: 0.0938 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 48s - loss: 2.4583 - accuracy: 0.0781 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 29s - loss: 2.4397 - accuracy: 0.0729 - precision_5: 0.0000e+00 - recall_5: 0.0000e+ - ETA: 20s - loss: 2.4726 - accuracy: 0.0781 - precision_5: 0.0000e+00 - recall_5: 0.0000e+ - ETA: 14s - loss: 2.4452 - accuracy: 0.0812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+ - ETA: 7s - loss: 2.4225 - accuracy: 0.0982 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - ETA: 5s - loss: 2.4095 - accuracy: 0.1289 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 2s - loss: 2.3742 - accuracy: 0.1531 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.3635 - accuracy: 0.1536 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 11s 26ms/sample - loss: 2.3521 - accuracy: 0.1455 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.0615 - val_accuracy: 0.2113 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0264 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0805 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0909 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0586 - accuracy: 0.1750 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0767 - accuracy: 0.1652 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0760 - accuracy: 0.1528 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0533 - accuracy: 0.1676 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0645 - accuracy: 0.1587 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0714 - accuracy: 0.1573 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.1558 - val_accuracy: 0.1479 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.3603 - accuracy: 0.0938 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0878 - accuracy: 0.1146 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0590 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9864 - accuracy: 0.1510 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9755 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9734 - accuracy: 0.1771 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0278 - accuracy: 0.1733 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0525 - accuracy: 0.1731 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0554 - accuracy: 0.1737 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.2333 - val_accuracy: 0.1338 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.1974 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.1830 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0379 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0307 - accuracy: 0.2054 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0499 - accuracy: 0.2083 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0534 - accuracy: 0.2159 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0515 - accuracy: 0.2067 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0478 - accuracy: 0.2066 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.1538 - val_accuracy: 0.1972 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.2348 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0047 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9489 - accuracy: 0.2375 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9374 - accuracy: 0.2545 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9751 - accuracy: 0.2465 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9931 - accuracy: 0.2528 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0056 - accuracy: 0.2476 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0095 - accuracy: 0.2488 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.0071 - val_accuracy: 0.2042 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 6/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0768 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9537 - accuracy: 0.2083 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9576 - accuracy: 0.2000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9488 - accuracy: 0.2292 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9502 - accuracy: 0.2227 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9525 - accuracy: 0.2281 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9598 - accuracy: 0.2161 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.9667 - accuracy: 0.2042 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8873 - val_accuracy: 0.2535 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 7/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8818 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8551 - accuracy: 0.2083 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8283 - accuracy: 0.2625 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8501 - accuracy: 0.2545 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8610 - accuracy: 0.2617 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8817 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8990 - accuracy: 0.2670 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9299 - accuracy: 0.2524 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.9304 - accuracy: 0.2488 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8858 - val_accuracy: 0.2535 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 8/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9144 - accuracy: 0.3438 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9437 - accuracy: 0.2292 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9573 - accuracy: 0.2250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0079 - accuracy: 0.2098 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0264 - accuracy: 0.2049 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0259 - accuracy: 0.2102 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0162 - accuracy: 0.1899 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0098 - accuracy: 0.1878 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.0391 - val_accuracy: 0.1761 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 9/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8562 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.1639 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.1071 - accuracy: 0.2109 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0527 - accuracy: 0.2292 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0297 - accuracy: 0.2148 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0288 - accuracy: 0.2118 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0145 - accuracy: 0.2313 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0096 - accuracy: 0.2318 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 2.0099 - accuracy: 0.2254 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.9579 - val_accuracy: 0.1972 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 10/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0040 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9890 - accuracy: 0.1354 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9490 - accuracy: 0.1750 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9346 - accuracy: 0.1771 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9274 - accuracy: 0.1992 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9527 - accuracy: 0.2125 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9598 - accuracy: 0.2102 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9837 - accuracy: 0.1947 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.9844 - accuracy: 0.1925 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.9307 - val_accuracy: 0.2394 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 11/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9591 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9078 - accuracy: 0.3333 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8703 - accuracy: 0.3250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8703 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8720 - accuracy: 0.2743 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8802 - accuracy: 0.2756 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8853 - accuracy: 0.2596 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8789 - accuracy: 0.2653 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8762 - val_accuracy: 0.2254 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 12/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9210 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9218 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9113 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8696 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8693 - accuracy: 0.2461 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8678 - accuracy: 0.2656 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8581 - accuracy: 0.2656 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8531 - accuracy: 0.2653 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 2.1897 - val_accuracy: 0.1972 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 13/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.4734 - accuracy: 0.0938 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.1314 - accuracy: 0.1667 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0536 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0247 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 2.0101 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9873 - accuracy: 0.2102 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9813 - accuracy: 0.2091 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.9787 - accuracy: 0.2066 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8245 - val_accuracy: 0.2113 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 14/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7758 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8714 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8457 - accuracy: 0.2062 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8421 - accuracy: 0.2098 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8449 - accuracy: 0.2222 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8483 - accuracy: 0.2216 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8621 - accuracy: 0.2115 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8626 - accuracy: 0.2089 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7879 - val_accuracy: 0.2254 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 15/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7813 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7499 - accuracy: 0.1719 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8339 - accuracy: 0.2031 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8275 - accuracy: 0.2344 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8432 - accuracy: 0.2383 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8386 - accuracy: 0.2326 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8474 - accuracy: 0.2438 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8464 - accuracy: 0.2448 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8442 - accuracy: 0.2380 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8442 - accuracy: 0.2394 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.9175 - val_accuracy: 0.2324 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 2.0185 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9376 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8738 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8530 - accuracy: 0.2589 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8773 - accuracy: 0.2617 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8764 - accuracy: 0.2531 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8719 - accuracy: 0.2578 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8637 - accuracy: 0.2512 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.9468 - val_accuracy: 0.1972 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 17/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 2.0132 - accuracy: 0.0625 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9719 - accuracy: 0.1771 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8698 - accuracy: 0.2062 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8381 - accuracy: 0.2411 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8684 - accuracy: 0.2431 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8717 - accuracy: 0.2443 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8681 - accuracy: 0.2428 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8647 - accuracy: 0.2418 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8643 - val_accuracy: 0.2113 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 18/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9043 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9023 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8408 - accuracy: 0.2562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8280 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8685 - accuracy: 0.2569 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8996 - accuracy: 0.2528 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.9210 - accuracy: 0.2308 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.9200 - accuracy: 0.2300 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8464 - val_accuracy: 0.2606 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 19/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8568 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8593 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8214 - accuracy: 0.1937 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8314 - accuracy: 0.1920 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8466 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8382 - accuracy: 0.2017 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8408 - accuracy: 0.2139 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8425 - accuracy: 0.2136 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8105 - val_accuracy: 0.2254 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 20/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7927 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8465 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7997 - accuracy: 0.2375 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7996 - accuracy: 0.2277 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8163 - accuracy: 0.2266 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8081 - accuracy: 0.2438 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8016 - accuracy: 0.2472 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8106 - accuracy: 0.2356 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8107 - accuracy: 0.2347 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7685 - val_accuracy: 0.2535 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 21/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7644 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7320 - accuracy: 0.2031 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8019 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7661 - accuracy: 0.2438 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7682 - accuracy: 0.2366 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7876 - accuracy: 0.2535 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7993 - accuracy: 0.2625 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7963 - accuracy: 0.2614 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7952 - accuracy: 0.2708 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7975 - accuracy: 0.2620 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7971 - accuracy: 0.2606 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.8365 - val_accuracy: 0.2042 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 22/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9263 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8905 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8286 - accuracy: 0.2625 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8080 - accuracy: 0.2634 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8257 - accuracy: 0.2695 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8274 - accuracy: 0.2781 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8224 - accuracy: 0.2786 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8277 - accuracy: 0.2653 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7740 - val_accuracy: 0.2394 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 23/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7974 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7627 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7974 - accuracy: 0.2292 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7840 - accuracy: 0.2109 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7669 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7689 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7849 - accuracy: 0.2578 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7833 - accuracy: 0.2535 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7793 - accuracy: 0.2670 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7849 - accuracy: 0.2668 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7857 - accuracy: 0.2629 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7625 - val_accuracy: 0.2324 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 24/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7394 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8023 - accuracy: 0.1771 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7985 - accuracy: 0.1719 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7674 - accuracy: 0.2240 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7691 - accuracy: 0.2277 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7726 - accuracy: 0.2431 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7801 - accuracy: 0.2443 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7905 - accuracy: 0.2476 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7893 - accuracy: 0.2441 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7344 - val_accuracy: 0.2394 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 25/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7050 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7801 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8108 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7631 - accuracy: 0.2375 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7592 - accuracy: 0.2411 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7903 - accuracy: 0.2422 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7961 - accuracy: 0.2562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7911 - accuracy: 0.2708 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7880 - accuracy: 0.2582 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7992 - val_accuracy: 0.2535 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 26/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8859 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8539 - accuracy: 0.2396 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8305 - accuracy: 0.2344 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7909 - accuracy: 0.2688 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7879 - accuracy: 0.2552 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7830 - accuracy: 0.2366 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8000 - accuracy: 0.2431 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8106 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8058 - accuracy: 0.2448 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.8094 - accuracy: 0.2324 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7658 - val_accuracy: 0.2042 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 27/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9195 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.8065 - accuracy: 0.1250 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7809 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7614 - accuracy: 0.2625 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7664 - accuracy: 0.2552 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7749 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7697 - accuracy: 0.2656 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7644 - accuracy: 0.2604 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7756 - accuracy: 0.2418 - precision_5: 0.2000 - recall_5: 0.0023 - val_loss: 1.7428 - val_accuracy: 0.2606 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 28/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7145 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7535 - accuracy: 0.2083 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7342 - accuracy: 0.2375 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7260 - accuracy: 0.2723 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7228 - accuracy: 0.2847 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7244 - accuracy: 0.3040 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7291 - accuracy: 0.3047 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7329 - accuracy: 0.3028 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7084 - val_accuracy: 0.2465 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 29/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6869 - accuracy: 0.1875 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6969 - accuracy: 0.2708 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7076 - accuracy: 0.2656 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6886 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6969 - accuracy: 0.2708 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6952 - accuracy: 0.2902 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7072 - accuracy: 0.2891 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6986 - accuracy: 0.2986 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7068 - accuracy: 0.3000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7026 - accuracy: 0.3097 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7009 - accuracy: 0.3125 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7033 - accuracy: 0.3005 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - 1s 2ms/sample - loss: 1.7015 - accuracy: 0.3005 - precision_5: 0.5000 - recall_5: 0.0023 - val_loss: 1.7332 - val_accuracy: 0.2324 - val_precision_5: 1.0000 - val_recall_5: 0.0141\n",
      "Epoch 30/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7805 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7713 - accuracy: 0.2083 - precision_5: 1.0000 - recall_5: 0.0104        - ETA: 0s - loss: 1.7587 - accuracy: 0.2188 - precision_5: 0.5000 - recall_5: 0.007 - ETA: 0s - loss: 1.7197 - accuracy: 0.2562 - precision_5: 0.8333 - recall_5: 0.031 - ETA: 0s - loss: 1.6930 - accuracy: 0.2857 - precision_5: 0.6364 - recall_5: 0.031 - ETA: 0s - loss: 1.7327 - accuracy: 0.2969 - precision_5: 0.6429 - recall_5: 0.035 - ETA: 0s - loss: 1.7152 - accuracy: 0.3090 - precision_5: 0.6667 - recall_5: 0.041 - ETA: 0s - loss: 1.7062 - accuracy: 0.3239 - precision_5: 0.6296 - recall_5: 0.048 - ETA: 0s - loss: 1.7001 - accuracy: 0.3197 - precision_5: 0.5667 - recall_5: 0.040 - 1s 2ms/sample - loss: 1.6961 - accuracy: 0.3169 - precision_5: 0.5806 - recall_5: 0.0423 - val_loss: 1.6948 - val_accuracy: 0.3028 - val_precision_5: 1.0000 - val_recall_5: 0.0282\n",
      "Epoch 31/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.8305 - accuracy: 0.1562 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7081 - accuracy: 0.2812 - precision_5: 1.0000 - recall_5: 0.0104        - ETA: 0s - loss: 1.6758 - accuracy: 0.3359 - precision_5: 0.5000 - recall_5: 0.015 - ETA: 0s - loss: 1.6335 - accuracy: 0.3375 - precision_5: 0.7000 - recall_5: 0.043 - ETA: 0s - loss: 1.6457 - accuracy: 0.3281 - precision_5: 0.5714 - recall_5: 0.041 - ETA: 0s - loss: 1.6559 - accuracy: 0.3281 - precision_5: 0.6316 - recall_5: 0.046 - ETA: 0s - loss: 1.6736 - accuracy: 0.3375 - precision_5: 0.6786 - recall_5: 0.059 - ETA: 0s - loss: 1.6666 - accuracy: 0.3438 - precision_5: 0.6471 - recall_5: 0.057 - 1s 2ms/sample - loss: 1.6625 - accuracy: 0.3521 - precision_5: 0.6111 - recall_5: 0.0516 - val_loss: 1.6930 - val_accuracy: 0.3028 - val_precision_5: 0.4000 - val_recall_5: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6770 - accuracy: 0.3750 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7075 - accuracy: 0.2917 - precision_5: 1.0000 - recall_5: 0.0104        - ETA: 0s - loss: 1.6815 - accuracy: 0.2891 - precision_5: 0.7500 - recall_5: 0.023 - ETA: 0s - loss: 1.6839 - accuracy: 0.3000 - precision_5: 0.6667 - recall_5: 0.025 - ETA: 0s - loss: 1.6705 - accuracy: 0.3021 - precision_5: 0.6000 - recall_5: 0.031 - ETA: 0s - loss: 1.6581 - accuracy: 0.3170 - precision_5: 0.6923 - recall_5: 0.040 - ETA: 0s - loss: 1.6690 - accuracy: 0.3164 - precision_5: 0.6875 - recall_5: 0.043 - ETA: 0s - loss: 1.6566 - accuracy: 0.3333 - precision_5: 0.6818 - recall_5: 0.052 - ETA: 0s - loss: 1.6657 - accuracy: 0.3250 - precision_5: 0.6800 - recall_5: 0.053 - ETA: 0s - loss: 1.6486 - accuracy: 0.3324 - precision_5: 0.6552 - recall_5: 0.054 - ETA: 0s - loss: 1.6516 - accuracy: 0.3317 - precision_5: 0.5405 - recall_5: 0.048 - 1s 2ms/sample - loss: 1.6472 - accuracy: 0.3357 - precision_5: 0.5500 - recall_5: 0.0516 - val_loss: 1.6865 - val_accuracy: 0.2746 - val_precision_5: 0.4091 - val_recall_5: 0.0634\n",
      "Epoch 33/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6835 - accuracy: 0.2188 - precision_5: 0.3333 - recall_5: 0.031 - ETA: 0s - loss: 1.6432 - accuracy: 0.2188 - precision_5: 0.5000 - recall_5: 0.046 - ETA: 0s - loss: 1.5881 - accuracy: 0.2917 - precision_5: 0.6250 - recall_5: 0.052 - ETA: 0s - loss: 1.6415 - accuracy: 0.2688 - precision_5: 0.6250 - recall_5: 0.062 - ETA: 0s - loss: 1.6422 - accuracy: 0.2946 - precision_5: 0.5909 - recall_5: 0.058 - ETA: 0s - loss: 1.6411 - accuracy: 0.2969 - precision_5: 0.6400 - recall_5: 0.062 - ETA: 0s - loss: 1.6184 - accuracy: 0.3056 - precision_5: 0.6562 - recall_5: 0.072 - ETA: 0s - loss: 1.6384 - accuracy: 0.3094 - precision_5: 0.6154 - recall_5: 0.075 - ETA: 0s - loss: 1.6372 - accuracy: 0.3255 - precision_5: 0.5870 - recall_5: 0.070 - 1s 3ms/sample - loss: 1.6287 - accuracy: 0.3310 - precision_5: 0.5600 - recall_5: 0.0657 - val_loss: 1.6898 - val_accuracy: 0.2535 - val_precision_5: 0.8750 - val_recall_5: 0.0493\n",
      "Epoch 34/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6686 - accuracy: 0.2812 - precision_5: 1.0000 - recall_5: 0.031 - ETA: 0s - loss: 1.6832 - accuracy: 0.2812 - precision_5: 1.0000 - recall_5: 0.031 - ETA: 0s - loss: 1.7085 - accuracy: 0.2937 - precision_5: 0.7273 - recall_5: 0.050 - ETA: 0s - loss: 1.6898 - accuracy: 0.3036 - precision_5: 0.6667 - recall_5: 0.044 - ETA: 0s - loss: 1.6653 - accuracy: 0.3056 - precision_5: 0.7273 - recall_5: 0.055 - ETA: 0s - loss: 1.6664 - accuracy: 0.3153 - precision_5: 0.7241 - recall_5: 0.059 - ETA: 0s - loss: 1.6460 - accuracy: 0.3293 - precision_5: 0.6286 - recall_5: 0.052 - 1s 2ms/sample - loss: 1.6431 - accuracy: 0.3286 - precision_5: 0.6389 - recall_5: 0.0540 - val_loss: 1.6953 - val_accuracy: 0.2606 - val_precision_5: 0.6667 - val_recall_5: 0.0423\n",
      "Epoch 35/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6314 - accuracy: 0.2500 - precision_5: 1.0000 - recall_5: 0.031 - ETA: 0s - loss: 1.6341 - accuracy: 0.2500 - precision_5: 1.0000 - recall_5: 0.031 - ETA: 0s - loss: 1.7613 - accuracy: 0.2578 - precision_5: 0.4286 - recall_5: 0.023 - ETA: 0s - loss: 1.7449 - accuracy: 0.2760 - precision_5: 0.5000 - recall_5: 0.041 - ETA: 0s - loss: 1.8241 - accuracy: 0.2539 - precision_5: 0.6000 - recall_5: 0.046 - ETA: 0s - loss: 1.8361 - accuracy: 0.2750 - precision_5: 0.6562 - recall_5: 0.065 - ETA: 0s - loss: 1.8307 - accuracy: 0.2734 - precision_5: 0.5897 - recall_5: 0.059 - ETA: 0s - loss: 1.8347 - accuracy: 0.2620 - precision_5: 0.5349 - recall_5: 0.055 - 1s 3ms/sample - loss: 1.8318 - accuracy: 0.2606 - precision_5: 0.5455 - recall_5: 0.0563 - val_loss: 1.8459 - val_accuracy: 0.2183 - val_precision_5: 0.4286 - val_recall_5: 0.0423\n",
      "Epoch 36/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9637 - accuracy: 0.1562 - precision_5: 0.3333 - recall_5: 0.031 - ETA: 0s - loss: 1.8348 - accuracy: 0.2031 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.8009 - accuracy: 0.2708 - precision_5: 0.3333 - recall_5: 0.020 - ETA: 0s - loss: 1.7875 - accuracy: 0.2656 - precision_5: 0.2500 - recall_5: 0.015 - ETA: 0s - loss: 1.7825 - accuracy: 0.2625 - precision_5: 0.2500 - recall_5: 0.012 - ETA: 0s - loss: 1.7694 - accuracy: 0.2760 - precision_5: 0.3000 - recall_5: 0.015 - ETA: 0s - loss: 1.7625 - accuracy: 0.2812 - precision_5: 0.4167 - recall_5: 0.022 - ETA: 0s - loss: 1.7801 - accuracy: 0.2812 - precision_5: 0.4167 - recall_5: 0.019 - ETA: 0s - loss: 1.7591 - accuracy: 0.2906 - precision_5: 0.5500 - recall_5: 0.034 - ETA: 0s - loss: 1.7490 - accuracy: 0.2865 - precision_5: 0.6250 - recall_5: 0.039 - 1s 3ms/sample - loss: 1.7364 - accuracy: 0.2793 - precision_5: 0.5667 - recall_5: 0.0399 - val_loss: 1.6964 - val_accuracy: 0.2324 - val_precision_5: 0.3448 - val_recall_5: 0.0704\n",
      "Epoch 37/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6743 - accuracy: 0.2500 - precision_5: 0.2857 - recall_5: 0.062 - ETA: 1s - loss: 1.6910 - accuracy: 0.2708 - precision_5: 0.3684 - recall_5: 0.072 - ETA: 0s - loss: 1.6809 - accuracy: 0.2656 - precision_5: 0.4000 - recall_5: 0.078 - ETA: 0s - loss: 1.6419 - accuracy: 0.2812 - precision_5: 0.4839 - recall_5: 0.093 - ETA: 0s - loss: 1.6376 - accuracy: 0.2723 - precision_5: 0.5000 - recall_5: 0.071 - ETA: 0s - loss: 1.6301 - accuracy: 0.2930 - precision_5: 0.5152 - recall_5: 0.066 - ETA: 0s - loss: 1.6074 - accuracy: 0.3090 - precision_5: 0.5556 - recall_5: 0.069 - ETA: 0s - loss: 1.6144 - accuracy: 0.3219 - precision_5: 0.5789 - recall_5: 0.068 - ETA: 0s - loss: 1.6139 - accuracy: 0.3359 - precision_5: 0.5952 - recall_5: 0.065 - 1s 2ms/sample - loss: 1.6175 - accuracy: 0.3310 - precision_5: 0.5510 - recall_5: 0.0634 - val_loss: 1.7233 - val_accuracy: 0.2676 - val_precision_5: 0.5385 - val_recall_5: 0.0493\n",
      "Epoch 38/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.2812 - precision_5: 0.3333 - recall_5: 0.031 - ETA: 0s - loss: 1.5967 - accuracy: 0.3125 - precision_5: 0.4000 - recall_5: 0.020 - ETA: 0s - loss: 1.6328 - accuracy: 0.3047 - precision_5: 0.3333 - recall_5: 0.015 - ETA: 0s - loss: 1.6131 - accuracy: 0.3281 - precision_5: 0.5556 - recall_5: 0.026 - ETA: 0s - loss: 1.6078 - accuracy: 0.3170 - precision_5: 0.6000 - recall_5: 0.026 - ETA: 0s - loss: 1.5888 - accuracy: 0.3264 - precision_5: 0.6923 - recall_5: 0.031 - ETA: 0s - loss: 1.6022 - accuracy: 0.3281 - precision_5: 0.7222 - recall_5: 0.040 - ETA: 0s - loss: 1.5993 - accuracy: 0.3385 - precision_5: 0.6522 - recall_5: 0.039 - ETA: 0s - loss: 1.6122 - accuracy: 0.3413 - precision_5: 0.5357 - recall_5: 0.036 - 1s 3ms/sample - loss: 1.6087 - accuracy: 0.3427 - precision_5: 0.5161 - recall_5: 0.0376 - val_loss: 1.6586 - val_accuracy: 0.2958 - val_precision_5: 0.4762 - val_recall_5: 0.0704\n",
      "Epoch 39/150\n",
      "426/426 [==============================] - ETA: 2s - loss: 1.5840 - accuracy: 0.1875 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 1s - loss: 1.5719 - accuracy: 0.3021 - precision_5: 0.5714 - recall_5: 0.041 - ETA: 1s - loss: 1.5494 - accuracy: 0.3125 - precision_5: 0.5000 - recall_5: 0.039 - ETA: 1s - loss: 1.5390 - accuracy: 0.3125 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.5264 - accuracy: 0.3333 - precision_5: 0.6471 - recall_5: 0.057 - ETA: 0s - loss: 1.5324 - accuracy: 0.3214 - precision_5: 0.6842 - recall_5: 0.058 - ETA: 0s - loss: 1.5290 - accuracy: 0.3242 - precision_5: 0.6842 - recall_5: 0.050 - ETA: 0s - loss: 1.5165 - accuracy: 0.3438 - precision_5: 0.7308 - recall_5: 0.059 - ETA: 0s - loss: 1.5142 - accuracy: 0.3542 - precision_5: 0.6765 - recall_5: 0.059 - ETA: 0s - loss: 1.5372 - accuracy: 0.3413 - precision_5: 0.5750 - recall_5: 0.055 - 2s 4ms/sample - loss: 1.5341 - accuracy: 0.3404 - precision_5: 0.5814 - recall_5: 0.0587 - val_loss: 1.7365 - val_accuracy: 0.2746 - val_precision_5: 0.3929 - val_recall_5: 0.0775\n",
      "Epoch 40/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5713 - accuracy: 0.2812 - precision_5: 0.2500 - recall_5: 0.031 - ETA: 0s - loss: 1.5715 - accuracy: 0.3542 - precision_5: 0.3333 - recall_5: 0.031 - ETA: 1s - loss: 1.5527 - accuracy: 0.3750 - precision_5: 0.3846 - recall_5: 0.039 - ETA: 0s - loss: 1.5241 - accuracy: 0.3812 - precision_5: 0.4667 - recall_5: 0.043 - ETA: 0s - loss: 1.5304 - accuracy: 0.3884 - precision_5: 0.4706 - recall_5: 0.035 - ETA: 0s - loss: 1.5179 - accuracy: 0.3993 - precision_5: 0.5263 - recall_5: 0.034 - ETA: 0s - loss: 1.5281 - accuracy: 0.3892 - precision_5: 0.5714 - recall_5: 0.034 - ETA: 0s - loss: 1.5394 - accuracy: 0.3750 - precision_5: 0.4815 - recall_5: 0.031 - 1s 2ms/sample - loss: 1.5317 - accuracy: 0.3756 - precision_5: 0.5172 - recall_5: 0.0352 - val_loss: 1.5999 - val_accuracy: 0.2817 - val_precision_5: 0.4000 - val_recall_5: 0.0704\n",
      "Epoch 41/150\n",
      "426/426 [==============================] - ETA: 1s - loss: 1.4680 - accuracy: 0.3750 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.4971 - accuracy: 0.3438 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.4902 - accuracy: 0.3313 - precision_5: 0.6250 - recall_5: 0.062 - ETA: 0s - loss: 1.4882 - accuracy: 0.3393 - precision_5: 0.6364 - recall_5: 0.062 - ETA: 0s - loss: 1.4916 - accuracy: 0.3516 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.5106 - accuracy: 0.3469 - precision_5: 0.6800 - recall_5: 0.053 - ETA: 0s - loss: 1.5122 - accuracy: 0.3490 - precision_5: 0.6923 - recall_5: 0.046 - 1s 2ms/sample - loss: 1.5177 - accuracy: 0.3404 - precision_5: 0.6452 - recall_5: 0.0469 - val_loss: 1.6506 - val_accuracy: 0.3239 - val_precision_5: 0.6000 - val_recall_5: 0.0423\n",
      "Epoch 42/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.3438 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5252 - accuracy: 0.2969 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5753 - accuracy: 0.3229 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5043 - accuracy: 0.3500 - precision_5: 0.4000 - recall_5: 0.0250        - ETA: 0s - loss: 1.5171 - accuracy: 0.3438 - precision_5: 0.5294 - recall_5: 0.040 - ETA: 0s - loss: 1.5327 - accuracy: 0.3398 - precision_5: 0.5789 - recall_5: 0.043 - ETA: 0s - loss: 1.5256 - accuracy: 0.3438 - precision_5: 0.6364 - recall_5: 0.048 - ETA: 0s - loss: 1.5369 - accuracy: 0.3466 - precision_5: 0.6800 - recall_5: 0.048 - ETA: 0s - loss: 1.5381 - accuracy: 0.3510 - precision_5: 0.6552 - recall_5: 0.045 - 1s 2ms/sample - loss: 1.5270 - accuracy: 0.3568 - precision_5: 0.6774 - recall_5: 0.0493 - val_loss: 1.5162 - val_accuracy: 0.3028 - val_precision_5: 0.5000 - val_recall_5: 0.0493\n",
      "Epoch 43/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5235 - accuracy: 0.2188 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.5055 - accuracy: 0.3854 - precision_5: 0.4444 - recall_5: 0.041 - ETA: 0s - loss: 1.4517 - accuracy: 0.4375 - precision_5: 0.6364 - recall_5: 0.087 - ETA: 0s - loss: 1.4277 - accuracy: 0.4420 - precision_5: 0.6216 - recall_5: 0.102 - ETA: 0s - loss: 1.4452 - accuracy: 0.4297 - precision_5: 0.6500 - recall_5: 0.101 - ETA: 0s - loss: 1.4620 - accuracy: 0.4250 - precision_5: 0.6735 - recall_5: 0.103 - ETA: 0s - loss: 1.4505 - accuracy: 0.4115 - precision_5: 0.6727 - recall_5: 0.096 - 1s 2ms/sample - loss: 1.4470 - accuracy: 0.4131 - precision_5: 0.6290 - recall_5: 0.0915 - val_loss: 1.4866 - val_accuracy: 0.3310 - val_precision_5: 0.6111 - val_recall_5: 0.0775\n",
      "Epoch 44/150\n",
      "426/426 [==============================] - ETA: 2s - loss: 1.4436 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 1s - loss: 1.4483 - accuracy: 0.3594 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 1s - loss: 1.4104 - accuracy: 0.4271 - precision_5: 0.4286 - recall_5: 0.031 - ETA: 1s - loss: 1.3949 - accuracy: 0.4453 - precision_5: 0.5000 - recall_5: 0.039 - ETA: 0s - loss: 1.3941 - accuracy: 0.4479 - precision_5: 0.5833 - recall_5: 0.072 - ETA: 0s - loss: 1.3845 - accuracy: 0.4492 - precision_5: 0.6333 - recall_5: 0.074 - ETA: 0s - loss: 1.3896 - accuracy: 0.4444 - precision_5: 0.6667 - recall_5: 0.076 - ETA: 0s - loss: 1.4472 - accuracy: 0.4233 - precision_5: 0.6667 - recall_5: 0.068 - ETA: 0s - loss: 1.4609 - accuracy: 0.4062 - precision_5: 0.6250 - recall_5: 0.060 - 1s 3ms/sample - loss: 1.4542 - accuracy: 0.4085 - precision_5: 0.6429 - recall_5: 0.0634 - val_loss: 1.7862 - val_accuracy: 0.2746 - val_precision_5: 0.3226 - val_recall_5: 0.0704\n",
      "Epoch 45/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.1875 - precision_5: 0.3333 - recall_5: 0.062 - ETA: 0s - loss: 1.7549 - accuracy: 0.3021 - precision_5: 0.3333 - recall_5: 0.052 - ETA: 0s - loss: 1.6580 - accuracy: 0.3500 - precision_5: 0.5217 - recall_5: 0.075 - ETA: 0s - loss: 1.6710 - accuracy: 0.3214 - precision_5: 0.5200 - recall_5: 0.058 - ETA: 0s - loss: 1.6619 - accuracy: 0.3368 - precision_5: 0.5714 - recall_5: 0.055 - ETA: 0s - loss: 1.6719 - accuracy: 0.3438 - precision_5: 0.5806 - recall_5: 0.056 - ETA: 0s - loss: 1.6453 - accuracy: 0.3438 - precision_5: 0.5429 - recall_5: 0.049 - 1s 2ms/sample - loss: 1.6469 - accuracy: 0.3404 - precision_5: 0.5000 - recall_5: 0.0469 - val_loss: 1.6464 - val_accuracy: 0.3380 - val_precision_5: 0.5625 - val_recall_5: 0.0634\n",
      "Epoch 46/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6323 - accuracy: 0.2812 - precision_5: 1.0000 - recall_5: 0.031 - ETA: 0s - loss: 1.5970 - accuracy: 0.3542 - precision_5: 0.7500 - recall_5: 0.031 - ETA: 0s - loss: 1.5606 - accuracy: 0.3906 - precision_5: 0.7500 - recall_5: 0.046 - ETA: 0s - loss: 1.5104 - accuracy: 0.3854 - precision_5: 0.8125 - recall_5: 0.067 - ETA: 0s - loss: 1.4910 - accuracy: 0.3906 - precision_5: 0.7895 - recall_5: 0.058 - ETA: 0s - loss: 1.4742 - accuracy: 0.3958 - precision_5: 0.8000 - recall_5: 0.055 - ETA: 0s - loss: 1.4733 - accuracy: 0.4062 - precision_5: 0.7826 - recall_5: 0.051 - ETA: 0s - loss: 1.4658 - accuracy: 0.4038 - precision_5: 0.7143 - recall_5: 0.048 - 1s 2ms/sample - loss: 1.4545 - accuracy: 0.4085 - precision_5: 0.7419 - recall_5: 0.0540 - val_loss: 1.5125 - val_accuracy: 0.3169 - val_precision_5: 0.5000 - val_recall_5: 0.0775\n",
      "Epoch 47/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4346 - accuracy: 0.2188 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.4073 - accuracy: 0.2708 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.3898 - accuracy: 0.3000 - precision_5: 0.7059 - recall_5: 0.075 - ETA: 0s - loss: 1.3746 - accuracy: 0.3348 - precision_5: 0.7037 - recall_5: 0.084 - ETA: 0s - loss: 1.3711 - accuracy: 0.3576 - precision_5: 0.7714 - recall_5: 0.093 - ETA: 0s - loss: 1.4133 - accuracy: 0.3562 - precision_5: 0.7568 - recall_5: 0.087 - ETA: 0s - loss: 1.4253 - accuracy: 0.3568 - precision_5: 0.7568 - recall_5: 0.072 - ETA: 0s - loss: 1.4413 - accuracy: 0.3510 - precision_5: 0.7000 - recall_5: 0.067 - 1s 2ms/sample - loss: 1.4381 - accuracy: 0.3521 - precision_5: 0.7143 - recall_5: 0.0704 - val_loss: 1.8975 - val_accuracy: 0.2535 - val_precision_5: 0.3824 - val_recall_5: 0.0915\n",
      "Epoch 48/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7676 - accuracy: 0.2188 - precision_5: 0.5714 - recall_5: 0.125 - ETA: 0s - loss: 1.7890 - accuracy: 0.2344 - precision_5: 0.5455 - recall_5: 0.093 - ETA: 0s - loss: 1.7494 - accuracy: 0.3125 - precision_5: 0.5556 - recall_5: 0.078 - ETA: 0s - loss: 1.6809 - accuracy: 0.3313 - precision_5: 0.6250 - recall_5: 0.093 - ETA: 0s - loss: 1.6335 - accuracy: 0.3393 - precision_5: 0.6897 - recall_5: 0.089 - ETA: 0s - loss: 1.6220 - accuracy: 0.3403 - precision_5: 0.6970 - recall_5: 0.079 - ETA: 0s - loss: 1.6103 - accuracy: 0.3409 - precision_5: 0.6667 - recall_5: 0.068 - ETA: 0s - loss: 1.6098 - accuracy: 0.3317 - precision_5: 0.5952 - recall_5: 0.060 - 1s 2ms/sample - loss: 1.6016 - accuracy: 0.3333 - precision_5: 0.6047 - recall_5: 0.0610 - val_loss: 1.6463 - val_accuracy: 0.2606 - val_precision_5: 0.4737 - val_recall_5: 0.0634\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.5854 - accuracy: 0.3125 - precision_5: 1.0000 - recall_5: 0.062 - ETA: 0s - loss: 1.5552 - accuracy: 0.3281 - precision_5: 0.8000 - recall_5: 0.062 - ETA: 0s - loss: 1.5308 - accuracy: 0.3516 - precision_5: 0.6154 - recall_5: 0.062 - ETA: 0s - loss: 1.5115 - accuracy: 0.3562 - precision_5: 0.6667 - recall_5: 0.087 - ETA: 0s - loss: 1.4687 - accuracy: 0.3705 - precision_5: 0.6061 - recall_5: 0.089 - ETA: 0s - loss: 1.4815 - accuracy: 0.3594 - precision_5: 0.6286 - recall_5: 0.085 - ETA: 0s - loss: 1.4777 - accuracy: 0.3688 - precision_5: 0.5882 - recall_5: 0.093 - ETA: 0s - loss: 1.4923 - accuracy: 0.3636 - precision_5: 0.5345 - recall_5: 0.088 - ETA: 0s - loss: 1.4954 - accuracy: 0.3594 - precision_5: 0.5161 - recall_5: 0.083 - ETA: 0s - loss: 1.5073 - accuracy: 0.3510 - precision_5: 0.4853 - recall_5: 0.079 - 1s 2ms/sample - loss: 1.4999 - accuracy: 0.3545 - precision_5: 0.4861 - recall_5: 0.0822 - val_loss: 1.5012 - val_accuracy: 0.3451 - val_precision_5: 0.5417 - val_recall_5: 0.0915\n",
      "Epoch 50/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3984 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 1s - loss: 1.4160 - accuracy: 0.3281 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.4330 - accuracy: 0.3438 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.4082 - accuracy: 0.3562 - precision_5: 0.7647 - recall_5: 0.081 - ETA: 0s - loss: 1.3898 - accuracy: 0.3750 - precision_5: 0.7391 - recall_5: 0.088 - ETA: 0s - loss: 1.3993 - accuracy: 0.3661 - precision_5: 0.6897 - recall_5: 0.089 - ETA: 0s - loss: 1.4294 - accuracy: 0.3555 - precision_5: 0.6875 - recall_5: 0.085 - ETA: 0s - loss: 1.4072 - accuracy: 0.3646 - precision_5: 0.7179 - recall_5: 0.097 - ETA: 0s - loss: 1.4273 - accuracy: 0.3625 - precision_5: 0.7073 - recall_5: 0.090 - ETA: 0s - loss: 1.4276 - accuracy: 0.3608 - precision_5: 0.6889 - recall_5: 0.088 - ETA: 0s - loss: 1.4152 - accuracy: 0.3750 - precision_5: 0.7037 - recall_5: 0.091 - 1s 3ms/sample - loss: 1.4034 - accuracy: 0.3826 - precision_5: 0.7333 - recall_5: 0.1033 - val_loss: 1.5954 - val_accuracy: 0.3169 - val_precision_5: 0.5217 - val_recall_5: 0.0845\n",
      "Epoch 51/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5948 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5314 - accuracy: 0.3750 - precision_5: 0.3636 - recall_5: 0.0417        - ETA: 0s - loss: 1.5523 - accuracy: 0.4062 - precision_5: 0.4375 - recall_5: 0.054 - ETA: 0s - loss: 1.5064 - accuracy: 0.4125 - precision_5: 0.5455 - recall_5: 0.075 - ETA: 0s - loss: 1.4802 - accuracy: 0.4107 - precision_5: 0.5789 - recall_5: 0.098 - ETA: 0s - loss: 1.4993 - accuracy: 0.3906 - precision_5: 0.5952 - recall_5: 0.097 - ETA: 0s - loss: 1.4911 - accuracy: 0.3889 - precision_5: 0.6250 - recall_5: 0.104 - ETA: 0s - loss: 1.5092 - accuracy: 0.3938 - precision_5: 0.6275 - recall_5: 0.100 - ETA: 0s - loss: 1.4931 - accuracy: 0.3977 - precision_5: 0.6346 - recall_5: 0.093 - ETA: 0s - loss: 1.5394 - accuracy: 0.3726 - precision_5: 0.6296 - recall_5: 0.081 - 1s 3ms/sample - loss: 1.5336 - accuracy: 0.3732 - precision_5: 0.6429 - recall_5: 0.0845 - val_loss: 1.6084 - val_accuracy: 0.3239 - val_precision_5: 0.8571 - val_recall_5: 0.0423\n",
      "Epoch 52/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6795 - accuracy: 0.2188 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.6723 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5395 - accuracy: 0.3542 - precision_5: 0.6667 - recall_5: 0.0208        - ETA: 0s - loss: 1.5619 - accuracy: 0.3828 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.5240 - accuracy: 0.3854 - precision_5: 0.6500 - recall_5: 0.067 - ETA: 0s - loss: 1.5064 - accuracy: 0.3973 - precision_5: 0.7083 - recall_5: 0.075 - ETA: 0s - loss: 1.4943 - accuracy: 0.4097 - precision_5: 0.7742 - recall_5: 0.083 - ETA: 0s - loss: 1.5089 - accuracy: 0.4062 - precision_5: 0.7353 - recall_5: 0.078 - ETA: 0s - loss: 1.5145 - accuracy: 0.4091 - precision_5: 0.7297 - recall_5: 0.076 - ETA: 0s - loss: 1.5158 - accuracy: 0.4141 - precision_5: 0.7436 - recall_5: 0.075 - ETA: 0s - loss: 1.5135 - accuracy: 0.4014 - precision_5: 0.7273 - recall_5: 0.076 - 1s 2ms/sample - loss: 1.4980 - accuracy: 0.4061 - precision_5: 0.7551 - recall_5: 0.0869 - val_loss: 1.6317 - val_accuracy: 0.2887 - val_precision_5: 0.4516 - val_recall_5: 0.0986\n",
      "Epoch 53/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7713 - accuracy: 0.2500 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.7591 - accuracy: 0.2708 - precision_5: 0.2941 - recall_5: 0.0521        - ETA: 0s - loss: 1.6925 - accuracy: 0.3125 - precision_5: 0.4211 - recall_5: 0.100 - ETA: 0s - loss: 1.7278 - accuracy: 0.3259 - precision_5: 0.4464 - recall_5: 0.111 - ETA: 0s - loss: 1.7348 - accuracy: 0.3164 - precision_5: 0.4500 - recall_5: 0.105 - ETA: 0s - loss: 1.7123 - accuracy: 0.3313 - precision_5: 0.4932 - recall_5: 0.112 - ETA: 0s - loss: 1.7023 - accuracy: 0.3281 - precision_5: 0.4699 - recall_5: 0.101 - ETA: 0s - loss: 1.7220 - accuracy: 0.3149 - precision_5: 0.4348 - recall_5: 0.096 - 1s 2ms/sample - loss: 1.7253 - accuracy: 0.3122 - precision_5: 0.4271 - recall_5: 0.0962 - val_loss: 1.7899 - val_accuracy: 0.2958 - val_precision_5: 0.5000 - val_recall_5: 0.0845\n",
      "Epoch 54/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.7505 - accuracy: 0.2500 - precision_5: 0.5000 - recall_5: 0.031 - ETA: 0s - loss: 1.6750 - accuracy: 0.2604 - precision_5: 0.7143 - recall_5: 0.052 - ETA: 0s - loss: 1.6171 - accuracy: 0.2688 - precision_5: 0.6875 - recall_5: 0.068 - ETA: 0s - loss: 1.5980 - accuracy: 0.2865 - precision_5: 0.7368 - recall_5: 0.072 - ETA: 0s - loss: 1.6147 - accuracy: 0.3086 - precision_5: 0.6087 - recall_5: 0.054 - ETA: 0s - loss: 1.6061 - accuracy: 0.3187 - precision_5: 0.6296 - recall_5: 0.053 - ETA: 0s - loss: 1.5907 - accuracy: 0.3210 - precision_5: 0.6000 - recall_5: 0.051 - ETA: 0s - loss: 1.5697 - accuracy: 0.3221 - precision_5: 0.6571 - recall_5: 0.055 - 1s 2ms/sample - loss: 1.5549 - accuracy: 0.3333 - precision_5: 0.7000 - recall_5: 0.0657 - val_loss: 1.6315 - val_accuracy: 0.3662 - val_precision_5: 0.6471 - val_recall_5: 0.0775\n",
      "Epoch 55/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6915 - accuracy: 0.2812 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5830 - accuracy: 0.3281 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.4813 - accuracy: 0.4271 - precision_5: 0.4286 - recall_5: 0.0312        - ETA: 0s - loss: 1.4459 - accuracy: 0.4125 - precision_5: 0.6190 - recall_5: 0.081 - ETA: 0s - loss: 1.4434 - accuracy: 0.4219 - precision_5: 0.6296 - recall_5: 0.088 - ETA: 0s - loss: 1.4331 - accuracy: 0.4152 - precision_5: 0.5833 - recall_5: 0.093 - ETA: 0s - loss: 1.5010 - accuracy: 0.4062 - precision_5: 0.5349 - recall_5: 0.089 - ETA: 0s - loss: 1.4807 - accuracy: 0.4132 - precision_5: 0.5600 - recall_5: 0.097 - ETA: 0s - loss: 1.4977 - accuracy: 0.4148 - precision_5: 0.5156 - recall_5: 0.093 - ETA: 0s - loss: 1.4860 - accuracy: 0.4219 - precision_5: 0.5152 - recall_5: 0.088 - ETA: 0s - loss: 1.4772 - accuracy: 0.4255 - precision_5: 0.5147 - recall_5: 0.084 - 1s 3ms/sample - loss: 1.4636 - accuracy: 0.4319 - precision_5: 0.5352 - recall_5: 0.0892 - val_loss: 1.8161 - val_accuracy: 0.2958 - val_precision_5: 0.3529 - val_recall_5: 0.0423\n",
      "Epoch 56/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.9518 - accuracy: 0.2188 - precision_5: 0.4000 - recall_5: 0.062 - ETA: 0s - loss: 1.7978 - accuracy: 0.2344 - precision_5: 0.2857 - recall_5: 0.031 - ETA: 0s - loss: 1.7189 - accuracy: 0.2708 - precision_5: 0.3636 - recall_5: 0.041 - ETA: 0s - loss: 1.5754 - accuracy: 0.3375 - precision_5: 0.5455 - recall_5: 0.075 - ETA: 0s - loss: 1.5805 - accuracy: 0.3281 - precision_5: 0.4839 - recall_5: 0.078 - ETA: 0s - loss: 1.5362 - accuracy: 0.3304 - precision_5: 0.5429 - recall_5: 0.084 - ETA: 0s - loss: 1.5591 - accuracy: 0.3333 - precision_5: 0.5581 - recall_5: 0.083 - ETA: 0s - loss: 1.5765 - accuracy: 0.3381 - precision_5: 0.5385 - recall_5: 0.079 - ETA: 0s - loss: 1.5604 - accuracy: 0.3534 - precision_5: 0.5000 - recall_5: 0.067 - 1s 2ms/sample - loss: 1.5474 - accuracy: 0.3615 - precision_5: 0.5088 - recall_5: 0.0681 - val_loss: 1.7227 - val_accuracy: 0.3380 - val_precision_5: 0.5000 - val_recall_5: 0.0211\n",
      "Epoch 57/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6973 - accuracy: 0.3125 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5697 - accuracy: 0.3854 - precision_5: 0.0000e+00 - recall_5: 0.0000e+0 - ETA: 0s - loss: 1.5333 - accuracy: 0.3688 - precision_5: 0.7000 - recall_5: 0.0437        - ETA: 0s - loss: 1.5089 - accuracy: 0.3906 - precision_5: 0.7143 - recall_5: 0.052 - ETA: 0s - loss: 1.4820 - accuracy: 0.3839 - precision_5: 0.7895 - recall_5: 0.067 - ETA: 0s - loss: 1.4722 - accuracy: 0.3924 - precision_5: 0.7500 - recall_5: 0.072 - ETA: 0s - loss: 1.4873 - accuracy: 0.3949 - precision_5: 0.7105 - recall_5: 0.076 - ETA: 0s - loss: 1.4807 - accuracy: 0.4010 - precision_5: 0.7250 - recall_5: 0.075 - ETA: 0s - loss: 1.4971 - accuracy: 0.3894 - precision_5: 0.6591 - recall_5: 0.069 - 1s 2ms/sample - loss: 1.4846 - accuracy: 0.3944 - precision_5: 0.6809 - recall_5: 0.0751 - val_loss: 1.4832 - val_accuracy: 0.3451 - val_precision_5: 0.4500 - val_recall_5: 0.0634\n",
      "Epoch 58/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.3125 - precision_5: 0.6000 - recall_5: 0.093 - ETA: 0s - loss: 1.4805 - accuracy: 0.2969 - precision_5: 0.6667 - recall_5: 0.062 - ETA: 0s - loss: 1.4133 - accuracy: 0.3542 - precision_5: 0.7500 - recall_5: 0.062 - ETA: 0s - loss: 1.4247 - accuracy: 0.3516 - precision_5: 0.7500 - recall_5: 0.070 - ETA: 0s - loss: 1.3577 - accuracy: 0.3875 - precision_5: 0.8333 - recall_5: 0.093 - ETA: 0s - loss: 1.3498 - accuracy: 0.4062 - precision_5: 0.7917 - recall_5: 0.099 - ETA: 0s - loss: 1.3383 - accuracy: 0.4196 - precision_5: 0.7778 - recall_5: 0.093 - ETA: 0s - loss: 1.3408 - accuracy: 0.4219 - precision_5: 0.7586 - recall_5: 0.085 - ETA: 0s - loss: 1.3420 - accuracy: 0.4375 - precision_5: 0.8056 - recall_5: 0.090 - ETA: 0s - loss: 1.3546 - accuracy: 0.4233 - precision_5: 0.8158 - recall_5: 0.088 - ETA: 0s - loss: 1.3621 - accuracy: 0.4089 - precision_5: 0.7442 - recall_5: 0.083 - ETA: 0s - loss: 1.3675 - accuracy: 0.4062 - precision_5: 0.7234 - recall_5: 0.081 - 1s 3ms/sample - loss: 1.3594 - accuracy: 0.4108 - precision_5: 0.7400 - recall_5: 0.0869 - val_loss: 1.5984 - val_accuracy: 0.2817 - val_precision_5: 0.4783 - val_recall_5: 0.0775\n",
      "Epoch 59/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5516 - accuracy: 0.2500 - precision_5: 0.3333 - recall_5: 0.031 - ETA: 0s - loss: 1.5035 - accuracy: 0.2344 - precision_5: 0.2500 - recall_5: 0.031 - ETA: 0s - loss: 1.4234 - accuracy: 0.3229 - precision_5: 0.3636 - recall_5: 0.041 - ETA: 0s - loss: 1.4077 - accuracy: 0.3594 - precision_5: 0.4667 - recall_5: 0.054 - ETA: 0s - loss: 1.3466 - accuracy: 0.3938 - precision_5: 0.6190 - recall_5: 0.081 - ETA: 0s - loss: 1.3261 - accuracy: 0.4219 - precision_5: 0.6296 - recall_5: 0.088 - ETA: 0s - loss: 1.3109 - accuracy: 0.4152 - precision_5: 0.6667 - recall_5: 0.089 - ETA: 0s - loss: 1.2990 - accuracy: 0.4271 - precision_5: 0.7368 - recall_5: 0.097 - ETA: 0s - loss: 1.3093 - accuracy: 0.4375 - precision_5: 0.7442 - recall_5: 0.090 - ETA: 0s - loss: 1.3079 - accuracy: 0.4401 - precision_5: 0.7442 - recall_5: 0.083 - ETA: 0s - loss: 1.3092 - accuracy: 0.4399 - precision_5: 0.7021 - recall_5: 0.079 - 1s 2ms/sample - loss: 1.3002 - accuracy: 0.4437 - precision_5: 0.7200 - recall_5: 0.0845 - val_loss: 1.4208 - val_accuracy: 0.3662 - val_precision_5: 0.5333 - val_recall_5: 0.1127\n",
      "Epoch 60/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2747 - accuracy: 0.4062 - precision_5: 0.5000 - recall_5: 0.125 - ETA: 0s - loss: 1.2624 - accuracy: 0.4375 - precision_5: 0.5000 - recall_5: 0.093 - ETA: 0s - loss: 1.2440 - accuracy: 0.4688 - precision_5: 0.5714 - recall_5: 0.125 - ETA: 0s - loss: 1.2762 - accuracy: 0.4688 - precision_5: 0.6296 - recall_5: 0.132 - ETA: 0s - loss: 1.2497 - accuracy: 0.4875 - precision_5: 0.6667 - recall_5: 0.150 - ETA: 0s - loss: 1.2547 - accuracy: 0.4598 - precision_5: 0.6481 - recall_5: 0.156 - ETA: 0s - loss: 1.2417 - accuracy: 0.4618 - precision_5: 0.6571 - recall_5: 0.159 - ETA: 0s - loss: 1.2650 - accuracy: 0.4531 - precision_5: 0.6400 - recall_5: 0.150 - ETA: 0s - loss: 1.2579 - accuracy: 0.4517 - precision_5: 0.6625 - recall_5: 0.150 - ETA: 0s - loss: 1.2468 - accuracy: 0.4635 - precision_5: 0.6548 - recall_5: 0.143 - ETA: 0s - loss: 1.2498 - accuracy: 0.4615 - precision_5: 0.6304 - recall_5: 0.139 - 1s 2ms/sample - loss: 1.2419 - accuracy: 0.4648 - precision_5: 0.6421 - recall_5: 0.1432 - val_loss: 1.3938 - val_accuracy: 0.3732 - val_precision_5: 0.4231 - val_recall_5: 0.0775\n",
      "Epoch 61/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2571 - accuracy: 0.3750 - precision_5: 0.7500 - recall_5: 0.093 - ETA: 0s - loss: 1.2498 - accuracy: 0.3906 - precision_5: 0.7000 - recall_5: 0.109 - ETA: 0s - loss: 1.2545 - accuracy: 0.4531 - precision_5: 0.7083 - recall_5: 0.132 - ETA: 0s - loss: 1.2264 - accuracy: 0.4427 - precision_5: 0.6667 - recall_5: 0.166 - ETA: 0s - loss: 1.2103 - accuracy: 0.4509 - precision_5: 0.6441 - recall_5: 0.169 - ETA: 0s - loss: 1.1842 - accuracy: 0.4618 - precision_5: 0.6944 - recall_5: 0.173 - ETA: 0s - loss: 1.2155 - accuracy: 0.4460 - precision_5: 0.6709 - recall_5: 0.150 - ETA: 0s - loss: 1.2130 - accuracy: 0.4543 - precision_5: 0.6452 - recall_5: 0.144 - 1s 2ms/sample - loss: 1.2066 - accuracy: 0.4577 - precision_5: 0.6526 - recall_5: 0.1455 - val_loss: 1.3508 - val_accuracy: 0.4014 - val_precision_5: 0.5200 - val_recall_5: 0.0915\n",
      "Epoch 62/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2517 - accuracy: 0.4062 - precision_5: 0.7500 - recall_5: 0.093 - ETA: 0s - loss: 1.1824 - accuracy: 0.5000 - precision_5: 0.8333 - recall_5: 0.156 - ETA: 0s - loss: 1.2012 - accuracy: 0.5312 - precision_5: 0.7600 - recall_5: 0.148 - ETA: 0s - loss: 1.2004 - accuracy: 0.5104 - precision_5: 0.7255 - recall_5: 0.192 - ETA: 0s - loss: 1.1692 - accuracy: 0.5117 - precision_5: 0.6974 - recall_5: 0.207 - ETA: 0s - loss: 1.1500 - accuracy: 0.5174 - precision_5: 0.7059 - recall_5: 0.208 - ETA: 0s - loss: 1.1648 - accuracy: 0.5156 - precision_5: 0.6957 - recall_5: 0.200 - ETA: 0s - loss: 1.1690 - accuracy: 0.5114 - precision_5: 0.6907 - recall_5: 0.190 - ETA: 0s - loss: 1.1618 - accuracy: 0.5182 - precision_5: 0.6762 - recall_5: 0.184 - ETA: 0s - loss: 1.1826 - accuracy: 0.5120 - precision_5: 0.6496 - recall_5: 0.182 - 1s 2ms/sample - loss: 1.1798 - accuracy: 0.5070 - precision_5: 0.6529 - recall_5: 0.1854 - val_loss: 1.4704 - val_accuracy: 0.3592 - val_precision_5: 0.4773 - val_recall_5: 0.1479\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.4245 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.156 - ETA: 0s - loss: 1.3044 - accuracy: 0.3958 - precision_5: 0.4800 - recall_5: 0.125 - ETA: 0s - loss: 1.3130 - accuracy: 0.4297 - precision_5: 0.5588 - recall_5: 0.148 - ETA: 0s - loss: 1.2591 - accuracy: 0.4375 - precision_5: 0.6415 - recall_5: 0.177 - ETA: 0s - loss: 1.2170 - accuracy: 0.4643 - precision_5: 0.6452 - recall_5: 0.178 - ETA: 0s - loss: 1.2286 - accuracy: 0.4648 - precision_5: 0.6471 - recall_5: 0.171 - ETA: 0s - loss: 1.2140 - accuracy: 0.4688 - precision_5: 0.6667 - recall_5: 0.180 - ETA: 0s - loss: 1.2491 - accuracy: 0.4500 - precision_5: 0.6552 - recall_5: 0.178 - ETA: 0s - loss: 1.2552 - accuracy: 0.4489 - precision_5: 0.6224 - recall_5: 0.173 - ETA: 0s - loss: 1.2617 - accuracy: 0.4505 - precision_5: 0.6154 - recall_5: 0.166 - ETA: 0s - loss: 1.2657 - accuracy: 0.4567 - precision_5: 0.6106 - recall_5: 0.165 - 1s 2ms/sample - loss: 1.2572 - accuracy: 0.4601 - precision_5: 0.6239 - recall_5: 0.1714 - val_loss: 1.4749 - val_accuracy: 0.3521 - val_precision_5: 0.4667 - val_recall_5: 0.1479\n",
      "Epoch 64/150\n",
      "426/426 [==============================] - ETA: 1s - loss: 1.2573 - accuracy: 0.4688 - precision_5: 0.6000 - recall_5: 0.187 - ETA: 1s - loss: 1.2261 - accuracy: 0.4844 - precision_5: 0.6667 - recall_5: 0.187 - ETA: 1s - loss: 1.2068 - accuracy: 0.5312 - precision_5: 0.7200 - recall_5: 0.187 - ETA: 1s - loss: 1.2228 - accuracy: 0.4922 - precision_5: 0.7273 - recall_5: 0.187 - ETA: 0s - loss: 1.1807 - accuracy: 0.5365 - precision_5: 0.7759 - recall_5: 0.234 - ETA: 0s - loss: 1.1710 - accuracy: 0.5312 - precision_5: 0.7681 - recall_5: 0.236 - ETA: 0s - loss: 1.1694 - accuracy: 0.5234 - precision_5: 0.7439 - recall_5: 0.238 - ETA: 0s - loss: 1.1644 - accuracy: 0.5344 - precision_5: 0.7426 - recall_5: 0.234 - ETA: 0s - loss: 1.1640 - accuracy: 0.5339 - precision_5: 0.7190 - recall_5: 0.226 - 1s 3ms/sample - loss: 1.1736 - accuracy: 0.5258 - precision_5: 0.6715 - recall_5: 0.2160 - val_loss: 1.4160 - val_accuracy: 0.3662 - val_precision_5: 0.5102 - val_recall_5: 0.1761\n",
      "Epoch 65/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4391 - accuracy: 0.2500 - precision_5: 0.4545 - recall_5: 0.156 - ETA: 0s - loss: 1.4552 - accuracy: 0.3281 - precision_5: 0.5294 - recall_5: 0.140 - ETA: 0s - loss: 1.3426 - accuracy: 0.3984 - precision_5: 0.6389 - recall_5: 0.179 - ETA: 0s - loss: 1.2874 - accuracy: 0.4219 - precision_5: 0.6786 - recall_5: 0.197 - ETA: 0s - loss: 1.3227 - accuracy: 0.4196 - precision_5: 0.6471 - recall_5: 0.196 - ETA: 0s - loss: 1.2881 - accuracy: 0.4479 - precision_5: 0.6627 - recall_5: 0.191 - ETA: 0s - loss: 1.2940 - accuracy: 0.4563 - precision_5: 0.6782 - recall_5: 0.184 - ETA: 0s - loss: 1.2734 - accuracy: 0.4740 - precision_5: 0.6915 - recall_5: 0.169 - ETA: 0s - loss: 1.2783 - accuracy: 0.4615 - precision_5: 0.6667 - recall_5: 0.158 - 1s 2ms/sample - loss: 1.2695 - accuracy: 0.4648 - precision_5: 0.6765 - recall_5: 0.1620 - val_loss: 1.4156 - val_accuracy: 0.4085 - val_precision_5: 0.4242 - val_recall_5: 0.0986\n",
      "Epoch 66/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3793 - accuracy: 0.2188 - precision_5: 0.5714 - recall_5: 0.125 - ETA: 0s - loss: 1.2860 - accuracy: 0.3125 - precision_5: 0.5385 - recall_5: 0.109 - ETA: 0s - loss: 1.2177 - accuracy: 0.3958 - precision_5: 0.6087 - recall_5: 0.145 - ETA: 0s - loss: 1.2288 - accuracy: 0.4141 - precision_5: 0.6364 - recall_5: 0.164 - ETA: 0s - loss: 1.1769 - accuracy: 0.4375 - precision_5: 0.6809 - recall_5: 0.200 - ETA: 0s - loss: 1.1465 - accuracy: 0.4598 - precision_5: 0.6765 - recall_5: 0.205 - ETA: 0s - loss: 1.1499 - accuracy: 0.4844 - precision_5: 0.6667 - recall_5: 0.203 - ETA: 0s - loss: 1.1245 - accuracy: 0.5035 - precision_5: 0.6860 - recall_5: 0.204 - ETA: 0s - loss: 1.1461 - accuracy: 0.4943 - precision_5: 0.6961 - recall_5: 0.201 - ETA: 0s - loss: 1.1507 - accuracy: 0.5072 - precision_5: 0.6937 - recall_5: 0.185 - 1s 3ms/sample - loss: 1.1433 - accuracy: 0.5094 - precision_5: 0.7018 - recall_5: 0.1878 - val_loss: 1.3703 - val_accuracy: 0.4014 - val_precision_5: 0.4615 - val_recall_5: 0.1690\n",
      "Epoch 67/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2478 - accuracy: 0.3750 - precision_5: 0.3750 - recall_5: 0.093 - ETA: 0s - loss: 1.1830 - accuracy: 0.4271 - precision_5: 0.4865 - recall_5: 0.187 - ETA: 0s - loss: 1.1794 - accuracy: 0.4563 - precision_5: 0.5345 - recall_5: 0.193 - ETA: 0s - loss: 1.1335 - accuracy: 0.4866 - precision_5: 0.5732 - recall_5: 0.209 - ETA: 0s - loss: 1.1326 - accuracy: 0.4961 - precision_5: 0.5761 - recall_5: 0.207 - ETA: 0s - loss: 1.1392 - accuracy: 0.5063 - precision_5: 0.6111 - recall_5: 0.206 - ETA: 0s - loss: 1.1479 - accuracy: 0.4974 - precision_5: 0.6066 - recall_5: 0.192 - 1s 2ms/sample - loss: 1.1522 - accuracy: 0.4883 - precision_5: 0.6000 - recall_5: 0.1831 - val_loss: 1.4679 - val_accuracy: 0.4296 - val_precision_5: 0.5172 - val_recall_5: 0.2113\n",
      "Epoch 68/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5134 - accuracy: 0.3125 - precision_5: 0.5556 - recall_5: 0.156 - ETA: 0s - loss: 1.2586 - accuracy: 0.5000 - precision_5: 0.6667 - recall_5: 0.229 - ETA: 0s - loss: 1.2145 - accuracy: 0.5000 - precision_5: 0.6792 - recall_5: 0.225 - ETA: 0s - loss: 1.1986 - accuracy: 0.4896 - precision_5: 0.6618 - recall_5: 0.234 - ETA: 0s - loss: 1.1693 - accuracy: 0.4955 - precision_5: 0.6625 - recall_5: 0.236 - ETA: 0s - loss: 1.1865 - accuracy: 0.5000 - precision_5: 0.6737 - recall_5: 0.250 - ETA: 0s - loss: 1.1845 - accuracy: 0.5069 - precision_5: 0.6729 - recall_5: 0.250 - ETA: 0s - loss: 1.2026 - accuracy: 0.5094 - precision_5: 0.6696 - recall_5: 0.240 - ETA: 0s - loss: 1.1818 - accuracy: 0.5234 - precision_5: 0.6917 - recall_5: 0.239 - ETA: 0s - loss: 1.1839 - accuracy: 0.5264 - precision_5: 0.6690 - recall_5: 0.233 - 1s 2ms/sample - loss: 1.1772 - accuracy: 0.5282 - precision_5: 0.6757 - recall_5: 0.2347 - val_loss: 1.4865 - val_accuracy: 0.3873 - val_precision_5: 0.4239 - val_recall_5: 0.2746\n",
      "Epoch 69/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4886 - accuracy: 0.3750 - precision_5: 0.2941 - recall_5: 0.156 - ETA: 0s - loss: 1.4175 - accuracy: 0.3438 - precision_5: 0.2973 - recall_5: 0.171 - ETA: 0s - loss: 1.3542 - accuracy: 0.4167 - precision_5: 0.4127 - recall_5: 0.270 - ETA: 0s - loss: 1.3381 - accuracy: 0.4375 - precision_5: 0.4444 - recall_5: 0.281 - ETA: 0s - loss: 1.2979 - accuracy: 0.4812 - precision_5: 0.4848 - recall_5: 0.300 - ETA: 0s - loss: 1.2681 - accuracy: 0.4948 - precision_5: 0.5086 - recall_5: 0.307 - ETA: 0s - loss: 1.2627 - accuracy: 0.4955 - precision_5: 0.5109 - recall_5: 0.312 - ETA: 0s - loss: 1.2485 - accuracy: 0.5078 - precision_5: 0.5168 - recall_5: 0.300 - ETA: 0s - loss: 1.2338 - accuracy: 0.5174 - precision_5: 0.5370 - recall_5: 0.302 - ETA: 0s - loss: 1.2303 - accuracy: 0.5227 - precision_5: 0.5556 - recall_5: 0.298 - ETA: 0s - loss: 1.2186 - accuracy: 0.5339 - precision_5: 0.5616 - recall_5: 0.296 - ETA: 0s - loss: 1.2317 - accuracy: 0.5216 - precision_5: 0.5525 - recall_5: 0.290 - 1s 3ms/sample - loss: 1.2263 - accuracy: 0.5235 - precision_5: 0.5541 - recall_5: 0.2887 - val_loss: 1.5491 - val_accuracy: 0.3592 - val_precision_5: 0.4000 - val_recall_5: 0.1268\n",
      "Epoch 70/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5132 - accuracy: 0.4062 - precision_5: 0.6250 - recall_5: 0.156 - ETA: 0s - loss: 1.5604 - accuracy: 0.4688 - precision_5: 0.5833 - recall_5: 0.109 - ETA: 0s - loss: 1.5537 - accuracy: 0.4375 - precision_5: 0.4583 - recall_5: 0.114 - ETA: 0s - loss: 1.6325 - accuracy: 0.3984 - precision_5: 0.4516 - recall_5: 0.109 - ETA: 0s - loss: 1.5837 - accuracy: 0.3958 - precision_5: 0.5000 - recall_5: 0.135 - ETA: 0s - loss: 1.5285 - accuracy: 0.4196 - precision_5: 0.5303 - recall_5: 0.156 - ETA: 0s - loss: 1.4459 - accuracy: 0.4549 - precision_5: 0.5474 - recall_5: 0.180 - ETA: 0s - loss: 1.4242 - accuracy: 0.4688 - precision_5: 0.5741 - recall_5: 0.193 - ETA: 0s - loss: 1.3873 - accuracy: 0.4844 - precision_5: 0.5909 - recall_5: 0.203 - ETA: 0s - loss: 1.3844 - accuracy: 0.4736 - precision_5: 0.5903 - recall_5: 0.204 - 1s 2ms/sample - loss: 1.3713 - accuracy: 0.4765 - precision_5: 0.6026 - recall_5: 0.2136 - val_loss: 1.3740 - val_accuracy: 0.3803 - val_precision_5: 0.4308 - val_recall_5: 0.1972\n",
      "Epoch 71/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4978 - accuracy: 0.3750 - precision_5: 0.4375 - recall_5: 0.218 - ETA: 0s - loss: 1.3893 - accuracy: 0.3906 - precision_5: 0.4667 - recall_5: 0.218 - ETA: 0s - loss: 1.3346 - accuracy: 0.4375 - precision_5: 0.5161 - recall_5: 0.250 - ETA: 0s - loss: 1.2644 - accuracy: 0.4792 - precision_5: 0.5833 - recall_5: 0.255 - ETA: 0s - loss: 1.2231 - accuracy: 0.4866 - precision_5: 0.5938 - recall_5: 0.254 - ETA: 0s - loss: 1.2074 - accuracy: 0.5039 - precision_5: 0.6075 - recall_5: 0.253 - ETA: 0s - loss: 1.1974 - accuracy: 0.5188 - precision_5: 0.6508 - recall_5: 0.256 - ETA: 0s - loss: 1.1763 - accuracy: 0.5391 - precision_5: 0.6690 - recall_5: 0.252 - ETA: 0s - loss: 1.1791 - accuracy: 0.5312 - precision_5: 0.6519 - recall_5: 0.247 - 1s 2ms/sample - loss: 1.1722 - accuracy: 0.5352 - precision_5: 0.6587 - recall_5: 0.2582 - val_loss: 1.2754 - val_accuracy: 0.4014 - val_precision_5: 0.5000 - val_recall_5: 0.2113\n",
      "Epoch 72/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2140 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.187 - ETA: 0s - loss: 1.1461 - accuracy: 0.5000 - precision_5: 0.6829 - recall_5: 0.291 - ETA: 0s - loss: 1.1622 - accuracy: 0.4688 - precision_5: 0.6912 - recall_5: 0.293 - ETA: 0s - loss: 1.1041 - accuracy: 0.5045 - precision_5: 0.6939 - recall_5: 0.303 - ETA: 0s - loss: 1.1079 - accuracy: 0.5078 - precision_5: 0.6818 - recall_5: 0.293 - ETA: 0s - loss: 1.0905 - accuracy: 0.5375 - precision_5: 0.7143 - recall_5: 0.296 - ETA: 0s - loss: 1.0949 - accuracy: 0.5443 - precision_5: 0.7025 - recall_5: 0.289 - 1s 2ms/sample - loss: 1.0964 - accuracy: 0.5423 - precision_5: 0.6961 - recall_5: 0.2958 - val_loss: 1.3477 - val_accuracy: 0.4366 - val_precision_5: 0.5077 - val_recall_5: 0.2324\n",
      "Epoch 73/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1433 - accuracy: 0.4375 - precision_5: 0.5000 - recall_5: 0.187 - ETA: 0s - loss: 1.0386 - accuracy: 0.5521 - precision_5: 0.7105 - recall_5: 0.281 - ETA: 0s - loss: 1.0622 - accuracy: 0.5250 - precision_5: 0.7015 - recall_5: 0.293 - ETA: 0s - loss: 1.0937 - accuracy: 0.5045 - precision_5: 0.6436 - recall_5: 0.290 - ETA: 0s - loss: 1.0753 - accuracy: 0.5243 - precision_5: 0.6716 - recall_5: 0.312 - ETA: 0s - loss: 1.0968 - accuracy: 0.5341 - precision_5: 0.6584 - recall_5: 0.301 - ETA: 0s - loss: 1.1160 - accuracy: 0.5288 - precision_5: 0.6510 - recall_5: 0.300 - 1s 2ms/sample - loss: 1.1087 - accuracy: 0.5305 - precision_5: 0.6583 - recall_5: 0.3075 - val_loss: 1.2779 - val_accuracy: 0.4366 - val_precision_5: 0.5263 - val_recall_5: 0.2817\n",
      "Epoch 74/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2913 - accuracy: 0.4062 - precision_5: 0.5333 - recall_5: 0.250 - ETA: 0s - loss: 1.1074 - accuracy: 0.5312 - precision_5: 0.6275 - recall_5: 0.333 - ETA: 0s - loss: 1.1449 - accuracy: 0.5188 - precision_5: 0.6098 - recall_5: 0.312 - ETA: 0s - loss: 1.1029 - accuracy: 0.5268 - precision_5: 0.6148 - recall_5: 0.334 - ETA: 0s - loss: 1.1034 - accuracy: 0.5278 - precision_5: 0.6178 - recall_5: 0.336 - ETA: 0s - loss: 1.1284 - accuracy: 0.5250 - precision_5: 0.6215 - recall_5: 0.343 - ETA: 0s - loss: 1.1208 - accuracy: 0.5312 - precision_5: 0.6256 - recall_5: 0.330 - 1s 2ms/sample - loss: 1.1246 - accuracy: 0.5141 - precision_5: 0.6167 - recall_5: 0.3286 - val_loss: 1.3604 - val_accuracy: 0.4155 - val_precision_5: 0.5167 - val_recall_5: 0.2183\n",
      "Epoch 75/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2548 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.156 - ETA: 0s - loss: 1.0796 - accuracy: 0.5312 - precision_5: 0.7105 - recall_5: 0.281 - ETA: 0s - loss: 1.1176 - accuracy: 0.5312 - precision_5: 0.6800 - recall_5: 0.265 - ETA: 0s - loss: 1.0938 - accuracy: 0.5500 - precision_5: 0.6923 - recall_5: 0.281 - ETA: 0s - loss: 1.1055 - accuracy: 0.5312 - precision_5: 0.6768 - recall_5: 0.299 - ETA: 0s - loss: 1.0618 - accuracy: 0.5556 - precision_5: 0.6953 - recall_5: 0.309 - ETA: 0s - loss: 1.0798 - accuracy: 0.5594 - precision_5: 0.6906 - recall_5: 0.300 - ETA: 0s - loss: 1.0796 - accuracy: 0.5729 - precision_5: 0.6959 - recall_5: 0.309 - 1s 2ms/sample - loss: 1.0761 - accuracy: 0.5681 - precision_5: 0.7016 - recall_5: 0.3146 - val_loss: 1.4180 - val_accuracy: 0.3944 - val_precision_5: 0.4429 - val_recall_5: 0.2183\n",
      "Epoch 76/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2238 - accuracy: 0.4688 - precision_5: 0.5714 - recall_5: 0.250 - ETA: 0s - loss: 1.1209 - accuracy: 0.5417 - precision_5: 0.7111 - recall_5: 0.333 - ETA: 0s - loss: 1.1287 - accuracy: 0.5188 - precision_5: 0.6795 - recall_5: 0.331 - ETA: 0s - loss: 1.1168 - accuracy: 0.5312 - precision_5: 0.6989 - recall_5: 0.338 - ETA: 0s - loss: 1.0827 - accuracy: 0.5391 - precision_5: 0.6818 - recall_5: 0.351 - ETA: 0s - loss: 1.0671 - accuracy: 0.5486 - precision_5: 0.6933 - recall_5: 0.361 - ETA: 0s - loss: 1.0979 - accuracy: 0.5375 - precision_5: 0.6890 - recall_5: 0.353 - ETA: 0s - loss: 1.0874 - accuracy: 0.5455 - precision_5: 0.6875 - recall_5: 0.343 - ETA: 0s - loss: 1.0971 - accuracy: 0.5339 - precision_5: 0.6649 - recall_5: 0.335 - 1s 2ms/sample - loss: 1.1115 - accuracy: 0.5188 - precision_5: 0.6435 - recall_5: 0.3263 - val_loss: 1.3986 - val_accuracy: 0.4085 - val_precision_5: 0.4154 - val_recall_5: 0.1901\n",
      "Epoch 77/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2247 - accuracy: 0.5625 - precision_5: 0.5333 - recall_5: 0.250 - ETA: 0s - loss: 1.2233 - accuracy: 0.5000 - precision_5: 0.5217 - recall_5: 0.250 - ETA: 0s - loss: 1.1408 - accuracy: 0.5125 - precision_5: 0.6203 - recall_5: 0.306 - ETA: 0s - loss: 1.1655 - accuracy: 0.5156 - precision_5: 0.6082 - recall_5: 0.307 - ETA: 0s - loss: 1.1204 - accuracy: 0.5391 - precision_5: 0.6231 - recall_5: 0.316 - ETA: 0s - loss: 1.1039 - accuracy: 0.5437 - precision_5: 0.6625 - recall_5: 0.331 - ETA: 0s - loss: 1.1052 - accuracy: 0.5426 - precision_5: 0.6591 - recall_5: 0.329 - ETA: 0s - loss: 1.0901 - accuracy: 0.5481 - precision_5: 0.6619 - recall_5: 0.334 - 1s 2ms/sample - loss: 1.0824 - accuracy: 0.5516 - precision_5: 0.6728 - recall_5: 0.3427 - val_loss: 1.2228 - val_accuracy: 0.4507 - val_precision_5: 0.6182 - val_recall_5: 0.2394\n",
      "Epoch 78/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0947 - accuracy: 0.4688 - precision_5: 0.5000 - recall_5: 0.250 - ETA: 0s - loss: 1.0464 - accuracy: 0.5938 - precision_5: 0.7317 - recall_5: 0.312 - ETA: 0s - loss: 1.0417 - accuracy: 0.5938 - precision_5: 0.7123 - recall_5: 0.325 - ETA: 0s - loss: 1.0083 - accuracy: 0.5938 - precision_5: 0.7143 - recall_5: 0.334 - ETA: 0s - loss: 1.0231 - accuracy: 0.5972 - precision_5: 0.7239 - recall_5: 0.336 - ETA: 0s - loss: 1.0649 - accuracy: 0.5966 - precision_5: 0.7024 - recall_5: 0.335 - ETA: 0s - loss: 1.0500 - accuracy: 0.5911 - precision_5: 0.7027 - recall_5: 0.338 - 1s 2ms/sample - loss: 1.0437 - accuracy: 0.5939 - precision_5: 0.7129 - recall_5: 0.3498 - val_loss: 1.2404 - val_accuracy: 0.4437 - val_precision_5: 0.5484 - val_recall_5: 0.3592\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.2052 - accuracy: 0.3750 - precision_5: 0.5500 - recall_5: 0.343 - ETA: 0s - loss: 1.0804 - accuracy: 0.5417 - precision_5: 0.7167 - recall_5: 0.447 - ETA: 0s - loss: 1.1296 - accuracy: 0.5125 - precision_5: 0.6701 - recall_5: 0.406 - ETA: 0s - loss: 1.1094 - accuracy: 0.5208 - precision_5: 0.6695 - recall_5: 0.411 - ETA: 0s - loss: 1.0616 - accuracy: 0.5469 - precision_5: 0.6879 - recall_5: 0.421 - ETA: 0s - loss: 1.0414 - accuracy: 0.5656 - precision_5: 0.7005 - recall_5: 0.431 - ETA: 0s - loss: 1.0310 - accuracy: 0.5703 - precision_5: 0.6946 - recall_5: 0.432 - 1s 2ms/sample - loss: 1.0595 - accuracy: 0.5587 - precision_5: 0.6691 - recall_5: 0.4319 - val_loss: 1.3158 - val_accuracy: 0.4930 - val_precision_5: 0.5652 - val_recall_5: 0.3662\n",
      "Epoch 80/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2244 - accuracy: 0.5625 - precision_5: 0.6500 - recall_5: 0.406 - ETA: 0s - loss: 1.0445 - accuracy: 0.5833 - precision_5: 0.6842 - recall_5: 0.406 - ETA: 0s - loss: 1.0634 - accuracy: 0.5391 - precision_5: 0.6667 - recall_5: 0.390 - ETA: 0s - loss: 1.0644 - accuracy: 0.5437 - precision_5: 0.6562 - recall_5: 0.393 - ETA: 0s - loss: 1.0225 - accuracy: 0.5625 - precision_5: 0.6765 - recall_5: 0.410 - ETA: 0s - loss: 1.0211 - accuracy: 0.5664 - precision_5: 0.6731 - recall_5: 0.410 - ETA: 0s - loss: 1.0233 - accuracy: 0.5719 - precision_5: 0.6719 - recall_5: 0.403 - ETA: 0s - loss: 1.0036 - accuracy: 0.5833 - precision_5: 0.6798 - recall_5: 0.403 - 1s 2ms/sample - loss: 1.0078 - accuracy: 0.5775 - precision_5: 0.6865 - recall_5: 0.4061 - val_loss: 1.2242 - val_accuracy: 0.5070 - val_precision_5: 0.6111 - val_recall_5: 0.3099\n",
      "Epoch 81/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0770 - accuracy: 0.6250 - precision_5: 0.5882 - recall_5: 0.312 - ETA: 0s - loss: 1.0394 - accuracy: 0.5938 - precision_5: 0.7059 - recall_5: 0.375 - ETA: 0s - loss: 1.1075 - accuracy: 0.5312 - precision_5: 0.6522 - recall_5: 0.351 - ETA: 0s - loss: 1.0464 - accuracy: 0.5562 - precision_5: 0.6706 - recall_5: 0.356 - ETA: 0s - loss: 1.0399 - accuracy: 0.5670 - precision_5: 0.6891 - recall_5: 0.366 - ETA: 0s - loss: 1.0487 - accuracy: 0.5781 - precision_5: 0.6884 - recall_5: 0.371 - ETA: 0s - loss: 1.0593 - accuracy: 0.5781 - precision_5: 0.6946 - recall_5: 0.362 - ETA: 0s - loss: 1.0498 - accuracy: 0.5795 - precision_5: 0.6978 - recall_5: 0.360 - ETA: 0s - loss: 1.0331 - accuracy: 0.5885 - precision_5: 0.7050 - recall_5: 0.367 - ETA: 0s - loss: 1.0403 - accuracy: 0.5769 - precision_5: 0.6959 - recall_5: 0.363 - 1s 3ms/sample - loss: 1.0316 - accuracy: 0.5822 - precision_5: 0.7054 - recall_5: 0.3709 - val_loss: 1.3460 - val_accuracy: 0.4789 - val_precision_5: 0.5679 - val_recall_5: 0.3239\n",
      "Epoch 82/150\n",
      "426/426 [==============================] - ETA: 1s - loss: 1.2085 - accuracy: 0.4062 - precision_5: 0.5882 - recall_5: 0.312 - ETA: 2s - loss: 1.0947 - accuracy: 0.5000 - precision_5: 0.6970 - recall_5: 0.359 - ETA: 1s - loss: 1.0084 - accuracy: 0.5729 - precision_5: 0.7358 - recall_5: 0.406 - ETA: 0s - loss: 1.0420 - accuracy: 0.5688 - precision_5: 0.7000 - recall_5: 0.393 - ETA: 0s - loss: 1.0256 - accuracy: 0.5625 - precision_5: 0.6930 - recall_5: 0.411 - ETA: 0s - loss: 0.9984 - accuracy: 0.5804 - precision_5: 0.7023 - recall_5: 0.410 - ETA: 0s - loss: 1.0104 - accuracy: 0.5820 - precision_5: 0.6908 - recall_5: 0.410 - ETA: 0s - loss: 0.9833 - accuracy: 0.6007 - precision_5: 0.7035 - recall_5: 0.420 - ETA: 0s - loss: 1.0177 - accuracy: 0.5969 - precision_5: 0.7053 - recall_5: 0.418 - ETA: 0s - loss: 1.0188 - accuracy: 0.5909 - precision_5: 0.6990 - recall_5: 0.409 - ETA: 0s - loss: 1.0192 - accuracy: 0.5938 - precision_5: 0.7004 - recall_5: 0.414 - ETA: 0s - loss: 1.0423 - accuracy: 0.5769 - precision_5: 0.6939 - recall_5: 0.408 - 1s 3ms/sample - loss: 1.0370 - accuracy: 0.5775 - precision_5: 0.6957 - recall_5: 0.4131 - val_loss: 1.2559 - val_accuracy: 0.5000 - val_precision_5: 0.5909 - val_recall_5: 0.3662\n",
      "Epoch 83/150\n",
      "426/426 [==============================] - ETA: 1s - loss: 1.2586 - accuracy: 0.4375 - precision_5: 0.3846 - recall_5: 0.156 - ETA: 0s - loss: 1.0389 - accuracy: 0.5938 - precision_5: 0.7273 - recall_5: 0.416 - ETA: 0s - loss: 1.0597 - accuracy: 0.5813 - precision_5: 0.6667 - recall_5: 0.400 - ETA: 0s - loss: 1.0530 - accuracy: 0.5781 - precision_5: 0.6807 - recall_5: 0.421 - ETA: 0s - loss: 1.0146 - accuracy: 0.5804 - precision_5: 0.6714 - recall_5: 0.419 - ETA: 0s - loss: 1.0102 - accuracy: 0.5820 - precision_5: 0.6626 - recall_5: 0.421 - ETA: 0s - loss: 0.9916 - accuracy: 0.6031 - precision_5: 0.6768 - recall_5: 0.418 - ETA: 0s - loss: 0.9968 - accuracy: 0.6016 - precision_5: 0.6820 - recall_5: 0.424 - ETA: 0s - loss: 1.0106 - accuracy: 0.5865 - precision_5: 0.6718 - recall_5: 0.418 - 1s 3ms/sample - loss: 1.0114 - accuracy: 0.5869 - precision_5: 0.6742 - recall_5: 0.4225 - val_loss: 1.2786 - val_accuracy: 0.4859 - val_precision_5: 0.5568 - val_recall_5: 0.3451\n",
      "Epoch 84/150\n",
      "426/426 [==============================] - ETA: 1s - loss: 1.0460 - accuracy: 0.5312 - precision_5: 0.5714 - recall_5: 0.375 - ETA: 0s - loss: 0.9411 - accuracy: 0.6406 - precision_5: 0.7073 - recall_5: 0.453 - ETA: 0s - loss: 0.9718 - accuracy: 0.6172 - precision_5: 0.6744 - recall_5: 0.453 - ETA: 0s - loss: 1.0138 - accuracy: 0.5938 - precision_5: 0.6449 - recall_5: 0.431 - ETA: 0s - loss: 1.0482 - accuracy: 0.5625 - precision_5: 0.6136 - recall_5: 0.421 - ETA: 0s - loss: 1.0462 - accuracy: 0.5508 - precision_5: 0.6047 - recall_5: 0.406 - ETA: 0s - loss: 1.0110 - accuracy: 0.5660 - precision_5: 0.6335 - recall_5: 0.420 - ETA: 0s - loss: 1.0118 - accuracy: 0.5781 - precision_5: 0.6425 - recall_5: 0.415 - ETA: 0s - loss: 1.0360 - accuracy: 0.5682 - precision_5: 0.6344 - recall_5: 0.409 - ETA: 0s - loss: 1.0175 - accuracy: 0.5781 - precision_5: 0.6504 - recall_5: 0.416 - ETA: 0s - loss: 1.0377 - accuracy: 0.5649 - precision_5: 0.6415 - recall_5: 0.408 - 1s 2ms/sample - loss: 1.0356 - accuracy: 0.5610 - precision_5: 0.6397 - recall_5: 0.4085 - val_loss: 1.3726 - val_accuracy: 0.4014 - val_precision_5: 0.4750 - val_recall_5: 0.2676\n",
      "Epoch 85/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2257 - accuracy: 0.4688 - precision_5: 0.6000 - recall_5: 0.281 - ETA: 0s - loss: 1.0873 - accuracy: 0.5781 - precision_5: 0.6552 - recall_5: 0.296 - ETA: 0s - loss: 1.0476 - accuracy: 0.5781 - precision_5: 0.6721 - recall_5: 0.320 - ETA: 0s - loss: 1.0597 - accuracy: 0.5469 - precision_5: 0.6632 - recall_5: 0.328 - ETA: 0s - loss: 1.0831 - accuracy: 0.5430 - precision_5: 0.6484 - recall_5: 0.324 - ETA: 0s - loss: 1.0736 - accuracy: 0.5469 - precision_5: 0.6687 - recall_5: 0.334 - ETA: 0s - loss: 1.0459 - accuracy: 0.5703 - precision_5: 0.6881 - recall_5: 0.362 - 1s 2ms/sample - loss: 1.0377 - accuracy: 0.5775 - precision_5: 0.6872 - recall_5: 0.3662 - val_loss: 1.2254 - val_accuracy: 0.4859 - val_precision_5: 0.5125 - val_recall_5: 0.2887\n",
      "Epoch 86/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2390 - accuracy: 0.5000 - precision_5: 0.5625 - recall_5: 0.281 - ETA: 0s - loss: 1.0517 - accuracy: 0.5938 - precision_5: 0.6600 - recall_5: 0.343 - ETA: 0s - loss: 1.0977 - accuracy: 0.5703 - precision_5: 0.6087 - recall_5: 0.328 - ETA: 0s - loss: 1.0282 - accuracy: 0.5781 - precision_5: 0.6216 - recall_5: 0.359 - ETA: 0s - loss: 0.9728 - accuracy: 0.6027 - precision_5: 0.6364 - recall_5: 0.375 - ETA: 0s - loss: 0.9640 - accuracy: 0.6094 - precision_5: 0.6579 - recall_5: 0.390 - ETA: 0s - loss: 0.9308 - accuracy: 0.6354 - precision_5: 0.6879 - recall_5: 0.413 - ETA: 0s - loss: 0.9432 - accuracy: 0.6406 - precision_5: 0.6927 - recall_5: 0.415 - ETA: 0s - loss: 0.9510 - accuracy: 0.6335 - precision_5: 0.6934 - recall_5: 0.417 - ETA: 0s - loss: 0.9301 - accuracy: 0.6406 - precision_5: 0.7034 - recall_5: 0.432 - ETA: 0s - loss: 0.9489 - accuracy: 0.6322 - precision_5: 0.6965 - recall_5: 0.430 - 1s 2ms/sample - loss: 0.9437 - accuracy: 0.6338 - precision_5: 0.7045 - recall_5: 0.4366 - val_loss: 1.4530 - val_accuracy: 0.4648 - val_precision_5: 0.4674 - val_recall_5: 0.3028\n",
      "Epoch 87/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5467 - accuracy: 0.5312 - precision_5: 0.5789 - recall_5: 0.343 - ETA: 0s - loss: 1.3154 - accuracy: 0.5000 - precision_5: 0.5606 - recall_5: 0.385 - ETA: 0s - loss: 1.3164 - accuracy: 0.4688 - precision_5: 0.5294 - recall_5: 0.351 - ETA: 0s - loss: 1.2611 - accuracy: 0.4938 - precision_5: 0.5566 - recall_5: 0.368 - ETA: 0s - loss: 1.2648 - accuracy: 0.5000 - precision_5: 0.5649 - recall_5: 0.385 - ETA: 0s - loss: 1.2066 - accuracy: 0.5134 - precision_5: 0.5906 - recall_5: 0.392 - ETA: 0s - loss: 1.1606 - accuracy: 0.5391 - precision_5: 0.6199 - recall_5: 0.414 - ETA: 0s - loss: 1.1212 - accuracy: 0.5521 - precision_5: 0.6392 - recall_5: 0.430 - ETA: 0s - loss: 1.1067 - accuracy: 0.5719 - precision_5: 0.6604 - recall_5: 0.437 - ETA: 0s - loss: 1.0880 - accuracy: 0.5677 - precision_5: 0.6587 - recall_5: 0.432 - 1s 2ms/sample - loss: 1.0891 - accuracy: 0.5563 - precision_5: 0.6547 - recall_5: 0.4272 - val_loss: 1.3672 - val_accuracy: 0.4014 - val_precision_5: 0.4333 - val_recall_5: 0.2746\n",
      "Epoch 88/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1318 - accuracy: 0.5625 - precision_5: 0.5714 - recall_5: 0.375 - ETA: 0s - loss: 1.2438 - accuracy: 0.4792 - precision_5: 0.5333 - recall_5: 0.333 - ETA: 0s - loss: 1.2286 - accuracy: 0.4766 - precision_5: 0.5385 - recall_5: 0.328 - ETA: 0s - loss: 1.2691 - accuracy: 0.4812 - precision_5: 0.5474 - recall_5: 0.325 - ETA: 0s - loss: 1.2569 - accuracy: 0.4844 - precision_5: 0.5690 - recall_5: 0.343 - ETA: 0s - loss: 1.2161 - accuracy: 0.5045 - precision_5: 0.5639 - recall_5: 0.334 - ETA: 0s - loss: 1.1785 - accuracy: 0.5234 - precision_5: 0.5882 - recall_5: 0.351 - ETA: 0s - loss: 1.1250 - accuracy: 0.5562 - precision_5: 0.6186 - recall_5: 0.375 - ETA: 0s - loss: 1.1087 - accuracy: 0.5625 - precision_5: 0.6239 - recall_5: 0.386 - ETA: 0s - loss: 1.1003 - accuracy: 0.5601 - precision_5: 0.6216 - recall_5: 0.387 - 1s 2ms/sample - loss: 1.0953 - accuracy: 0.5634 - precision_5: 0.6269 - recall_5: 0.3944 - val_loss: 1.4074 - val_accuracy: 0.4789 - val_precision_5: 0.4891 - val_recall_5: 0.3169\n",
      "Epoch 89/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.4062 - precision_5: 0.5000 - recall_5: 0.312 - ETA: 0s - loss: 1.0414 - accuracy: 0.5312 - precision_5: 0.6349 - recall_5: 0.416 - ETA: 0s - loss: 1.0787 - accuracy: 0.5312 - precision_5: 0.6145 - recall_5: 0.398 - ETA: 0s - loss: 1.0414 - accuracy: 0.5469 - precision_5: 0.6508 - recall_5: 0.427 - ETA: 0s - loss: 0.9976 - accuracy: 0.5625 - precision_5: 0.6529 - recall_5: 0.433 - ETA: 0s - loss: 0.9772 - accuracy: 0.5875 - precision_5: 0.6731 - recall_5: 0.437 - ETA: 0s - loss: 0.9807 - accuracy: 0.5938 - precision_5: 0.6842 - recall_5: 0.440 - 1s 2ms/sample - loss: 1.0007 - accuracy: 0.5822 - precision_5: 0.6739 - recall_5: 0.4366 - val_loss: 1.4477 - val_accuracy: 0.4789 - val_precision_5: 0.5190 - val_recall_5: 0.2887\n",
      "Epoch 90/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.3651 - accuracy: 0.5000 - precision_5: 0.4762 - recall_5: 0.312 - ETA: 0s - loss: 1.1211 - accuracy: 0.5833 - precision_5: 0.6230 - recall_5: 0.395 - ETA: 0s - loss: 1.0723 - accuracy: 0.5875 - precision_5: 0.6421 - recall_5: 0.381 - ETA: 0s - loss: 1.0403 - accuracy: 0.5893 - precision_5: 0.6418 - recall_5: 0.383 - ETA: 0s - loss: 1.0251 - accuracy: 0.5972 - precision_5: 0.6629 - recall_5: 0.409 - ETA: 0s - loss: 1.0232 - accuracy: 0.6023 - precision_5: 0.6712 - recall_5: 0.417 - ETA: 0s - loss: 1.0071 - accuracy: 0.6094 - precision_5: 0.6695 - recall_5: 0.416 - 1s 2ms/sample - loss: 1.0202 - accuracy: 0.5845 - precision_5: 0.6442 - recall_5: 0.4038 - val_loss: 1.2229 - val_accuracy: 0.4507 - val_precision_5: 0.5181 - val_recall_5: 0.3028\n",
      "Epoch 91/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0862 - accuracy: 0.6875 - precision_5: 0.7500 - recall_5: 0.468 - ETA: 0s - loss: 1.0657 - accuracy: 0.6250 - precision_5: 0.6216 - recall_5: 0.359 - ETA: 0s - loss: 1.0494 - accuracy: 0.5703 - precision_5: 0.6667 - recall_5: 0.375 - ETA: 0s - loss: 1.0833 - accuracy: 0.5729 - precision_5: 0.6228 - recall_5: 0.369 - ETA: 0s - loss: 1.0507 - accuracy: 0.5938 - precision_5: 0.6579 - recall_5: 0.390 - ETA: 0s - loss: 1.0419 - accuracy: 0.6062 - precision_5: 0.6717 - recall_5: 0.415 - ETA: 0s - loss: 1.0554 - accuracy: 0.5990 - precision_5: 0.6667 - recall_5: 0.416 - 1s 2ms/sample - loss: 1.0774 - accuracy: 0.5775 - precision_5: 0.6448 - recall_5: 0.3920 - val_loss: 1.4595 - val_accuracy: 0.4225 - val_precision_5: 0.4474 - val_recall_5: 0.2394\n",
      "Epoch 92/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.4019 - accuracy: 0.4062 - precision_5: 0.4500 - recall_5: 0.281 - ETA: 0s - loss: 1.2713 - accuracy: 0.4896 - precision_5: 0.6038 - recall_5: 0.333 - ETA: 0s - loss: 1.2055 - accuracy: 0.5312 - precision_5: 0.6522 - recall_5: 0.375 - ETA: 0s - loss: 1.1281 - accuracy: 0.5536 - precision_5: 0.6489 - recall_5: 0.379 - ETA: 0s - loss: 1.1165 - accuracy: 0.5590 - precision_5: 0.6512 - recall_5: 0.388 - ETA: 0s - loss: 1.1046 - accuracy: 0.5682 - precision_5: 0.6731 - recall_5: 0.397 - ETA: 0s - loss: 1.1350 - accuracy: 0.5529 - precision_5: 0.6545 - recall_5: 0.387 - 1s 2ms/sample - loss: 1.1360 - accuracy: 0.5469 - precision_5: 0.6534 - recall_5: 0.3850 - val_loss: 1.6339 - val_accuracy: 0.4014 - val_precision_5: 0.4810 - val_recall_5: 0.2676\n",
      "Epoch 93/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.4688 - precision_5: 0.5294 - recall_5: 0.281 - ETA: 0s - loss: 1.3504 - accuracy: 0.5208 - precision_5: 0.5472 - recall_5: 0.302 - ETA: 0s - loss: 1.2151 - accuracy: 0.5625 - precision_5: 0.5824 - recall_5: 0.331 - ETA: 0s - loss: 1.1840 - accuracy: 0.5446 - precision_5: 0.5952 - recall_5: 0.334 - ETA: 0s - loss: 1.1480 - accuracy: 0.5451 - precision_5: 0.6168 - recall_5: 0.357 - ETA: 0s - loss: 1.1861 - accuracy: 0.5426 - precision_5: 0.6146 - recall_5: 0.358 - ETA: 0s - loss: 1.1653 - accuracy: 0.5433 - precision_5: 0.6194 - recall_5: 0.367 - 1s 2ms/sample - loss: 1.1541 - accuracy: 0.5469 - precision_5: 0.6235 - recall_5: 0.3732 - val_loss: 1.2943 - val_accuracy: 0.4155 - val_precision_5: 0.5294 - val_recall_5: 0.3169\n",
      "Epoch 94/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2656 - accuracy: 0.3750 - precision_5: 0.5000 - recall_5: 0.343 - ETA: 0s - loss: 1.1120 - accuracy: 0.5417 - precision_5: 0.6271 - recall_5: 0.385 - ETA: 0s - loss: 1.0873 - accuracy: 0.5688 - precision_5: 0.6436 - recall_5: 0.406 - ETA: 0s - loss: 1.0846 - accuracy: 0.5625 - precision_5: 0.6325 - recall_5: 0.385 - ETA: 0s - loss: 1.0384 - accuracy: 0.5759 - precision_5: 0.6444 - recall_5: 0.388 - ETA: 0s - loss: 1.0158 - accuracy: 0.5938 - precision_5: 0.6724 - recall_5: 0.406 - ETA: 0s - loss: 1.0189 - accuracy: 0.6023 - precision_5: 0.6814 - recall_5: 0.394 - ETA: 0s - loss: 1.0130 - accuracy: 0.6146 - precision_5: 0.6909 - recall_5: 0.395 - ETA: 0s - loss: 1.0349 - accuracy: 0.6034 - precision_5: 0.6809 - recall_5: 0.384 - 1s 2ms/sample - loss: 1.0359 - accuracy: 0.6009 - precision_5: 0.6763 - recall_5: 0.3826 - val_loss: 1.4117 - val_accuracy: 0.4366 - val_precision_5: 0.5068 - val_recall_5: 0.2606\n",
      "Epoch 95/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0974 - accuracy: 0.5000 - precision_5: 0.6667 - recall_5: 0.437 - ETA: 0s - loss: 0.9953 - accuracy: 0.5156 - precision_5: 0.6923 - recall_5: 0.421 - ETA: 0s - loss: 0.9874 - accuracy: 0.5547 - precision_5: 0.6750 - recall_5: 0.421 - ETA: 0s - loss: 0.9850 - accuracy: 0.5677 - precision_5: 0.6452 - recall_5: 0.416 - ETA: 0s - loss: 0.9701 - accuracy: 0.5781 - precision_5: 0.6548 - recall_5: 0.429 - ETA: 0s - loss: 0.9576 - accuracy: 0.5906 - precision_5: 0.6796 - recall_5: 0.437 - ETA: 0s - loss: 0.9525 - accuracy: 0.6042 - precision_5: 0.6908 - recall_5: 0.447 - 1s 2ms/sample - loss: 0.9664 - accuracy: 0.5962 - precision_5: 0.6810 - recall_5: 0.4460 - val_loss: 1.3720 - val_accuracy: 0.4507 - val_precision_5: 0.4783 - val_recall_5: 0.3099\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1217 - accuracy: 0.5625 - precision_5: 0.6957 - recall_5: 0.500 - ETA: 0s - loss: 1.0353 - accuracy: 0.5938 - precision_5: 0.6429 - recall_5: 0.468 - ETA: 0s - loss: 0.9863 - accuracy: 0.5875 - precision_5: 0.6455 - recall_5: 0.443 - ETA: 0s - loss: 0.9377 - accuracy: 0.5982 - precision_5: 0.6708 - recall_5: 0.482 - ETA: 0s - loss: 0.9283 - accuracy: 0.6111 - precision_5: 0.6816 - recall_5: 0.475 - ETA: 0s - loss: 0.9509 - accuracy: 0.6062 - precision_5: 0.6818 - recall_5: 0.468 - ETA: 0s - loss: 0.9623 - accuracy: 0.6068 - precision_5: 0.6742 - recall_5: 0.463 - 1s 2ms/sample - loss: 0.9496 - accuracy: 0.6197 - precision_5: 0.6959 - recall_5: 0.4836 - val_loss: 1.5227 - val_accuracy: 0.4014 - val_precision_5: 0.4742 - val_recall_5: 0.3239\n",
      "Epoch 97/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.6172 - accuracy: 0.4375 - precision_5: 0.5217 - recall_5: 0.375 - ETA: 0s - loss: 1.2220 - accuracy: 0.5104 - precision_5: 0.6377 - recall_5: 0.458 - ETA: 0s - loss: 1.1178 - accuracy: 0.5375 - precision_5: 0.6250 - recall_5: 0.437 - ETA: 0s - loss: 1.0409 - accuracy: 0.5804 - precision_5: 0.6646 - recall_5: 0.486 - ETA: 0s - loss: 1.0473 - accuracy: 0.5833 - precision_5: 0.6698 - recall_5: 0.493 - ETA: 0s - loss: 1.0634 - accuracy: 0.5881 - precision_5: 0.6743 - recall_5: 0.500 - ETA: 0s - loss: 1.0750 - accuracy: 0.5865 - precision_5: 0.6733 - recall_5: 0.490 - 1s 2ms/sample - loss: 1.0651 - accuracy: 0.5915 - precision_5: 0.6774 - recall_5: 0.4930 - val_loss: 1.2746 - val_accuracy: 0.4789 - val_precision_5: 0.5647 - val_recall_5: 0.3380\n",
      "Epoch 98/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.4375 - precision_5: 0.6316 - recall_5: 0.375 - ETA: 0s - loss: 1.0672 - accuracy: 0.5521 - precision_5: 0.6613 - recall_5: 0.427 - ETA: 0s - loss: 1.0582 - accuracy: 0.5562 - precision_5: 0.6729 - recall_5: 0.450 - ETA: 0s - loss: 1.0425 - accuracy: 0.5804 - precision_5: 0.6928 - recall_5: 0.473 - ETA: 0s - loss: 1.0163 - accuracy: 0.5729 - precision_5: 0.6990 - recall_5: 0.475 - ETA: 0s - loss: 1.0679 - accuracy: 0.5710 - precision_5: 0.6763 - recall_5: 0.463 - ETA: 0s - loss: 1.0558 - accuracy: 0.5721 - precision_5: 0.6786 - recall_5: 0.456 - 1s 2ms/sample - loss: 1.0508 - accuracy: 0.5751 - precision_5: 0.6817 - recall_5: 0.4624 - val_loss: 1.2697 - val_accuracy: 0.5282 - val_precision_5: 0.5306 - val_recall_5: 0.3662\n",
      "Epoch 99/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9939 - accuracy: 0.5938 - precision_5: 0.6522 - recall_5: 0.468 - ETA: 0s - loss: 0.9105 - accuracy: 0.6146 - precision_5: 0.7121 - recall_5: 0.489 - ETA: 0s - loss: 0.9348 - accuracy: 0.6062 - precision_5: 0.7019 - recall_5: 0.456 - ETA: 0s - loss: 0.9350 - accuracy: 0.5938 - precision_5: 0.6944 - recall_5: 0.446 - ETA: 0s - loss: 0.8962 - accuracy: 0.6250 - precision_5: 0.7135 - recall_5: 0.458 - ETA: 0s - loss: 0.9139 - accuracy: 0.6165 - precision_5: 0.7110 - recall_5: 0.440 - ETA: 0s - loss: 0.9123 - accuracy: 0.6202 - precision_5: 0.7054 - recall_5: 0.437 - 1s 2ms/sample - loss: 0.9042 - accuracy: 0.6244 - precision_5: 0.7132 - recall_5: 0.4437 - val_loss: 1.3569 - val_accuracy: 0.4648 - val_precision_5: 0.4737 - val_recall_5: 0.3169\n",
      "Epoch 100/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1242 - accuracy: 0.5938 - precision_5: 0.6818 - recall_5: 0.468 - ETA: 0s - loss: 0.9984 - accuracy: 0.6042 - precision_5: 0.6761 - recall_5: 0.500 - ETA: 0s - loss: 0.9925 - accuracy: 0.5875 - precision_5: 0.6460 - recall_5: 0.456 - ETA: 0s - loss: 0.9527 - accuracy: 0.5938 - precision_5: 0.6688 - recall_5: 0.468 - ETA: 0s - loss: 0.9231 - accuracy: 0.6146 - precision_5: 0.6850 - recall_5: 0.475 - ETA: 0s - loss: 0.9383 - accuracy: 0.6136 - precision_5: 0.6878 - recall_5: 0.463 - ETA: 0s - loss: 0.9427 - accuracy: 0.6058 - precision_5: 0.6920 - recall_5: 0.459 - 1s 2ms/sample - loss: 0.9361 - accuracy: 0.6103 - precision_5: 0.6975 - recall_5: 0.4601 - val_loss: 1.4161 - val_accuracy: 0.4366 - val_precision_5: 0.4433 - val_recall_5: 0.3028\n",
      "Epoch 101/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2122 - accuracy: 0.5312 - precision_5: 0.6000 - recall_5: 0.375 - ETA: 0s - loss: 0.9823 - accuracy: 0.6146 - precision_5: 0.7188 - recall_5: 0.479 - ETA: 0s - loss: 1.0317 - accuracy: 0.5781 - precision_5: 0.6707 - recall_5: 0.429 - ETA: 0s - loss: 0.9870 - accuracy: 0.5833 - precision_5: 0.6614 - recall_5: 0.437 - ETA: 0s - loss: 0.9823 - accuracy: 0.6016 - precision_5: 0.6647 - recall_5: 0.449 - ETA: 0s - loss: 0.9629 - accuracy: 0.6281 - precision_5: 0.6825 - recall_5: 0.450 - ETA: 0s - loss: 0.9379 - accuracy: 0.6354 - precision_5: 0.6984 - recall_5: 0.458 - 1s 2ms/sample - loss: 0.9443 - accuracy: 0.6315 - precision_5: 0.6989 - recall_5: 0.4577 - val_loss: 1.2734 - val_accuracy: 0.4577 - val_precision_5: 0.4891 - val_recall_5: 0.3169\n",
      "Epoch 102/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0144 - accuracy: 0.5938 - precision_5: 0.6364 - recall_5: 0.437 - ETA: 0s - loss: 1.0227 - accuracy: 0.5833 - precision_5: 0.6462 - recall_5: 0.437 - ETA: 0s - loss: 0.9718 - accuracy: 0.6000 - precision_5: 0.6726 - recall_5: 0.475 - ETA: 0s - loss: 0.9535 - accuracy: 0.5990 - precision_5: 0.6691 - recall_5: 0.474 - ETA: 0s - loss: 0.9323 - accuracy: 0.6161 - precision_5: 0.6832 - recall_5: 0.491 - ETA: 0s - loss: 0.9252 - accuracy: 0.6133 - precision_5: 0.6978 - recall_5: 0.496 - ETA: 0s - loss: 0.9023 - accuracy: 0.6281 - precision_5: 0.7229 - recall_5: 0.521 - ETA: 0s - loss: 0.9001 - accuracy: 0.6354 - precision_5: 0.7292 - recall_5: 0.526 - 1s 2ms/sample - loss: 0.9182 - accuracy: 0.6221 - precision_5: 0.7124 - recall_5: 0.5117 - val_loss: 1.2777 - val_accuracy: 0.4789 - val_precision_5: 0.5612 - val_recall_5: 0.3873\n",
      "Epoch 103/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9836 - accuracy: 0.6250 - precision_5: 0.7143 - recall_5: 0.468 - ETA: 0s - loss: 0.9208 - accuracy: 0.6406 - precision_5: 0.7556 - recall_5: 0.531 - ETA: 0s - loss: 0.8634 - accuracy: 0.6562 - precision_5: 0.7500 - recall_5: 0.562 - ETA: 0s - loss: 0.8982 - accuracy: 0.6328 - precision_5: 0.7021 - recall_5: 0.515 - ETA: 0s - loss: 0.9450 - accuracy: 0.6062 - precision_5: 0.6667 - recall_5: 0.487 - ETA: 0s - loss: 0.9360 - accuracy: 0.6116 - precision_5: 0.6646 - recall_5: 0.486 - ETA: 0s - loss: 0.9492 - accuracy: 0.6094 - precision_5: 0.6559 - recall_5: 0.476 - ETA: 0s - loss: 0.9230 - accuracy: 0.6250 - precision_5: 0.6731 - recall_5: 0.486 - ETA: 0s - loss: 0.9473 - accuracy: 0.6281 - precision_5: 0.6814 - recall_5: 0.481 - ETA: 0s - loss: 0.9532 - accuracy: 0.6222 - precision_5: 0.6815 - recall_5: 0.480 - ETA: 0s - loss: 0.9510 - accuracy: 0.6274 - precision_5: 0.6847 - recall_5: 0.485 - 1s 3ms/sample - loss: 0.9405 - accuracy: 0.6338 - precision_5: 0.6921 - recall_5: 0.4906 - val_loss: 1.3610 - val_accuracy: 0.4366 - val_precision_5: 0.4796 - val_recall_5: 0.3310\n",
      "Epoch 104/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1638 - accuracy: 0.5312 - precision_5: 0.6667 - recall_5: 0.375 - ETA: 0s - loss: 1.0822 - accuracy: 0.5625 - precision_5: 0.6585 - recall_5: 0.421 - ETA: 0s - loss: 1.0027 - accuracy: 0.6042 - precision_5: 0.6866 - recall_5: 0.479 - ETA: 0s - loss: 0.9843 - accuracy: 0.5938 - precision_5: 0.6882 - recall_5: 0.500 - ETA: 0s - loss: 0.9374 - accuracy: 0.5990 - precision_5: 0.6667 - recall_5: 0.500 - ETA: 0s - loss: 0.8936 - accuracy: 0.6250 - precision_5: 0.7006 - recall_5: 0.522 - ETA: 0s - loss: 0.8818 - accuracy: 0.6328 - precision_5: 0.7219 - recall_5: 0.527 - ETA: 0s - loss: 0.8596 - accuracy: 0.6562 - precision_5: 0.7445 - recall_5: 0.528 - ETA: 0s - loss: 0.8587 - accuracy: 0.6562 - precision_5: 0.7410 - recall_5: 0.528 - ETA: 0s - loss: 0.8509 - accuracy: 0.6641 - precision_5: 0.7463 - recall_5: 0.528 - 1s 2ms/sample - loss: 0.8757 - accuracy: 0.6502 - precision_5: 0.7351 - recall_5: 0.5211 - val_loss: 1.4416 - val_accuracy: 0.4437 - val_precision_5: 0.4845 - val_recall_5: 0.3310\n",
      "Epoch 105/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1435 - accuracy: 0.5000 - precision_5: 0.6111 - recall_5: 0.343 - ETA: 0s - loss: 1.1274 - accuracy: 0.5417 - precision_5: 0.6667 - recall_5: 0.458 - ETA: 0s - loss: 1.1689 - accuracy: 0.5125 - precision_5: 0.6228 - recall_5: 0.443 - ETA: 0s - loss: 1.2325 - accuracy: 0.4955 - precision_5: 0.6178 - recall_5: 0.433 - ETA: 0s - loss: 1.1799 - accuracy: 0.5312 - precision_5: 0.6615 - recall_5: 0.447 - ETA: 0s - loss: 1.1723 - accuracy: 0.5312 - precision_5: 0.6579 - recall_5: 0.426 - ETA: 0s - loss: 1.1673 - accuracy: 0.5339 - precision_5: 0.6639 - recall_5: 0.421 - ETA: 0s - loss: 1.1841 - accuracy: 0.5240 - precision_5: 0.6513 - recall_5: 0.408 - 1s 2ms/sample - loss: 1.1682 - accuracy: 0.5305 - precision_5: 0.6604 - recall_5: 0.4155 - val_loss: 1.2545 - val_accuracy: 0.4930 - val_precision_5: 0.5833 - val_recall_5: 0.2958\n",
      "Epoch 106/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1558 - accuracy: 0.4688 - precision_5: 0.5714 - recall_5: 0.250 - ETA: 0s - loss: 1.0939 - accuracy: 0.5000 - precision_5: 0.5758 - recall_5: 0.296 - ETA: 0s - loss: 0.9992 - accuracy: 0.5703 - precision_5: 0.6711 - recall_5: 0.398 - ETA: 0s - loss: 0.9711 - accuracy: 0.5833 - precision_5: 0.6838 - recall_5: 0.416 - ETA: 0s - loss: 0.9549 - accuracy: 0.6161 - precision_5: 0.7080 - recall_5: 0.433 - ETA: 0s - loss: 0.9419 - accuracy: 0.6424 - precision_5: 0.7184 - recall_5: 0.434 - ETA: 0s - loss: 0.9403 - accuracy: 0.6438 - precision_5: 0.7292 - recall_5: 0.437 - ETA: 0s - loss: 0.9554 - accuracy: 0.6335 - precision_5: 0.7075 - recall_5: 0.426 - ETA: 0s - loss: 0.9667 - accuracy: 0.6354 - precision_5: 0.7051 - recall_5: 0.429 - ETA: 0s - loss: 0.9958 - accuracy: 0.6154 - precision_5: 0.6865 - recall_5: 0.415 - 1s 2ms/sample - loss: 0.9914 - accuracy: 0.6150 - precision_5: 0.6899 - recall_5: 0.4178 - val_loss: 1.3986 - val_accuracy: 0.4366 - val_precision_5: 0.5052 - val_recall_5: 0.3451\n",
      "Epoch 107/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.6250 - precision_5: 0.7059 - recall_5: 0.375 - ETA: 0s - loss: 0.9754 - accuracy: 0.6094 - precision_5: 0.7297 - recall_5: 0.421 - ETA: 0s - loss: 0.9699 - accuracy: 0.6146 - precision_5: 0.7119 - recall_5: 0.437 - ETA: 0s - loss: 0.9838 - accuracy: 0.6016 - precision_5: 0.6750 - recall_5: 0.421 - ETA: 0s - loss: 0.9952 - accuracy: 0.5938 - precision_5: 0.6693 - recall_5: 0.442 - ETA: 0s - loss: 1.0248 - accuracy: 0.5742 - precision_5: 0.6400 - recall_5: 0.437 - ETA: 0s - loss: 1.0089 - accuracy: 0.5764 - precision_5: 0.6480 - recall_5: 0.441 - ETA: 0s - loss: 1.0413 - accuracy: 0.5719 - precision_5: 0.6560 - recall_5: 0.446 - ETA: 0s - loss: 1.0528 - accuracy: 0.5710 - precision_5: 0.6570 - recall_5: 0.451 - ETA: 0s - loss: 1.0398 - accuracy: 0.5755 - precision_5: 0.6679 - recall_5: 0.455 - ETA: 0s - loss: 1.0512 - accuracy: 0.5721 - precision_5: 0.6573 - recall_5: 0.451 - 1s 3ms/sample - loss: 1.0410 - accuracy: 0.5775 - precision_5: 0.6655 - recall_5: 0.4577 - val_loss: 1.3704 - val_accuracy: 0.4577 - val_precision_5: 0.4643 - val_recall_5: 0.3662\n",
      "Epoch 108/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.5000 - precision_5: 0.5500 - recall_5: 0.343 - ETA: 0s - loss: 1.1621 - accuracy: 0.5417 - precision_5: 0.6032 - recall_5: 0.395 - ETA: 0s - loss: 1.2004 - accuracy: 0.5063 - precision_5: 0.5688 - recall_5: 0.387 - ETA: 0s - loss: 1.1362 - accuracy: 0.5268 - precision_5: 0.5960 - recall_5: 0.401 - ETA: 0s - loss: 1.1165 - accuracy: 0.5430 - precision_5: 0.6176 - recall_5: 0.410 - ETA: 0s - loss: 1.0766 - accuracy: 0.5660 - precision_5: 0.6417 - recall_5: 0.416 - ETA: 0s - loss: 1.1007 - accuracy: 0.5594 - precision_5: 0.6488 - recall_5: 0.415 - ETA: 0s - loss: 1.0660 - accuracy: 0.5677 - precision_5: 0.6626 - recall_5: 0.419 - ETA: 0s - loss: 1.0759 - accuracy: 0.5625 - precision_5: 0.6577 - recall_5: 0.411 - 1s 2ms/sample - loss: 1.0637 - accuracy: 0.5681 - precision_5: 0.6667 - recall_5: 0.4178 - val_loss: 1.2609 - val_accuracy: 0.4648 - val_precision_5: 0.5821 - val_recall_5: 0.2746\n",
      "Epoch 109/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0702 - accuracy: 0.5000 - precision_5: 0.6923 - recall_5: 0.281 - ETA: 0s - loss: 0.9895 - accuracy: 0.5417 - precision_5: 0.6923 - recall_5: 0.375 - ETA: 0s - loss: 1.0199 - accuracy: 0.5469 - precision_5: 0.7121 - recall_5: 0.367 - ETA: 0s - loss: 1.0594 - accuracy: 0.5312 - precision_5: 0.6731 - recall_5: 0.364 - ETA: 0s - loss: 1.0666 - accuracy: 0.5446 - precision_5: 0.6967 - recall_5: 0.379 - ETA: 0s - loss: 1.0300 - accuracy: 0.5660 - precision_5: 0.7355 - recall_5: 0.395 - ETA: 0s - loss: 1.0456 - accuracy: 0.5625 - precision_5: 0.7251 - recall_5: 0.387 - ETA: 0s - loss: 1.0170 - accuracy: 0.5729 - precision_5: 0.7381 - recall_5: 0.403 - ETA: 0s - loss: 1.0271 - accuracy: 0.5649 - precision_5: 0.7143 - recall_5: 0.396 - 1s 2ms/sample - loss: 1.0157 - accuracy: 0.5728 - precision_5: 0.7215 - recall_5: 0.4014 - val_loss: 1.2262 - val_accuracy: 0.5211 - val_precision_5: 0.6250 - val_recall_5: 0.3521\n",
      "Epoch 110/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9980 - accuracy: 0.6562 - precision_5: 0.7692 - recall_5: 0.312 - ETA: 0s - loss: 0.8867 - accuracy: 0.6771 - precision_5: 0.7593 - recall_5: 0.427 - ETA: 0s - loss: 0.9185 - accuracy: 0.6562 - precision_5: 0.7128 - recall_5: 0.418 - ETA: 0s - loss: 0.9240 - accuracy: 0.6562 - precision_5: 0.7179 - recall_5: 0.437 - ETA: 0s - loss: 0.8571 - accuracy: 0.6992 - precision_5: 0.7622 - recall_5: 0.488 - ETA: 0s - loss: 0.8317 - accuracy: 0.7153 - precision_5: 0.7802 - recall_5: 0.493 - ETA: 0s - loss: 0.8518 - accuracy: 0.6989 - precision_5: 0.7699 - recall_5: 0.494 - ETA: 0s - loss: 0.8390 - accuracy: 0.7083 - precision_5: 0.7828 - recall_5: 0.497 - 1s 2ms/sample - loss: 0.8464 - accuracy: 0.6925 - precision_5: 0.7761 - recall_5: 0.4883 - val_loss: 1.2431 - val_accuracy: 0.5000 - val_precision_5: 0.5543 - val_recall_5: 0.3592\n",
      "Epoch 111/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.7188 - precision_5: 0.8000 - recall_5: 0.500 - ETA: 0s - loss: 0.8387 - accuracy: 0.6562 - precision_5: 0.7761 - recall_5: 0.541 - ETA: 0s - loss: 0.8629 - accuracy: 0.6406 - precision_5: 0.7614 - recall_5: 0.523 - ETA: 0s - loss: 0.8618 - accuracy: 0.6438 - precision_5: 0.7544 - recall_5: 0.537 - ETA: 0s - loss: 0.8700 - accuracy: 0.6458 - precision_5: 0.7609 - recall_5: 0.546 - ETA: 0s - loss: 0.8290 - accuracy: 0.6602 - precision_5: 0.7705 - recall_5: 0.550 - ETA: 0s - loss: 0.7970 - accuracy: 0.6736 - precision_5: 0.7902 - recall_5: 0.562 - ETA: 0s - loss: 0.7979 - accuracy: 0.6781 - precision_5: 0.7885 - recall_5: 0.559 - ETA: 0s - loss: 0.8076 - accuracy: 0.6705 - precision_5: 0.7840 - recall_5: 0.556 - ETA: 0s - loss: 0.7995 - accuracy: 0.6803 - precision_5: 0.7852 - recall_5: 0.562 - 1s 2ms/sample - loss: 0.7911 - accuracy: 0.6831 - precision_5: 0.7876 - recall_5: 0.5657 - val_loss: 1.2274 - val_accuracy: 0.5070 - val_precision_5: 0.5980 - val_recall_5: 0.4296\n",
      "Epoch 112/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9455 - accuracy: 0.5938 - precision_5: 0.7273 - recall_5: 0.500 - ETA: 0s - loss: 0.8012 - accuracy: 0.6771 - precision_5: 0.8235 - recall_5: 0.583 - ETA: 0s - loss: 0.7967 - accuracy: 0.6562 - precision_5: 0.8000 - recall_5: 0.575 - ETA: 0s - loss: 0.7983 - accuracy: 0.6615 - precision_5: 0.7943 - recall_5: 0.583 - ETA: 0s - loss: 0.7523 - accuracy: 0.6953 - precision_5: 0.8125 - recall_5: 0.609 - ETA: 0s - loss: 0.7391 - accuracy: 0.7063 - precision_5: 0.8193 - recall_5: 0.609 - ETA: 0s - loss: 0.7325 - accuracy: 0.7161 - precision_5: 0.8269 - recall_5: 0.609 - 1s 2ms/sample - loss: 0.7369 - accuracy: 0.7207 - precision_5: 0.8179 - recall_5: 0.6009 - val_loss: 1.2193 - val_accuracy: 0.5352 - val_precision_5: 0.5370 - val_recall_5: 0.4085\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.6250 - precision_5: 0.7500 - recall_5: 0.562 - ETA: 0s - loss: 0.7926 - accuracy: 0.6771 - precision_5: 0.7632 - recall_5: 0.604 - ETA: 0s - loss: 0.8028 - accuracy: 0.6625 - precision_5: 0.7402 - recall_5: 0.587 - ETA: 0s - loss: 0.7743 - accuracy: 0.6830 - precision_5: 0.7624 - recall_5: 0.616 - ETA: 0s - loss: 0.7347 - accuracy: 0.7153 - precision_5: 0.7854 - recall_5: 0.635 - ETA: 0s - loss: 0.7748 - accuracy: 0.6932 - precision_5: 0.7695 - recall_5: 0.616 - ETA: 0s - loss: 0.7757 - accuracy: 0.6947 - precision_5: 0.7697 - recall_5: 0.610 - 1s 2ms/sample - loss: 0.7643 - accuracy: 0.7019 - precision_5: 0.7758 - recall_5: 0.6174 - val_loss: 1.3192 - val_accuracy: 0.5423 - val_precision_5: 0.5755 - val_recall_5: 0.4296\n",
      "Epoch 114/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8793 - accuracy: 0.6562 - precision_5: 0.6250 - recall_5: 0.468 - ETA: 0s - loss: 0.7918 - accuracy: 0.6667 - precision_5: 0.7162 - recall_5: 0.552 - ETA: 0s - loss: 0.7894 - accuracy: 0.6812 - precision_5: 0.7302 - recall_5: 0.575 - ETA: 0s - loss: 0.7567 - accuracy: 0.6964 - precision_5: 0.7486 - recall_5: 0.611 - ETA: 0s - loss: 0.7408 - accuracy: 0.7153 - precision_5: 0.7637 - recall_5: 0.628 - ETA: 0s - loss: 0.7499 - accuracy: 0.7102 - precision_5: 0.7631 - recall_5: 0.622 - ETA: 0s - loss: 0.7528 - accuracy: 0.7139 - precision_5: 0.7581 - recall_5: 0.617 - 1s 2ms/sample - loss: 0.7445 - accuracy: 0.7183 - precision_5: 0.7644 - recall_5: 0.6244 - val_loss: 1.2575 - val_accuracy: 0.5352 - val_precision_5: 0.5614 - val_recall_5: 0.4507\n",
      "Epoch 115/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.7812 - precision_5: 0.8077 - recall_5: 0.656 - ETA: 0s - loss: 0.6969 - accuracy: 0.7812 - precision_5: 0.8025 - recall_5: 0.677 - ETA: 0s - loss: 0.7240 - accuracy: 0.7563 - precision_5: 0.7786 - recall_5: 0.637 - ETA: 0s - loss: 0.6970 - accuracy: 0.7589 - precision_5: 0.7861 - recall_5: 0.656 - ETA: 0s - loss: 0.6697 - accuracy: 0.7743 - precision_5: 0.8033 - recall_5: 0.680 - ETA: 0s - loss: 0.6800 - accuracy: 0.7642 - precision_5: 0.7940 - recall_5: 0.679 - ETA: 0s - loss: 0.6873 - accuracy: 0.7548 - precision_5: 0.7887 - recall_5: 0.673 - 1s 2ms/sample - loss: 0.6803 - accuracy: 0.7582 - precision_5: 0.7906 - recall_5: 0.6737 - val_loss: 1.3131 - val_accuracy: 0.5352 - val_precision_5: 0.5603 - val_recall_5: 0.4577\n",
      "Epoch 116/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8141 - accuracy: 0.6875 - precision_5: 0.7200 - recall_5: 0.562 - ETA: 0s - loss: 0.7395 - accuracy: 0.7031 - precision_5: 0.7451 - recall_5: 0.593 - ETA: 0s - loss: 0.7599 - accuracy: 0.6953 - precision_5: 0.7297 - recall_5: 0.632 - ETA: 0s - loss: 0.8073 - accuracy: 0.6823 - precision_5: 0.7083 - recall_5: 0.619 - ETA: 0s - loss: 0.7877 - accuracy: 0.6953 - precision_5: 0.7212 - recall_5: 0.636 - ETA: 0s - loss: 0.7630 - accuracy: 0.7156 - precision_5: 0.7447 - recall_5: 0.656 - ETA: 0s - loss: 0.7303 - accuracy: 0.7292 - precision_5: 0.7618 - recall_5: 0.674 - 1s 2ms/sample - loss: 0.7447 - accuracy: 0.7254 - precision_5: 0.7566 - recall_5: 0.6714 - val_loss: 1.2364 - val_accuracy: 0.5211 - val_precision_5: 0.5702 - val_recall_5: 0.4859\n",
      "Epoch 117/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.6875 - precision_5: 0.8148 - recall_5: 0.687 - ETA: 0s - loss: 0.7204 - accuracy: 0.6771 - precision_5: 0.7468 - recall_5: 0.614 - ETA: 0s - loss: 0.7605 - accuracy: 0.6687 - precision_5: 0.7197 - recall_5: 0.593 - ETA: 0s - loss: 0.7659 - accuracy: 0.6830 - precision_5: 0.7292 - recall_5: 0.625 - ETA: 0s - loss: 0.7435 - accuracy: 0.7153 - precision_5: 0.7572 - recall_5: 0.638 - ETA: 0s - loss: 0.7911 - accuracy: 0.6938 - precision_5: 0.7444 - recall_5: 0.618 - ETA: 0s - loss: 0.8403 - accuracy: 0.6667 - precision_5: 0.7188 - recall_5: 0.585 - ETA: 0s - loss: 0.8677 - accuracy: 0.6587 - precision_5: 0.7134 - recall_5: 0.574 - 1s 2ms/sample - loss: 0.8593 - accuracy: 0.6620 - precision_5: 0.7172 - recall_5: 0.5775 - val_loss: 1.3515 - val_accuracy: 0.5282 - val_precision_5: 0.5556 - val_recall_5: 0.4577\n",
      "Epoch 118/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7993 - accuracy: 0.6562 - precision_5: 0.7200 - recall_5: 0.562 - ETA: 0s - loss: 0.7433 - accuracy: 0.7083 - precision_5: 0.7564 - recall_5: 0.614 - ETA: 0s - loss: 0.7882 - accuracy: 0.6938 - precision_5: 0.7188 - recall_5: 0.575 - ETA: 0s - loss: 0.7862 - accuracy: 0.7054 - precision_5: 0.7337 - recall_5: 0.602 - ETA: 0s - loss: 0.7937 - accuracy: 0.7070 - precision_5: 0.7343 - recall_5: 0.593 - ETA: 0s - loss: 0.7932 - accuracy: 0.7094 - precision_5: 0.7500 - recall_5: 0.600 - ETA: 0s - loss: 0.8051 - accuracy: 0.6953 - precision_5: 0.7386 - recall_5: 0.588 - 1s 2ms/sample - loss: 0.8048 - accuracy: 0.6948 - precision_5: 0.7347 - recall_5: 0.5915 - val_loss: 1.2961 - val_accuracy: 0.5282 - val_precision_5: 0.5702 - val_recall_5: 0.4577\n",
      "Epoch 119/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9260 - accuracy: 0.6562 - precision_5: 0.6667 - recall_5: 0.562 - ETA: 0s - loss: 0.7767 - accuracy: 0.6771 - precision_5: 0.7215 - recall_5: 0.593 - ETA: 0s - loss: 0.8136 - accuracy: 0.6438 - precision_5: 0.7000 - recall_5: 0.568 - ETA: 0s - loss: 0.8234 - accuracy: 0.6562 - precision_5: 0.7033 - recall_5: 0.571 - ETA: 0s - loss: 0.8241 - accuracy: 0.6632 - precision_5: 0.7112 - recall_5: 0.572 - ETA: 0s - loss: 0.8345 - accuracy: 0.6705 - precision_5: 0.7283 - recall_5: 0.571 - ETA: 0s - loss: 0.8322 - accuracy: 0.6707 - precision_5: 0.7315 - recall_5: 0.569 - 1s 2ms/sample - loss: 0.8227 - accuracy: 0.6761 - precision_5: 0.7357 - recall_5: 0.5751 - val_loss: 1.3078 - val_accuracy: 0.5775 - val_precision_5: 0.5963 - val_recall_5: 0.4577\n",
      "Epoch 120/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9105 - accuracy: 0.5938 - precision_5: 0.7500 - recall_5: 0.562 - ETA: 0s - loss: 0.8080 - accuracy: 0.6875 - precision_5: 0.7531 - recall_5: 0.635 - ETA: 0s - loss: 0.9029 - accuracy: 0.6438 - precision_5: 0.7037 - recall_5: 0.593 - ETA: 0s - loss: 0.9483 - accuracy: 0.6295 - precision_5: 0.6786 - recall_5: 0.593 - ETA: 0s - loss: 0.9085 - accuracy: 0.6285 - precision_5: 0.6786 - recall_5: 0.593 - ETA: 0s - loss: 0.9366 - accuracy: 0.6307 - precision_5: 0.6786 - recall_5: 0.593 - ETA: 0s - loss: 0.9516 - accuracy: 0.6328 - precision_5: 0.6766 - recall_5: 0.588 - 1s 2ms/sample - loss: 0.9819 - accuracy: 0.6268 - precision_5: 0.6685 - recall_5: 0.5775 - val_loss: 1.3205 - val_accuracy: 0.4718 - val_precision_5: 0.5315 - val_recall_5: 0.4155\n",
      "Epoch 121/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1631 - accuracy: 0.5000 - precision_5: 0.5200 - recall_5: 0.406 - ETA: 0s - loss: 0.9974 - accuracy: 0.5521 - precision_5: 0.6104 - recall_5: 0.489 - ETA: 0s - loss: 0.9606 - accuracy: 0.6062 - precision_5: 0.6457 - recall_5: 0.512 - ETA: 0s - loss: 0.9036 - accuracy: 0.6250 - precision_5: 0.6667 - recall_5: 0.544 - ETA: 0s - loss: 0.8956 - accuracy: 0.6328 - precision_5: 0.6699 - recall_5: 0.546 - ETA: 0s - loss: 0.8833 - accuracy: 0.6375 - precision_5: 0.6795 - recall_5: 0.550 - ETA: 0s - loss: 0.8856 - accuracy: 0.6420 - precision_5: 0.6866 - recall_5: 0.554 - ETA: 0s - loss: 0.8899 - accuracy: 0.6394 - precision_5: 0.6795 - recall_5: 0.550 - 1s 2ms/sample - loss: 0.8775 - accuracy: 0.6455 - precision_5: 0.6870 - recall_5: 0.5563 - val_loss: 1.2235 - val_accuracy: 0.5352 - val_precision_5: 0.5648 - val_recall_5: 0.4296\n",
      "Epoch 122/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.7188 - precision_5: 0.7500 - recall_5: 0.468 - ETA: 0s - loss: 0.8151 - accuracy: 0.7083 - precision_5: 0.7600 - recall_5: 0.593 - ETA: 0s - loss: 0.8476 - accuracy: 0.6797 - precision_5: 0.7353 - recall_5: 0.585 - ETA: 0s - loss: 0.8452 - accuracy: 0.6750 - precision_5: 0.7154 - recall_5: 0.581 - ETA: 0s - loss: 0.8452 - accuracy: 0.6696 - precision_5: 0.7021 - recall_5: 0.589 - ETA: 0s - loss: 0.8427 - accuracy: 0.6758 - precision_5: 0.7150 - recall_5: 0.597 - ETA: 0s - loss: 0.8253 - accuracy: 0.6844 - precision_5: 0.7280 - recall_5: 0.593 - ETA: 0s - loss: 0.7927 - accuracy: 0.7005 - precision_5: 0.7468 - recall_5: 0.599 - ETA: 0s - loss: 0.8121 - accuracy: 0.6875 - precision_5: 0.7372 - recall_5: 0.586 - 1s 2ms/sample - loss: 0.8035 - accuracy: 0.6901 - precision_5: 0.7404 - recall_5: 0.5892 - val_loss: 1.3121 - val_accuracy: 0.5563 - val_precision_5: 0.6019 - val_recall_5: 0.4366\n",
      "Epoch 123/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8966 - accuracy: 0.6562 - precision_5: 0.7500 - recall_5: 0.562 - ETA: 0s - loss: 0.8242 - accuracy: 0.6719 - precision_5: 0.7708 - recall_5: 0.578 - ETA: 0s - loss: 0.8653 - accuracy: 0.6641 - precision_5: 0.7525 - recall_5: 0.593 - ETA: 0s - loss: 0.8314 - accuracy: 0.6687 - precision_5: 0.7540 - recall_5: 0.593 - ETA: 0s - loss: 0.7702 - accuracy: 0.6964 - precision_5: 0.7680 - recall_5: 0.620 - ETA: 0s - loss: 0.7704 - accuracy: 0.7031 - precision_5: 0.7703 - recall_5: 0.628 - ETA: 0s - loss: 0.7439 - accuracy: 0.7257 - precision_5: 0.7854 - recall_5: 0.635 - ETA: 0s - loss: 0.7751 - accuracy: 0.7156 - precision_5: 0.7791 - recall_5: 0.628 - ETA: 0s - loss: 0.7750 - accuracy: 0.7161 - precision_5: 0.7799 - recall_5: 0.627 - ETA: 0s - loss: 0.7848 - accuracy: 0.7043 - precision_5: 0.7711 - recall_5: 0.615 - 1s 2ms/sample - loss: 0.7741 - accuracy: 0.7089 - precision_5: 0.7765 - recall_5: 0.6197 - val_loss: 1.1469 - val_accuracy: 0.5915 - val_precision_5: 0.6239 - val_recall_5: 0.4789\n",
      "Epoch 124/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7612 - accuracy: 0.7188 - precision_5: 0.8261 - recall_5: 0.593 - ETA: 0s - loss: 0.7563 - accuracy: 0.7188 - precision_5: 0.8333 - recall_5: 0.625 - ETA: 0s - loss: 0.7908 - accuracy: 0.6953 - precision_5: 0.7524 - recall_5: 0.617 - ETA: 0s - loss: 0.7752 - accuracy: 0.6812 - precision_5: 0.7368 - recall_5: 0.612 - ETA: 0s - loss: 0.7396 - accuracy: 0.7009 - precision_5: 0.7487 - recall_5: 0.625 - ETA: 0s - loss: 0.7191 - accuracy: 0.7188 - precision_5: 0.7685 - recall_5: 0.648 - ETA: 0s - loss: 0.7114 - accuracy: 0.7281 - precision_5: 0.7852 - recall_5: 0.662 - ETA: 0s - loss: 0.7605 - accuracy: 0.7188 - precision_5: 0.7718 - recall_5: 0.653 - ETA: 0s - loss: 0.7633 - accuracy: 0.7188 - precision_5: 0.7672 - recall_5: 0.641 - 1s 2ms/sample - loss: 0.7516 - accuracy: 0.7230 - precision_5: 0.7731 - recall_5: 0.6479 - val_loss: 1.2888 - val_accuracy: 0.5352 - val_precision_5: 0.5963 - val_recall_5: 0.4577\n",
      "Epoch 125/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0850 - accuracy: 0.5625 - precision_5: 0.6957 - recall_5: 0.500 - ETA: 0s - loss: 0.8404 - accuracy: 0.7031 - precision_5: 0.8000 - recall_5: 0.625 - ETA: 0s - loss: 0.8924 - accuracy: 0.6875 - precision_5: 0.7564 - recall_5: 0.614 - ETA: 0s - loss: 0.8224 - accuracy: 0.7000 - precision_5: 0.7576 - recall_5: 0.625 - ETA: 0s - loss: 0.8067 - accuracy: 0.6964 - precision_5: 0.7581 - recall_5: 0.629 - ETA: 0s - loss: 0.8157 - accuracy: 0.6992 - precision_5: 0.7477 - recall_5: 0.625 - ETA: 0s - loss: 0.7935 - accuracy: 0.7125 - precision_5: 0.7630 - recall_5: 0.643 - ETA: 0s - loss: 0.7808 - accuracy: 0.7214 - precision_5: 0.7740 - recall_5: 0.651 - 1s 2ms/sample - loss: 0.7865 - accuracy: 0.7136 - precision_5: 0.7731 - recall_5: 0.6479 - val_loss: 1.1724 - val_accuracy: 0.6197 - val_precision_5: 0.6410 - val_recall_5: 0.5282\n",
      "Epoch 126/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9009 - accuracy: 0.6562 - precision_5: 0.6957 - recall_5: 0.500 - ETA: 0s - loss: 0.8302 - accuracy: 0.6979 - precision_5: 0.7179 - recall_5: 0.583 - ETA: 0s - loss: 0.8260 - accuracy: 0.6875 - precision_5: 0.7170 - recall_5: 0.593 - ETA: 0s - loss: 0.7694 - accuracy: 0.7000 - precision_5: 0.7388 - recall_5: 0.618 - ETA: 0s - loss: 0.7666 - accuracy: 0.6927 - precision_5: 0.7329 - recall_5: 0.614 - ETA: 0s - loss: 0.7157 - accuracy: 0.7232 - precision_5: 0.7672 - recall_5: 0.647 - ETA: 0s - loss: 0.7323 - accuracy: 0.7266 - precision_5: 0.7752 - recall_5: 0.660 - ETA: 0s - loss: 0.6928 - accuracy: 0.7437 - precision_5: 0.7950 - recall_5: 0.690 - ETA: 0s - loss: 0.7023 - accuracy: 0.7358 - precision_5: 0.7850 - recall_5: 0.684 - ETA: 0s - loss: 0.7082 - accuracy: 0.7308 - precision_5: 0.7824 - recall_5: 0.682 - 1s 2ms/sample - loss: 0.6951 - accuracy: 0.7371 - precision_5: 0.7882 - recall_5: 0.6901 - val_loss: 1.1638 - val_accuracy: 0.5986 - val_precision_5: 0.6328 - val_recall_5: 0.5704\n",
      "Epoch 127/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.8438 - precision_5: 0.8519 - recall_5: 0.718 - ETA: 0s - loss: 0.6743 - accuracy: 0.8021 - precision_5: 0.8214 - recall_5: 0.718 - ETA: 0s - loss: 0.6684 - accuracy: 0.8000 - precision_5: 0.8069 - recall_5: 0.731 - ETA: 0s - loss: 0.6674 - accuracy: 0.7857 - precision_5: 0.7941 - recall_5: 0.723 - ETA: 0s - loss: 0.6390 - accuracy: 0.7986 - precision_5: 0.8068 - recall_5: 0.739 - ETA: 0s - loss: 0.6488 - accuracy: 0.7898 - precision_5: 0.8062 - recall_5: 0.733 - ETA: 0s - loss: 0.6330 - accuracy: 0.7969 - precision_5: 0.8138 - recall_5: 0.739 - ETA: 0s - loss: 0.6535 - accuracy: 0.7909 - precision_5: 0.8059 - recall_5: 0.728 - 1s 2ms/sample - loss: 0.6430 - accuracy: 0.7958 - precision_5: 0.8104 - recall_5: 0.7324 - val_loss: 1.2165 - val_accuracy: 0.6127 - val_precision_5: 0.6218 - val_recall_5: 0.5211\n",
      "Epoch 128/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.7188 - precision_5: 0.8077 - recall_5: 0.656 - ETA: 0s - loss: 0.6368 - accuracy: 0.7812 - precision_5: 0.8193 - recall_5: 0.708 - ETA: 0s - loss: 0.6620 - accuracy: 0.7563 - precision_5: 0.7872 - recall_5: 0.693 - ETA: 0s - loss: 0.6414 - accuracy: 0.7589 - precision_5: 0.7908 - recall_5: 0.692 - ETA: 0s - loss: 0.6223 - accuracy: 0.7778 - precision_5: 0.8088 - recall_5: 0.704 - ETA: 0s - loss: 0.6208 - accuracy: 0.7812 - precision_5: 0.8206 - recall_5: 0.701 - ETA: 0s - loss: 0.6390 - accuracy: 0.7620 - precision_5: 0.8034 - recall_5: 0.687 - 1s 2ms/sample - loss: 0.6284 - accuracy: 0.7676 - precision_5: 0.8087 - recall_5: 0.6948 - val_loss: 1.1822 - val_accuracy: 0.5634 - val_precision_5: 0.5840 - val_recall_5: 0.5141\n",
      "Epoch 129/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.8125 - precision_5: 0.8214 - recall_5: 0.718 - ETA: 0s - loss: 0.6266 - accuracy: 0.7708 - precision_5: 0.8000 - recall_5: 0.708 - ETA: 0s - loss: 0.6952 - accuracy: 0.7578 - precision_5: 0.7807 - recall_5: 0.695 - ETA: 0s - loss: 0.7230 - accuracy: 0.7292 - precision_5: 0.7514 - recall_5: 0.677 - ETA: 0s - loss: 0.7099 - accuracy: 0.7321 - precision_5: 0.7624 - recall_5: 0.687 - ETA: 0s - loss: 0.7112 - accuracy: 0.7227 - precision_5: 0.7576 - recall_5: 0.683 - ETA: 0s - loss: 0.6805 - accuracy: 0.7361 - precision_5: 0.7722 - recall_5: 0.694 - ETA: 0s - loss: 0.7102 - accuracy: 0.7273 - precision_5: 0.7619 - recall_5: 0.681 - ETA: 0s - loss: 0.6989 - accuracy: 0.7318 - precision_5: 0.7668 - recall_5: 0.684 - 1s 2ms/sample - loss: 0.7027 - accuracy: 0.7277 - precision_5: 0.7664 - recall_5: 0.6854 - val_loss: 1.2623 - val_accuracy: 0.5704 - val_precision_5: 0.6080 - val_recall_5: 0.5352\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - ETA: 0s - loss: 1.1491 - accuracy: 0.5938 - precision_5: 0.7391 - recall_5: 0.531 - ETA: 0s - loss: 0.8743 - accuracy: 0.6979 - precision_5: 0.7901 - recall_5: 0.666 - ETA: 0s - loss: 0.9090 - accuracy: 0.6797 - precision_5: 0.7545 - recall_5: 0.648 - ETA: 0s - loss: 0.8578 - accuracy: 0.6875 - precision_5: 0.7412 - recall_5: 0.656 - ETA: 0s - loss: 0.7440 - accuracy: 0.7422 - precision_5: 0.7895 - recall_5: 0.703 - ETA: 0s - loss: 0.7254 - accuracy: 0.7431 - precision_5: 0.7945 - recall_5: 0.697 - ETA: 0s - loss: 0.7310 - accuracy: 0.7437 - precision_5: 0.7936 - recall_5: 0.696 - ETA: 0s - loss: 0.7694 - accuracy: 0.7292 - precision_5: 0.7798 - recall_5: 0.682 - 1s 2ms/sample - loss: 0.7804 - accuracy: 0.7183 - precision_5: 0.7715 - recall_5: 0.6737 - val_loss: 1.5620 - val_accuracy: 0.4930 - val_precision_5: 0.5254 - val_recall_5: 0.4366\n",
      "Epoch 131/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.2264 - accuracy: 0.5000 - precision_5: 0.6154 - recall_5: 0.500 - ETA: 0s - loss: 1.1992 - accuracy: 0.5625 - precision_5: 0.6125 - recall_5: 0.510 - ETA: 0s - loss: 1.1593 - accuracy: 0.5781 - precision_5: 0.6346 - recall_5: 0.515 - ETA: 0s - loss: 1.1040 - accuracy: 0.5990 - precision_5: 0.6497 - recall_5: 0.531 - ETA: 0s - loss: 1.0695 - accuracy: 0.6027 - precision_5: 0.6556 - recall_5: 0.526 - ETA: 0s - loss: 1.0079 - accuracy: 0.6319 - precision_5: 0.6943 - recall_5: 0.552 - ETA: 0s - loss: 0.9999 - accuracy: 0.6313 - precision_5: 0.6960 - recall_5: 0.543 - ETA: 0s - loss: 0.9946 - accuracy: 0.6307 - precision_5: 0.6949 - recall_5: 0.536 - ETA: 0s - loss: 0.9659 - accuracy: 0.6406 - precision_5: 0.7045 - recall_5: 0.533 - ETA: 0s - loss: 0.9588 - accuracy: 0.6418 - precision_5: 0.7129 - recall_5: 0.531 - 1s 2ms/sample - loss: 0.9439 - accuracy: 0.6479 - precision_5: 0.7201 - recall_5: 0.5376 - val_loss: 1.3968 - val_accuracy: 0.5141 - val_precision_5: 0.5604 - val_recall_5: 0.3592\n",
      "Epoch 132/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.6250 - precision_5: 0.7619 - recall_5: 0.500 - ETA: 0s - loss: 0.8912 - accuracy: 0.6562 - precision_5: 0.8036 - recall_5: 0.468 - ETA: 0s - loss: 0.9049 - accuracy: 0.6562 - precision_5: 0.8000 - recall_5: 0.468 - ETA: 0s - loss: 0.9021 - accuracy: 0.6354 - precision_5: 0.7876 - recall_5: 0.463 - ETA: 0s - loss: 0.8556 - accuracy: 0.6741 - precision_5: 0.8134 - recall_5: 0.486 - ETA: 0s - loss: 0.8591 - accuracy: 0.6667 - precision_5: 0.8208 - recall_5: 0.493 - ETA: 0s - loss: 0.9076 - accuracy: 0.6506 - precision_5: 0.7820 - recall_5: 0.468 - ETA: 0s - loss: 0.9034 - accuracy: 0.6466 - precision_5: 0.7795 - recall_5: 0.476 - 1s 2ms/sample - loss: 0.8912 - accuracy: 0.6479 - precision_5: 0.7854 - recall_5: 0.4812 - val_loss: 1.4620 - val_accuracy: 0.5141 - val_precision_5: 0.4945 - val_recall_5: 0.3169\n",
      "Epoch 133/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1961 - accuracy: 0.6250 - precision_5: 0.6667 - recall_5: 0.437 - ETA: 0s - loss: 1.0127 - accuracy: 0.6667 - precision_5: 0.7333 - recall_5: 0.458 - ETA: 0s - loss: 1.0550 - accuracy: 0.6375 - precision_5: 0.7083 - recall_5: 0.425 - ETA: 0s - loss: 1.0127 - accuracy: 0.6615 - precision_5: 0.7395 - recall_5: 0.458 - ETA: 0s - loss: 1.0544 - accuracy: 0.6484 - precision_5: 0.7215 - recall_5: 0.445 - ETA: 0s - loss: 1.0331 - accuracy: 0.6597 - precision_5: 0.7330 - recall_5: 0.447 - ETA: 0s - loss: 1.0743 - accuracy: 0.6335 - precision_5: 0.7321 - recall_5: 0.434 - ETA: 0s - loss: 1.0762 - accuracy: 0.6250 - precision_5: 0.7162 - recall_5: 0.427 - ETA: 0s - loss: 1.0888 - accuracy: 0.6130 - precision_5: 0.7080 - recall_5: 0.425 - 1s 2ms/sample - loss: 1.0882 - accuracy: 0.6127 - precision_5: 0.7109 - recall_5: 0.4272 - val_loss: 1.6638 - val_accuracy: 0.4155 - val_precision_5: 0.4872 - val_recall_5: 0.2676\n",
      "Epoch 134/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.5405 - accuracy: 0.4375 - precision_5: 0.5294 - recall_5: 0.281 - ETA: 0s - loss: 1.3647 - accuracy: 0.4531 - precision_5: 0.5294 - recall_5: 0.281 - ETA: 0s - loss: 1.3030 - accuracy: 0.4688 - precision_5: 0.5490 - recall_5: 0.291 - ETA: 0s - loss: 1.1642 - accuracy: 0.5188 - precision_5: 0.6628 - recall_5: 0.356 - ETA: 0s - loss: 1.1152 - accuracy: 0.5580 - precision_5: 0.7063 - recall_5: 0.397 - ETA: 0s - loss: 1.1246 - accuracy: 0.5547 - precision_5: 0.6944 - recall_5: 0.390 - ETA: 0s - loss: 1.1466 - accuracy: 0.5469 - precision_5: 0.6875 - recall_5: 0.378 - ETA: 0s - loss: 1.1414 - accuracy: 0.5483 - precision_5: 0.6891 - recall_5: 0.377 - ETA: 0s - loss: 1.1055 - accuracy: 0.5721 - precision_5: 0.7069 - recall_5: 0.394 - 1s 2ms/sample - loss: 1.0883 - accuracy: 0.5798 - precision_5: 0.7155 - recall_5: 0.4014 - val_loss: 1.3564 - val_accuracy: 0.5000 - val_precision_5: 0.5904 - val_recall_5: 0.3451\n",
      "Epoch 135/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1453 - accuracy: 0.4375 - precision_5: 0.5789 - recall_5: 0.343 - ETA: 0s - loss: 1.1240 - accuracy: 0.5729 - precision_5: 0.6724 - recall_5: 0.406 - ETA: 0s - loss: 1.1257 - accuracy: 0.5562 - precision_5: 0.7065 - recall_5: 0.406 - ETA: 0s - loss: 1.1308 - accuracy: 0.5573 - precision_5: 0.6937 - recall_5: 0.401 - ETA: 0s - loss: 1.0827 - accuracy: 0.5848 - precision_5: 0.7077 - recall_5: 0.410 - ETA: 0s - loss: 1.0572 - accuracy: 0.5977 - precision_5: 0.7248 - recall_5: 0.421 - ETA: 0s - loss: 1.0063 - accuracy: 0.6250 - precision_5: 0.7396 - recall_5: 0.434 - ETA: 0s - loss: 0.9808 - accuracy: 0.6307 - precision_5: 0.7571 - recall_5: 0.451 - ETA: 0s - loss: 1.0083 - accuracy: 0.6130 - precision_5: 0.7247 - recall_5: 0.430 - 1s 2ms/sample - loss: 0.9912 - accuracy: 0.6197 - precision_5: 0.7344 - recall_5: 0.4413 - val_loss: 1.2214 - val_accuracy: 0.5563 - val_precision_5: 0.6386 - val_recall_5: 0.3732\n",
      "Epoch 136/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.0113 - accuracy: 0.7188 - precision_5: 0.8125 - recall_5: 0.406 - ETA: 0s - loss: 0.9252 - accuracy: 0.6875 - precision_5: 0.7500 - recall_5: 0.468 - ETA: 0s - loss: 0.9600 - accuracy: 0.6484 - precision_5: 0.7342 - recall_5: 0.453 - ETA: 0s - loss: 0.9238 - accuracy: 0.6510 - precision_5: 0.7750 - recall_5: 0.484 - ETA: 0s - loss: 0.8850 - accuracy: 0.6680 - precision_5: 0.7914 - recall_5: 0.503 - ETA: 0s - loss: 0.8568 - accuracy: 0.6771 - precision_5: 0.7935 - recall_5: 0.506 - ETA: 0s - loss: 0.8514 - accuracy: 0.6847 - precision_5: 0.8044 - recall_5: 0.514 - ETA: 0s - loss: 0.8374 - accuracy: 0.6979 - precision_5: 0.8138 - recall_5: 0.523 - ETA: 0s - loss: 0.8520 - accuracy: 0.6851 - precision_5: 0.8000 - recall_5: 0.519 - 1s 2ms/sample - loss: 0.8400 - accuracy: 0.6878 - precision_5: 0.8029 - recall_5: 0.5258 - val_loss: 1.1399 - val_accuracy: 0.5845 - val_precision_5: 0.6404 - val_recall_5: 0.4014\n",
      "Epoch 137/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.7188 - precision_5: 0.8182 - recall_5: 0.562 - ETA: 0s - loss: 0.7608 - accuracy: 0.7188 - precision_5: 0.8082 - recall_5: 0.614 - ETA: 0s - loss: 0.8166 - accuracy: 0.6875 - precision_5: 0.7812 - recall_5: 0.585 - ETA: 0s - loss: 0.7972 - accuracy: 0.6875 - precision_5: 0.7899 - recall_5: 0.587 - ETA: 0s - loss: 0.7375 - accuracy: 0.7277 - precision_5: 0.8150 - recall_5: 0.629 - ETA: 0s - loss: 0.7323 - accuracy: 0.7396 - precision_5: 0.8241 - recall_5: 0.618 - ETA: 0s - loss: 0.7570 - accuracy: 0.7301 - precision_5: 0.8147 - recall_5: 0.599 - ETA: 0s - loss: 0.7533 - accuracy: 0.7344 - precision_5: 0.8185 - recall_5: 0.599 - ETA: 0s - loss: 0.7640 - accuracy: 0.7284 - precision_5: 0.8072 - recall_5: 0.593 - 1s 2ms/sample - loss: 0.7510 - accuracy: 0.7347 - precision_5: 0.8127 - recall_5: 0.6009 - val_loss: 1.1792 - val_accuracy: 0.6268 - val_precision_5: 0.6600 - val_recall_5: 0.4648\n",
      "Epoch 138/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.7500 - precision_5: 0.8261 - recall_5: 0.593 - ETA: 0s - loss: 0.7487 - accuracy: 0.7292 - precision_5: 0.8026 - recall_5: 0.635 - ETA: 0s - loss: 0.7552 - accuracy: 0.7250 - precision_5: 0.7874 - recall_5: 0.625 - ETA: 0s - loss: 0.6970 - accuracy: 0.7679 - precision_5: 0.8132 - recall_5: 0.660 - ETA: 0s - loss: 0.6836 - accuracy: 0.7743 - precision_5: 0.8263 - recall_5: 0.677 - ETA: 0s - loss: 0.6915 - accuracy: 0.7781 - precision_5: 0.8264 - recall_5: 0.684 - ETA: 0s - loss: 0.6810 - accuracy: 0.7786 - precision_5: 0.8243 - recall_5: 0.671 - 1s 2ms/sample - loss: 0.6938 - accuracy: 0.7700 - precision_5: 0.8156 - recall_5: 0.6643 - val_loss: 1.1001 - val_accuracy: 0.6127 - val_precision_5: 0.6525 - val_recall_5: 0.5423\n",
      "Epoch 139/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7088 - accuracy: 0.7812 - precision_5: 0.8400 - recall_5: 0.656 - ETA: 0s - loss: 0.6802 - accuracy: 0.7500 - precision_5: 0.8025 - recall_5: 0.677 - ETA: 0s - loss: 0.7380 - accuracy: 0.7188 - precision_5: 0.7798 - recall_5: 0.664 - ETA: 0s - loss: 0.7286 - accuracy: 0.7250 - precision_5: 0.7810 - recall_5: 0.668 - ETA: 0s - loss: 0.6719 - accuracy: 0.7545 - precision_5: 0.8063 - recall_5: 0.687 - ETA: 0s - loss: 0.6368 - accuracy: 0.7674 - precision_5: 0.8264 - recall_5: 0.694 - ETA: 0s - loss: 0.6442 - accuracy: 0.7656 - precision_5: 0.8240 - recall_5: 0.687 - ETA: 0s - loss: 0.6341 - accuracy: 0.7734 - precision_5: 0.8370 - recall_5: 0.695 - ETA: 0s - loss: 0.6562 - accuracy: 0.7620 - precision_5: 0.8184 - recall_5: 0.682 - 1s 2ms/sample - loss: 0.6482 - accuracy: 0.7629 - precision_5: 0.8202 - recall_5: 0.6854 - val_loss: 1.1839 - val_accuracy: 0.6268 - val_precision_5: 0.6422 - val_recall_5: 0.4930\n",
      "Epoch 140/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8076 - accuracy: 0.6562 - precision_5: 0.8261 - recall_5: 0.593 - ETA: 0s - loss: 0.6865 - accuracy: 0.7500 - precision_5: 0.8571 - recall_5: 0.656 - ETA: 0s - loss: 0.6744 - accuracy: 0.7500 - precision_5: 0.8113 - recall_5: 0.671 - ETA: 0s - loss: 0.6769 - accuracy: 0.7437 - precision_5: 0.8092 - recall_5: 0.662 - ETA: 0s - loss: 0.6876 - accuracy: 0.7344 - precision_5: 0.7950 - recall_5: 0.666 - ETA: 0s - loss: 0.6605 - accuracy: 0.7578 - precision_5: 0.8186 - recall_5: 0.687 - ETA: 0s - loss: 0.6631 - accuracy: 0.7750 - precision_5: 0.8271 - recall_5: 0.687 - ETA: 0s - loss: 0.6412 - accuracy: 0.7812 - precision_5: 0.8423 - recall_5: 0.695 - 1s 2ms/sample - loss: 0.6705 - accuracy: 0.7653 - precision_5: 0.8239 - recall_5: 0.6808 - val_loss: 1.3544 - val_accuracy: 0.5423 - val_precision_5: 0.5619 - val_recall_5: 0.4155\n",
      "Epoch 141/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 1.1560 - accuracy: 0.5938 - precision_5: 0.6923 - recall_5: 0.562 - ETA: 0s - loss: 0.8832 - accuracy: 0.6771 - precision_5: 0.7229 - recall_5: 0.625 - ETA: 0s - loss: 0.8634 - accuracy: 0.6797 - precision_5: 0.7315 - recall_5: 0.617 - ETA: 0s - loss: 0.7941 - accuracy: 0.7188 - precision_5: 0.7500 - recall_5: 0.656 - ETA: 0s - loss: 0.7545 - accuracy: 0.7422 - precision_5: 0.7768 - recall_5: 0.679 - ETA: 0s - loss: 0.7390 - accuracy: 0.7469 - precision_5: 0.7857 - recall_5: 0.687 - ETA: 0s - loss: 0.7260 - accuracy: 0.7474 - precision_5: 0.7868 - recall_5: 0.682 - ETA: 0s - loss: 0.7316 - accuracy: 0.7404 - precision_5: 0.7827 - recall_5: 0.675 - 1s 2ms/sample - loss: 0.7200 - accuracy: 0.7441 - precision_5: 0.7859 - recall_5: 0.6808 - val_loss: 1.1278 - val_accuracy: 0.6549 - val_precision_5: 0.6810 - val_recall_5: 0.5563\n",
      "Epoch 142/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8362 - accuracy: 0.6875 - precision_5: 0.7586 - recall_5: 0.687 - ETA: 0s - loss: 0.7114 - accuracy: 0.7188 - precision_5: 0.7931 - recall_5: 0.718 - ETA: 0s - loss: 0.6549 - accuracy: 0.7396 - precision_5: 0.7865 - recall_5: 0.729 - ETA: 0s - loss: 0.6617 - accuracy: 0.7422 - precision_5: 0.7863 - recall_5: 0.718 - ETA: 0s - loss: 0.6440 - accuracy: 0.7448 - precision_5: 0.7829 - recall_5: 0.713 - ETA: 0s - loss: 0.6209 - accuracy: 0.7578 - precision_5: 0.8052 - recall_5: 0.726 - ETA: 0s - loss: 0.6067 - accuracy: 0.7708 - precision_5: 0.8123 - recall_5: 0.736 - ETA: 0s - loss: 0.6055 - accuracy: 0.7756 - precision_5: 0.8208 - recall_5: 0.741 - ETA: 0s - loss: 0.6100 - accuracy: 0.7692 - precision_5: 0.8090 - recall_5: 0.733 - 1s 2ms/sample - loss: 0.5976 - accuracy: 0.7746 - precision_5: 0.8140 - recall_5: 0.7394 - val_loss: 1.1620 - val_accuracy: 0.6056 - val_precision_5: 0.6279 - val_recall_5: 0.5704\n",
      "Epoch 143/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.7500 - precision_5: 0.7931 - recall_5: 0.718 - ETA: 0s - loss: 0.6930 - accuracy: 0.7396 - precision_5: 0.7701 - recall_5: 0.697 - ETA: 0s - loss: 0.7210 - accuracy: 0.7266 - precision_5: 0.7586 - recall_5: 0.687 - ETA: 0s - loss: 0.6793 - accuracy: 0.7344 - precision_5: 0.7751 - recall_5: 0.682 - ETA: 0s - loss: 0.6295 - accuracy: 0.7539 - precision_5: 0.7974 - recall_5: 0.707 - ETA: 0s - loss: 0.6374 - accuracy: 0.7688 - precision_5: 0.8057 - recall_5: 0.712 - ETA: 0s - loss: 0.6291 - accuracy: 0.7682 - precision_5: 0.8095 - recall_5: 0.708 - ETA: 0s - loss: 0.6454 - accuracy: 0.7620 - precision_5: 0.8022 - recall_5: 0.701 - 1s 2ms/sample - loss: 0.6362 - accuracy: 0.7653 - precision_5: 0.8070 - recall_5: 0.7066 - val_loss: 1.1996 - val_accuracy: 0.5845 - val_precision_5: 0.6581 - val_recall_5: 0.5423\n",
      "Epoch 144/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8167 - accuracy: 0.7500 - precision_5: 0.8148 - recall_5: 0.687 - ETA: 0s - loss: 0.7811 - accuracy: 0.7500 - precision_5: 0.7818 - recall_5: 0.671 - ETA: 0s - loss: 0.6945 - accuracy: 0.7500 - precision_5: 0.8148 - recall_5: 0.687 - ETA: 0s - loss: 0.7012 - accuracy: 0.7344 - precision_5: 0.7909 - recall_5: 0.679 - ETA: 0s - loss: 0.7792 - accuracy: 0.7240 - precision_5: 0.7771 - recall_5: 0.671 - ETA: 0s - loss: 0.7608 - accuracy: 0.7344 - precision_5: 0.7803 - recall_5: 0.679 - ETA: 0s - loss: 0.7515 - accuracy: 0.7292 - precision_5: 0.7800 - recall_5: 0.677 - ETA: 0s - loss: 0.7680 - accuracy: 0.7216 - precision_5: 0.7748 - recall_5: 0.664 - ETA: 0s - loss: 0.7536 - accuracy: 0.7240 - precision_5: 0.7798 - recall_5: 0.664 - 1s 2ms/sample - loss: 0.7436 - accuracy: 0.7300 - precision_5: 0.7818 - recall_5: 0.6643 - val_loss: 1.2820 - val_accuracy: 0.5704 - val_precision_5: 0.6000 - val_recall_5: 0.5070\n",
      "Epoch 145/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.7188 - precision_5: 0.8636 - recall_5: 0.593 - ETA: 0s - loss: 0.6639 - accuracy: 0.7083 - precision_5: 0.7922 - recall_5: 0.635 - ETA: 0s - loss: 0.7130 - accuracy: 0.6938 - precision_5: 0.7698 - recall_5: 0.606 - ETA: 0s - loss: 0.7114 - accuracy: 0.6875 - precision_5: 0.7697 - recall_5: 0.609 - ETA: 0s - loss: 0.6883 - accuracy: 0.7148 - precision_5: 0.7961 - recall_5: 0.640 - ETA: 0s - loss: 0.6596 - accuracy: 0.7257 - precision_5: 0.8103 - recall_5: 0.652 - ETA: 0s - loss: 0.6696 - accuracy: 0.7273 - precision_5: 0.8140 - recall_5: 0.659 - ETA: 0s - loss: 0.6820 - accuracy: 0.7212 - precision_5: 0.8101 - recall_5: 0.656 - 1s 2ms/sample - loss: 0.6683 - accuracy: 0.7277 - precision_5: 0.8156 - recall_5: 0.6643 - val_loss: 1.1643 - val_accuracy: 0.6197 - val_precision_5: 0.6609 - val_recall_5: 0.5352\n",
      "Epoch 146/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.7188 - precision_5: 0.7857 - recall_5: 0.687 - ETA: 0s - loss: 0.6578 - accuracy: 0.7917 - precision_5: 0.8235 - recall_5: 0.729 - ETA: 0s - loss: 0.6774 - accuracy: 0.7734 - precision_5: 0.8018 - recall_5: 0.695 - ETA: 0s - loss: 0.6587 - accuracy: 0.7604 - precision_5: 0.7917 - recall_5: 0.692 - ETA: 0s - loss: 0.6101 - accuracy: 0.7812 - precision_5: 0.8081 - recall_5: 0.714 - ETA: 0s - loss: 0.5728 - accuracy: 0.7951 - precision_5: 0.8235 - recall_5: 0.729 - ETA: 0s - loss: 0.5683 - accuracy: 0.7983 - precision_5: 0.8323 - recall_5: 0.733 - ETA: 0s - loss: 0.5630 - accuracy: 0.7943 - precision_5: 0.8338 - recall_5: 0.731 - 1s 2ms/sample - loss: 0.5720 - accuracy: 0.7887 - precision_5: 0.8249 - recall_5: 0.7300 - val_loss: 1.1181 - val_accuracy: 0.6197 - val_precision_5: 0.6639 - val_recall_5: 0.5704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.7500 - precision_5: 0.8571 - recall_5: 0.750 - ETA: 0s - loss: 0.5661 - accuracy: 0.7969 - precision_5: 0.8393 - recall_5: 0.734 - ETA: 0s - loss: 0.5773 - accuracy: 0.8047 - precision_5: 0.8261 - recall_5: 0.742 - ETA: 0s - loss: 0.5676 - accuracy: 0.7875 - precision_5: 0.8298 - recall_5: 0.731 - ETA: 0s - loss: 0.5664 - accuracy: 0.7865 - precision_5: 0.8323 - recall_5: 0.724 - ETA: 0s - loss: 0.5622 - accuracy: 0.7857 - precision_5: 0.8359 - recall_5: 0.727 - ETA: 0s - loss: 0.5277 - accuracy: 0.8125 - precision_5: 0.8645 - recall_5: 0.753 - ETA: 0s - loss: 0.5293 - accuracy: 0.8156 - precision_5: 0.8638 - recall_5: 0.753 - ETA: 0s - loss: 0.5318 - accuracy: 0.8203 - precision_5: 0.8623 - recall_5: 0.750 - 1s 2ms/sample - loss: 0.5572 - accuracy: 0.8075 - precision_5: 0.8495 - recall_5: 0.7418 - val_loss: 1.1277 - val_accuracy: 0.6479 - val_precision_5: 0.6475 - val_recall_5: 0.5563\n",
      "Epoch 148/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.8438 - precision_5: 0.8889 - recall_5: 0.750 - ETA: 0s - loss: 0.4888 - accuracy: 0.8646 - precision_5: 0.8966 - recall_5: 0.812 - ETA: 0s - loss: 0.5821 - accuracy: 0.8125 - precision_5: 0.8462 - recall_5: 0.756 - ETA: 0s - loss: 0.5470 - accuracy: 0.8259 - precision_5: 0.8507 - recall_5: 0.763 - ETA: 0s - loss: 0.5245 - accuracy: 0.8368 - precision_5: 0.8687 - recall_5: 0.781 - ETA: 0s - loss: 0.5348 - accuracy: 0.8267 - precision_5: 0.8662 - recall_5: 0.772 - ETA: 0s - loss: 0.5626 - accuracy: 0.8125 - precision_5: 0.8478 - recall_5: 0.750 - 1s 2ms/sample - loss: 0.5526 - accuracy: 0.8169 - precision_5: 0.8519 - recall_5: 0.7559 - val_loss: 1.2212 - val_accuracy: 0.6056 - val_precision_5: 0.6183 - val_recall_5: 0.5704\n",
      "Epoch 149/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.7812 - precision_5: 0.8571 - recall_5: 0.750 - ETA: 0s - loss: 0.5663 - accuracy: 0.7917 - precision_5: 0.8295 - recall_5: 0.760 - ETA: 0s - loss: 0.6074 - accuracy: 0.7812 - precision_5: 0.8182 - recall_5: 0.731 - ETA: 0s - loss: 0.6069 - accuracy: 0.7865 - precision_5: 0.8150 - recall_5: 0.734 - ETA: 0s - loss: 0.6016 - accuracy: 0.7891 - precision_5: 0.8190 - recall_5: 0.742 - ETA: 0s - loss: 0.5941 - accuracy: 0.7969 - precision_5: 0.8231 - recall_5: 0.756 - ETA: 0s - loss: 0.6059 - accuracy: 0.7917 - precision_5: 0.8153 - recall_5: 0.747 - ETA: 0s - loss: 0.6157 - accuracy: 0.7885 - precision_5: 0.8136 - recall_5: 0.745 - 1s 2ms/sample - loss: 0.6025 - accuracy: 0.7934 - precision_5: 0.8184 - recall_5: 0.7512 - val_loss: 1.1941 - val_accuracy: 0.6479 - val_precision_5: 0.6772 - val_recall_5: 0.6056\n",
      "Epoch 150/150\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.8491 - accuracy: 0.7500 - precision_5: 0.7500 - recall_5: 0.750 - ETA: 0s - loss: 0.7179 - accuracy: 0.7656 - precision_5: 0.7619 - recall_5: 0.750 - ETA: 0s - loss: 0.6600 - accuracy: 0.7891 - precision_5: 0.8049 - recall_5: 0.773 - ETA: 0s - loss: 0.6453 - accuracy: 0.7865 - precision_5: 0.8111 - recall_5: 0.760 - ETA: 0s - loss: 0.6205 - accuracy: 0.7969 - precision_5: 0.8228 - recall_5: 0.761 - ETA: 0s - loss: 0.5918 - accuracy: 0.8062 - precision_5: 0.8265 - recall_5: 0.759 - ETA: 0s - loss: 0.5837 - accuracy: 0.7995 - precision_5: 0.8239 - recall_5: 0.755 - 1s 2ms/sample - loss: 0.5928 - accuracy: 0.7911 - precision_5: 0.8179 - recall_5: 0.7488 - val_loss: 1.2473 - val_accuracy: 0.5845 - val_precision_5: 0.6098 - val_recall_5: 0.5282\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(256, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(128, return_sequences=True)) \n",
    "model.add(layers.LSTM(256, return_sequences=True)) \n",
    "model.add(layers.LSTM(96, return_sequences=True)) \n",
    "model.add(layers.LSTM(64))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=150,validation_data=(x_val,y_val),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 598,540\n",
      "Trainable params: 598,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(256, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(128, return_sequences=True)) \n",
    "model.add(layers.LSTM(64))  \n",
    "\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "#history=model.fit(x_train,y_train,epochs=120,validation_data=(x_val,y_val),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tuner object into pickle file\n",
    "so it can be used in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_\"f\"{starttime}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best Trial from Tuner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 222,476\n",
      "Trainable params: 222,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 222,476\n",
      "Trainable params: 222,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "bestmodel= tuner.hypermodel.build(best_hp)\n",
    "\n",
    "bestmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 6s - loss: 2.3301 - accuracy: 0.1643 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.2724 - val_accuracy: 0.1761 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.0706 - accuracy: 0.1784 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.9539 - val_accuracy: 0.2042 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 1.9467 - accuracy: 0.2066 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.0146 - val_accuracy: 0.2042 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 2.5727 - accuracy: 0.1056 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.5653 - val_accuracy: 0.0775 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 2.4842 - accuracy: 0.0587 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.4607 - val_accuracy: 0.0915 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 2.4289 - accuracy: 0.0869 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.4167 - val_accuracy: 0.0915 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 2.4077 - accuracy: 0.0751 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.4104 - val_accuracy: 0.0915 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 2.3971 - accuracy: 0.0751 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.3967 - val_accuracy: 0.0915 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 2.3513 - accuracy: 0.1056 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.3303 - val_accuracy: 0.0915 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 2.2351 - accuracy: 0.1479 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 2.1797 - val_accuracy: 0.1479 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 2.0239 - accuracy: 0.1667 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.9181 - val_accuracy: 0.1620 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.9301 - accuracy: 0.2089 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.8661 - val_accuracy: 0.1901 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.9166 - accuracy: 0.1995 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.8357 - val_accuracy: 0.1901 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.9679 - accuracy: 0.1901 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.7815 - val_accuracy: 0.2535 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.8828 - accuracy: 0.2042 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.9315 - val_accuracy: 0.1620 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.9225 - accuracy: 0.1784 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.8041 - val_accuracy: 0.2183 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.8651 - accuracy: 0.2254 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.7601 - val_accuracy: 0.2676 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.8150 - accuracy: 0.2324 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.7261 - val_accuracy: 0.2676 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.7631 - accuracy: 0.2770 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.7528 - val_accuracy: 0.2746 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.7364 - accuracy: 0.3122 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.8013 - val_accuracy: 0.2676 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.7359 - accuracy: 0.2958 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.6996 - val_accuracy: 0.3451 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.6423 - accuracy: 0.3122 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 1.6636 - val_accuracy: 0.3169 - val_precision_4: 0.5556 - val_recall_4: 0.0352\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.6028 - accuracy: 0.3521 - precision_4: 0.5833 - recall_4: 0.0164 - val_loss: 1.6582 - val_accuracy: 0.2887 - val_precision_4: 0.6000 - val_recall_4: 0.0211\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.5957 - accuracy: 0.3075 - precision_4: 0.4615 - recall_4: 0.0704 - val_loss: 1.6670 - val_accuracy: 0.3099 - val_precision_4: 0.5909 - val_recall_4: 0.0915\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.5585 - accuracy: 0.3474 - precision_4: 0.6667 - recall_4: 0.0423 - val_loss: 1.6300 - val_accuracy: 0.3310 - val_precision_4: 0.9091 - val_recall_4: 0.0704\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.5352 - accuracy: 0.3474 - precision_4: 0.5823 - recall_4: 0.1080 - val_loss: 1.7618 - val_accuracy: 0.3310 - val_precision_4: 0.5926 - val_recall_4: 0.1127\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5682 - accuracy: 0.3615 - precision_4: 0.5505 - recall_4: 0.1408 - val_loss: 1.6794 - val_accuracy: 0.2958 - val_precision_4: 0.7200 - val_recall_4: 0.1268\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.5409 - accuracy: 0.3920 - precision_4: 0.6579 - recall_4: 0.1174 - val_loss: 1.6720 - val_accuracy: 0.3380 - val_precision_4: 0.7143 - val_recall_4: 0.1056\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.4858 - accuracy: 0.4178 - precision_4: 0.6484 - recall_4: 0.1385 - val_loss: 1.6793 - val_accuracy: 0.3521 - val_precision_4: 0.5714 - val_recall_4: 0.1127\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.5054 - accuracy: 0.4155 - precision_4: 0.5821 - recall_4: 0.1831 - val_loss: 1.7256 - val_accuracy: 0.2958 - val_precision_4: 0.5263 - val_recall_4: 0.1408\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.5140 - accuracy: 0.4038 - precision_4: 0.5672 - recall_4: 0.1784 - val_loss: 1.6455 - val_accuracy: 0.3099 - val_precision_4: 0.7200 - val_recall_4: 0.1268\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.4772 - accuracy: 0.4225 - precision_4: 0.6542 - recall_4: 0.1643 - val_loss: 1.4979 - val_accuracy: 0.3873 - val_precision_4: 0.6316 - val_recall_4: 0.1690\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4057 - accuracy: 0.4437 - precision_4: 0.6491 - recall_4: 0.1737 - val_loss: 1.4840 - val_accuracy: 0.4085 - val_precision_4: 0.6471 - val_recall_4: 0.2324\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.3845 - accuracy: 0.4671 - precision_4: 0.6378 - recall_4: 0.1901 - val_loss: 1.6059 - val_accuracy: 0.3732 - val_precision_4: 0.7391 - val_recall_4: 0.1197\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.4061 - accuracy: 0.4554 - precision_4: 0.6496 - recall_4: 0.2089 - val_loss: 1.5360 - val_accuracy: 0.3803 - val_precision_4: 0.5918 - val_recall_4: 0.2042\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.3677 - accuracy: 0.4648 - precision_4: 0.6763 - recall_4: 0.2207 - val_loss: 1.5659 - val_accuracy: 0.3732 - val_precision_4: 0.5536 - val_recall_4: 0.2183\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.3783 - accuracy: 0.4460 - precision_4: 0.6114 - recall_4: 0.2512 - val_loss: 1.7114 - val_accuracy: 0.3169 - val_precision_4: 0.3947 - val_recall_4: 0.2113\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.3623 - accuracy: 0.4765 - precision_4: 0.6199 - recall_4: 0.2488 - val_loss: 1.5136 - val_accuracy: 0.3944 - val_precision_4: 0.5192 - val_recall_4: 0.1901\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.3900 - accuracy: 0.4296 - precision_4: 0.6048 - recall_4: 0.2371 - val_loss: 1.5098 - val_accuracy: 0.3732 - val_precision_4: 0.6000 - val_recall_4: 0.2324\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.4234 - accuracy: 0.4507 - precision_4: 0.5867 - recall_4: 0.2066 - val_loss: 1.7318 - val_accuracy: 0.3239 - val_precision_4: 0.4444 - val_recall_4: 0.1127\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.4460 - accuracy: 0.4507 - precision_4: 0.5703 - recall_4: 0.1714 - val_loss: 1.7000 - val_accuracy: 0.3380 - val_precision_4: 0.4717 - val_recall_4: 0.1761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.3874 - accuracy: 0.4437 - precision_4: 0.6846 - recall_4: 0.2089 - val_loss: 1.5238 - val_accuracy: 0.3944 - val_precision_4: 0.6250 - val_recall_4: 0.1761\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.3414 - accuracy: 0.4977 - precision_4: 0.6667 - recall_4: 0.2629 - val_loss: 1.4532 - val_accuracy: 0.4014 - val_precision_4: 0.6429 - val_recall_4: 0.1901\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.2991 - accuracy: 0.4789 - precision_4: 0.6894 - recall_4: 0.2606 - val_loss: 1.4317 - val_accuracy: 0.3944 - val_precision_4: 0.5862 - val_recall_4: 0.2394\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.5110 - accuracy: 0.4343 - precision_4: 0.5517 - recall_4: 0.2629 - val_loss: 2.1214 - val_accuracy: 0.2324 - val_precision_4: 0.3729 - val_recall_4: 0.1549\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.7415 - accuracy: 0.3545 - precision_4: 0.5246 - recall_4: 0.1502 - val_loss: 1.8230 - val_accuracy: 0.3592 - val_precision_4: 0.5000 - val_recall_4: 0.1549\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.5802 - accuracy: 0.3873 - precision_4: 0.6571 - recall_4: 0.1080 - val_loss: 1.5955 - val_accuracy: 0.3662 - val_precision_4: 0.5778 - val_recall_4: 0.1831\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.4280 - accuracy: 0.4413 - precision_4: 0.5924 - recall_4: 0.2183 - val_loss: 1.5962 - val_accuracy: 0.4085 - val_precision_4: 0.6522 - val_recall_4: 0.2113\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.3558 - accuracy: 0.5023 - precision_4: 0.6759 - recall_4: 0.2300 - val_loss: 1.6638 - val_accuracy: 0.3592 - val_precision_4: 0.6600 - val_recall_4: 0.2324\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3722 - accuracy: 0.4953 - precision_4: 0.6786 - recall_4: 0.2676 - val_loss: 1.4112 - val_accuracy: 0.4789 - val_precision_4: 0.6852 - val_recall_4: 0.2606\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.2232 - accuracy: 0.5728 - precision_4: 0.7193 - recall_4: 0.2887 - val_loss: 1.5217 - val_accuracy: 0.4014 - val_precision_4: 0.5600 - val_recall_4: 0.2958\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.2223 - accuracy: 0.5469 - precision_4: 0.6887 - recall_4: 0.3427 - val_loss: 1.5065 - val_accuracy: 0.4155 - val_precision_4: 0.6441 - val_recall_4: 0.2676\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.1896 - accuracy: 0.5493 - precision_4: 0.7156 - recall_4: 0.3779 - val_loss: 1.5886 - val_accuracy: 0.3944 - val_precision_4: 0.5484 - val_recall_4: 0.2394\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.2310 - accuracy: 0.5446 - precision_4: 0.6756 - recall_4: 0.3568 - val_loss: 1.3806 - val_accuracy: 0.4648 - val_precision_4: 0.6267 - val_recall_4: 0.3310\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.1303 - accuracy: 0.6009 - precision_4: 0.7078 - recall_4: 0.4038 - val_loss: 1.4687 - val_accuracy: 0.4507 - val_precision_4: 0.5970 - val_recall_4: 0.2817\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.1703 - accuracy: 0.5798 - precision_4: 0.6908 - recall_4: 0.4038 - val_loss: 1.6255 - val_accuracy: 0.4225 - val_precision_4: 0.5065 - val_recall_4: 0.2746\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.1657 - accuracy: 0.5446 - precision_4: 0.6582 - recall_4: 0.3662 - val_loss: 1.2345 - val_accuracy: 0.5141 - val_precision_4: 0.6081 - val_recall_4: 0.3169\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.0318 - accuracy: 0.6385 - precision_4: 0.7318 - recall_4: 0.4484 - val_loss: 1.4403 - val_accuracy: 0.4789 - val_precision_4: 0.6053 - val_recall_4: 0.3239\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.1411 - accuracy: 0.5798 - precision_4: 0.6715 - recall_4: 0.4319 - val_loss: 1.5821 - val_accuracy: 0.4437 - val_precision_4: 0.5789 - val_recall_4: 0.3099\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.3450 - accuracy: 0.4789 - precision_4: 0.5270 - recall_4: 0.2981 - val_loss: 1.7438 - val_accuracy: 0.3592 - val_precision_4: 0.4627 - val_recall_4: 0.2183\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.4085 - accuracy: 0.4742 - precision_4: 0.6188 - recall_4: 0.2629 - val_loss: 1.3795 - val_accuracy: 0.4507 - val_precision_4: 0.6901 - val_recall_4: 0.3451\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.3219 - accuracy: 0.4977 - precision_4: 0.6339 - recall_4: 0.2723 - val_loss: 1.2647 - val_accuracy: 0.5070 - val_precision_4: 0.7049 - val_recall_4: 0.3028\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.1507 - accuracy: 0.5939 - precision_4: 0.7487 - recall_4: 0.3286 - val_loss: 1.3412 - val_accuracy: 0.4930 - val_precision_4: 0.6056 - val_recall_4: 0.3028\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.0727 - accuracy: 0.6197 - precision_4: 0.7280 - recall_4: 0.4460 - val_loss: 1.1264 - val_accuracy: 0.5563 - val_precision_4: 0.6941 - val_recall_4: 0.4155\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 0.9709 - accuracy: 0.6479 - precision_4: 0.7544 - recall_4: 0.5047 - val_loss: 1.2422 - val_accuracy: 0.5211 - val_precision_4: 0.5977 - val_recall_4: 0.3662\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.0777 - accuracy: 0.6127 - precision_4: 0.6469 - recall_4: 0.4859 - val_loss: 1.2436 - val_accuracy: 0.5141 - val_precision_4: 0.5667 - val_recall_4: 0.3592\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 0.9954 - accuracy: 0.6338 - precision_4: 0.7296 - recall_4: 0.4624 - val_loss: 1.2602 - val_accuracy: 0.5070 - val_precision_4: 0.5824 - val_recall_4: 0.3732\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 0.9718 - accuracy: 0.6761 - precision_4: 0.7401 - recall_4: 0.5282 - val_loss: 1.0090 - val_accuracy: 0.6056 - val_precision_4: 0.7667 - val_recall_4: 0.4859\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 0.8314 - accuracy: 0.7183 - precision_4: 0.7759 - recall_4: 0.6338 - val_loss: 1.0732 - val_accuracy: 0.5845 - val_precision_4: 0.6699 - val_recall_4: 0.4859\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 0.8543 - accuracy: 0.7042 - precision_4: 0.7623 - recall_4: 0.6174 - val_loss: 1.0018 - val_accuracy: 0.5845 - val_precision_4: 0.6759 - val_recall_4: 0.5141\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 0.8559 - accuracy: 0.6901 - precision_4: 0.7507 - recall_4: 0.6291 - val_loss: 1.0773 - val_accuracy: 0.5845 - val_precision_4: 0.6124 - val_recall_4: 0.5563\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 0.8831 - accuracy: 0.6972 - precision_4: 0.7590 - recall_4: 0.5915 - val_loss: 1.0476 - val_accuracy: 0.5986 - val_precision_4: 0.6800 - val_recall_4: 0.4789\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 0.9494 - accuracy: 0.6784 - precision_4: 0.7373 - recall_4: 0.5469 - val_loss: 1.3623 - val_accuracy: 0.5211 - val_precision_4: 0.6341 - val_recall_4: 0.3662\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 0.9669 - accuracy: 0.6362 - precision_4: 0.7070 - recall_4: 0.5211 - val_loss: 1.2406 - val_accuracy: 0.5423 - val_precision_4: 0.6250 - val_recall_4: 0.4930\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 0.8906 - accuracy: 0.6667 - precision_4: 0.7500 - recall_4: 0.5634 - val_loss: 0.9955 - val_accuracy: 0.5986 - val_precision_4: 0.6579 - val_recall_4: 0.5282\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 0.8870 - accuracy: 0.6925 - precision_4: 0.7378 - recall_4: 0.6009 - val_loss: 1.0878 - val_accuracy: 0.5563 - val_precision_4: 0.6050 - val_recall_4: 0.5070\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 0.9663 - accuracy: 0.6432 - precision_4: 0.6963 - recall_4: 0.5329 - val_loss: 1.0426 - val_accuracy: 0.5915 - val_precision_4: 0.6771 - val_recall_4: 0.4577\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 0.8447 - accuracy: 0.6878 - precision_4: 0.7764 - recall_4: 0.5869 - val_loss: 1.1082 - val_accuracy: 0.5563 - val_precision_4: 0.6396 - val_recall_4: 0.5000\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.8283 - accuracy: 0.7019 - precision_4: 0.7514 - recall_4: 0.6244 - val_loss: 1.0780 - val_accuracy: 0.6127 - val_precision_4: 0.6789 - val_recall_4: 0.5211\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.8371 - accuracy: 0.6925 - precision_4: 0.7586 - recall_4: 0.6197 - val_loss: 0.9714 - val_accuracy: 0.6479 - val_precision_4: 0.6783 - val_recall_4: 0.5493\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.7939 - accuracy: 0.7066 - precision_4: 0.7806 - recall_4: 0.6432 - val_loss: 0.9974 - val_accuracy: 0.6197 - val_precision_4: 0.6863 - val_recall_4: 0.4930\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.7867 - accuracy: 0.7019 - precision_4: 0.7749 - recall_4: 0.6385 - val_loss: 1.0286 - val_accuracy: 0.5845 - val_precision_4: 0.6698 - val_recall_4: 0.5000\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.8435 - accuracy: 0.6854 - precision_4: 0.7537 - recall_4: 0.6033 - val_loss: 0.9596 - val_accuracy: 0.6056 - val_precision_4: 0.6789 - val_recall_4: 0.5211\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.7857 - accuracy: 0.7230 - precision_4: 0.8056 - recall_4: 0.6127 - val_loss: 1.0871 - val_accuracy: 0.5775 - val_precision_4: 0.6283 - val_recall_4: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.8139 - accuracy: 0.7019 - precision_4: 0.7642 - recall_4: 0.6315 - val_loss: 0.8652 - val_accuracy: 0.6901 - val_precision_4: 0.7119 - val_recall_4: 0.5915\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.6909 - accuracy: 0.7394 - precision_4: 0.7961 - recall_4: 0.6690 - val_loss: 0.9731 - val_accuracy: 0.6056 - val_precision_4: 0.6466 - val_recall_4: 0.5282\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.6898 - accuracy: 0.7629 - precision_4: 0.8039 - recall_4: 0.6737 - val_loss: 0.8832 - val_accuracy: 0.6620 - val_precision_4: 0.7097 - val_recall_4: 0.6197\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.6319 - accuracy: 0.7559 - precision_4: 0.7969 - recall_4: 0.7277 - val_loss: 1.0141 - val_accuracy: 0.6690 - val_precision_4: 0.6692 - val_recall_4: 0.6268\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.6658 - accuracy: 0.7793 - precision_4: 0.7995 - recall_4: 0.7300 - val_loss: 0.9441 - val_accuracy: 0.6408 - val_precision_4: 0.6560 - val_recall_4: 0.5775\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.6769 - accuracy: 0.7465 - precision_4: 0.7726 - recall_4: 0.7019 - val_loss: 0.8501 - val_accuracy: 0.6972 - val_precision_4: 0.7438 - val_recall_4: 0.6338\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.6154 - accuracy: 0.7840 - precision_4: 0.8189 - recall_4: 0.7535 - val_loss: 0.8191 - val_accuracy: 0.6972 - val_precision_4: 0.7317 - val_recall_4: 0.6338\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.5940 - accuracy: 0.7934 - precision_4: 0.8286 - recall_4: 0.7488 - val_loss: 1.1245 - val_accuracy: 0.5986 - val_precision_4: 0.6406 - val_recall_4: 0.5775\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.7699 - accuracy: 0.7089 - precision_4: 0.7500 - recall_4: 0.6549 - val_loss: 1.1160 - val_accuracy: 0.5915 - val_precision_4: 0.6525 - val_recall_4: 0.5423\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.7239 - accuracy: 0.7254 - precision_4: 0.8035 - recall_4: 0.6432 - val_loss: 0.9675 - val_accuracy: 0.5915 - val_precision_4: 0.6500 - val_recall_4: 0.5493\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.6756 - accuracy: 0.7465 - precision_4: 0.7757 - recall_4: 0.6901 - val_loss: 0.8851 - val_accuracy: 0.6408 - val_precision_4: 0.6724 - val_recall_4: 0.5493\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.6894 - accuracy: 0.7441 - precision_4: 0.7885 - recall_4: 0.7089 - val_loss: 1.0444 - val_accuracy: 0.5986 - val_precision_4: 0.6393 - val_recall_4: 0.5493\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.6516 - accuracy: 0.7653 - precision_4: 0.8187 - recall_4: 0.6995 - val_loss: 0.8177 - val_accuracy: 0.6549 - val_precision_4: 0.6930 - val_recall_4: 0.5563\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.5724 - accuracy: 0.7864 - precision_4: 0.8272 - recall_4: 0.7418 - val_loss: 0.8554 - val_accuracy: 0.6197 - val_precision_4: 0.7143 - val_recall_4: 0.5634\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.5635 - accuracy: 0.7864 - precision_4: 0.8289 - recall_4: 0.7394 - val_loss: 0.8453 - val_accuracy: 0.6479 - val_precision_4: 0.7016 - val_recall_4: 0.6127\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.5118 - accuracy: 0.8192 - precision_4: 0.8524 - recall_4: 0.7864 - val_loss: 0.8489 - val_accuracy: 0.6690 - val_precision_4: 0.7109 - val_recall_4: 0.6408\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.4985 - accuracy: 0.8239 - precision_4: 0.8475 - recall_4: 0.7958 - val_loss: 0.8731 - val_accuracy: 0.6408 - val_precision_4: 0.6983 - val_recall_4: 0.5704\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.8616 - accuracy: 0.7136 - precision_4: 0.7682 - recall_4: 0.6690 - val_loss: 1.2177 - val_accuracy: 0.5423 - val_precision_4: 0.7349 - val_recall_4: 0.4296\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.9012 - accuracy: 0.6573 - precision_4: 0.7759 - recall_4: 0.5446 - val_loss: 1.0739 - val_accuracy: 0.5634 - val_precision_4: 0.6571 - val_recall_4: 0.4859\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.7520 - accuracy: 0.7394 - precision_4: 0.8069 - recall_4: 0.6573 - val_loss: 1.0388 - val_accuracy: 0.5915 - val_precision_4: 0.6446 - val_recall_4: 0.5493\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.7487 - accuracy: 0.7254 - precision_4: 0.7781 - recall_4: 0.6831 - val_loss: 1.1303 - val_accuracy: 0.6127 - val_precision_4: 0.6281 - val_recall_4: 0.5352\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.7672 - accuracy: 0.7160 - precision_4: 0.7601 - recall_4: 0.6620 - val_loss: 0.9759 - val_accuracy: 0.6197 - val_precision_4: 0.6937 - val_recall_4: 0.5423\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.7044 - accuracy: 0.7347 - precision_4: 0.8017 - recall_4: 0.6549 - val_loss: 0.9428 - val_accuracy: 0.6831 - val_precision_4: 0.7207 - val_recall_4: 0.5634\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.6247 - accuracy: 0.7723 - precision_4: 0.8414 - recall_4: 0.6972 - val_loss: 1.0365 - val_accuracy: 0.6549 - val_precision_4: 0.6752 - val_recall_4: 0.5563\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6059 - accuracy: 0.7700 - precision_4: 0.8100 - recall_4: 0.7207 - val_loss: 0.9011 - val_accuracy: 0.6620 - val_precision_4: 0.6977 - val_recall_4: 0.6338\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.5486 - accuracy: 0.7981 - precision_4: 0.8325 - recall_4: 0.7465 - val_loss: 0.9050 - val_accuracy: 0.6831 - val_precision_4: 0.7440 - val_recall_4: 0.6549\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.4986 - accuracy: 0.8310 - precision_4: 0.8564 - recall_4: 0.7981 - val_loss: 0.8802 - val_accuracy: 0.6831 - val_precision_4: 0.7438 - val_recall_4: 0.6338\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.4937 - accuracy: 0.8286 - precision_4: 0.8450 - recall_4: 0.7934 - val_loss: 0.8253 - val_accuracy: 0.7113 - val_precision_4: 0.7348 - val_recall_4: 0.6831\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.5132 - accuracy: 0.8099 - precision_4: 0.8350 - recall_4: 0.7840 - val_loss: 0.9867 - val_accuracy: 0.6620 - val_precision_4: 0.6947 - val_recall_4: 0.6408\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.5435 - accuracy: 0.8075 - precision_4: 0.8244 - recall_4: 0.7606 - val_loss: 1.0324 - val_accuracy: 0.6549 - val_precision_4: 0.6769 - val_recall_4: 0.6197\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.5142 - accuracy: 0.8146 - precision_4: 0.8338 - recall_4: 0.7770 - val_loss: 0.9746 - val_accuracy: 0.6620 - val_precision_4: 0.6929 - val_recall_4: 0.6197\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.5502 - accuracy: 0.7864 - precision_4: 0.8201 - recall_4: 0.7488 - val_loss: 0.8635 - val_accuracy: 0.6831 - val_precision_4: 0.7480 - val_recall_4: 0.6690\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5856 - accuracy: 0.7840 - precision_4: 0.7990 - recall_4: 0.7465 - val_loss: 0.9831 - val_accuracy: 0.6831 - val_precision_4: 0.7177 - val_recall_4: 0.6268\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.6420 - accuracy: 0.7582 - precision_4: 0.8230 - recall_4: 0.6878 - val_loss: 1.0081 - val_accuracy: 0.6268 - val_precision_4: 0.7290 - val_recall_4: 0.5493\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.6107 - accuracy: 0.7793 - precision_4: 0.8266 - recall_4: 0.7160 - val_loss: 0.8401 - val_accuracy: 0.6479 - val_precision_4: 0.6977 - val_recall_4: 0.6338\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.4980 - accuracy: 0.8005 - precision_4: 0.8472 - recall_4: 0.7676 - val_loss: 0.9092 - val_accuracy: 0.6479 - val_precision_4: 0.6880 - val_recall_4: 0.6056\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.5038 - accuracy: 0.8216 - precision_4: 0.8434 - recall_4: 0.7840 - val_loss: 0.8279 - val_accuracy: 0.7324 - val_precision_4: 0.7581 - val_recall_4: 0.6620\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.4674 - accuracy: 0.8169 - precision_4: 0.8495 - recall_4: 0.7817 - val_loss: 0.9644 - val_accuracy: 0.6620 - val_precision_4: 0.6977 - val_recall_4: 0.6338\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.6470 - accuracy: 0.7606 - precision_4: 0.7954 - recall_4: 0.7300 - val_loss: 1.1219 - val_accuracy: 0.6197 - val_precision_4: 0.6833 - val_recall_4: 0.5775\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.6870 - accuracy: 0.7582 - precision_4: 0.7989 - recall_4: 0.7089 - val_loss: 0.9058 - val_accuracy: 0.6549 - val_precision_4: 0.7350 - val_recall_4: 0.6056\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.6729 - accuracy: 0.7582 - precision_4: 0.8113 - recall_4: 0.7066 - val_loss: 0.9504 - val_accuracy: 0.6408 - val_precision_4: 0.6875 - val_recall_4: 0.6197\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.6405 - accuracy: 0.7559 - precision_4: 0.8189 - recall_4: 0.7324 - val_loss: 1.0010 - val_accuracy: 0.6268 - val_precision_4: 0.6852 - val_recall_4: 0.5211\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.7001 - accuracy: 0.7230 - precision_4: 0.7787 - recall_4: 0.6690 - val_loss: 1.1132 - val_accuracy: 0.6268 - val_precision_4: 0.6777 - val_recall_4: 0.5775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.7237 - accuracy: 0.7183 - precision_4: 0.7620 - recall_4: 0.6690 - val_loss: 0.9431 - val_accuracy: 0.6549 - val_precision_4: 0.6984 - val_recall_4: 0.6197\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.5823 - accuracy: 0.7840 - precision_4: 0.8130 - recall_4: 0.7347 - val_loss: 1.0331 - val_accuracy: 0.6268 - val_precision_4: 0.6777 - val_recall_4: 0.5775\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.6393 - accuracy: 0.7629 - precision_4: 0.7716 - recall_4: 0.7136 - val_loss: 0.8903 - val_accuracy: 0.6831 - val_precision_4: 0.6977 - val_recall_4: 0.6338\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.5870 - accuracy: 0.7817 - precision_4: 0.8175 - recall_4: 0.7254 - val_loss: 0.8019 - val_accuracy: 0.6901 - val_precision_4: 0.7422 - val_recall_4: 0.6690\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.4745 - accuracy: 0.8075 - precision_4: 0.8550 - recall_4: 0.7887 - val_loss: 0.8757 - val_accuracy: 0.6761 - val_precision_4: 0.7188 - val_recall_4: 0.6479\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.4274 - accuracy: 0.8498 - precision_4: 0.8799 - recall_4: 0.7911 - val_loss: 0.8314 - val_accuracy: 0.7113 - val_precision_4: 0.7398 - val_recall_4: 0.6408\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.4045 - accuracy: 0.8592 - precision_4: 0.8775 - recall_4: 0.8239 - val_loss: 0.7449 - val_accuracy: 0.7465 - val_precision_4: 0.7680 - val_recall_4: 0.6761\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.3861 - accuracy: 0.8568 - precision_4: 0.8750 - recall_4: 0.8380 - val_loss: 0.7925 - val_accuracy: 0.7324 - val_precision_4: 0.7388 - val_recall_4: 0.6972\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.3759 - accuracy: 0.8662 - precision_4: 0.8892 - recall_4: 0.8474 - val_loss: 0.9120 - val_accuracy: 0.6901 - val_precision_4: 0.6940 - val_recall_4: 0.6549\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.3702 - accuracy: 0.8638 - precision_4: 0.8790 - recall_4: 0.8357 - val_loss: 0.8929 - val_accuracy: 0.6901 - val_precision_4: 0.7222 - val_recall_4: 0.6408\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.3927 - accuracy: 0.8615 - precision_4: 0.8815 - recall_4: 0.8380 - val_loss: 0.8043 - val_accuracy: 0.7113 - val_precision_4: 0.7407 - val_recall_4: 0.7042\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.3129 - accuracy: 0.8991 - precision_4: 0.9098 - recall_4: 0.8756 - val_loss: 0.8757 - val_accuracy: 0.7183 - val_precision_4: 0.7481 - val_recall_4: 0.6901\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.2881 - accuracy: 0.9014 - precision_4: 0.9150 - recall_4: 0.8850 - val_loss: 0.9334 - val_accuracy: 0.7042 - val_precision_4: 0.7132 - val_recall_4: 0.6831\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.2842 - accuracy: 0.8991 - precision_4: 0.9133 - recall_4: 0.8897 - val_loss: 0.8305 - val_accuracy: 0.7535 - val_precision_4: 0.7518 - val_recall_4: 0.7254\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.3313 - accuracy: 0.8967 - precision_4: 0.9098 - recall_4: 0.8756 - val_loss: 1.0570 - val_accuracy: 0.7042 - val_precision_4: 0.7174 - val_recall_4: 0.6972\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.4007 - accuracy: 0.8685 - precision_4: 0.8723 - recall_4: 0.8498 - val_loss: 1.0562 - val_accuracy: 0.6972 - val_precision_4: 0.7308 - val_recall_4: 0.6690\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.5485 - accuracy: 0.7958 - precision_4: 0.8304 - recall_4: 0.7700 - val_loss: 0.9759 - val_accuracy: 0.6831 - val_precision_4: 0.7197 - val_recall_4: 0.6690\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4593 - accuracy: 0.8192 - precision_4: 0.8579 - recall_4: 0.7934 - val_loss: 0.9786 - val_accuracy: 0.6479 - val_precision_4: 0.6667 - val_recall_4: 0.6197\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.3852 - accuracy: 0.8521 - precision_4: 0.8624 - recall_4: 0.8239 - val_loss: 0.9177 - val_accuracy: 0.7042 - val_precision_4: 0.7077 - val_recall_4: 0.6479\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.4051 - accuracy: 0.8474 - precision_4: 0.8721 - recall_4: 0.8005 - val_loss: 1.0023 - val_accuracy: 0.6620 - val_precision_4: 0.7097 - val_recall_4: 0.6197\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.4565 - accuracy: 0.8192 - precision_4: 0.8379 - recall_4: 0.7887 - val_loss: 0.9088 - val_accuracy: 0.7042 - val_precision_4: 0.7385 - val_recall_4: 0.6761\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.3829 - accuracy: 0.8545 - precision_4: 0.8835 - recall_4: 0.8192 - val_loss: 0.8705 - val_accuracy: 0.7254 - val_precision_4: 0.7463 - val_recall_4: 0.7042\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.3872 - accuracy: 0.8662 - precision_4: 0.8762 - recall_4: 0.8310 - val_loss: 0.9541 - val_accuracy: 0.6972 - val_precision_4: 0.7099 - val_recall_4: 0.6549\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.4840 - accuracy: 0.8263 - precision_4: 0.8553 - recall_4: 0.7911 - val_loss: 1.1262 - val_accuracy: 0.6549 - val_precision_4: 0.6769 - val_recall_4: 0.6197\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.4586 - accuracy: 0.8146 - precision_4: 0.8409 - recall_4: 0.7817 - val_loss: 0.9855 - val_accuracy: 0.6831 - val_precision_4: 0.7015 - val_recall_4: 0.6620\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.4289 - accuracy: 0.8498 - precision_4: 0.8710 - recall_4: 0.8239 - val_loss: 0.9009 - val_accuracy: 0.7042 - val_precision_4: 0.7424 - val_recall_4: 0.6901\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.3770 - accuracy: 0.8732 - precision_4: 0.8853 - recall_4: 0.8333 - val_loss: 0.9492 - val_accuracy: 0.7042 - val_precision_4: 0.7308 - val_recall_4: 0.6690\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.3146 - accuracy: 0.8897 - precision_4: 0.9064 - recall_4: 0.8638 - val_loss: 0.9011 - val_accuracy: 0.7254 - val_precision_4: 0.7445 - val_recall_4: 0.7183\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.2826 - accuracy: 0.9038 - precision_4: 0.9183 - recall_4: 0.8967 - val_loss: 0.8329 - val_accuracy: 0.7465 - val_precision_4: 0.7556 - val_recall_4: 0.7183\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.2713 - accuracy: 0.8967 - precision_4: 0.9137 - recall_4: 0.8944 - val_loss: 0.8497 - val_accuracy: 0.7254 - val_precision_4: 0.7338 - val_recall_4: 0.7183\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.2713 - accuracy: 0.8991 - precision_4: 0.9082 - recall_4: 0.8826 - val_loss: 0.8547 - val_accuracy: 0.7324 - val_precision_4: 0.7574 - val_recall_4: 0.7254\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.3064 - accuracy: 0.8826 - precision_4: 0.8976 - recall_4: 0.8638 - val_loss: 0.9427 - val_accuracy: 0.7183 - val_precision_4: 0.7463 - val_recall_4: 0.7042\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.2869 - accuracy: 0.8944 - precision_4: 0.9098 - recall_4: 0.8756 - val_loss: 0.9151 - val_accuracy: 0.7394 - val_precision_4: 0.7372 - val_recall_4: 0.7113\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.2682 - accuracy: 0.9108 - precision_4: 0.9141 - recall_4: 0.8991 - val_loss: 0.8688 - val_accuracy: 0.7254 - val_precision_4: 0.7463 - val_recall_4: 0.7042\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.2637 - accuracy: 0.9131 - precision_4: 0.9220 - recall_4: 0.8873 - val_loss: 0.9510 - val_accuracy: 0.6901 - val_precision_4: 0.7059 - val_recall_4: 0.6761\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.2593 - accuracy: 0.9085 - precision_4: 0.9173 - recall_4: 0.8850 - val_loss: 0.9514 - val_accuracy: 0.7254 - val_precision_4: 0.7463 - val_recall_4: 0.7042\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.2213 - accuracy: 0.9366 - precision_4: 0.9448 - recall_4: 0.9249 - val_loss: 0.9045 - val_accuracy: 0.7254 - val_precision_4: 0.7426 - val_recall_4: 0.7113\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.2602 - accuracy: 0.9038 - precision_4: 0.9179 - recall_4: 0.8920 - val_loss: 0.9217 - val_accuracy: 0.7183 - val_precision_4: 0.7445 - val_recall_4: 0.7183\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.2396 - accuracy: 0.9319 - precision_4: 0.9376 - recall_4: 0.9178 - val_loss: 1.1188 - val_accuracy: 0.6479 - val_precision_4: 0.6715 - val_recall_4: 0.6479\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.3302 - accuracy: 0.8803 - precision_4: 0.8956 - recall_4: 0.8662 - val_loss: 1.1048 - val_accuracy: 0.6408 - val_precision_4: 0.6496 - val_recall_4: 0.6268\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.5534 - accuracy: 0.8099 - precision_4: 0.8346 - recall_4: 0.7817 - val_loss: 1.2830 - val_accuracy: 0.6197 - val_precision_4: 0.6391 - val_recall_4: 0.5986\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.5960 - accuracy: 0.7793 - precision_4: 0.8000 - recall_4: 0.7512 - val_loss: 1.0376 - val_accuracy: 0.7183 - val_precision_4: 0.7538 - val_recall_4: 0.6901\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.6003 - accuracy: 0.8122 - precision_4: 0.8247 - recall_4: 0.7840 - val_loss: 0.9066 - val_accuracy: 0.7113 - val_precision_4: 0.7600 - val_recall_4: 0.6690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.4829 - accuracy: 0.8286 - precision_4: 0.8636 - recall_4: 0.8028 - val_loss: 0.8254 - val_accuracy: 0.7113 - val_precision_4: 0.7581 - val_recall_4: 0.6620\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.4083 - accuracy: 0.8498 - precision_4: 0.8790 - recall_4: 0.8357 - val_loss: 0.8680 - val_accuracy: 0.7113 - val_precision_4: 0.7385 - val_recall_4: 0.6761\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.3298 - accuracy: 0.8897 - precision_4: 0.9100 - recall_4: 0.8779 - val_loss: 1.0412 - val_accuracy: 0.6690 - val_precision_4: 0.6894 - val_recall_4: 0.6408\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.3402 - accuracy: 0.8779 - precision_4: 0.8968 - recall_4: 0.8568 - val_loss: 0.8499 - val_accuracy: 0.7535 - val_precision_4: 0.7500 - val_recall_4: 0.7183\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.2587 - accuracy: 0.9225 - precision_4: 0.9325 - recall_4: 0.9085 - val_loss: 0.9814 - val_accuracy: 0.7113 - val_precision_4: 0.7313 - val_recall_4: 0.6901\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.2942 - accuracy: 0.9108 - precision_4: 0.9201 - recall_4: 0.8920 - val_loss: 0.8626 - val_accuracy: 0.7465 - val_precision_4: 0.7536 - val_recall_4: 0.7324\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.2666 - accuracy: 0.9155 - precision_4: 0.9345 - recall_4: 0.9038 - val_loss: 0.8300 - val_accuracy: 0.7324 - val_precision_4: 0.7481 - val_recall_4: 0.7113\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.2811 - accuracy: 0.9038 - precision_4: 0.9124 - recall_4: 0.8803 - val_loss: 0.9926 - val_accuracy: 0.7183 - val_precision_4: 0.7279 - val_recall_4: 0.6972\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.7293 - accuracy: 0.7770 - precision_4: 0.7990 - recall_4: 0.7559 - val_loss: 1.2045 - val_accuracy: 0.6268 - val_precision_4: 0.6585 - val_recall_4: 0.5704\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.6028 - accuracy: 0.7911 - precision_4: 0.8299 - recall_4: 0.7559 - val_loss: 0.9081 - val_accuracy: 0.7183 - val_precision_4: 0.7680 - val_recall_4: 0.6761\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.4458 - accuracy: 0.8357 - precision_4: 0.8807 - recall_4: 0.8146 - val_loss: 1.0421 - val_accuracy: 0.6338 - val_precision_4: 0.6875 - val_recall_4: 0.6197\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.5605 - accuracy: 0.7981 - precision_4: 0.8282 - recall_4: 0.7582 - val_loss: 0.9268 - val_accuracy: 0.6901 - val_precision_4: 0.7049 - val_recall_4: 0.6056\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.4412 - accuracy: 0.8427 - precision_4: 0.8672 - recall_4: 0.8122 - val_loss: 0.9956 - val_accuracy: 0.7113 - val_precision_4: 0.7218 - val_recall_4: 0.6761\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.3693 - accuracy: 0.8709 - precision_4: 0.8714 - recall_4: 0.8427 - val_loss: 0.9451 - val_accuracy: 0.6690 - val_precision_4: 0.6894 - val_recall_4: 0.6408\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.3453 - accuracy: 0.8826 - precision_4: 0.8900 - recall_4: 0.8732 - val_loss: 0.8305 - val_accuracy: 0.7183 - val_precision_4: 0.7424 - val_recall_4: 0.6901\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.2697 - accuracy: 0.9038 - precision_4: 0.9201 - recall_4: 0.8920 - val_loss: 0.9625 - val_accuracy: 0.7254 - val_precision_4: 0.7319 - val_recall_4: 0.7113\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.4363 - accuracy: 0.8521 - precision_4: 0.8680 - recall_4: 0.8333 - val_loss: 1.1857 - val_accuracy: 0.6268 - val_precision_4: 0.6541 - val_recall_4: 0.6127\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.6339 - accuracy: 0.7723 - precision_4: 0.7878 - recall_4: 0.7582 - val_loss: 0.9866 - val_accuracy: 0.6268 - val_precision_4: 0.6512 - val_recall_4: 0.5915\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.5695 - accuracy: 0.7653 - precision_4: 0.7904 - recall_4: 0.7347 - val_loss: 0.8825 - val_accuracy: 0.7113 - val_precision_4: 0.7444 - val_recall_4: 0.6972\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.4237 - accuracy: 0.8451 - precision_4: 0.8738 - recall_4: 0.8286 - val_loss: 0.9663 - val_accuracy: 0.6901 - val_precision_4: 0.6963 - val_recall_4: 0.6620\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.4330 - accuracy: 0.8357 - precision_4: 0.8600 - recall_4: 0.8216 - val_loss: 1.0728 - val_accuracy: 0.6901 - val_precision_4: 0.7266 - val_recall_4: 0.6549\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.4393 - accuracy: 0.8286 - precision_4: 0.8633 - recall_4: 0.8005 - val_loss: 0.9809 - val_accuracy: 0.7183 - val_precision_4: 0.7407 - val_recall_4: 0.7042\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.4177 - accuracy: 0.8239 - precision_4: 0.8498 - recall_4: 0.8099 - val_loss: 0.8397 - val_accuracy: 0.7113 - val_precision_4: 0.7594 - val_recall_4: 0.7113\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.3909 - accuracy: 0.8521 - precision_4: 0.8809 - recall_4: 0.8333 - val_loss: 0.8888 - val_accuracy: 0.7606 - val_precision_4: 0.7868 - val_recall_4: 0.7535\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.2952 - accuracy: 0.8944 - precision_4: 0.9005 - recall_4: 0.8709 - val_loss: 0.8130 - val_accuracy: 0.7958 - val_precision_4: 0.8043 - val_recall_4: 0.7817\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.2693 - accuracy: 0.9108 - precision_4: 0.9275 - recall_4: 0.9014 - val_loss: 0.7222 - val_accuracy: 0.7958 - val_precision_4: 0.8129 - val_recall_4: 0.7958\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.2094 - accuracy: 0.9249 - precision_4: 0.9354 - recall_4: 0.9178 - val_loss: 0.7390 - val_accuracy: 0.7958 - val_precision_4: 0.7929 - val_recall_4: 0.7817\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.1863 - accuracy: 0.9390 - precision_4: 0.9409 - recall_4: 0.9343 - val_loss: 0.7083 - val_accuracy: 0.8169 - val_precision_4: 0.8222 - val_recall_4: 0.7817\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.1529 - accuracy: 0.9484 - precision_4: 0.9528 - recall_4: 0.9484 - val_loss: 0.7202 - val_accuracy: 0.8028 - val_precision_4: 0.8071 - val_recall_4: 0.7958\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.1391 - accuracy: 0.9460 - precision_4: 0.9527 - recall_4: 0.9460 - val_loss: 0.6936 - val_accuracy: 0.8099 - val_precision_4: 0.8188 - val_recall_4: 0.7958\n"
     ]
    }
   ],
   "source": [
    "#tmp_chekpoints= \"tmp\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "#csv_log = tf.keras.callbacks.CSVLogger(\"log.csv\", separator=',', append=False)\n",
    "csv_log = tf.keras.callbacks.CSVLogger(\"C:\\ML\\logs\\log.csv\", separator=',', append=False)\n",
    "\n",
    "#tb = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir='C:\\ML\\logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "chk= tf.keras.callbacks.ModelCheckpoint(tmp_chekpoints, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=200,batch_size=32, validation_data=(x_val,y_val),shuffle=False, verbose=2, callbacks=[csv_log,tb, chk])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.savefig(\"C:/ML/loss\"f\"{starttime}.png\")\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower right')\n",
    "pyplot.savefig(\"C:/ML/accuracy_\"f\"{starttime}.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit Example\n",
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png\" width=\"400\">\n",
    "\n",
    "#### Good Fit Example\n",
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-a-Good-Fit-for-a-Model.png\" width=\"400\">\n",
    "\n",
    "#### Overfit Example\n",
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "This may be a sign of too many training epochs.\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 - 0s - loss: 0.8799 - accuracy: 0.7465 - precision_4: 0.7591 - recall_4: 0.7324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8798884858547802, 0.74647886, 0.7591241, 0.73239434]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('./tmp/epoch49-0.90-0.39.hdf5')\n",
    "\n",
    "\n",
    "#bestmodel.evaluate(x=x_test, y=y_test, verbose=2)\n",
    "model.evaluate(x=x_test, y=y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel.save(\"sign_lang_recognition_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
