{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"./data/\"\n",
    "\n",
    "# Constant frame count.\n",
    "frames = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation Stage\n",
    "### Load data and normalize\n",
    "For training it's required to extend/reduce every dataset to n frames, where n is `frames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
    "data = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, frames)), fill_value=0.0)\n",
    "        content.fillna(0.0, inplace = True) \n",
    "        data.append((wordname, content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unser'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the content of the first dataframe\n",
    "data[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "Split the dataset up into the following segments:\n",
    "1. Training Data: 60%\n",
    "2. Validation Data: 20%\n",
    "3. Test Data: 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
   "execution_count": 4,
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Klassensätze\n",
      "Computer :  127;  Deutschland :  124;  Haben :  71;  Hallo :  123;  Mainz :  71;  Software :  70;  Welt :  123;  du :  71;  ich :  71;  unser :  71;  zeigen :  71;   \n",
      "Trainings Klassensätze\n",
      "Computer :  75;  Deutschland :  72;  Haben :  43;  Hallo :  79;  Mainz :  48;  Software :  44;  Welt :  73;  du :  37;  ich :  32;  unser :  50;  zeigen :  42;   \n",
      "Test Klassensätze\n",
      "Computer :  27;  Deutschland :  23;  Haben :  17;  Hallo :  23;  Mainz :  14;  Software :  14;  Welt :  23;  du :  10;  ich :  21;  unser :  11;  zeigen :  16;   \n",
      "Validation Klassensätze\n",
      "Computer :  25;  Deutschland :  29;  Haben :  11;  Hallo :  21;  Mainz :  9;  Software :  12;  Welt :  27;  du :  24;  ich :  18;  unser :  10;  zeigen :  13;   \n"
     ]
    }
   ],
      "Computer :  75;  Deutschland :  72;  Haben :  43;  Hallo :  79;  Mainz :  48;  Software :  44;  Welt :  73;  du :  37;  ich :  32;  unser :  50;  zeigen :  42;   \n",
      "Test Klassensätze\n",
      "Computer :  27;  Deutschland :  23;  Haben :  17;  Hallo :  23;  Mainz :  14;  Software :  14;  Welt :  23;  du :  10;  ich :  21;  unser :  11;  zeigen :  16;   \n",
      "Validation Klassensätze\n",
      "Computer :  25;  Deutschland :  29;  Haben :  11;  Hallo :  21;  Mainz :  9;  Software :  12;  Welt :  27;  du :  24;  ich :  18;  unser :  10;  zeigen :  13;   \n"
    "    for i in range(len(labels)):\n",
    "        print(labels[i], ': ', wortCounter[i], end =\";  \")\n",
    "    print(' ')\n",
    "        \n",
    "        \n",
    "print('Alle Klassensätze')\n",
    "printCountDataSets(labels)\n",
    "print('Trainings Klassensätze')\n",
    "printCountDataSets(y_train)\n",
    "print('Test Klassensätze')\n",
    "printCountDataSets(y_test) \n",
    "print('Validation Klassensätze')\n",
    "printCountDataSets(y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 993\n",
      "Training: 595 59.91943605236657\n",
      "Val: 199 20.040281973816718\n",
      "Test: 199 20.040281973816718\n"
     ]
    }
   ],
   "source": [
    "# Display data distribution\n",
   "execution_count": 7,
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize (One Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'deutschland': 2, 'du': 3, 'haben': 4, 'hallo': 5, 'ich': 6, 'mainz': 7, 'software': 8, 'unser': 9, 'welt': 10, 'zeigen': 11}\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tools.tokenize(dirname)\n",
   "execution_count": 8,
    "y_val = to_categorical(encoded_val)\n",
    "y_test = to_categorical(encoded_test)\n",
    "print(y_train)"
   ]
  },
  {
      "{'computer': 1, 'deutschland': 2, 'du': 3, 'haben': 4, 'hallo': 5, 'ich': 6, 'mainz': 7, 'software': 8, 'unser': 9, 'welt': 10, 'zeigen': 11}\n",
    "# Making numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_val=np.array(x_val)\n",
    "y_val=np.array(y_val)\n",
    "x_test=np.array(x_test)\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.464727  0.0802216 0.51021   ... 0.        0.        0.       ]\n",
      "  [0.468408  0.122253  0.420319  ... 0.        0.        0.       ]\n",
      "  [0.462211  0.117836  0.396451  ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.52613   0.302176  0.227828  ... 0.        0.        0.       ]\n",
      "  [0.527445  0.30221   0.239347  ... 0.        0.        0.       ]\n",
   "execution_count": 9,
      "\n",
      " [[0.46422   0.326161  0.792549  ... 0.72014   0.128272  0.738572 ]\n",
      "  [0.463434  0.327905  0.179201  ... 0.        0.        0.       ]\n",
      "  [0.4619    0.32941   0.230538  ... 0.707578  0.752394  0.718603 ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.450457  0.384537  0.631671  ... 0.        0.        0.       ]\n",
      "  [0.453716  0.383546  0.293156  ... 0.811655  0.644107  0.835152 ]\n",
      "  [0.456639  0.381632  0.293727  ... 0.8005    0.643448  0.832593 ]\n",
   "execution_count": 10,
      " [[0.485265  0.205642  0.155539  ... 0.        0.        0.       ]\n",
      "  [0.482153  0.23008   0.317113  ... 0.        0.        0.       ]\n",
      "  [0.48124   0.229325  0.311979  ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "[[[0.464727  0.0802216 0.51021   ... 0.        0.        0.       ]\n",
      "  [0.468408  0.122253  0.420319  ... 0.        0.        0.       ]\n",
      "  [0.462211  0.117836  0.396451  ... 0.        0.        0.       ]\n",
     ]
    }
   ],
   "source": [
    "print(x_train)"
      " [[0.52613   0.302176  0.227828  ... 0.        0.        0.       ]\n",
      "  [0.527445  0.30221   0.239347  ... 0.        0.        0.       ]\n",
      "  [0.518558  0.316052  0.257128  ... 0.        0.        0.       ]\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
      " [[0.46422   0.326161  0.792549  ... 0.72014   0.128272  0.738572 ]\n",
      "  [0.463434  0.327905  0.179201  ... 0.        0.        0.       ]\n",
      "  [0.4619    0.32941   0.230538  ... 0.707578  0.752394  0.718603 ]\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
      " [[0.450457  0.384537  0.631671  ... 0.        0.        0.       ]\n",
      "  [0.453716  0.383546  0.293156  ... 0.811655  0.644107  0.835152 ]\n",
      "  [0.456639  0.381632  0.293727  ... 0.8005    0.643448  0.832593 ]\n",
    "model.add(layers.LSTM(256, return_sequences=True,\n",
    "               input_shape=(100, 86)))\n",
    "model.add(layers.LSTM(64, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(layers.LSTM(32))  # return a single vector of dimension 32\n",
    "#model.add(layers.LSTM(16))  # return a single vector of dimension 32\n",
      " [[0.485265  0.205642  0.155539  ... 0.        0.        0.       ]\n",
      "  [0.482153  0.23008   0.317113  ... 0.        0.        0.       ]\n",
      "  [0.48124   0.229325  0.311979  ... 0.        0.        0.       ]\n",
   "source": [
    "### or\n",
    "#### Bidirectional LSTM"
   ]
  },
      " [[0.434708  0.419858  0.260987  ... 0.        0.        0.       ]\n",
      "  [0.434479  0.419663  0.264854  ... 0.        0.        0.       ]\n",
      "  [0.434403  0.419045  0.24722   ... 0.        0.        0.       ]\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or\n",
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, input_shape=(200, 42)))\n",
    "model.add(Dense(64, activation=\"softmax\")) #softmax, linear 어떤걸 기준으로 하지\n",
    "model.add(Dense(128, activation=\"linear\")) #softmax, linear 어떤걸 기준으로 하지\n",
    "model.add(Dense(21))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595 samples, validate on 199 samples\n",
   "execution_count": 11,
      "595/595 [==============================] - 1s 974us/sample - loss: 2.3784 - accuracy: 0.1328 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3862 - val_accuracy: 0.1055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 2.3789 - accuracy: 0.1479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3723 - val_accuracy: 0.1256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "595/595 [==============================] - 1s 966us/sample - loss: 2.3531 - accuracy: 0.1563 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2930 - val_accuracy: 0.2010 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "595/595 [==============================] - 1s 973us/sample - loss: 2.2484 - accuracy: 0.2202 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1766 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 2.0672 - accuracy: 0.2487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0525 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "595/595 [==============================] - 1s 970us/sample - loss: 1.9951 - accuracy: 0.2387 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0276 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "595/595 [==============================] - 1s 977us/sample - loss: 1.9746 - accuracy: 0.2538 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0000 - val_accuracy: 0.2764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 2.1146 - accuracy: 0.2370 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9819 - val_accuracy: 0.2513 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.9299 - accuracy: 0.2555 - precision: 0.7188 - recall: 0.0387 - val_loss: 2.0109 - val_accuracy: 0.1658 - val_precision: 1.0000 - val_recall: 0.0101\n",
      "Epoch 12/80\n",
      "595/595 [==============================] - 1s 994us/sample - loss: 1.9582 - accuracy: 0.2655 - precision: 0.7419 - recall: 0.0773 - val_loss: 2.0180 - val_accuracy: 0.2060 - val_precision: 0.9167 - val_recall: 0.0553\n",
      "Epoch 13/80\n",
      "595/595 [==============================] - 1s 981us/sample - loss: 1.8765 - accuracy: 0.2824 - precision: 0.6395 - recall: 0.0924 - val_loss: 2.0319 - val_accuracy: 0.1910 - val_precision: 1.0000 - val_recall: 0.0101\n",
      "Epoch 14/80\n",
      "595/595 [==============================] - 1s 963us/sample - loss: 1.9028 - accuracy: 0.2941 - precision: 0.7619 - recall: 0.0807 - val_loss: 1.9158 - val_accuracy: 0.2764 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 15/80\n",
      "595/595 [==============================] - 1s 972us/sample - loss: 1.8096 - accuracy: 0.3277 - precision: 0.6761 - recall: 0.0807 - val_loss: 1.9398 - val_accuracy: 0.2412 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 16/80\n",
      "595/595 [==============================] - 1s 976us/sample - loss: 1.8095 - accuracy: 0.3210 - precision: 0.6706 - recall: 0.0958 - val_loss: 1.8717 - val_accuracy: 0.2814 - val_precision: 0.7586 - val_recall: 0.1106\n",
      "Epoch 17/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 1.8357 - accuracy: 0.2958 - precision: 0.6322 - recall: 0.0924 - val_loss: 1.9553 - val_accuracy: 0.2161 - val_precision: 0.6429 - val_recall: 0.0905\n",
      "Epoch 18/80\n",
      "595/595 [==============================] - 1s 992us/sample - loss: 1.7918 - accuracy: 0.3277 - precision: 0.6220 - recall: 0.0857 - val_loss: 1.8528 - val_accuracy: 0.2714 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 19/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7914 - accuracy: 0.3277 - precision: 0.6885 - recall: 0.0706 - val_loss: 1.8544 - val_accuracy: 0.2613 - val_precision: 0.9333 - val_recall: 0.0704\n",
      "Epoch 20/80\n",
      "595/595 [==============================] - 1s 985us/sample - loss: 1.7763 - accuracy: 0.3277 - precision: 0.7636 - recall: 0.0706 - val_loss: 1.8665 - val_accuracy: 0.2814 - val_precision: 0.9444 - val_recall: 0.0854\n",
      "Epoch 21/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7715 - accuracy: 0.3126 - precision: 0.7636 - recall: 0.0706 - val_loss: 1.8191 - val_accuracy: 0.2915 - val_precision: 0.8750 - val_recall: 0.0704\n",
      "Epoch 22/80\n",
      "595/595 [==============================] - 1s 954us/sample - loss: 1.7485 - accuracy: 0.3328 - precision: 0.8077 - recall: 0.0706 - val_loss: 1.8512 - val_accuracy: 0.2714 - val_precision: 0.9375 - val_recall: 0.0754\n",
      "Epoch 23/80\n",
      "595/595 [==============================] - 1s 972us/sample - loss: 1.7364 - accuracy: 0.3227 - precision: 0.7458 - recall: 0.0739 - val_loss: 1.8531 - val_accuracy: 0.2915 - val_precision: 0.8000 - val_recall: 0.0804\n",
      "Epoch 24/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7331 - accuracy: 0.3445 - precision: 0.7843 - recall: 0.0672 - val_loss: 1.8296 - val_accuracy: 0.2714 - val_precision: 0.7619 - val_recall: 0.0804\n",
      "Epoch 25/80\n",
      "595/595 [==============================] - 1s 987us/sample - loss: 1.7487 - accuracy: 0.3277 - precision: 0.7042 - recall: 0.0840 - val_loss: 1.8320 - val_accuracy: 0.3467 - val_precision: 0.8235 - val_recall: 0.0704\n",
      "Epoch 26/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.7208 - accuracy: 0.3496 - precision: 0.8136 - recall: 0.0807 - val_loss: 1.8095 - val_accuracy: 0.3015 - val_precision: 0.9412 - val_recall: 0.0804\n",
      "Epoch 27/80\n",
      "595/595 [==============================] - 1s 954us/sample - loss: 1.6966 - accuracy: 0.3546 - precision: 0.8519 - recall: 0.0773 - val_loss: 1.8078 - val_accuracy: 0.3518 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 28/80\n",
      "595/595 [==============================] - 1s 957us/sample - loss: 1.6882 - accuracy: 0.3630 - precision: 0.8060 - recall: 0.0908 - val_loss: 1.7944 - val_accuracy: 0.3869 - val_precision: 0.8636 - val_recall: 0.0955\n",
      "Epoch 29/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.6631 - accuracy: 0.4000 - precision: 0.7215 - recall: 0.0958 - val_loss: 1.7806 - val_accuracy: 0.3367 - val_precision: 0.7742 - val_recall: 0.1206\n",
      "Epoch 30/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.6911 - accuracy: 0.3849 - precision: 0.7179 - recall: 0.0941 - val_loss: 1.7028 - val_accuracy: 0.4070 - val_precision: 0.9524 - val_recall: 0.1005\n",
      "Epoch 31/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.6722 - accuracy: 0.3748 - precision: 0.7500 - recall: 0.0958 - val_loss: 1.7209 - val_accuracy: 0.4221 - val_precision: 0.9444 - val_recall: 0.0854\n",
      "Epoch 32/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.6910 - accuracy: 0.3882 - precision: 0.7463 - recall: 0.0840 - val_loss: 1.7507 - val_accuracy: 0.3568 - val_precision: 0.7857 - val_recall: 0.1106\n",
      "Epoch 33/80\n",
      "595/595 [==============================] - 1s 993us/sample - loss: 1.7406 - accuracy: 0.3261 - precision: 0.7045 - recall: 0.1042 - val_loss: 1.8178 - val_accuracy: 0.3166 - val_precision: 0.8667 - val_recall: 0.0653\n",
      "Epoch 34/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.7835 - accuracy: 0.3412 - precision: 0.7191 - recall: 0.1076 - val_loss: 1.7182 - val_accuracy: 0.4623 - val_precision: 0.7500 - val_recall: 0.0905\n",
      "Epoch 35/80\n",
      "595/595 [==============================] - 1s 959us/sample - loss: 1.6342 - accuracy: 0.4050 - precision: 0.7595 - recall: 0.1008 - val_loss: 1.6660 - val_accuracy: 0.4573 - val_precision: 0.8889 - val_recall: 0.1206\n"
     ]
    },
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595 samples, validate on 199 samples\n",
      "Epoch 1/80\n",
      "595/595 [==============================] - 9s 15ms/sample - loss: 2.4722 - accuracy: 0.1311 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3984 - val_accuracy: 0.1256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "595/595 [==============================] - 1s 986us/sample - loss: 2.3901 - accuracy: 0.1361 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3849 - val_accuracy: 0.1256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "595/595 [==============================] - 1s 974us/sample - loss: 2.3784 - accuracy: 0.1328 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3862 - val_accuracy: 0.1055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 2.3789 - accuracy: 0.1479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3723 - val_accuracy: 0.1256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "595/595 [==============================] - 1s 966us/sample - loss: 2.3531 - accuracy: 0.1563 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2930 - val_accuracy: 0.2010 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "595/595 [==============================] - 1s 973us/sample - loss: 2.2484 - accuracy: 0.2202 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1766 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 2.0672 - accuracy: 0.2487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0525 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "595/595 [==============================] - 1s 970us/sample - loss: 1.9951 - accuracy: 0.2387 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0276 - val_accuracy: 0.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "595/595 [==============================] - 1s 977us/sample - loss: 1.9746 - accuracy: 0.2538 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0000 - val_accuracy: 0.2764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 2.1146 - accuracy: 0.2370 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9819 - val_accuracy: 0.2513 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.9299 - accuracy: 0.2555 - precision: 0.7188 - recall: 0.0387 - val_loss: 2.0109 - val_accuracy: 0.1658 - val_precision: 1.0000 - val_recall: 0.0101\n",
      "Epoch 12/80\n",
      "595/595 [==============================] - 1s 994us/sample - loss: 1.9582 - accuracy: 0.2655 - precision: 0.7419 - recall: 0.0773 - val_loss: 2.0180 - val_accuracy: 0.2060 - val_precision: 0.9167 - val_recall: 0.0553\n",
      "Epoch 13/80\n",
      "595/595 [==============================] - 1s 981us/sample - loss: 1.8765 - accuracy: 0.2824 - precision: 0.6395 - recall: 0.0924 - val_loss: 2.0319 - val_accuracy: 0.1910 - val_precision: 1.0000 - val_recall: 0.0101\n",
      "Epoch 14/80\n",
      "595/595 [==============================] - 1s 963us/sample - loss: 1.9028 - accuracy: 0.2941 - precision: 0.7619 - recall: 0.0807 - val_loss: 1.9158 - val_accuracy: 0.2764 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 15/80\n",
      "595/595 [==============================] - 1s 972us/sample - loss: 1.8096 - accuracy: 0.3277 - precision: 0.6761 - recall: 0.0807 - val_loss: 1.9398 - val_accuracy: 0.2412 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 16/80\n",
      "595/595 [==============================] - 1s 976us/sample - loss: 1.8095 - accuracy: 0.3210 - precision: 0.6706 - recall: 0.0958 - val_loss: 1.8717 - val_accuracy: 0.2814 - val_precision: 0.7586 - val_recall: 0.1106\n",
      "Epoch 17/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 1.8357 - accuracy: 0.2958 - precision: 0.6322 - recall: 0.0924 - val_loss: 1.9553 - val_accuracy: 0.2161 - val_precision: 0.6429 - val_recall: 0.0905\n",
      "Epoch 18/80\n",
      "595/595 [==============================] - 1s 992us/sample - loss: 1.7918 - accuracy: 0.3277 - precision: 0.6220 - recall: 0.0857 - val_loss: 1.8528 - val_accuracy: 0.2714 - val_precision: 0.9286 - val_recall: 0.0653\n",
      "Epoch 19/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7914 - accuracy: 0.3277 - precision: 0.6885 - recall: 0.0706 - val_loss: 1.8544 - val_accuracy: 0.2613 - val_precision: 0.9333 - val_recall: 0.0704\n",
      "Epoch 20/80\n",
      "595/595 [==============================] - 1s 985us/sample - loss: 1.7763 - accuracy: 0.3277 - precision: 0.7636 - recall: 0.0706 - val_loss: 1.8665 - val_accuracy: 0.2814 - val_precision: 0.9444 - val_recall: 0.0854\n",
      "Epoch 21/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7715 - accuracy: 0.3126 - precision: 0.7636 - recall: 0.0706 - val_loss: 1.8191 - val_accuracy: 0.2915 - val_precision: 0.8750 - val_recall: 0.0704\n",
      "Epoch 22/80\n",
      "595/595 [==============================] - 1s 954us/sample - loss: 1.7485 - accuracy: 0.3328 - precision: 0.8077 - recall: 0.0706 - val_loss: 1.8512 - val_accuracy: 0.2714 - val_precision: 0.9375 - val_recall: 0.0754\n",
      "Epoch 23/80\n",
      "595/595 [==============================] - 1s 972us/sample - loss: 1.7364 - accuracy: 0.3227 - precision: 0.7458 - recall: 0.0739 - val_loss: 1.8531 - val_accuracy: 0.2915 - val_precision: 0.8000 - val_recall: 0.0804\n",
      "Epoch 24/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.7331 - accuracy: 0.3445 - precision: 0.7843 - recall: 0.0672 - val_loss: 1.8296 - val_accuracy: 0.2714 - val_precision: 0.7619 - val_recall: 0.0804\n",
      "Epoch 25/80\n",
      "595/595 [==============================] - 1s 987us/sample - loss: 1.7487 - accuracy: 0.3277 - precision: 0.7042 - recall: 0.0840 - val_loss: 1.8320 - val_accuracy: 0.3467 - val_precision: 0.8235 - val_recall: 0.0704\n",
      "Epoch 26/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.7208 - accuracy: 0.3496 - precision: 0.8136 - recall: 0.0807 - val_loss: 1.8095 - val_accuracy: 0.3015 - val_precision: 0.9412 - val_recall: 0.0804\n",
      "Epoch 27/80\n",
      "595/595 [==============================] - 1s 954us/sample - loss: 1.6966 - accuracy: 0.3546 - precision: 0.8519 - recall: 0.0773 - val_loss: 1.8078 - val_accuracy: 0.3518 - val_precision: 1.0000 - val_recall: 0.0704\n",
      "Epoch 28/80\n",
      "595/595 [==============================] - 1s 957us/sample - loss: 1.6882 - accuracy: 0.3630 - precision: 0.8060 - recall: 0.0908 - val_loss: 1.7944 - val_accuracy: 0.3869 - val_precision: 0.8636 - val_recall: 0.0955\n",
      "Epoch 29/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.6631 - accuracy: 0.4000 - precision: 0.7215 - recall: 0.0958 - val_loss: 1.7806 - val_accuracy: 0.3367 - val_precision: 0.7742 - val_recall: 0.1206\n",
      "Epoch 30/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.6911 - accuracy: 0.3849 - precision: 0.7179 - recall: 0.0941 - val_loss: 1.7028 - val_accuracy: 0.4070 - val_precision: 0.9524 - val_recall: 0.1005\n",
      "Epoch 31/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.6722 - accuracy: 0.3748 - precision: 0.7500 - recall: 0.0958 - val_loss: 1.7209 - val_accuracy: 0.4221 - val_precision: 0.9444 - val_recall: 0.0854\n",
      "Epoch 32/80\n",
      "595/595 [==============================] - 1s 965us/sample - loss: 1.6910 - accuracy: 0.3882 - precision: 0.7463 - recall: 0.0840 - val_loss: 1.7507 - val_accuracy: 0.3568 - val_precision: 0.7857 - val_recall: 0.1106\n",
      "Epoch 33/80\n",
      "595/595 [==============================] - 1s 993us/sample - loss: 1.7406 - accuracy: 0.3261 - precision: 0.7045 - recall: 0.1042 - val_loss: 1.8178 - val_accuracy: 0.3166 - val_precision: 0.8667 - val_recall: 0.0653\n",
      "Epoch 34/80\n",
      "595/595 [==============================] - 1s 964us/sample - loss: 1.7835 - accuracy: 0.3412 - precision: 0.7191 - recall: 0.1076 - val_loss: 1.7182 - val_accuracy: 0.4623 - val_precision: 0.7500 - val_recall: 0.0905\n",
      "Epoch 35/80\n",
      "595/595 [==============================] - 1s 959us/sample - loss: 1.6342 - accuracy: 0.4050 - precision: 0.7595 - recall: 0.1008 - val_loss: 1.6660 - val_accuracy: 0.4573 - val_precision: 0.8889 - val_recall: 0.1206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/80\n",
      "595/595 [==============================] - 1s 1ms/sample - loss: 1.6443 - accuracy: 0.3950 - precision: 0.7158 - recall: 0.1143 - val_loss: 1.6603 - val_accuracy: 0.4523 - val_precision: 0.8000 - val_recall: 0.1206\n",
      "Epoch 37/80\n",
      "595/595 [==============================] - 1s 1ms/sample - loss: 1.6530 - accuracy: 0.4067 - precision: 0.6900 - recall: 0.1160 - val_loss: 1.6594 - val_accuracy: 0.4472 - val_precision: 0.9048 - val_recall: 0.0955\n",
      "Epoch 38/80\n",
      "595/595 [==============================] - 1s 973us/sample - loss: 1.5771 - accuracy: 0.4235 - precision: 0.7447 - recall: 0.1176 - val_loss: 1.6277 - val_accuracy: 0.4422 - val_precision: 0.7576 - val_recall: 0.2513\n",
      "Epoch 39/80\n",
      "595/595 [==============================] - 1s 989us/sample - loss: 1.5986 - accuracy: 0.4101 - precision: 0.7214 - recall: 0.1697 - val_loss: 1.6423 - val_accuracy: 0.4271 - val_precision: 0.9400 - val_recall: 0.2362\n",
      "Epoch 40/80\n",
      "595/595 [==============================] - 1s 983us/sample - loss: 1.5328 - accuracy: 0.4286 - precision: 0.7550 - recall: 0.1916 - val_loss: 1.5968 - val_accuracy: 0.4221 - val_precision: 0.8095 - val_recall: 0.2563\n",
      "Epoch 41/80\n",
      "595/595 [==============================] - 1s 1ms/sample - loss: 1.5296 - accuracy: 0.4336 - precision: 0.7571 - recall: 0.2252 - val_loss: 1.7700 - val_accuracy: 0.4121 - val_precision: 0.5146 - val_recall: 0.2663\n",
      "Epoch 42/80\n",
      "595/595 [==============================] - 1s 1ms/sample - loss: 1.5219 - accuracy: 0.4336 - precision: 0.7487 - recall: 0.2353 - val_loss: 1.5463 - val_accuracy: 0.4422 - val_precision: 0.8667 - val_recall: 0.2613\n",
      "Epoch 43/80\n",
      "595/595 [==============================] - 1s 985us/sample - loss: 1.4561 - accuracy: 0.4521 - precision: 0.8118 - recall: 0.2319 - val_loss: 1.5158 - val_accuracy: 0.4523 - val_precision: 0.8525 - val_recall: 0.2613\n",
      "Epoch 44/80\n",
      "595/595 [==============================] - 1s 982us/sample - loss: 1.4536 - accuracy: 0.4471 - precision: 0.8452 - recall: 0.2202 - val_loss: 1.4651 - val_accuracy: 0.4874 - val_precision: 0.8689 - val_recall: 0.2663\n",
      "Epoch 45/80\n",
      "595/595 [==============================] - 1s 991us/sample - loss: 1.4247 - accuracy: 0.4756 - precision: 0.7964 - recall: 0.2235 - val_loss: 1.5145 - val_accuracy: 0.4724 - val_precision: 0.8361 - val_recall: 0.2563\n",
      "Epoch 46/80\n",
      "595/595 [==============================] - 1s 978us/sample - loss: 1.4101 - accuracy: 0.4672 - precision: 0.8129 - recall: 0.2336 - val_loss: 1.5132 - val_accuracy: 0.4573 - val_precision: 0.9057 - val_recall: 0.2412\n",
      "Epoch 47/80\n",
      "595/595 [==============================] - 1s 967us/sample - loss: 1.3739 - accuracy: 0.4908 - precision: 0.7819 - recall: 0.2471 - val_loss: 1.4281 - val_accuracy: 0.5276 - val_precision: 0.8205 - val_recall: 0.3216\n",
      "Epoch 48/80\n",
      "595/595 [==============================] - 1s 966us/sample - loss: 1.3540 - accuracy: 0.5126 - precision: 0.8145 - recall: 0.3025 - val_loss: 1.4090 - val_accuracy: 0.4824 - val_precision: 0.8852 - val_recall: 0.2714\n",
      "Epoch 49/80\n",
      "595/595 [==============================] - 1s 986us/sample - loss: 1.3118 - accuracy: 0.4958 - precision: 0.7920 - recall: 0.3008 - val_loss: 1.3461 - val_accuracy: 0.4975 - val_precision: 0.8391 - val_recall: 0.3668\n",
      "Epoch 50/80\n",
      "595/595 [==============================] - 1s 977us/sample - loss: 1.3228 - accuracy: 0.5143 - precision: 0.7490 - recall: 0.3160 - val_loss: 1.3316 - val_accuracy: 0.5276 - val_precision: 0.8372 - val_recall: 0.3618\n",
      "Epoch 51/80\n",
      "595/595 [==============================] - 1s 967us/sample - loss: 1.3024 - accuracy: 0.5193 - precision: 0.7220 - recall: 0.2924 - val_loss: 1.5144 - val_accuracy: 0.4523 - val_precision: 0.8769 - val_recall: 0.2864\n",
      "Epoch 52/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 1.2460 - accuracy: 0.5395 - precision: 0.8128 - recall: 0.3210 - val_loss: 1.3311 - val_accuracy: 0.5377 - val_precision: 0.8391 - val_recall: 0.3668\n",
      "Epoch 53/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.3039 - accuracy: 0.5176 - precision: 0.7886 - recall: 0.3261 - val_loss: 1.4394 - val_accuracy: 0.4774 - val_precision: 0.7761 - val_recall: 0.2613\n",
      "Epoch 54/80\n",
      "595/595 [==============================] - 1s 980us/sample - loss: 1.2275 - accuracy: 0.5529 - precision: 0.8067 - recall: 0.3227 - val_loss: 1.1864 - val_accuracy: 0.5628 - val_precision: 0.8315 - val_recall: 0.3719\n",
      "Epoch 55/80\n",
      "595/595 [==============================] - 1s 972us/sample - loss: 1.1902 - accuracy: 0.5445 - precision: 0.7790 - recall: 0.3496 - val_loss: 1.1877 - val_accuracy: 0.5729 - val_precision: 0.8280 - val_recall: 0.3869\n",
      "Epoch 56/80\n",
      "595/595 [==============================] - 1s 979us/sample - loss: 1.1889 - accuracy: 0.5462 - precision: 0.7912 - recall: 0.3630 - val_loss: 1.2037 - val_accuracy: 0.5578 - val_precision: 0.8495 - val_recall: 0.3970\n",
      "Epoch 57/80\n",
      "595/595 [==============================] - 1s 979us/sample - loss: 1.1504 - accuracy: 0.5899 - precision: 0.8216 - recall: 0.3714 - val_loss: 1.1973 - val_accuracy: 0.5528 - val_precision: 0.7570 - val_recall: 0.4070\n",
      "Epoch 58/80\n",
      "595/595 [==============================] - 1s 992us/sample - loss: 1.1631 - accuracy: 0.5798 - precision: 0.7936 - recall: 0.3748 - val_loss: 1.2416 - val_accuracy: 0.5427 - val_precision: 0.7570 - val_recall: 0.4070\n",
      "Epoch 59/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 1.0385 - accuracy: 0.6000 - precision: 0.7848 - recall: 0.4353 - val_loss: 1.0510 - val_accuracy: 0.5879 - val_precision: 0.8571 - val_recall: 0.4221\n",
      "Epoch 60/80\n",
      "595/595 [==============================] - 1s 989us/sample - loss: 1.0511 - accuracy: 0.5815 - precision: 0.7734 - recall: 0.4303 - val_loss: 1.2237 - val_accuracy: 0.5528 - val_precision: 0.8462 - val_recall: 0.3317\n",
      "Epoch 61/80\n",
      "595/595 [==============================] - 1s 1000us/sample - loss: 1.1474 - accuracy: 0.5916 - precision: 0.8106 - recall: 0.3597 - val_loss: 1.1730 - val_accuracy: 0.5628 - val_precision: 0.8421 - val_recall: 0.4020\n",
      "Epoch 62/80\n",
      "595/595 [==============================] - 1s 987us/sample - loss: 1.0748 - accuracy: 0.6034 - precision: 0.8108 - recall: 0.4034 - val_loss: 1.2169 - val_accuracy: 0.5729 - val_precision: 0.7822 - val_recall: 0.3970\n",
      "Epoch 63/80\n",
      "595/595 [==============================] - 1s 980us/sample - loss: 1.3802 - accuracy: 0.4857 - precision: 0.8130 - recall: 0.3143 - val_loss: 1.4251 - val_accuracy: 0.4623 - val_precision: 0.8228 - val_recall: 0.3266\n",
      "Epoch 64/80\n",
      "595/595 [==============================] - 1s 978us/sample - loss: 1.3038 - accuracy: 0.5345 - precision: 0.7645 - recall: 0.3109 - val_loss: 1.3786 - val_accuracy: 0.5075 - val_precision: 0.8904 - val_recall: 0.3266\n",
      "Epoch 65/80\n",
      "595/595 [==============================] - 1s 984us/sample - loss: 1.1767 - accuracy: 0.5983 - precision: 0.7792 - recall: 0.4151 - val_loss: 1.1121 - val_accuracy: 0.5628 - val_precision: 0.8587 - val_recall: 0.3970\n",
      "Epoch 66/80\n",
      "595/595 [==============================] - 1s 987us/sample - loss: 1.0107 - accuracy: 0.6303 - precision: 0.7957 - recall: 0.4387 - val_loss: 1.0552 - val_accuracy: 0.6131 - val_precision: 0.8020 - val_recall: 0.4070\n",
      "Epoch 67/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 1.0352 - accuracy: 0.6101 - precision: 0.7778 - recall: 0.4235 - val_loss: 1.0850 - val_accuracy: 0.5829 - val_precision: 0.7810 - val_recall: 0.4121\n",
      "Epoch 68/80\n",
      "595/595 [==============================] - 1s 978us/sample - loss: 0.9668 - accuracy: 0.6471 - precision: 0.8288 - recall: 0.4639 - val_loss: 1.1087 - val_accuracy: 0.5879 - val_precision: 0.8273 - val_recall: 0.4573\n",
      "Epoch 69/80\n",
      "595/595 [==============================] - 1s 986us/sample - loss: 1.0083 - accuracy: 0.6286 - precision: 0.7890 - recall: 0.4840 - val_loss: 1.1981 - val_accuracy: 0.5276 - val_precision: 0.8667 - val_recall: 0.3920\n",
      "Epoch 70/80\n",
      "595/595 [==============================] - 1s 980us/sample - loss: 0.9147 - accuracy: 0.6622 - precision: 0.8258 - recall: 0.4622 - val_loss: 0.9985 - val_accuracy: 0.6382 - val_precision: 0.8454 - val_recall: 0.4121\n",
      "Epoch 71/80\n",
      "595/595 [==============================] - 1s 989us/sample - loss: 0.8987 - accuracy: 0.6655 - precision: 0.8237 - recall: 0.4790 - val_loss: 1.0217 - val_accuracy: 0.6131 - val_precision: 0.8000 - val_recall: 0.4221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "595/595 [==============================] - 1s 993us/sample - loss: 0.8755 - accuracy: 0.6706 - precision: 0.8199 - recall: 0.4975 - val_loss: 0.9778 - val_accuracy: 0.6533 - val_precision: 0.8125 - val_recall: 0.4573\n",
      "Epoch 73/80\n",
      "595/595 [==============================] - 1s 974us/sample - loss: 0.9387 - accuracy: 0.6487 - precision: 0.8022 - recall: 0.4975 - val_loss: 1.0083 - val_accuracy: 0.6633 - val_precision: 0.8276 - val_recall: 0.4824\n",
      "Epoch 74/80\n",
      "595/595 [==============================] - 1s 969us/sample - loss: 0.8094 - accuracy: 0.7160 - precision: 0.8249 - recall: 0.5462 - val_loss: 1.0084 - val_accuracy: 0.6432 - val_precision: 0.8070 - val_recall: 0.4623\n",
      "Epoch 75/80\n",
      "595/595 [==============================] - 1s 966us/sample - loss: 0.9268 - accuracy: 0.6756 - precision: 0.8368 - recall: 0.5429 - val_loss: 1.0650 - val_accuracy: 0.6131 - val_precision: 0.6825 - val_recall: 0.4322\n",
      "Epoch 76/80\n",
      "595/595 [==============================] - 1s 986us/sample - loss: 0.8541 - accuracy: 0.6891 - precision: 0.7981 - recall: 0.5647 - val_loss: 1.0430 - val_accuracy: 0.6131 - val_precision: 0.7177 - val_recall: 0.4472\n",
      "Epoch 77/80\n",
      "595/595 [==============================] - 1s 968us/sample - loss: 0.8338 - accuracy: 0.6958 - precision: 0.7894 - recall: 0.5731 - val_loss: 0.8976 - val_accuracy: 0.6482 - val_precision: 0.8074 - val_recall: 0.5477\n",
      "Epoch 78/80\n",
      "595/595 [==============================] - 1s 970us/sample - loss: 0.9119 - accuracy: 0.6790 - precision: 0.7956 - recall: 0.5429 - val_loss: 0.9418 - val_accuracy: 0.6784 - val_precision: 0.7984 - val_recall: 0.4975\n",
      "Epoch 79/80\n",
      "595/595 [==============================] - 1s 966us/sample - loss: 0.8390 - accuracy: 0.6908 - precision: 0.8135 - recall: 0.5277 - val_loss: 0.9817 - val_accuracy: 0.6784 - val_precision: 0.8231 - val_recall: 0.5377\n",
      "Epoch 80/80\n",
      "595/595 [==============================] - 1s 971us/sample - loss: 0.8074 - accuracy: 0.7176 - precision: 0.8234 - recall: 0.5798 - val_loss: 1.0254 - val_accuracy: 0.6231 - val_precision: 0.7795 - val_recall: 0.4975\n"
      "text/plain": [
       "[1.1315479850649235, 0.5829146, 0.71875, 0.46231157]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sign_lang_recognition.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
